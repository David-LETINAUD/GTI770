{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 : Arbre de désision, Bayes naïf et KNN\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2019                                            |\n",
    "| Groupe                | 1                                                       |\n",
    "| Numéro du laboratoire | 2                                                       |\n",
    "| Professeur            | Prof. LOMBAERT                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 27/10/2019                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Au cours de ce second laboratoire, nous allons étudier l’utilisation de trois algorithmes de classification. Nous utiliserons les arbres de décision comme vu précédemment, Bayes naïf et les K plus proches voisins (KNN). Nous allons aborder deux problèmes : la classification des galaxies ansi que la classification des courriels indésirables.\n",
    "Afin de classer les galaxies en « spirales » ou « smooth », nous allons nous appuyer sur deux nouveaux algorithmes (Bayes naïf et KNN) ainsi que des prétraitements de données adaptées (MinMaxScaler). Dans le deuxième cas nous utiliserons également ces deux nouveaux algorithmes et ajouterons un cas de prétraitement supplémentaire (Discrétisation non-supervisée).\n",
    "Enfin nous appliquerons le concept de validation croisée (cross-validation) et nous le comparerons à la validation holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Méthode de création des ensembles de données\n",
    "Pour éviter de recalculer plusieurs fois les features, il peut être plus efficace de les enregistrer pour pouvoir les réutiliser par la suite. On va par exemple enregistrer les features utilisées dans le TP1 dans un fichier csv. Pour cela, on utilise la bibliothèque 'csv' et on ouvre un fichier en écriture. On utilisera ensuite la fonction 'writerows' pour écrire dans ce fichier une list en format compatible csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "\n",
    "import csv\n",
    "from color import crop_center\n",
    "from main_functions import  FeaturesProcess"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = \"/home/ens/AQ38840/Desktop/data/data/csv/galaxy/galaxy_label_data_set.csv\"\n",
    "dataset_path = \"/home/alex/Desktop/GTI770-tp2/csv/galaxy/galaxy_feature_vectors.csv\"\n",
    "#image_path = \"/home/ens/AQ38840/Desktop/data/data/images/\"\n",
    "image_path = \"/home/alex/Desktop/GTI770-tp2/csv/images/\"\n",
    "# Fichier de sortie\n",
    "TP1_features_path = \"/home/alex/Desktop/GTI770-tp2/csv/galaxy/TP1_features.csv\"\n",
    "mail_data_path=\"/home/alex/Desktop/GTI770-tp2/csv/spam/spam.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "[Errno 2] No such file or directory: '/home/alex/Desktop/GTI770-tp2/csv/images/8.309560000000000000e+05.jpg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-694b5dd6f36e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0ml_CSV\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# Lecture et rognage de l'image\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcrop_center\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mimage_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mligne\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\".jpg\"\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcrop_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFeaturesProcess\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_center_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfft_threshold\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbp_calibration\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/_io.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, as_gray, plugin, flatten, **plugin_args)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mfile_or_url_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_plugin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'imread'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplugin\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mplugin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mplugin_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'ndim'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/manage_plugins.pyc\u001b[0m in \u001b[0;36mcall_plugin\u001b[0;34m(kind, *args, **kwargs)\u001b[0m\n\u001b[1;32m    212\u001b[0m                                (plugin, kind))\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 214\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    215\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    216\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/skimage/io/_plugins/pil_plugin.pyc\u001b[0m in \u001b[0;36mimread\u001b[0;34m(fname, dtype, img_num, **kwargs)\u001b[0m\n\u001b[1;32m     33\u001b[0m     \"\"\"\n\u001b[1;32m     34\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 35\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     36\u001b[0m             \u001b[0mim\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpil_to_ndarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mimg_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: [Errno 2] No such file or directory: '/home/alex/Desktop/GTI770-tp2/csv/images/8.309560000000000000e+05.jpg'"
     ]
    }
   ],
   "source": [
    "# Taille de rognage de l'image\n",
    "crop_size = 180\n",
    "\n",
    "TP1_feat_lignes = []\n",
    "\n",
    "# Hyperaramètres de chaque features determinées au TP1\n",
    "fft_threshold = 140\n",
    "color_center_size = 18\n",
    "bp_calibration = [100,50]\n",
    "  \n",
    "########################################   Lecture   ########################################\n",
    "# Lecture du fichier CSV\n",
    "with open(dataset_path) as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    next(f_csv) # On passe la 1ere ligne d'entête\n",
    "    \n",
    "    # Lecture ligne par ligne\n",
    "    for ligne in f_csv:#,i in zip(f_csv,range(nb_img)):\n",
    "        l_CSV = []\n",
    "        # Lecture et rognage de l'image\n",
    "        image = crop_center(io.imread( image_path + ligne[0] + \".jpg\" ),crop_size,crop_size)\n",
    "        X = FeaturesProcess(image, color_center_size, fft_threshold, bp_calibration)\n",
    "\n",
    "        l_CSV.append(ligne[0])   # numéro d'image\n",
    "        l_CSV.append(str(X[0]))  # feature 1\n",
    "        l_CSV.append(str(X[1]))  # feature 2  \n",
    "        l_CSV.append(str(X[2]))  # feature 3\n",
    "        l_CSV.append(str(1 * (ligne[1]==\"spiral\"))) # classe de l'image\n",
    "        TP1_feat_lignes.append(l_CSV)\n",
    "\n",
    "f.close()\n",
    "########################################   Ecriture   ########################################\n",
    "print(TP1_feat_lignes)\n",
    "with open(TP1_features_path, 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(TP1_feat_lignes)\n",
    "    writeFile.close()\n",
    "    \n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Détails des ensembles produits\n",
    "L'ensemble de données ainsi produit contient toutes les informations utiles pour de l'apprentissage supervisée et sont disposées de cette façon :\n",
    "['numero_image', 'feature_1','feature_2','feature_3', 'classe_image']\n",
    "\n",
    "Le fichier TP1_features.csv sera ainsi utilisé pour compléter les features contenu dans le fichiers 'galaxy_feature_vectors.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### Approche de validation proposée et justification\n",
    "Nous allons ici utiliser 3 approches de classification différentes (arbre de décision, Bayes naïf et KNN) pour traiter des mails et des images.\n",
    "\n",
    "Pour valider et comparer l'efficacité des modèles nous utiliserons la précision en combinaison avec le F1-score.\n",
    "\n",
    "La précision mesure quelle proportion de bonne classification. Elle permet de savoir immédiatement si un modèle est correctement entraîné et comment il peut fonctionner en général. Toutefois, il ne donne pas d'informations détaillées concernant son application au problème, c'est pour cela qu'on le combine avec le F1 score.\n",
    "\n",
    "F1 score est une mesure globale de la précision d'un modèle de classification binaire, qui combine précision et rappel. La précision répond à la question : Quelle proportion d'identifications positives était effectivement correcte ? alors que le Rappel (ou sensitivité) : Quelle proportion de résultats positifs réels a été identifiée correctement ?\n",
    "Un bon F1 score signifie que le modèle prédit peu de faux positifs et peu de faux négatifs. Le F1 score est considéré comme parfait lorsqu'il est de 1, alors que le modèle est un échec total lorsqu'il est de 0.\n",
    "\n",
    "Nous avons utilisé la méthode de validation holdout (split stratify) qui est la plus simple et la plus rapide pour tester les algorithmes de classification. Stratify nous permet de garder la même répartition des données dans les données de tests et d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Matrice des expérimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Étude des hyperparamètres et des modèles\n",
    "Pour choisir les meilleurs hyperparamètres des différents modèles nous allons mesurer les performances de prédiction pour chaque valeur des hyperparamètres.\n",
    "\n",
    "Pour ce faire, nous allons entraîner chaque modèle avec 100% du dataset. La méthode de validation holdout nous permet de le faire. Chaque modèle est entrainé successivement avec des valeurs d'hyperparamètres compris dans un intervalle choisi judicieusement. La précision et le F1-score sont à chaque fois sauvegardés dans une matrice. On pourra ainsi choisir les hyperparamètres qui donne les meilleures performances au modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name plot_tree",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-956e821ff50d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mmain_functions\u001b[0m \u001b[0;32mimport\u001b[0m  \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mTree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecision_tree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mKnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mKNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mBayes\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mbayes_gaussian_noProcess\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_mutltinomial_scaleData\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbayes_multinomial_kbinDiscretization\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/alex/Desktop/GTI770-master(5)/GTI770-master/GTI770_Laboratoire2_-_BLEA14058906_LETD05129708_LIOT20069605/Tree.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtree\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDecisionTreeClassifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplot_tree\u001b[0m  \u001b[0;31m# Import Decision Tree Classifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0msklearn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name plot_tree"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "from main_functions import  *\n",
    "\n",
    "from Tree import decision_tree\n",
    "from Knn import KNN\n",
    "from Bayes import bayes_gaussian_noProcess, bayes_mutltinomial_scaleData, bayes_multinomial_kbinDiscretization\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################   Initialisations   ########################################\n",
    "#dataset_path = \"/home/ens/AQ38840/Desktop/data/data/csv/galaxy/galaxy_feature_vectors.csv\"\n",
    "TP1_features_path = \"/home/ens/AQ38840/Desktop/data/data/csv/galaxy/TP1_features.csv\"\n",
    "#dataset_path = \"/home/alex/Desktop/GTI770-tp2/csv/galaxy/galaxy_feature_vectors.csv\"\n",
    "TP1_features_path = \"/home/alex/Desktop/GTI770-tp2/csv/galaxy/TP1_features.csv\"\n",
    "mail_data_path=\"/home/alex/Desktop/GTI770-tp2/csv/spam/spam.csv\"\n",
    "# Nombre d'images total du dataset (training + testing)\n",
    "nb_img = 16000\n",
    "nb_mail=3000\n",
    "# Pourcentage de données utilisées pour l'entrainement\n",
    "ratio_train = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-c1d28fff6356>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# Recuperation des numéros des images dans l'ordre généré par le TP1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mTP1_features_list_np\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTP1_features_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0;31m# Lecture ligne par ligne\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "X=[]\n",
    "Y=[]\n",
    "\n",
    "########################################   Lecture   ########################################\n",
    "# Lecture du fichier CSV\n",
    "with open(dataset_path, 'r') as f:\n",
    "    with open(TP1_features_path, 'r') as f_TP1:\n",
    "        TP1_features_list = list(csv.reader(f_TP1, delimiter=','))\n",
    "        features_list = list(csv.reader(f, delimiter=','))\n",
    "\n",
    "        # Recuperation des numéros des images dans l'ordre généré par le TP1\n",
    "        TP1_features_list_np = np.array(TP1_features_list)[:,0]\n",
    "\n",
    "        # Lecture ligne par ligne\n",
    "        for c in range(nb_img):\n",
    "            features = [float(i) for i in features_list[0][1:75]]\n",
    "\n",
    "            num_img = str(int(float(features_list[0][0])))\n",
    "\n",
    "            try :\n",
    "                # Cherche l'index de l'image num_img dans TP1_features_list\n",
    "                # pour faire correspondre les features du TP1 avec les nouveaux features\n",
    "                index = np.where(TP1_features_list_np==num_img)[0]\n",
    "\n",
    "                features_TP1 = [float(i) for i in TP1_features_list[index[0]][1:4]]\n",
    "\n",
    "                # concatenation des features\n",
    "                features = features_TP1 + features\n",
    "\n",
    "                galaxy_class = int(float(features_list[0][75]))\n",
    "\n",
    "                X.append(features)\n",
    "                Y.append(galaxy_class)\n",
    "            except :\n",
    "                print(\"Image {} not find\".format(num_img) )\n",
    "\n",
    "            features_list.pop(0)\n",
    "            #print(type(features),type(galaxy_class))\n",
    "\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=ratio_train,random_state=1, stratify=Y)  # 80% training and 20% test\n",
    "\n",
    "Y_train = np.array(Y_train)\n",
    "Y_test = np.array(Y_test)\n",
    "\n",
    "\n",
    "X_mail=[]\n",
    "Y_mail=[]  \n",
    "    \n",
    "########################################   Lecture Spam   ######################################## \n",
    "with open(mail_data_path, 'r') as f:\n",
    "    mail_features_list = list(csv.reader(f, delimiter=','))\n",
    "\n",
    "\n",
    "    # Lecture ligne par ligne                                                                                                                                                        \n",
    "    for c in range(nb_mail):\n",
    "        mail_features = [float(i) for i in mail_features_list[0][0:57]]\n",
    "        mail_class = int(float( mail_features_list[0][57]))\n",
    "        mail_features_list.pop(0)\n",
    "                                                                                                                                   \n",
    "\n",
    "        X_mail.append(mail_features)\n",
    "        Y_mail.append(mail_class)\n",
    "        #print(X_mail)\n",
    "        #print(\"--------------Ymail--------------\")\n",
    "        #print( Y_mail)\n",
    "        \n",
    "############## FIN LECTURE SPAM #########################            \n",
    "        \n",
    "########################################   Separation mail   ######################################## \n",
    "X_mail_train, X_mail_test, Y_mail_train, Y_mail_test = train_test_split(X_mail, Y_mail, train_size=ratio_train, random_state=1) # 70% training and 30% test\n",
    "Y_mail_train = np.array(Y_mail_train)\n",
    "Y_mail_test = np.array(Y_mail_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Puisque le dataset des galaxies est grand et assez bien équilibré, l'option 'stratify' n'est pas forcemment très utile mais le sera pour le dataset des courriels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d441036ff4cf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Etendu de test des hyperparamètres\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlist_zt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlist_K\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlist_nbins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Etendu de test des hyperparamètres\n",
    "list_zt = [None, 3, 5, 10, 30, 50]\n",
    "list_K = np.arange(1, 50, 2)\n",
    "\n",
    "list_nbins = np.arange(3, 15, 1)\n",
    "list_var_smoothing = [i for i in np.linspace(1e-11, 1e-8, 10)]  # On fait varier l'hyperparamètre pour le\n",
    "list_scaler = [i for i in np.linspace(0.2, 3, 10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decision_tree' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1a598ec556be>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calcul de la meilleure profondeur de l'arbre de décision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_hyper_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecision_tree\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_zt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"zoo_tree :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best acc :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best f1 : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decision_tree' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcul de la meilleure profondeur de l'arbre de décision \n",
    "max_acc, max_f1, elem_acc, elem_f1, x_plot, acc_plot, f1_plot = best_hyper_param(decision_tree,X_train, X_test, Y_train, Y_test, list_zt)\n",
    "print(\"zoo_tree :\")\n",
    "print(\"    Best acc :\", max_acc, elem_acc)\n",
    "print(\"    Best f1 : \", max_f1, elem_f1)\n",
    "plot_hyper_param( x_plot, acc_plot, f1_plot, \"Profondeur TREE\")\n",
    "\n",
    "\n",
    "# Calcul de la meilleure profondeur de l'arbre de décision pour les spam \n",
    "max_acc_mail, max_f1_mail, elem_acc_mail, elem_f1_mail, x_plot_mail, acc_plot_mail, f1_plot_mail = best_hyper_param(decision_tree,X_mail_train, X_mail_test, Y_mail_train, Y_mail_test, list_zt)\n",
    "print(\"zoo_tree mail:\")\n",
    "print(\"    Best acc_mail :\", max_acc_mail, elem_acc_mail)\n",
    "print(\"    Best f1_mail : \", max_f1_mail, elem_f1_mail)\n",
    "plot_hyper_param( x_plot_mail, acc_plot_mail, f1_plot_mail, \"Profondeur TREE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'KNN' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-16ecfe4e26df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calcul du meilleur nombre de voisins K\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_hyper_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mKNN\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_K\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"KNN :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best acc :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best f1 : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'KNN' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcul du meilleur nombre de voisins K\n",
    "max_acc, max_f1, elem_acc, elem_f1, x_plot, acc_plot, f1_plot = best_hyper_param(KNN,X_train, X_test, Y_train, Y_test, list_K)\n",
    "print(\"KNN :\")\n",
    "print(\"    Best acc :\", max_acc, elem_acc)\n",
    "print(\"    Best f1 : \", max_f1, elem_f1)\n",
    "plot_hyper_param( x_plot, acc_plot, f1_plot, \"K\")\n",
    "# Calcul du meilleur nombre de voisins K pour les mail \n",
    "max_acc_mail, max_f1_mail, elem_acc_mail, elem_f1_mail, x_plot_mail, acc_plot_mail, f1_plot_mail = best_hyper_param(KNN,X_mail_train, X_mail_test, Y_mail_train, Y_mail_test, list_K)\n",
    "print(\"KNN_mail :\")\n",
    "print(\"    Best acc_mail :\", max_acc_mail, elem_acc_mail)\n",
    "print(\"    Best f1_mail : \", max_f1_mail, elem_f1_mail)\n",
    "plot_hyper_param( x_plot_mail, acc_plot_mail, f1_plot_mail, \"K\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cas, l'évolution de la précision de KNN en fonction de K est assez surprenante. En effet, on s'attendait plutôt que la précision chute avec l'augmentation de K. QU'EST-CE QUI EST A REVOIR!!!!!?????"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bayes_gaussian_noProcess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-54b1b4a51146>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calcul du meilleur var_smooth\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_hyper_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes_gaussian_noProcess\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_var_smoothing\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bayes gauss no process :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best acc :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best f1 : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bayes_gaussian_noProcess' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcul du meilleur var_smooth\n",
    "max_acc, max_f1, elem_acc, elem_f1, x_plot, acc_plot, f1_plot = best_hyper_param(bayes_gaussian_noProcess,X_train, X_test, Y_train, Y_test, list_var_smoothing)\n",
    "print(\"Bayes gauss no process :\")\n",
    "print(\"    Best acc :\", max_acc, elem_acc)\n",
    "print(\"    Best f1 : \", max_f1, elem_f1)\n",
    "plot_hyper_param( x_plot, acc_plot, f1_plot, \"var_smooth\")\n",
    "# Calcul du meilleur var pour les mail \n",
    "max_acc_mail, max_f1_mail, elem_acc_mail, elem_f1_mail, x_plot_mail, acc_plot_mail, f1_plot_mail = best_hyper_param(bayes_gaussian_noProcess,X_mail_train, X_mail_test, Y_mail_train, Y_mail_test, list_var_smoothing)\n",
    "print(\"Bayes gauss no process mail :\")\n",
    "print(\"    Best acc_mail :\", max_acc_mail, elem_acc_mail)\n",
    "print(\"    Best f1_mail : \", max_f1_mail, elem_f1_mail)\n",
    "plot_hyper_param( x_plot_mail, acc_plot_mail, f1_plot_mail, \"var_smooth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bayes_mutltinomial_scaleData' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-69779488dccb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calcul du meilleur scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_hyper_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes_mutltinomial_scaleData\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_scaler\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bayes multinomial scale :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best acc :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best f1 : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bayes_mutltinomial_scaleData' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcul du meilleur scale\n",
    "max_acc, max_f1, elem_acc, elem_f1, x_plot, acc_plot, f1_plot = best_hyper_param(bayes_mutltinomial_scaleData,X_train, X_test, Y_train, Y_test, list_scaler)\n",
    "print(\"Bayes multinomial scale :\")\n",
    "print(\"    Best acc :\", max_acc, elem_acc)\n",
    "print(\"    Best f1 : \", max_f1, elem_f1)\n",
    "plot_hyper_param( x_plot, acc_plot, f1_plot, \"scale\")\n",
    "\n",
    "# Calcul du meilleur scale mail\n",
    "max_acc_mail, max_f1_mail, elem_acc_mail, elem_f1_mail, x_plot_mail, acc_plot_mail, f1_plot_mail = best_hyper_param(bayes_mutltinomial_scaleData,X_mail_train, X_mail_test, Y_mail_train, Y_mail_test, list_scaler)\n",
    "print(\"Bayes multinomial scale :\")\n",
    "print(\"    Best acc_mail :\", max_acc_mail, elem_acc_mail)\n",
    "print(\"    Best f1_mail : \", max_f1_mail, elem_f1_mail)\n",
    "plot_hyper_param( x_plot_mail, acc_plot_mail, f1_plot_mail, \"scale\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bayes_multinomial_kbinDiscretization' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-e17607f14938>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Calcul du meilleur nbins\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macc_plot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf1_plot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_hyper_param\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbayes_multinomial_kbinDiscretization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist_nbins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Bayes Discretization :\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best acc :\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_acc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"    Best f1 : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_f1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0melem_f1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'bayes_multinomial_kbinDiscretization' is not defined"
     ]
    }
   ],
   "source": [
    "# Calcul du meilleur nbins\n",
    "max_acc, max_f1, elem_acc, elem_f1, x_plot, acc_plot, f1_plot = best_hyper_param(bayes_multinomial_kbinDiscretization,X_train, X_test, Y_train, Y_test, list_nbins)\n",
    "print(\"Bayes Discretization :\")\n",
    "print(\"    Best acc :\", max_acc, elem_acc)\n",
    "print(\"    Best f1 : \", max_f1, elem_f1)\n",
    "plot_hyper_param( x_plot, acc_plot, f1_plot, \"nbins\")\n",
    "# Calcul du meilleur nbins mail\n",
    "max_acc_mail, max_f1_mail, elem_acc_mail, elem_f1_mail, x_plot_mail, acc_plot_mail, f1_plot_mail = best_hyper_param(bayes_multinomial_kbinDiscretization,X_mail_train, X_mail_test, Y_mail_train, Y_mail_test, list_nbins)\n",
    "print(\"Bayes Discretization mail:\")\n",
    "print(\"    Best acc_mail :\", max_acc_mail, elem_acc_mail)\n",
    "print(\"    Best f1_mail : \", max_f1_mail, elem_f1_mail)\n",
    "plot_hyper_param( x_plot_mail, acc_plot_mail, f1_plot_mail, \"nbins\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut ainsi faire une étude similaire dans le cas du dataset des courriels.\n",
    "Il faut toutefois faire attention ici, le dataset est plutôt restreint et les données ne sont pas également réparties. L'option 'Stratify' est donc importante, nous verifierons son bon fonctionnement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut vérifier que l'option 'stratify' fonctionne bien comme voulue :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "den_train = np.size(Y_mail_train)\n",
    "den_test = np.size(Y_mail_test)\n",
    "num_train = np.size(np.where(Y_mail_train ==0))\n",
    "num_test = np.size(np.where(Y_mail_test ==0))\n",
    "print(num_train/den_train, num_test/den_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Les ratios sont quasi-identiques, le jeu de donnée est donc correctement balancé entre X_train et X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Impact de la taille des ensembles de données sur la performance de classification\n",
    "Plus l'ensemble de données est grand et plus le modèle est efficace. Si on utilise un trop petit nombre d'échantillons pour entraîner un modèle, il risque de ne pas être très performant lors de la prédiction. En effet, il est probable que le nombre d'échantillons atypiques soit sur-représentés.\n",
    "\n",
    "Toutefois, la méthode de cross validation s'avère plus efficace quand il s'agit de traiter des petits ensembles de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Impact du bruit dans les ensembles de données sur la performance de classification\n",
    "Dans un ensemble de données, le bruit peu diminuer les performances d'un modèle. Il est important de prendre un nombre d'échantillons assez grand pour éviter d'entraîner un modèle avec un nombre d'échantillons atypiques trop grand par rapport aux autres.\n",
    "\n",
    "Toutefois, le bruit peut avoir des impacts différents sur certains modèles. Les arbres de décision sont peu robuste face aux bruits des données. On peut aussi prendre comme exemple KNN. Plus le bruit est important plus il est préférable d'augmenter l'hyperparamètre K (nombre de voisins) pour lisser l'effet du bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Discussion sur la nature des données\n",
    "\n",
    "Comme nous l'avons évoqué précédemment, les galaxies sont équitablement réparties entre \"smooth\" et \"spiral\". En ce sens, ces proportions sont gardées dans les données de test et d'entrainement en utilisant la méthode \"hold out\". Ceci améliore donc la précision de notre étude. Par ailleurs, afin d'augmenter les performances de nos systèmes d'apprentissage, nous avons également utilisé différents prétraitements.\n",
    "\n",
    "- Scale Data : permet de normaliser toutes les valeurs numériques des features dans un intervalle donné.\n",
    "\n",
    "- K-bins discretizer : permet de ranger les valeurs suivant plusieurs intervalles. \n",
    "\n",
    "La composition du dataset des pourriels est tout autre. En effet, nous avons un ratio se rapprochant de 60% de pourriels et 40% de mails valides. Nous avons donc du utliser la méthode \"stratify\" afin de nous rapprocher d'une répartition de équitable dans le dataset. Nous pouvons donc utiliser la méthode hold out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "### Recommandations\n",
    "L'amélioration que nous pourrions apporter se trouve dans la méthode utilisée (hold out) lors de l'étude des meilleurs paramètres. Nous avons donc utilisé la méthode hold out car celle-ci est la moins coûteuse en terme de ressources comparativement à LOOCV et k-fold CV. L'idéal aurait été de faire l'étude des meilleurs paramètres avec la méthode LOOCV ainsi que les tests sur nos données. L'erreur sur les l'ensemble des données de test et d'apprentissage sont réduites au maximum et améliore l'apprentissage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "### Améliorations possibles\n",
    "Dans ce lab, nous avons exploré 3 types de modèles, mais un autre modèle pourrait peut-être être plus performant dans notre cas. On pourrait tester un plus grand nombre de modèles comme par exemple un réseau de neurones ou des SVM. \n",
    "Par ailleurs, il serait judicieux d'augmenter le nombre d'échantillons du dataset des mails et faire en sorte que le nombre de spams soit environ égale à celui des mails. On pourrait par exemple utiliser des techniques d'augmentation de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Au cours de ce laboratoire nous avons vu différents modèles d'apprentissage machine ainsi que deux méthodes d'apprentissage (hold out et K-fold CV). Les modèles que nous avons étudier sont sujet ou non à des prétraitements. Ces derniers peuvent améliorer la qualité de l'apprentissage. Par ailleurs, nous avons donc pu observer que la méthode K-fold rendait l'apprentissage plus efficace mais demandait davantage de ressources comparée à la méthode hold out sur les mêmes caractéristiques de modèle. Il est donc nécessaire pour un ingénieur de savoir utiliser l'ensemble de ces modèles et méthodes d'apprentissage afin de retirer le meilleur compromis pour les applications visées."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
