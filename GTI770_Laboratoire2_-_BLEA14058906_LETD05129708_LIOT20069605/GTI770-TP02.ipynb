{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 2 : Arbre de désision, Bayes naïf et KNN\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2019                                            |\n",
    "| Groupe                | 1                                                       |\n",
    "| Numéro du laboratoire | 2                                                       |\n",
    "| Professeur            | Prof. LOMBAERT                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 27/10/2019                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "Au cours de ce second laboratoire, nous allons étudier l’utilisation de trois algorithmes de classification. Nous utiliserons les arbres de décision comme vu précédemment, Bayes naïf et les K plus proches voisins (KNN). Nous allons aborder deux problèmes : la classification des galaxies ansi que la classification des courriels indésirables.\n",
    "Afin de classer les galaxies en « spirales » ou « smooth », nous allons nous appuyer sur deux nouveaux algorithmes (Bayes naïf et KNN) ainsi que des prétraitements de données adaptées (MinMaxScaler). Dans le deuxième cas nous utiliserons également ces deux nouveaux algorithmes et ajouterons un cas de prétraitement supplémentaire (Discrétisation non-supervisée).\n",
    "Enfin nous appliquerons le concept de validation croisée (cross-validation) et nous le comparerons à la validation holdout."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_path = \"/home/ens/AQ38840/Desktop/data/data/csv/galaxy/galaxy_label_data_set.csv\"\n",
    "image_path = \"/home/ens/AQ38840/Desktop/data/data/images/\"\n",
    "# Fichier de sortie\n",
    "TP1_features_path = \"/home/ens/AQ38840/Desktop/data/data/csv/galaxy/TP1_features.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-83fe594449e9>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-1-83fe594449e9>\"\u001b[1;36m, line \u001b[1;32m1\u001b[0m\n\u001b[1;33m    python TP1_features.py\u001b[0m\n\u001b[1;37m                      ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Taille de rognage de l'image\n",
    "crop_size = 180\n",
    "\n",
    "TP1_feat_lignes = []\n",
    "\n",
    "# Paramètres de chaque features determinees au TP1\n",
    "fft_threshold = 140\n",
    "color_center_size = 18\n",
    "bp_calibration = [100,50]\n",
    "\n",
    "def FeaturesProcess(img,cs_color,th_fft,nr_binaryPattern):\n",
    "    \"\"\"\n",
    "    Fonction qui permet le calcul de chaque features d'img\n",
    "    \n",
    "    input :\n",
    "        img (ndarray) : image quelconque\n",
    "        cs_color (int) : taille du centre de l'image à prendre en compte pour calculer la moyenne du niveau de gris\n",
    "        th_fft (int) : seuil à partir duquel on prend en compte les fréquences (strictement positif)\n",
    "        nr_binaryPattern ([int,int]) : \n",
    "                    nr_binaryPattern[0] : nombre de points à prendre en compte sur le périmètre du cercle\n",
    "                    nr_binaryPattern[1] : taille du rayon du cercle\n",
    "    output : \n",
    "        (list) retourne la liste des features calculées\n",
    "    \n",
    "    \"\"\"\n",
    "    Features = []\n",
    "\n",
    "    # Calculs des Features\n",
    "    f_c = center_color(img,cs_color)\n",
    "    f_fft = fourier_transform(img,th_fft)\n",
    "    f_bp = binaryPatterns(img,nr_binaryPattern[0],nr_binaryPattern[1])  \n",
    "\n",
    "    Features.append(f_c)   \n",
    "    Features.append(f_fft)\n",
    "    Features.append(f_bp)\n",
    "\n",
    "    # Retourne les features calculés\n",
    "    return Features    \n",
    "\n",
    "########################################   Lecture   ########################################\n",
    "# Lecture du fichier CSV\n",
    "with open(dataset_path) as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    next(f_csv) # On passe la 1ere ligne d'entête\n",
    "    \n",
    "    # Lecture ligne par ligne\n",
    "    for ligne in f_csv:#,i in zip(f_csv,range(nb_img)):\n",
    "        l_CSV = []\n",
    "        # Lecture et rognage de l'image\n",
    "        image = crop_center(io.imread( image_path + ligne[0] + \".jpg\" ),crop_size,crop_size)\n",
    "        X = FeaturesProcess(image, color_center_size, fft_threshold, bp_calibration)\n",
    "        l_CSV.append(ligne[0])   # numéro d'image\n",
    "        l_CSV.append(str(X[0]))  # feature 1\n",
    "        l_CSV.append(str(X[1]))  # feature 2  \n",
    "        l_CSV.append(str(X[2]))  # feature 3\n",
    "        l_CSV.append(str(1 * (ligne[1]==\"spiral\"))) # classe de l'image\n",
    "        TP1_feat_lignes.append(l_CSV)\n",
    "\n",
    "f.close()\n",
    "########################################   Ecriture   ########################################\n",
    "print(TP1_feat_lignes)\n",
    "with open(TP1_features_path, 'w') as writeFile:\n",
    "    writer = csv.writer(writeFile)\n",
    "    writer.writerows(TP1_feat_lignes)\n",
    "    writeFile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1\n",
    "### Détails des ensembles produits\n",
    "L'ensemble de données ainsi produit contient toutes les informations utiles pour de l'apprentissage supervisée et sont disposées de cette façon :\n",
    "['numero_image', 'feature_1','feature_2','feature_3', 'classe_image']\n",
    "\n",
    "Le fichier TP1_features.csv sera ainsi utilisé pour compléter les features contenu dans le fichiers 'galaxy_feature_vectors.csv'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2\n",
    "### Approche de validation proposée et justification\n",
    "Nous allons ici utiliser 3 approches de classification différentes (arbre de décision, Bayes naïf et KNN) pour traiter des mails et des images.\n",
    "\n",
    "Pour valider et comparer l'efficacité des modèle nous utiliserons la précision en combinaison avec le F1-score.\n",
    "\n",
    "La précision mesure quelle proportion de bonne classification. Elle permet de savoir immédiatement si un modèle est correctement entraîné et comment il peut fonctionner en général. Toutefois, il ne donne pas d'informations détaillées concernant son application au problème, c'est pour cela qu'on le combine avec le F1 score.\n",
    "\n",
    "F1 score est une mesure globale de la précision d'un modèle de classification binaire, qui combine précision et rappel. La précision répond à la question : Quelle proportion d'identifications positives était effectivement correcte ? alors que le Rappel (ou sensitivité) : Quelle proportion de résultats positifs réels a été identifiée correctement ?\n",
    "Un bon F1 score signifie que le modèle prédit peu de faux positifs et peu de faux négatifs. Le F1 score est considéré comme parfait lorsqu'il est de 1, alors que le modèle est un échec total lorsqu'il est de 0.\n",
    "\n",
    "Nous avons utilisé la méthode de validation holdout (split stratify) qui est la plus simple et la plus rapide pour tester les algorithmes de classification. Stratify nous permet de garder la même répartition des données dans les données de tests et d'entrainement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Matrice des expérimentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Étude des hyperparamètres et des modèles\n",
    "Pour choisir les meilleurs hyperparamètres des différents modèles nous allons mesurer les performances de prédiction chaque valeur des hyperparamètres.\n",
    "\n",
    "Pour ce faire, nous allons entraîner chaque modèle avec 100% du dataset. La méthode de validation holdout nous permet de le faire. Chaque modèle est entrainé successivement avec des valeurs d'hyperparamètres compris dans un intervalle choisi judicieusement. La précision et le F1-score sont à chaque fois sauvegardés dans une matrice. On pourra ainsi choisir les hyperparamètres qui donne les meilleures performances au modèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Impact de la taille des ensembles de données sur la performance de classification\n",
    "Plus l'ensemble de données est grand et plus le modèle est efficace. Si on utilise un trop petit nombre d'échantillons pour entraîner un modèle, il risque de ne pas être très performant lors de la prédiction. En effet, il est probable que le nombre d'échantillons atypiques soient sur-représentés.\n",
    "Toutefois, de part le fonctionnement de la cross-validation, cette méthode s'avère plus efficace quand il s'agit de traiter des petits ensembles de données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Impact du bruit dans les ensembles de données sur la performance de classification\n",
    "Dans un ensemble de données, le bruit peu diminuer les performances d'un modèle. Il est important de prendre un nombre d'échantillons assez grand pour éviter d'entraîner un modèle avec un nombre d'échantillons atypiques trop grand par rapport aux autres.\n",
    "Toutefois, le bruit peu avoir des impacts différents sur certains modèles. On peut prendre comme exemple KNN. Plus le bruit est important plus il est préférable d'augmenter l'hyperparamètre K (nombre de voisins) pour lisser l'effet du bruit."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Discussion sur la nature des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7\n",
    "### Recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 8\n",
    "### Améliorations possibles\n",
    "Dans ce lab, nous avons exploré 3 types de modèles, mais un autre modèle pourrait peut-être être plus performant dans notre cas. On pourrait tester un plus grand nombre de modèles comme par exemple un réseau de neurones ou des SVM. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "Ici, le problème de base était la classification de mail et d'images. Toutefois, pour obtenir les meilleurs résultats, cela soulève plusieurs problématiques. Il a été par exemple utile de tester plusieurs types de modèles pour être capable de choisir celui qui performe le mieux. D'autre part, l'analyse de performances a également été cruciale. Il a été nécessaire d'étudier les hyperparamètres qui donnent les meilleurs résultats."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
