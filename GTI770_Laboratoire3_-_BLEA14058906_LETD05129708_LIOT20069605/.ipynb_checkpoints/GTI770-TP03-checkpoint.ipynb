{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Laboratoire 3 : Machines à vecteur de support et réseaux neuronaux\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2019                                            |\n",
    "| Groupe                | 1                                                       |\n",
    "| Numéro du laboratoire | 3                                                       |\n",
    "| Professeur            | Prof. LOMBAERT                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 18/11/2019                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Au cours de ce troisième laboratoire, nous allons étudier deux nouveaux algorithmes d'apprentissage supervisé pour résoudre le problème de classification des galaxies : les réseaux neuronaux et les machines à vecteurs de support (SVM). \n",
    "Nous allons également apprendre à utiliser la librairie tensorflow en association avec tensorboard pour pouvoir visualiser en temps réel l'évolution de l'apprentissage du réseau de neurones.\n",
    "Dans un premier temps, nous allons concevoir un modèle de réseaux neuronaux basé sur le Multi-Layer Perceptron. Nous entrainerons ce modèle afin qu'il puisse classer les galaxies en \"smooth\" ou \"spiral\" en utilisant l'ensemble des primitives. Nous utiliserons le module keras de Google tensorflow.\n",
    "Le deuxième modèle d'apprentissage s'appuie sur un modèle d'optimisation convexe dans le cas du SVM. Dans ce cas, nous n'utiliserons qu'une partie des primitives proposées qui seront couplées à nos primitives développées lors du premier laboratoire.\n",
    "\n",
    "Nous étudierons notamment l'influence des hyperparamètres de ces deux méthodes afin de proposer le modèle le plus optimal dans le cas de notre problème de classification de galaxies. Nous verrons également l'impact de la taille du dataset sur les performances des modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 1\n",
    "\n",
    "Dans le cas des réseaux neuronaux, l'utilisation d'une méthode de validation croisée prendrait beaucoup de temps. En effet, il faudrait répéter plusieurs tests avec un nombre \"d'epochs\" conséquent : ceci serait très chronophage. Nous avons donc décidé d'utiliser la méthode de validation hold-out avec 80% de données d'entrainement et 20% de test.\n",
    "\n",
    "Concernant le modèle SVM, nous utilisons la méthode de cross validation avec 5 groupes de données (cv=5). Contrairement à Hold-out, la validation croisée effectue plusieurs cycles de validation pour réduire la variabilité. Ainsi, la validation croisée à l'avantage de combiner les mesures de l'aptitude à la prédiction pour obtenir une estimation plus précise de la performance de prédiction du modèle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 2\n",
    "\n",
    "Nous normalisons nos données grâce à la méthode \"normalize\" de la librairie preprocessing. La normalisation se fait par rapport à la valeur maximale. Nous avons décidé de normaliser les primitives indépendamment les unes des autres (axis = 0). Par ailleurs, nous avons remarqué avec nos premiers tests que les performances étaient meilleures si l'on normalise par rapport à la valeur maximale (norm = 'max').\n",
    "\n",
    "Cette fonction est utilisée dans la procédure \"get_data()\" dans functions.py de la manière suivante :\n",
    "\n",
    "X = preprocessing.normalize(X, norm='max',axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 3\n",
    "\n",
    "Nous allons d'abord utiliser un réseau neuronal de type \"multilayer perceptron\" (MLP).\n",
    "Celui-ci se compose notamment d'une couche d'entrée, une de sortie et d'une ou plusieurs couches cachées. Ce type de réseau de neurones apprend à classifier par une succession de calculs matriciels qu'on appelle propagation et rétropropagation, ces 2 étapes constituent une epoch. \n",
    "Ce modèle possède plusieurs hyperparamètres notamment:\n",
    ". Le nombre de couches cachées\n",
    ". Le nombre de perceptrons sur les couches cachées\n",
    ". Le nombre d'itérations (epochs)\n",
    ". Le taux d'apprentissage (learning rate)\n",
    "\"Dropout\" est également un paramètre important. En effet, celui-ci permet de réduire le surapprentissage d'un réseau neuronal en supprimant temporairement des neurones pendant l'entrainement pour être ensuite réactivé dans la phase de test. Dans notre cas, ce paramètre sera fixé à 0.5 pour les couches cachées. C'est-à-dire qu'on laisse une probabilité de 0.5 de retenir la sortie de chaque noeud.\n",
    "\n",
    "En machine learning, la fonction coût d'un réseau neuronal mesure la \"distance\" entre la valeur prédite et la valeur réelle. Ici, la fonction de coût que nous avons choisie est \"Binary Cross-Entropy Loss\". En effet, nous avons choisi cette fonction, car nos valeurs cibles sont binaires, soit \"smooth\" ou \"spiral\".\n",
    "\n",
    "\n",
    "La principale contrainte du modèle MLP est de trouver un compromis entre le temps d'apprentissage et la précision. La première architecture proposée par l'énoncé est de trois couches cachées : 100, 100, 2 (nombre de perceptrons), 60 epochs et un learning rate de 0.0005. Nous avons étudié différents cas avec 60 epochs :  \n",
    "1 - l'influence du nombre de perceptrons avec un nombre de couches fixé.  \n",
    "2 - l'influence du nombre de couches avec le même nombre de perceptrons par couche.  \n",
    "3 - l'influence du learning rate.\n",
    "\n",
    "Pour la méthode MLP, les algorithmes ont été executés sur un ordinateur avec les caractéristiques suivantes :\n",
    "\n",
    "Memoire : 8 Go 1600 MHz DDR3\n",
    "Processor : 2,6 GHz Intel Core i5 \n",
    "Graphics : Intel Iris 1536 Mo  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from RN_model import *\n",
    "from functions import get_data , plot_perf, plot_delay\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.callbacks import TensorBoard # Pour affichage sur tensorboard\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import and normalize data\n",
    "X_train, X_test, Y_train, Y_test = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialisations\n",
    "layer_sizes = [100, 100, 2]\n",
    "epochs = 60\n",
    "learning_rate = 0.0005\n",
    "batch_size = 100\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "# Pour affichage\n",
    "sub_title = ['loss','acc','f1','val_loss','val_acc', 'val_f1']\n",
    "x_lab = \"epochs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Voici donc nos résultats avec différentes structures de réseaux de neurones :\n",
    "\n",
    "1 - Influence du nombre de perceptrons:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing to delete\n",
      "WARNING:tensorflow:From /Users/thomas/anaconda3/envs/gti770/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /Users/thomas/anaconda3/envs/gti770/lib/python3.7/site-packages/tensorflow/python/ops/nn_impl.py:180: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 2s 181us/sample - loss: 0.6938 - acc: 0.5214 - f1: 0.6650 - val_loss: 0.6923 - val_acc: 0.5203 - val_f1: 0.6832\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.6826 - acc: 0.5452 - f1: 0.6795 - val_loss: 0.6775 - val_acc: 0.5344 - val_f1: 0.6890\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 53us/sample - loss: 0.6546 - acc: 0.5924 - f1: 0.7021 - val_loss: 0.5886 - val_acc: 0.8775 - val_f1: 0.8851\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 53us/sample - loss: 0.6283 - acc: 0.5998 - f1: 0.7032 - val_loss: 0.5254 - val_acc: 0.8809 - val_f1: 0.8841\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.6034 - acc: 0.6141 - f1: 0.7125 - val_loss: 0.5096 - val_acc: 0.8772 - val_f1: 0.8917\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.5828 - acc: 0.6958 - f1: 0.7362 - val_loss: 0.4612 - val_acc: 0.9091 - val_f1: 0.9148\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.5686 - acc: 0.7251 - f1: 0.7537 - val_loss: 0.4153 - val_acc: 0.9187 - val_f1: 0.9227\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.5586 - acc: 0.7273 - f1: 0.7551 - val_loss: 0.4080 - val_acc: 0.9234 - val_f1: 0.9273\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 71us/sample - loss: 0.5477 - acc: 0.7482 - f1: 0.7727 - val_loss: 0.3740 - val_acc: 0.9319 - val_f1: 0.9353\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 70us/sample - loss: 0.5384 - acc: 0.7560 - f1: 0.7769 - val_loss: 0.3504 - val_acc: 0.9325 - val_f1: 0.9343\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 52us/sample - loss: 0.5369 - acc: 0.7556 - f1: 0.7764 - val_loss: 0.3388 - val_acc: 0.9388 - val_f1: 0.9409\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 54us/sample - loss: 0.5281 - acc: 0.7666 - f1: 0.7882 - val_loss: 0.3259 - val_acc: 0.9297 - val_f1: 0.9296\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 51us/sample - loss: 0.5286 - acc: 0.7682 - f1: 0.7864 - val_loss: 0.3211 - val_acc: 0.9378 - val_f1: 0.9403\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 51us/sample - loss: 0.5230 - acc: 0.7652 - f1: 0.7846 - val_loss: 0.3218 - val_acc: 0.9337 - val_f1: 0.9380\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 52us/sample - loss: 0.5211 - acc: 0.7679 - f1: 0.7869 - val_loss: 0.2997 - val_acc: 0.9347 - val_f1: 0.9345\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 53us/sample - loss: 0.5215 - acc: 0.7684 - f1: 0.7874 - val_loss: 0.3167 - val_acc: 0.9350 - val_f1: 0.9352\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 53us/sample - loss: 0.5147 - acc: 0.7788 - f1: 0.7974 - val_loss: 0.2968 - val_acc: 0.9441 - val_f1: 0.9455\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 52us/sample - loss: 0.5115 - acc: 0.7718 - f1: 0.7900 - val_loss: 0.2767 - val_acc: 0.9409 - val_f1: 0.9417\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 48us/sample - loss: 0.5072 - acc: 0.7773 - f1: 0.7950 - val_loss: 0.2699 - val_acc: 0.9391 - val_f1: 0.9403\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 47us/sample - loss: 0.5085 - acc: 0.7746 - f1: 0.7931 - val_loss: 0.2569 - val_acc: 0.9453 - val_f1: 0.9470\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 47us/sample - loss: 0.5080 - acc: 0.7780 - f1: 0.7959 - val_loss: 0.2573 - val_acc: 0.9459 - val_f1: 0.9478\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 49us/sample - loss: 0.5160 - acc: 0.7680 - f1: 0.7868 - val_loss: 0.2846 - val_acc: 0.9344 - val_f1: 0.9334\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 51us/sample - loss: 0.5038 - acc: 0.7771 - f1: 0.7948 - val_loss: 0.2595 - val_acc: 0.9422 - val_f1: 0.9453\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.5086 - acc: 0.7728 - f1: 0.7916 - val_loss: 0.2588 - val_acc: 0.9431 - val_f1: 0.9446\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.5016 - acc: 0.7790 - f1: 0.7959 - val_loss: 0.2691 - val_acc: 0.9472 - val_f1: 0.9500\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 52us/sample - loss: 0.4953 - acc: 0.7799 - f1: 0.7958 - val_loss: 0.2611 - val_acc: 0.9475 - val_f1: 0.9491\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.4925 - acc: 0.7847 - f1: 0.7996 - val_loss: 0.2362 - val_acc: 0.9459 - val_f1: 0.9469\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.4880 - acc: 0.7882 - f1: 0.8033 - val_loss: 0.2444 - val_acc: 0.9478 - val_f1: 0.9498\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 79us/sample - loss: 0.4963 - acc: 0.7881 - f1: 0.8030 - val_loss: 0.2330 - val_acc: 0.9450 - val_f1: 0.9465\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 75us/sample - loss: 0.4857 - acc: 0.7920 - f1: 0.8060 - val_loss: 0.2275 - val_acc: 0.9481 - val_f1: 0.9491\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.4864 - acc: 0.7920 - f1: 0.8058 - val_loss: 0.2603 - val_acc: 0.9400 - val_f1: 0.9428\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 114us/sample - loss: 0.4815 - acc: 0.7973 - f1: 0.8112 - val_loss: 0.2267 - val_acc: 0.9431 - val_f1: 0.9423\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 80us/sample - loss: 0.4820 - acc: 0.7991 - f1: 0.8121 - val_loss: 0.2229 - val_acc: 0.9484 - val_f1: 0.9513\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 67us/sample - loss: 0.4782 - acc: 0.7965 - f1: 0.8102 - val_loss: 0.2232 - val_acc: 0.9500 - val_f1: 0.9521\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 75us/sample - loss: 0.4800 - acc: 0.8023 - f1: 0.8151 - val_loss: 0.2136 - val_acc: 0.9494 - val_f1: 0.9511\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 77us/sample - loss: 0.4700 - acc: 0.7984 - f1: 0.8095 - val_loss: 0.2217 - val_acc: 0.9319 - val_f1: 0.9314\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 77us/sample - loss: 0.4813 - acc: 0.7969 - f1: 0.8095 - val_loss: 0.2345 - val_acc: 0.9372 - val_f1: 0.9372\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.4744 - acc: 0.8005 - f1: 0.8129 - val_loss: 0.2100 - val_acc: 0.9488 - val_f1: 0.9516\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 2s 139us/sample - loss: 0.4682 - acc: 0.8052 - f1: 0.8161 - val_loss: 0.2188 - val_acc: 0.9463 - val_f1: 0.9495\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.4786 - acc: 0.7959 - f1: 0.8095 - val_loss: 0.2019 - val_acc: 0.9497 - val_f1: 0.9508\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 74us/sample - loss: 0.4787 - acc: 0.8035 - f1: 0.8157 - val_loss: 0.2147 - val_acc: 0.9509 - val_f1: 0.9524\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4797 - acc: 0.8003 - f1: 0.8129 - val_loss: 0.2513 - val_acc: 0.9416 - val_f1: 0.9417\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.4820 - acc: 0.7941 - f1: 0.8070 - val_loss: 0.2161 - val_acc: 0.9453 - val_f1: 0.9487\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.4773 - acc: 0.7955 - f1: 0.8080 - val_loss: 0.2000 - val_acc: 0.9528 - val_f1: 0.9546\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.4737 - acc: 0.7980 - f1: 0.8102 - val_loss: 0.2105 - val_acc: 0.9516 - val_f1: 0.9532\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 71us/sample - loss: 0.4769 - acc: 0.7970 - f1: 0.8123 - val_loss: 0.2119 - val_acc: 0.9516 - val_f1: 0.9540\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 66us/sample - loss: 0.4765 - acc: 0.7945 - f1: 0.8067 - val_loss: 0.2111 - val_acc: 0.9513 - val_f1: 0.9522\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 65us/sample - loss: 0.4758 - acc: 0.7993 - f1: 0.8125 - val_loss: 0.2057 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 76us/sample - loss: 0.4773 - acc: 0.7996 - f1: 0.8122 - val_loss: 0.2134 - val_acc: 0.9528 - val_f1: 0.9546\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 73us/sample - loss: 0.4714 - acc: 0.8055 - f1: 0.8178 - val_loss: 0.1907 - val_acc: 0.9528 - val_f1: 0.9542\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 70us/sample - loss: 0.4738 - acc: 0.8036 - f1: 0.8149 - val_loss: 0.1968 - val_acc: 0.9519 - val_f1: 0.9523\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.4724 - acc: 0.8011 - f1: 0.8142 - val_loss: 0.2296 - val_acc: 0.9431 - val_f1: 0.9429\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.4737 - acc: 0.8023 - f1: 0.8144 - val_loss: 0.1919 - val_acc: 0.9534 - val_f1: 0.9547\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.4749 - acc: 0.7998 - f1: 0.8120 - val_loss: 0.2087 - val_acc: 0.9506 - val_f1: 0.9519\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 52us/sample - loss: 0.4827 - acc: 0.7902 - f1: 0.8034 - val_loss: 0.1936 - val_acc: 0.9525 - val_f1: 0.9545\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 54us/sample - loss: 0.4749 - acc: 0.7982 - f1: 0.8109 - val_loss: 0.2044 - val_acc: 0.9516 - val_f1: 0.9541\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 51us/sample - loss: 0.4767 - acc: 0.8012 - f1: 0.8141 - val_loss: 0.2093 - val_acc: 0.9481 - val_f1: 0.9503\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 53us/sample - loss: 0.4633 - acc: 0.8078 - f1: 0.8200 - val_loss: 0.1925 - val_acc: 0.9556 - val_f1: 0.9571\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 54us/sample - loss: 0.4746 - acc: 0.7980 - f1: 0.8116 - val_loss: 0.2181 - val_acc: 0.9491 - val_f1: 0.9501\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 54us/sample - loss: 0.4697 - acc: 0.8001 - f1: 0.8136 - val_loss: 0.1966 - val_acc: 0.9472 - val_f1: 0.9478\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 3s 254us/sample - loss: 0.6828 - acc: 0.5687 - f1: 0.5862 - val_loss: 0.6325 - val_acc: 0.7400 - val_f1: 0.6920\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.6042 - acc: 0.7258 - f1: 0.7454 - val_loss: 0.5179 - val_acc: 0.8634 - val_f1: 0.8670\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.5486 - acc: 0.7756 - f1: 0.8040 - val_loss: 0.4600 - val_acc: 0.8991 - val_f1: 0.9054\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.5120 - acc: 0.8041 - f1: 0.8298 - val_loss: 0.4127 - val_acc: 0.9109 - val_f1: 0.9143\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4943 - acc: 0.8068 - f1: 0.8334 - val_loss: 0.3885 - val_acc: 0.9100 - val_f1: 0.9116\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.4783 - acc: 0.8139 - f1: 0.8403 - val_loss: 0.3784 - val_acc: 0.9287 - val_f1: 0.9330\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4635 - acc: 0.8209 - f1: 0.8458 - val_loss: 0.3562 - val_acc: 0.9328 - val_f1: 0.9365\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.4546 - acc: 0.8228 - f1: 0.8477 - val_loss: 0.3449 - val_acc: 0.9259 - val_f1: 0.9271\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.4503 - acc: 0.8218 - f1: 0.8473 - val_loss: 0.3672 - val_acc: 0.9184 - val_f1: 0.9249\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.4419 - acc: 0.8232 - f1: 0.8485 - val_loss: 0.3337 - val_acc: 0.9300 - val_f1: 0.9357\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.4331 - acc: 0.8280 - f1: 0.8523 - val_loss: 0.3221 - val_acc: 0.9344 - val_f1: 0.9383\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 82us/sample - loss: 0.4270 - acc: 0.8305 - f1: 0.8545 - val_loss: 0.2997 - val_acc: 0.9419 - val_f1: 0.9442\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4216 - acc: 0.8303 - f1: 0.8542 - val_loss: 0.3053 - val_acc: 0.9397 - val_f1: 0.9437\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.4202 - acc: 0.8288 - f1: 0.8536 - val_loss: 0.2837 - val_acc: 0.9447 - val_f1: 0.9457\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.4274 - acc: 0.8257 - f1: 0.8508 - val_loss: 0.2864 - val_acc: 0.9431 - val_f1: 0.9462\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.4089 - acc: 0.8349 - f1: 0.8585 - val_loss: 0.2742 - val_acc: 0.9494 - val_f1: 0.9514\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4133 - acc: 0.8336 - f1: 0.8573 - val_loss: 0.2724 - val_acc: 0.9475 - val_f1: 0.9488\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 82us/sample - loss: 0.4013 - acc: 0.8398 - f1: 0.8609 - val_loss: 0.2740 - val_acc: 0.9441 - val_f1: 0.9476\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.4101 - acc: 0.8323 - f1: 0.8564 - val_loss: 0.3116 - val_acc: 0.9175 - val_f1: 0.9259\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 82us/sample - loss: 0.4090 - acc: 0.8323 - f1: 0.8558 - val_loss: 0.2616 - val_acc: 0.9478 - val_f1: 0.9505\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.3964 - acc: 0.8402 - f1: 0.8618 - val_loss: 0.2451 - val_acc: 0.9525 - val_f1: 0.9545\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3948 - acc: 0.8404 - f1: 0.8618 - val_loss: 0.2452 - val_acc: 0.9491 - val_f1: 0.9512\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 106us/sample - loss: 0.3985 - acc: 0.8395 - f1: 0.8619 - val_loss: 0.2400 - val_acc: 0.9509 - val_f1: 0.9524\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 104us/sample - loss: 0.3919 - acc: 0.8435 - f1: 0.8647 - val_loss: 0.2345 - val_acc: 0.9491 - val_f1: 0.9514\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 102us/sample - loss: 0.3859 - acc: 0.8458 - f1: 0.8667 - val_loss: 0.2486 - val_acc: 0.9425 - val_f1: 0.9467\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 2s 137us/sample - loss: 0.3909 - acc: 0.8412 - f1: 0.8634 - val_loss: 0.2307 - val_acc: 0.9522 - val_f1: 0.9537\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 2s 148us/sample - loss: 0.3965 - acc: 0.8371 - f1: 0.8599 - val_loss: 0.2333 - val_acc: 0.9503 - val_f1: 0.9524\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 2s 145us/sample - loss: 0.3939 - acc: 0.8389 - f1: 0.8614 - val_loss: 0.2263 - val_acc: 0.9544 - val_f1: 0.9559\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 105us/sample - loss: 0.3888 - acc: 0.8451 - f1: 0.8666 - val_loss: 0.2297 - val_acc: 0.9497 - val_f1: 0.9526\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 2s 119us/sample - loss: 0.3767 - acc: 0.8484 - f1: 0.8692 - val_loss: 0.2508 - val_acc: 0.9369 - val_f1: 0.9418\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 2s 123us/sample - loss: 0.3890 - acc: 0.8423 - f1: 0.8642 - val_loss: 0.2214 - val_acc: 0.9522 - val_f1: 0.9535\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 2s 160us/sample - loss: 0.3886 - acc: 0.8421 - f1: 0.8633 - val_loss: 0.2295 - val_acc: 0.9463 - val_f1: 0.9466\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 107us/sample - loss: 0.3921 - acc: 0.8413 - f1: 0.8630 - val_loss: 0.2191 - val_acc: 0.9513 - val_f1: 0.9538\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 117us/sample - loss: 0.3839 - acc: 0.8436 - f1: 0.8655 - val_loss: 0.2236 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 2s 126us/sample - loss: 0.3848 - acc: 0.8436 - f1: 0.8651 - val_loss: 0.2282 - val_acc: 0.9478 - val_f1: 0.9504\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 2s 130us/sample - loss: 0.3832 - acc: 0.8468 - f1: 0.8676 - val_loss: 0.2195 - val_acc: 0.9506 - val_f1: 0.9529\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 2s 123us/sample - loss: 0.3828 - acc: 0.8459 - f1: 0.8664 - val_loss: 0.2314 - val_acc: 0.9431 - val_f1: 0.9473\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 97us/sample - loss: 0.3833 - acc: 0.8442 - f1: 0.8661 - val_loss: 0.2126 - val_acc: 0.9550 - val_f1: 0.9568\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 98us/sample - loss: 0.3793 - acc: 0.8466 - f1: 0.8680 - val_loss: 0.2182 - val_acc: 0.9497 - val_f1: 0.9501\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.3852 - acc: 0.8406 - f1: 0.8629 - val_loss: 0.2179 - val_acc: 0.9513 - val_f1: 0.9541\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.3765 - acc: 0.8480 - f1: 0.8688 - val_loss: 0.2200 - val_acc: 0.9463 - val_f1: 0.9487\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 100us/sample - loss: 0.3755 - acc: 0.8484 - f1: 0.8688 - val_loss: 0.2167 - val_acc: 0.9500 - val_f1: 0.9526\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 109us/sample - loss: 0.3788 - acc: 0.8469 - f1: 0.8680 - val_loss: 0.2090 - val_acc: 0.9544 - val_f1: 0.9553\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3854 - acc: 0.8440 - f1: 0.8646 - val_loss: 0.2165 - val_acc: 0.9481 - val_f1: 0.9509\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3848 - acc: 0.8413 - f1: 0.8634 - val_loss: 0.2167 - val_acc: 0.9513 - val_f1: 0.9535\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.3774 - acc: 0.8470 - f1: 0.8676 - val_loss: 0.2074 - val_acc: 0.9519 - val_f1: 0.9541\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 104us/sample - loss: 0.3854 - acc: 0.8425 - f1: 0.8646 - val_loss: 0.2074 - val_acc: 0.9553 - val_f1: 0.9569\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 98us/sample - loss: 0.3768 - acc: 0.8490 - f1: 0.8697 - val_loss: 0.2089 - val_acc: 0.9563 - val_f1: 0.9572\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 113us/sample - loss: 0.3769 - acc: 0.8473 - f1: 0.8679 - val_loss: 0.2054 - val_acc: 0.9563 - val_f1: 0.9573\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.3821 - acc: 0.8448 - f1: 0.8667 - val_loss: 0.2059 - val_acc: 0.9594 - val_f1: 0.9604\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.3785 - acc: 0.8438 - f1: 0.8655 - val_loss: 0.2132 - val_acc: 0.9553 - val_f1: 0.9563\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.3781 - acc: 0.8470 - f1: 0.8676 - val_loss: 0.2215 - val_acc: 0.9491 - val_f1: 0.9522\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.3688 - acc: 0.8515 - f1: 0.8715 - val_loss: 0.2028 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.3772 - acc: 0.8474 - f1: 0.8681 - val_loss: 0.2184 - val_acc: 0.9488 - val_f1: 0.9521\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.3782 - acc: 0.8467 - f1: 0.8679 - val_loss: 0.2059 - val_acc: 0.9563 - val_f1: 0.9587\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 106us/sample - loss: 0.3810 - acc: 0.8434 - f1: 0.8650 - val_loss: 0.2154 - val_acc: 0.9506 - val_f1: 0.9536\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.3865 - acc: 0.8406 - f1: 0.8636 - val_loss: 0.2009 - val_acc: 0.9597 - val_f1: 0.9612\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.3742 - acc: 0.8478 - f1: 0.8683 - val_loss: 0.2327 - val_acc: 0.9434 - val_f1: 0.9468\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.3738 - acc: 0.8499 - f1: 0.8701 - val_loss: 0.2077 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.3736 - acc: 0.8505 - f1: 0.8706 - val_loss: 0.2044 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 6s 467us/sample - loss: 0.4507 - acc: 0.7880 - f1: 0.7995 - val_loss: 0.2235 - val_acc: 0.9112 - val_f1: 0.9120\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 5s 408us/sample - loss: 0.2045 - acc: 0.9205 - f1: 0.9236 - val_loss: 0.1494 - val_acc: 0.9425 - val_f1: 0.9451\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 6s 451us/sample - loss: 0.1676 - acc: 0.9370 - f1: 0.9389 - val_loss: 0.1421 - val_acc: 0.9444 - val_f1: 0.9447\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 5s 392us/sample - loss: 0.1582 - acc: 0.9406 - f1: 0.9425 - val_loss: 0.1323 - val_acc: 0.9503 - val_f1: 0.9516\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 4s 330us/sample - loss: 0.1391 - acc: 0.9486 - f1: 0.9498 - val_loss: 0.1519 - val_acc: 0.9428 - val_f1: 0.9431\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 4s 346us/sample - loss: 0.1472 - acc: 0.9448 - f1: 0.9460 - val_loss: 0.1331 - val_acc: 0.9488 - val_f1: 0.9488\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 4s 325us/sample - loss: 0.1366 - acc: 0.9505 - f1: 0.9518 - val_loss: 0.1488 - val_acc: 0.9441 - val_f1: 0.9439\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 5s 359us/sample - loss: 0.1341 - acc: 0.9521 - f1: 0.9537 - val_loss: 0.1193 - val_acc: 0.9563 - val_f1: 0.9572\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 6s 450us/sample - loss: 0.1259 - acc: 0.9535 - f1: 0.9549 - val_loss: 0.1233 - val_acc: 0.9544 - val_f1: 0.9549\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 4s 320us/sample - loss: 0.1286 - acc: 0.9514 - f1: 0.9524 - val_loss: 0.1246 - val_acc: 0.9553 - val_f1: 0.9567\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 4s 328us/sample - loss: 0.1272 - acc: 0.9523 - f1: 0.9538 - val_loss: 0.1181 - val_acc: 0.9563 - val_f1: 0.9574\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 4s 336us/sample - loss: 0.1249 - acc: 0.9523 - f1: 0.9536 - val_loss: 0.1183 - val_acc: 0.9569 - val_f1: 0.9588\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 5s 410us/sample - loss: 0.1254 - acc: 0.9535 - f1: 0.9546 - val_loss: 0.1937 - val_acc: 0.9256 - val_f1: 0.9326\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 8s 602us/sample - loss: 0.1215 - acc: 0.9539 - f1: 0.9553 - val_loss: 0.1195 - val_acc: 0.9569 - val_f1: 0.9579\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 4s 349us/sample - loss: 0.1176 - acc: 0.9570 - f1: 0.9584 - val_loss: 0.1157 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 4s 335us/sample - loss: 0.1176 - acc: 0.9561 - f1: 0.9578 - val_loss: 0.1331 - val_acc: 0.9478 - val_f1: 0.9479\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 4s 330us/sample - loss: 0.1141 - acc: 0.9588 - f1: 0.9600 - val_loss: 0.1110 - val_acc: 0.9603 - val_f1: 0.9614\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 5s 402us/sample - loss: 0.1153 - acc: 0.9583 - f1: 0.9596 - val_loss: 0.1111 - val_acc: 0.9588 - val_f1: 0.9601\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 5s 416us/sample - loss: 0.1147 - acc: 0.9576 - f1: 0.9589 - val_loss: 0.1538 - val_acc: 0.9422 - val_f1: 0.9460\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 6s 457us/sample - loss: 0.1131 - acc: 0.9577 - f1: 0.9590 - val_loss: 0.1139 - val_acc: 0.9588 - val_f1: 0.9601\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 5s 409us/sample - loss: 0.1135 - acc: 0.9567 - f1: 0.9581 - val_loss: 0.1137 - val_acc: 0.9569 - val_f1: 0.9575\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 5s 365us/sample - loss: 0.1072 - acc: 0.9596 - f1: 0.9609 - val_loss: 0.1146 - val_acc: 0.9553 - val_f1: 0.9568\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 5s 400us/sample - loss: 0.1069 - acc: 0.9600 - f1: 0.9612 - val_loss: 0.1180 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 4s 315us/sample - loss: 0.1070 - acc: 0.9593 - f1: 0.9607 - val_loss: 0.1213 - val_acc: 0.9550 - val_f1: 0.9578\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 4s 319us/sample - loss: 0.1086 - acc: 0.9594 - f1: 0.9607 - val_loss: 0.1260 - val_acc: 0.9525 - val_f1: 0.9527\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 4s 309us/sample - loss: 0.1066 - acc: 0.9603 - f1: 0.9613 - val_loss: 0.1134 - val_acc: 0.9578 - val_f1: 0.9588\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 4s 314us/sample - loss: 0.1066 - acc: 0.9600 - f1: 0.9613 - val_loss: 0.1117 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 4s 312us/sample - loss: 0.1072 - acc: 0.9599 - f1: 0.9609 - val_loss: 0.1165 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 5s 353us/sample - loss: 0.1050 - acc: 0.9602 - f1: 0.9615 - val_loss: 0.1222 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 4s 326us/sample - loss: 0.1027 - acc: 0.9618 - f1: 0.9627 - val_loss: 0.1145 - val_acc: 0.9591 - val_f1: 0.9606\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 4s 311us/sample - loss: 0.1012 - acc: 0.9637 - f1: 0.9645 - val_loss: 0.1085 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 4s 321us/sample - loss: 0.0971 - acc: 0.9642 - f1: 0.9655 - val_loss: 0.1065 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 4s 341us/sample - loss: 0.1040 - acc: 0.9618 - f1: 0.9629 - val_loss: 0.1058 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 5s 387us/sample - loss: 0.0986 - acc: 0.9643 - f1: 0.9656 - val_loss: 0.1057 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 5s 385us/sample - loss: 0.1004 - acc: 0.9617 - f1: 0.9628 - val_loss: 0.1069 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 5s 374us/sample - loss: 0.1018 - acc: 0.9606 - f1: 0.9617 - val_loss: 0.1057 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 4s 320us/sample - loss: 0.1017 - acc: 0.9623 - f1: 0.9635 - val_loss: 0.1348 - val_acc: 0.9488 - val_f1: 0.9491\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 4s 303us/sample - loss: 0.0935 - acc: 0.9655 - f1: 0.9663 - val_loss: 0.1077 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 4s 313us/sample - loss: 0.0894 - acc: 0.9667 - f1: 0.9677 - val_loss: 0.1060 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 4s 320us/sample - loss: 0.0928 - acc: 0.9661 - f1: 0.9670 - val_loss: 0.1190 - val_acc: 0.9578 - val_f1: 0.9582\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 4s 304us/sample - loss: 0.1004 - acc: 0.9623 - f1: 0.9633 - val_loss: 0.1198 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 4s 305us/sample - loss: 0.0910 - acc: 0.9646 - f1: 0.9655 - val_loss: 0.1054 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 4s 316us/sample - loss: 0.0960 - acc: 0.9641 - f1: 0.9654 - val_loss: 0.1063 - val_acc: 0.9628 - val_f1: 0.9631\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 4s 334us/sample - loss: 0.0889 - acc: 0.9668 - f1: 0.9679 - val_loss: 0.1528 - val_acc: 0.9459 - val_f1: 0.9496\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 4s 309us/sample - loss: 0.0936 - acc: 0.9656 - f1: 0.9667 - val_loss: 0.1106 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 4s 311us/sample - loss: 0.0852 - acc: 0.9672 - f1: 0.9682 - val_loss: 0.1109 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 4s 314us/sample - loss: 0.0902 - acc: 0.9674 - f1: 0.9684 - val_loss: 0.1312 - val_acc: 0.9531 - val_f1: 0.9538\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 4s 334us/sample - loss: 0.0900 - acc: 0.9663 - f1: 0.9670 - val_loss: 0.1115 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 4s 305us/sample - loss: 0.0930 - acc: 0.9644 - f1: 0.9654 - val_loss: 0.1133 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 4s 325us/sample - loss: 0.0934 - acc: 0.9652 - f1: 0.9660 - val_loss: 0.1190 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 4s 323us/sample - loss: 0.0874 - acc: 0.9677 - f1: 0.9685 - val_loss: 0.1048 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 4s 342us/sample - loss: 0.0851 - acc: 0.9674 - f1: 0.9685 - val_loss: 0.1114 - val_acc: 0.9641 - val_f1: 0.9646\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 4s 330us/sample - loss: 0.0838 - acc: 0.9683 - f1: 0.9692 - val_loss: 0.1108 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 4s 332us/sample - loss: 0.0835 - acc: 0.9686 - f1: 0.9693 - val_loss: 0.1072 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 4s 350us/sample - loss: 0.0914 - acc: 0.9659 - f1: 0.9669 - val_loss: 0.1209 - val_acc: 0.9553 - val_f1: 0.9562\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 4s 319us/sample - loss: 0.0870 - acc: 0.9669 - f1: 0.9679 - val_loss: 0.1107 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 4s 334us/sample - loss: 0.0806 - acc: 0.9708 - f1: 0.9714 - val_loss: 0.1122 - val_acc: 0.9606 - val_f1: 0.9615\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 4s 324us/sample - loss: 0.0787 - acc: 0.9709 - f1: 0.9718 - val_loss: 0.1153 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 4s 350us/sample - loss: 0.0792 - acc: 0.9704 - f1: 0.9709 - val_loss: 0.1150 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 4s 319us/sample - loss: 0.0881 - acc: 0.9680 - f1: 0.9689 - val_loss: 0.1109 - val_acc: 0.9647 - val_f1: 0.9661\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "nb_perceptrons_range = [[5, 4, 4],[100, 100, 2],[500, 500, 500]]                                                                                                                      \n",
    "\n",
    "# Suppression de la dernière étude d'hyperparamètre\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    shutil.rmtree('./logs')\n",
    "except:\n",
    "    print(\"nothing to delete\")\n",
    "    \n",
    "# Callbacks pour affichage des performances dans tensorflow : 1 callback pour chaque hyperparamètre\n",
    "tensorboard_callback = []\n",
    "for i in range(3):\n",
    "    tensorboard_callback.append(TensorBoard(log_dir=\"logs\\{}\".format(i)))\n",
    "# Par invité de commande : \n",
    "# tensorboard --logdir=\"./logs\" --port 6006\n",
    "cpt = 0\n",
    "for nb_perceptrons in nb_perceptrons_range:                                                                                                                                                  \n",
    "    model = RN_model(nb_perceptrons, dropout, learning_rate)                                                                                                                              \n",
    "    #### Apprentissage                                                                                                                                                             \n",
    "    start = time.time()                                                                                                                                                            \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test), callbacks = [tensorboard_callback[cpt]])                                                             \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    training_delay_RN.append(end - start)                                                                                                                                          \n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                \n",
    "    start = time.time()                                                                                                                                                            \n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    predicting_delay_RN.append(end - start)    \n",
    "    cpt+=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in nb_perceptrons_range]                                                                                                                                          \n",
    "\n",
    "titre = \"RN : HyperParam = layer size\"   \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Nous remarquons qu'avec trois couches, les performances d'accuracy et de f1_score sont meilleures dans le cas de [500,500,500] (dépassant les 95%). On remarque également que la perte (\"loss\") est, en quelque sorte, inversement proportionnelle aux f1_score et accuracy dans ce cas. C'est-à-dire que pour un f1_score et une accuracy plus faible (nombre de perceptrons inférieur) la valeur de perte sera plus importante que les architectures avec plus de perceptrons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "En revanche, ajouter un nombre de perceptrons par couche important influence grandement le temps d'entrainement et de prédiction.\n",
    "\n",
    "\n",
    "2 : Influence du nombre de couches :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing to delete\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 2s 138us/sample - loss: 0.6292 - acc: 0.6778 - f1: 0.6957 - val_loss: 0.5179 - val_acc: 0.8200 - val_f1: 0.8215\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.4356 - acc: 0.8280 - f1: 0.8329 - val_loss: 0.3649 - val_acc: 0.8497 - val_f1: 0.8478\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.3332 - acc: 0.8703 - f1: 0.8735 - val_loss: 0.2828 - val_acc: 0.8956 - val_f1: 0.8997\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.2703 - acc: 0.8998 - f1: 0.9027 - val_loss: 0.2299 - val_acc: 0.9162 - val_f1: 0.9186\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.2309 - acc: 0.9173 - f1: 0.9197 - val_loss: 0.1995 - val_acc: 0.9234 - val_f1: 0.9260\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.2030 - acc: 0.9282 - f1: 0.9301 - val_loss: 0.1800 - val_acc: 0.9306 - val_f1: 0.9320\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1896 - acc: 0.9293 - f1: 0.9311 - val_loss: 0.1814 - val_acc: 0.9269 - val_f1: 0.9256\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 68us/sample - loss: 0.1756 - acc: 0.9359 - f1: 0.9379 - val_loss: 0.1565 - val_acc: 0.9388 - val_f1: 0.9402\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1652 - acc: 0.9392 - f1: 0.9408 - val_loss: 0.1521 - val_acc: 0.9463 - val_f1: 0.9483\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1638 - acc: 0.9386 - f1: 0.9404 - val_loss: 0.1469 - val_acc: 0.9428 - val_f1: 0.9443\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.1576 - acc: 0.9428 - f1: 0.9445 - val_loss: 0.1483 - val_acc: 0.9419 - val_f1: 0.9425\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1536 - acc: 0.9441 - f1: 0.9455 - val_loss: 0.1456 - val_acc: 0.9447 - val_f1: 0.9448\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1484 - acc: 0.9461 - f1: 0.9478 - val_loss: 0.1486 - val_acc: 0.9425 - val_f1: 0.9434\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1446 - acc: 0.9488 - f1: 0.9499 - val_loss: 0.1350 - val_acc: 0.9456 - val_f1: 0.9469\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1470 - acc: 0.9466 - f1: 0.9478 - val_loss: 0.1342 - val_acc: 0.9509 - val_f1: 0.9521\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1444 - acc: 0.9475 - f1: 0.9488 - val_loss: 0.1435 - val_acc: 0.9438 - val_f1: 0.9443\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1434 - acc: 0.9466 - f1: 0.9484 - val_loss: 0.1306 - val_acc: 0.9494 - val_f1: 0.9511\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1404 - acc: 0.9494 - f1: 0.9511 - val_loss: 0.1523 - val_acc: 0.9394 - val_f1: 0.9392\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1375 - acc: 0.9514 - f1: 0.9529 - val_loss: 0.1295 - val_acc: 0.9491 - val_f1: 0.9502\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1358 - acc: 0.9512 - f1: 0.9522 - val_loss: 0.1296 - val_acc: 0.9494 - val_f1: 0.9508\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1348 - acc: 0.9518 - f1: 0.9531 - val_loss: 0.1270 - val_acc: 0.9509 - val_f1: 0.9526\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1319 - acc: 0.9523 - f1: 0.9539 - val_loss: 0.1228 - val_acc: 0.9538 - val_f1: 0.9549\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1363 - acc: 0.9488 - f1: 0.9503 - val_loss: 0.1275 - val_acc: 0.9509 - val_f1: 0.9511\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1325 - acc: 0.9511 - f1: 0.9525 - val_loss: 0.1371 - val_acc: 0.9466 - val_f1: 0.9473\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1292 - acc: 0.9519 - f1: 0.9532 - val_loss: 0.1319 - val_acc: 0.9478 - val_f1: 0.9478\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1348 - acc: 0.9503 - f1: 0.9519 - val_loss: 0.1219 - val_acc: 0.9538 - val_f1: 0.9554\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1268 - acc: 0.9536 - f1: 0.9553 - val_loss: 0.1224 - val_acc: 0.9544 - val_f1: 0.9566\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1332 - acc: 0.9530 - f1: 0.9543 - val_loss: 0.1170 - val_acc: 0.9553 - val_f1: 0.9566\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 65us/sample - loss: 0.1280 - acc: 0.9534 - f1: 0.9550 - val_loss: 0.1197 - val_acc: 0.9553 - val_f1: 0.9570\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.1245 - acc: 0.9541 - f1: 0.9554 - val_loss: 0.1200 - val_acc: 0.9522 - val_f1: 0.9533\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1228 - acc: 0.9548 - f1: 0.9566 - val_loss: 0.1152 - val_acc: 0.9534 - val_f1: 0.9556\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1236 - acc: 0.9548 - f1: 0.9564 - val_loss: 0.1152 - val_acc: 0.9566 - val_f1: 0.9579\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.1196 - acc: 0.9560 - f1: 0.9573 - val_loss: 0.1135 - val_acc: 0.9556 - val_f1: 0.9577\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1215 - acc: 0.9545 - f1: 0.9559 - val_loss: 0.1117 - val_acc: 0.9575 - val_f1: 0.9588\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1232 - acc: 0.9544 - f1: 0.9559 - val_loss: 0.1140 - val_acc: 0.9569 - val_f1: 0.9583\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1232 - acc: 0.9541 - f1: 0.9555 - val_loss: 0.1149 - val_acc: 0.9559 - val_f1: 0.9569\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1205 - acc: 0.9564 - f1: 0.9576 - val_loss: 0.1204 - val_acc: 0.9556 - val_f1: 0.9579\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1204 - acc: 0.9568 - f1: 0.9582 - val_loss: 0.1226 - val_acc: 0.9531 - val_f1: 0.9532\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1167 - acc: 0.9578 - f1: 0.9591 - val_loss: 0.1181 - val_acc: 0.9525 - val_f1: 0.9528\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1221 - acc: 0.9559 - f1: 0.9571 - val_loss: 0.1168 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1202 - acc: 0.9560 - f1: 0.9573 - val_loss: 0.1083 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1154 - acc: 0.9582 - f1: 0.9598 - val_loss: 0.1122 - val_acc: 0.9575 - val_f1: 0.9582\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1150 - acc: 0.9595 - f1: 0.9606 - val_loss: 0.1080 - val_acc: 0.9591 - val_f1: 0.9595\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1139 - acc: 0.9589 - f1: 0.9599 - val_loss: 0.1057 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 57us/sample - loss: 0.1143 - acc: 0.9583 - f1: 0.9599 - val_loss: 0.1050 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1145 - acc: 0.9578 - f1: 0.9591 - val_loss: 0.1036 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1118 - acc: 0.9588 - f1: 0.9599 - val_loss: 0.1033 - val_acc: 0.9594 - val_f1: 0.9607\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1182 - acc: 0.9574 - f1: 0.9585 - val_loss: 0.1111 - val_acc: 0.9559 - val_f1: 0.9568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.1127 - acc: 0.9591 - f1: 0.9606 - val_loss: 0.1027 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.1137 - acc: 0.9602 - f1: 0.9612 - val_loss: 0.1036 - val_acc: 0.9597 - val_f1: 0.9611\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.1082 - acc: 0.9609 - f1: 0.9620 - val_loss: 0.1102 - val_acc: 0.9547 - val_f1: 0.9550\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.1122 - acc: 0.9593 - f1: 0.9604 - val_loss: 0.1102 - val_acc: 0.9563 - val_f1: 0.9567\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1115 - acc: 0.9580 - f1: 0.9590 - val_loss: 0.1190 - val_acc: 0.9544 - val_f1: 0.9546\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1108 - acc: 0.9606 - f1: 0.9620 - val_loss: 0.1022 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.1099 - acc: 0.9606 - f1: 0.9620 - val_loss: 0.1011 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.1061 - acc: 0.9623 - f1: 0.9633 - val_loss: 0.1015 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.1094 - acc: 0.9608 - f1: 0.9617 - val_loss: 0.1058 - val_acc: 0.9563 - val_f1: 0.9575\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 55us/sample - loss: 0.1067 - acc: 0.9627 - f1: 0.9639 - val_loss: 0.1024 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.1055 - acc: 0.9613 - f1: 0.9625 - val_loss: 0.1027 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 56us/sample - loss: 0.1079 - acc: 0.9609 - f1: 0.9619 - val_loss: 0.0987 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 2s 178us/sample - loss: 0.6930 - acc: 0.5219 - f1: 0.6677 - val_loss: 0.6693 - val_acc: 0.5188 - val_f1: 0.6817\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.6058 - acc: 0.6305 - f1: 0.7112 - val_loss: 0.4590 - val_acc: 0.8481 - val_f1: 0.8456\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.5265 - acc: 0.6894 - f1: 0.7525 - val_loss: 0.3763 - val_acc: 0.8972 - val_f1: 0.8982\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4805 - acc: 0.7044 - f1: 0.7652 - val_loss: 0.3036 - val_acc: 0.9169 - val_f1: 0.9189\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4634 - acc: 0.7153 - f1: 0.7738 - val_loss: 0.2819 - val_acc: 0.9294 - val_f1: 0.9331\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4511 - acc: 0.7192 - f1: 0.7770 - val_loss: 0.2567 - val_acc: 0.9428 - val_f1: 0.9444\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4468 - acc: 0.7211 - f1: 0.7797 - val_loss: 0.2339 - val_acc: 0.9447 - val_f1: 0.9467\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4409 - acc: 0.7251 - f1: 0.7826 - val_loss: 0.2208 - val_acc: 0.9478 - val_f1: 0.9490\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4386 - acc: 0.7277 - f1: 0.7845 - val_loss: 0.2206 - val_acc: 0.9513 - val_f1: 0.9526\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4259 - acc: 0.7367 - f1: 0.7909 - val_loss: 0.2016 - val_acc: 0.9475 - val_f1: 0.9494\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4296 - acc: 0.7293 - f1: 0.7863 - val_loss: 0.1961 - val_acc: 0.9475 - val_f1: 0.9491\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.4275 - acc: 0.7271 - f1: 0.7847 - val_loss: 0.2016 - val_acc: 0.9528 - val_f1: 0.9545\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4337 - acc: 0.7258 - f1: 0.7840 - val_loss: 0.1949 - val_acc: 0.9469 - val_f1: 0.9482\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4206 - acc: 0.7302 - f1: 0.7871 - val_loss: 0.1990 - val_acc: 0.9525 - val_f1: 0.9542\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4203 - acc: 0.7332 - f1: 0.7886 - val_loss: 0.2041 - val_acc: 0.9522 - val_f1: 0.9540\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4175 - acc: 0.7308 - f1: 0.7881 - val_loss: 0.1926 - val_acc: 0.9481 - val_f1: 0.9511\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4233 - acc: 0.7324 - f1: 0.7883 - val_loss: 0.1757 - val_acc: 0.9494 - val_f1: 0.9503\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4202 - acc: 0.7273 - f1: 0.7857 - val_loss: 0.1910 - val_acc: 0.9453 - val_f1: 0.9458\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4157 - acc: 0.7315 - f1: 0.7888 - val_loss: 0.1768 - val_acc: 0.9500 - val_f1: 0.9508\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4159 - acc: 0.7324 - f1: 0.7893 - val_loss: 0.1814 - val_acc: 0.9538 - val_f1: 0.9561\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.4225 - acc: 0.7333 - f1: 0.7894 - val_loss: 0.1886 - val_acc: 0.9538 - val_f1: 0.9553\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4152 - acc: 0.7379 - f1: 0.7928 - val_loss: 0.1759 - val_acc: 0.9419 - val_f1: 0.9421\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4170 - acc: 0.7346 - f1: 0.7912 - val_loss: 0.1739 - val_acc: 0.9541 - val_f1: 0.9544\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4164 - acc: 0.7354 - f1: 0.7911 - val_loss: 0.1825 - val_acc: 0.9550 - val_f1: 0.9575\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4183 - acc: 0.7344 - f1: 0.7907 - val_loss: 0.1691 - val_acc: 0.9581 - val_f1: 0.9595\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4124 - acc: 0.7339 - f1: 0.7907 - val_loss: 0.1678 - val_acc: 0.9572 - val_f1: 0.9584\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4150 - acc: 0.7321 - f1: 0.7896 - val_loss: 0.1618 - val_acc: 0.9556 - val_f1: 0.9565\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4087 - acc: 0.7386 - f1: 0.7939 - val_loss: 0.1593 - val_acc: 0.9550 - val_f1: 0.9553\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4146 - acc: 0.7345 - f1: 0.7906 - val_loss: 0.1722 - val_acc: 0.9509 - val_f1: 0.9521\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4162 - acc: 0.7334 - f1: 0.7898 - val_loss: 0.1717 - val_acc: 0.9531 - val_f1: 0.9555\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.4089 - acc: 0.7352 - f1: 0.7917 - val_loss: 0.1724 - val_acc: 0.9559 - val_f1: 0.9570\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4056 - acc: 0.7388 - f1: 0.7938 - val_loss: 0.1615 - val_acc: 0.9559 - val_f1: 0.9578\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4155 - acc: 0.7397 - f1: 0.7941 - val_loss: 0.2052 - val_acc: 0.9381 - val_f1: 0.9427\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4114 - acc: 0.7351 - f1: 0.7915 - val_loss: 0.1601 - val_acc: 0.9550 - val_f1: 0.9572\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4124 - acc: 0.7333 - f1: 0.7902 - val_loss: 0.1608 - val_acc: 0.9581 - val_f1: 0.9595\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4112 - acc: 0.7370 - f1: 0.7929 - val_loss: 0.1513 - val_acc: 0.9584 - val_f1: 0.9600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4105 - acc: 0.7344 - f1: 0.7905 - val_loss: 0.1642 - val_acc: 0.9550 - val_f1: 0.9551\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4069 - acc: 0.7370 - f1: 0.7931 - val_loss: 0.1586 - val_acc: 0.9553 - val_f1: 0.9553\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4133 - acc: 0.7320 - f1: 0.7900 - val_loss: 0.1588 - val_acc: 0.9550 - val_f1: 0.9580\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.4054 - acc: 0.7406 - f1: 0.7959 - val_loss: 0.1537 - val_acc: 0.9600 - val_f1: 0.9606\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4045 - acc: 0.7379 - f1: 0.7929 - val_loss: 0.1492 - val_acc: 0.9588 - val_f1: 0.9599\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.3998 - acc: 0.7427 - f1: 0.7969 - val_loss: 0.1483 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4134 - acc: 0.7352 - f1: 0.7917 - val_loss: 0.1538 - val_acc: 0.9566 - val_f1: 0.9574\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4104 - acc: 0.7330 - f1: 0.7900 - val_loss: 0.1496 - val_acc: 0.9547 - val_f1: 0.9558\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4079 - acc: 0.7365 - f1: 0.7927 - val_loss: 0.1574 - val_acc: 0.9581 - val_f1: 0.9586\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4067 - acc: 0.7387 - f1: 0.7939 - val_loss: 0.1431 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4096 - acc: 0.7335 - f1: 0.7910 - val_loss: 0.1519 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.3976 - acc: 0.7424 - f1: 0.7970 - val_loss: 0.1374 - val_acc: 0.9588 - val_f1: 0.9598\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.4078 - acc: 0.7392 - f1: 0.7943 - val_loss: 0.1384 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4059 - acc: 0.7350 - f1: 0.7925 - val_loss: 0.1464 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.3982 - acc: 0.7427 - f1: 0.7967 - val_loss: 0.1301 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4073 - acc: 0.7388 - f1: 0.7948 - val_loss: 0.1498 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4031 - acc: 0.7410 - f1: 0.7956 - val_loss: 0.1497 - val_acc: 0.9575 - val_f1: 0.9578\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4040 - acc: 0.7362 - f1: 0.7931 - val_loss: 0.1423 - val_acc: 0.9584 - val_f1: 0.9610\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4044 - acc: 0.7363 - f1: 0.7921 - val_loss: 0.1310 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.3984 - acc: 0.7405 - f1: 0.7957 - val_loss: 0.1467 - val_acc: 0.9631 - val_f1: 0.9631\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4029 - acc: 0.7390 - f1: 0.7948 - val_loss: 0.1485 - val_acc: 0.9572 - val_f1: 0.9595\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.3995 - acc: 0.7405 - f1: 0.7956 - val_loss: 0.1387 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.4030 - acc: 0.7371 - f1: 0.7935 - val_loss: 0.1656 - val_acc: 0.9450 - val_f1: 0.9445\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.4077 - acc: 0.7366 - f1: 0.7927 - val_loss: 0.1445 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 4s 294us/sample - loss: 0.6962 - acc: 0.5166 - f1: 0.6492 - val_loss: 0.6928 - val_acc: 0.5191 - val_f1: 0.6828\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 2s 178us/sample - loss: 0.6928 - acc: 0.5202 - f1: 0.6774 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.6927 - acc: 0.5198 - f1: 0.6778 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.6922 - acc: 0.5212 - f1: 0.6764 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.6923 - acc: 0.5233 - f1: 0.6738 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6823\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.6603 - acc: 0.6096 - f1: 0.6942 - val_loss: 0.5019 - val_acc: 0.8625 - val_f1: 0.8658\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.5544 - acc: 0.7686 - f1: 0.8031 - val_loss: 0.5204 - val_acc: 0.8253 - val_f1: 0.8546\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.5082 - acc: 0.7987 - f1: 0.8284 - val_loss: 0.4574 - val_acc: 0.8578 - val_f1: 0.8787\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4923 - acc: 0.8023 - f1: 0.8329 - val_loss: 0.3677 - val_acc: 0.9247 - val_f1: 0.9269\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4766 - acc: 0.8122 - f1: 0.8410 - val_loss: 0.3567 - val_acc: 0.9241 - val_f1: 0.9279\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4705 - acc: 0.8109 - f1: 0.8401 - val_loss: 0.3558 - val_acc: 0.9194 - val_f1: 0.9257\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 2s 169us/sample - loss: 0.4587 - acc: 0.8154 - f1: 0.8436 - val_loss: 0.4333 - val_acc: 0.8594 - val_f1: 0.8804\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4482 - acc: 0.8247 - f1: 0.8501 - val_loss: 0.3232 - val_acc: 0.9369 - val_f1: 0.9397\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4425 - acc: 0.8236 - f1: 0.8497 - val_loss: 0.3113 - val_acc: 0.9375 - val_f1: 0.9407\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 2s 161us/sample - loss: 0.4368 - acc: 0.8276 - f1: 0.8518 - val_loss: 0.3010 - val_acc: 0.9391 - val_f1: 0.9418\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 2s 162us/sample - loss: 0.4293 - acc: 0.8282 - f1: 0.8532 - val_loss: 0.2943 - val_acc: 0.9409 - val_f1: 0.9437\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4282 - acc: 0.8308 - f1: 0.8552 - val_loss: 0.2871 - val_acc: 0.9428 - val_f1: 0.9438\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4270 - acc: 0.8293 - f1: 0.8536 - val_loss: 0.2884 - val_acc: 0.9422 - val_f1: 0.9454\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 2s 159us/sample - loss: 0.4177 - acc: 0.8334 - f1: 0.8566 - val_loss: 0.2941 - val_acc: 0.9413 - val_f1: 0.9446\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4137 - acc: 0.8361 - f1: 0.8583 - val_loss: 0.2651 - val_acc: 0.9428 - val_f1: 0.9440\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 2s 169us/sample - loss: 0.4070 - acc: 0.8334 - f1: 0.8573 - val_loss: 0.2712 - val_acc: 0.9334 - val_f1: 0.9334\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4146 - acc: 0.8327 - f1: 0.8569 - val_loss: 0.2660 - val_acc: 0.9388 - val_f1: 0.9402\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4218 - acc: 0.8263 - f1: 0.8514 - val_loss: 0.2556 - val_acc: 0.9488 - val_f1: 0.9512\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4086 - acc: 0.8341 - f1: 0.8576 - val_loss: 0.2579 - val_acc: 0.9491 - val_f1: 0.9510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 2s 159us/sample - loss: 0.3980 - acc: 0.8391 - f1: 0.8612 - val_loss: 0.2473 - val_acc: 0.9475 - val_f1: 0.9485\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 2s 168us/sample - loss: 0.4030 - acc: 0.8356 - f1: 0.8586 - val_loss: 0.2448 - val_acc: 0.9484 - val_f1: 0.9504\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4026 - acc: 0.8371 - f1: 0.8600 - val_loss: 0.2504 - val_acc: 0.9459 - val_f1: 0.9489\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4048 - acc: 0.8357 - f1: 0.8584 - val_loss: 0.2497 - val_acc: 0.9478 - val_f1: 0.9504\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4024 - acc: 0.8342 - f1: 0.8582 - val_loss: 0.2395 - val_acc: 0.9509 - val_f1: 0.9535\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4032 - acc: 0.8339 - f1: 0.8578 - val_loss: 0.2405 - val_acc: 0.9500 - val_f1: 0.9527\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.3970 - acc: 0.8390 - f1: 0.8614 - val_loss: 0.2819 - val_acc: 0.9322 - val_f1: 0.9378\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4015 - acc: 0.8359 - f1: 0.8586 - val_loss: 0.2344 - val_acc: 0.9425 - val_f1: 0.9437\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3942 - acc: 0.8428 - f1: 0.8643 - val_loss: 0.2426 - val_acc: 0.9466 - val_f1: 0.9504\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.3936 - acc: 0.8398 - f1: 0.8623 - val_loss: 0.2278 - val_acc: 0.9513 - val_f1: 0.9540\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 2s 159us/sample - loss: 0.3925 - acc: 0.8425 - f1: 0.8641 - val_loss: 0.2312 - val_acc: 0.9469 - val_f1: 0.9475\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 2s 165us/sample - loss: 0.3935 - acc: 0.8445 - f1: 0.8656 - val_loss: 0.2616 - val_acc: 0.9422 - val_f1: 0.9456\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3949 - acc: 0.8383 - f1: 0.8610 - val_loss: 0.2254 - val_acc: 0.9522 - val_f1: 0.9540\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.4005 - acc: 0.8359 - f1: 0.8590 - val_loss: 0.2327 - val_acc: 0.9516 - val_f1: 0.9539\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.4038 - acc: 0.8384 - f1: 0.8604 - val_loss: 0.2180 - val_acc: 0.9528 - val_f1: 0.9529\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 2s 160us/sample - loss: 0.3952 - acc: 0.8391 - f1: 0.8614 - val_loss: 0.2163 - val_acc: 0.9553 - val_f1: 0.9558\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 2s 166us/sample - loss: 0.3935 - acc: 0.8399 - f1: 0.8623 - val_loss: 0.2159 - val_acc: 0.9541 - val_f1: 0.9544\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3901 - acc: 0.8444 - f1: 0.8658 - val_loss: 0.2972 - val_acc: 0.9225 - val_f1: 0.9302\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.3883 - acc: 0.8429 - f1: 0.8643 - val_loss: 0.2168 - val_acc: 0.9534 - val_f1: 0.9551\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3874 - acc: 0.8439 - f1: 0.8653 - val_loss: 0.2285 - val_acc: 0.9475 - val_f1: 0.9505\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3932 - acc: 0.8401 - f1: 0.8624 - val_loss: 0.2296 - val_acc: 0.9525 - val_f1: 0.9548\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3965 - acc: 0.8368 - f1: 0.8600 - val_loss: 0.2179 - val_acc: 0.9472 - val_f1: 0.9474\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 2s 157us/sample - loss: 0.3885 - acc: 0.8430 - f1: 0.8644 - val_loss: 0.2306 - val_acc: 0.9509 - val_f1: 0.9532\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 2s 158us/sample - loss: 0.3907 - acc: 0.8405 - f1: 0.8629 - val_loss: 0.2241 - val_acc: 0.9525 - val_f1: 0.9549\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 2s 159us/sample - loss: 0.3922 - acc: 0.8403 - f1: 0.8624 - val_loss: 0.2277 - val_acc: 0.9528 - val_f1: 0.9554\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 2s 180us/sample - loss: 0.3818 - acc: 0.8475 - f1: 0.8682 - val_loss: 0.2229 - val_acc: 0.9516 - val_f1: 0.9543\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 3s 229us/sample - loss: 0.3869 - acc: 0.8414 - f1: 0.8639 - val_loss: 0.2097 - val_acc: 0.9547 - val_f1: 0.9562\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 3s 253us/sample - loss: 0.3918 - acc: 0.8408 - f1: 0.8625 - val_loss: 0.2377 - val_acc: 0.9438 - val_f1: 0.9473\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 3s 217us/sample - loss: 0.3853 - acc: 0.8438 - f1: 0.8650 - val_loss: 0.2479 - val_acc: 0.9394 - val_f1: 0.9436\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 3s 217us/sample - loss: 0.3896 - acc: 0.8388 - f1: 0.8612 - val_loss: 0.2310 - val_acc: 0.9478 - val_f1: 0.9513\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 2s 161us/sample - loss: 0.3928 - acc: 0.8377 - f1: 0.8609 - val_loss: 0.2197 - val_acc: 0.9531 - val_f1: 0.9559\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 2s 160us/sample - loss: 0.3878 - acc: 0.8419 - f1: 0.8640 - val_loss: 0.2363 - val_acc: 0.9481 - val_f1: 0.9510\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 2s 163us/sample - loss: 0.3854 - acc: 0.8453 - f1: 0.8663 - val_loss: 0.2266 - val_acc: 0.9416 - val_f1: 0.9424\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 2s 166us/sample - loss: 0.3885 - acc: 0.8409 - f1: 0.8630 - val_loss: 0.2139 - val_acc: 0.9509 - val_f1: 0.9512\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 2s 161us/sample - loss: 0.3959 - acc: 0.8405 - f1: 0.8629 - val_loss: 0.2149 - val_acc: 0.9556 - val_f1: 0.9573\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 2s 164us/sample - loss: 0.3866 - acc: 0.8430 - f1: 0.8645 - val_loss: 0.2213 - val_acc: 0.9419 - val_f1: 0.9417\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "layer_sizes_range = [[100],[100, 100, 2],[100, 100, 100, 100, 100, 2]]\n",
    "\n",
    "# Suppression de la dernière étude d'hyperparamètre\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    shutil.rmtree('./logs')\n",
    "except:\n",
    "    print(\"nothing to delete\")\n",
    "\n",
    "# Callbacks pour affichage des performances dans tensorflow : 1 callback pour chaque hyperparamètre\n",
    "tensorboard_callback = []\n",
    "for i in range(3):\n",
    "    tensorboard_callback.append(TensorBoard(log_dir=\"logs\\{}\".format(i)))\n",
    "# Par invité de commande : \n",
    "# tensorboard --logdir=\"./logs\" --port 6006\n",
    "cpt = 0\n",
    "for layer_s in layer_sizes_range:\n",
    "    model = RN_model(layer_s, dropout, learning_rate)\n",
    "    #### Apprentissage                                                                                                                                                               \n",
    "    start = time.time()                                                                                                                   \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test), callbacks = [tensorboard_callback[cpt]]) \n",
    "\n",
    "    end = time.time()\n",
    "    training_delay_RN.append(end - start)\n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                  \n",
    "    start = time.time()\n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)\n",
    "\n",
    "    end = time.time()\n",
    "    predicting_delay_RN.append(end - start)\n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in layer_sizes_range]                                                                                                                                              \n",
    "\n",
    "titre = \"RN : HyperParam = number of layer\"                                                                                                                                         \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dans notre problème de classification de galaxies, on note que le les valeurs des accuracy et des f1_scores tendent vers les mêmes performances sur les jeux de données de tests qu'il y ait une, trois ou six couches (nombreb de perceptrons constant par couche). On remarque également que la valeur de perte est moins importante dans le cas où il y a le moins de couches. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ici, nous remarquons que : plus le nombre de couches est important plus le temps d'entrainement et de prédiction sont élevés.\n",
    "\n",
    "3 - Influence du taux d'apprentissage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nothing to delete\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 3s 252us/sample - loss: 0.7097 - acc: 0.5020 - f1: 0.5683 - val_loss: 0.6926 - val_acc: 0.5169 - val_f1: 0.6784\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.7031 - acc: 0.5091 - f1: 0.6160 - val_loss: 0.6917 - val_acc: 0.5181 - val_f1: 0.6770\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.7009 - acc: 0.5114 - f1: 0.6205 - val_loss: 0.6913 - val_acc: 0.5200 - val_f1: 0.6776\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.6985 - acc: 0.5138 - f1: 0.6245 - val_loss: 0.6918 - val_acc: 0.5194 - val_f1: 0.6802\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6967 - acc: 0.5197 - f1: 0.6316 - val_loss: 0.6925 - val_acc: 0.5184 - val_f1: 0.6793\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.6950 - acc: 0.5191 - f1: 0.6343 - val_loss: 0.6929 - val_acc: 0.5191 - val_f1: 0.6807\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6959 - acc: 0.5139 - f1: 0.6321 - val_loss: 0.6930 - val_acc: 0.5188 - val_f1: 0.6806\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6936 - acc: 0.5219 - f1: 0.6405 - val_loss: 0.6930 - val_acc: 0.5184 - val_f1: 0.6806\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.6933 - acc: 0.5204 - f1: 0.6410 - val_loss: 0.6930 - val_acc: 0.5188 - val_f1: 0.6812\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6917 - acc: 0.5306 - f1: 0.6488 - val_loss: 0.6930 - val_acc: 0.5188 - val_f1: 0.6811\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.6937 - acc: 0.5231 - f1: 0.6410 - val_loss: 0.6930 - val_acc: 0.5191 - val_f1: 0.6813\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.6919 - acc: 0.5324 - f1: 0.6476 - val_loss: 0.6930 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 97us/sample - loss: 0.6910 - acc: 0.5265 - f1: 0.6444 - val_loss: 0.6928 - val_acc: 0.5191 - val_f1: 0.6818\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6903 - acc: 0.5269 - f1: 0.6451 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6810\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6899 - acc: 0.5328 - f1: 0.6508 - val_loss: 0.6923 - val_acc: 0.5194 - val_f1: 0.6817\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6884 - acc: 0.5367 - f1: 0.6518 - val_loss: 0.6916 - val_acc: 0.5228 - val_f1: 0.6828\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6883 - acc: 0.5380 - f1: 0.6518 - val_loss: 0.6911 - val_acc: 0.5369 - val_f1: 0.6892\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.6879 - acc: 0.5409 - f1: 0.6526 - val_loss: 0.6902 - val_acc: 0.5834 - val_f1: 0.7109\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6863 - acc: 0.5447 - f1: 0.6529 - val_loss: 0.6877 - val_acc: 0.6094 - val_f1: 0.7230\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6862 - acc: 0.5449 - f1: 0.6521 - val_loss: 0.6859 - val_acc: 0.6828 - val_f1: 0.7623\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6842 - acc: 0.5508 - f1: 0.6568 - val_loss: 0.6825 - val_acc: 0.7475 - val_f1: 0.7965\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6852 - acc: 0.5471 - f1: 0.6486 - val_loss: 0.6795 - val_acc: 0.7909 - val_f1: 0.8198\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 2s 122us/sample - loss: 0.6844 - acc: 0.5502 - f1: 0.6502 - val_loss: 0.6758 - val_acc: 0.7997 - val_f1: 0.8215\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 111us/sample - loss: 0.6815 - acc: 0.5584 - f1: 0.6541 - val_loss: 0.6722 - val_acc: 0.8119 - val_f1: 0.8273\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6808 - acc: 0.5545 - f1: 0.6503 - val_loss: 0.6688 - val_acc: 0.8087 - val_f1: 0.8270\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 2s 144us/sample - loss: 0.6788 - acc: 0.5599 - f1: 0.6527 - val_loss: 0.6649 - val_acc: 0.8069 - val_f1: 0.8272\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.6771 - acc: 0.5670 - f1: 0.6540 - val_loss: 0.6617 - val_acc: 0.8191 - val_f1: 0.8293\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.6769 - acc: 0.5628 - f1: 0.6496 - val_loss: 0.6586 - val_acc: 0.8209 - val_f1: 0.8295\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 99us/sample - loss: 0.6733 - acc: 0.5730 - f1: 0.6533 - val_loss: 0.6555 - val_acc: 0.8238 - val_f1: 0.8333\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 97us/sample - loss: 0.6714 - acc: 0.5722 - f1: 0.6534 - val_loss: 0.6521 - val_acc: 0.8228 - val_f1: 0.8366\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 98us/sample - loss: 0.6690 - acc: 0.5791 - f1: 0.6593 - val_loss: 0.6489 - val_acc: 0.8244 - val_f1: 0.8353\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.6661 - acc: 0.5863 - f1: 0.6642 - val_loss: 0.6453 - val_acc: 0.8275 - val_f1: 0.8367\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.6665 - acc: 0.5795 - f1: 0.6585 - val_loss: 0.6421 - val_acc: 0.8278 - val_f1: 0.8404\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 99us/sample - loss: 0.6622 - acc: 0.5910 - f1: 0.6642 - val_loss: 0.6387 - val_acc: 0.8303 - val_f1: 0.8395\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.6592 - acc: 0.5927 - f1: 0.6644 - val_loss: 0.6349 - val_acc: 0.8306 - val_f1: 0.8406\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6568 - acc: 0.5955 - f1: 0.6705 - val_loss: 0.6306 - val_acc: 0.8328 - val_f1: 0.8411\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.6536 - acc: 0.6020 - f1: 0.6725 - val_loss: 0.6269 - val_acc: 0.8313 - val_f1: 0.8378\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.6506 - acc: 0.6051 - f1: 0.6742 - val_loss: 0.6227 - val_acc: 0.8353 - val_f1: 0.8423\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.6477 - acc: 0.6082 - f1: 0.6771 - val_loss: 0.6189 - val_acc: 0.8394 - val_f1: 0.8484\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.6441 - acc: 0.6054 - f1: 0.6755 - val_loss: 0.6150 - val_acc: 0.8381 - val_f1: 0.8437\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.6450 - acc: 0.6062 - f1: 0.6762 - val_loss: 0.6114 - val_acc: 0.8375 - val_f1: 0.8418\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.6393 - acc: 0.6099 - f1: 0.6795 - val_loss: 0.6078 - val_acc: 0.8381 - val_f1: 0.8443\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.6336 - acc: 0.6187 - f1: 0.6857 - val_loss: 0.6032 - val_acc: 0.8403 - val_f1: 0.8451\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.6327 - acc: 0.6157 - f1: 0.6825 - val_loss: 0.5992 - val_acc: 0.8425 - val_f1: 0.8480\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.6333 - acc: 0.6157 - f1: 0.6835 - val_loss: 0.5963 - val_acc: 0.8416 - val_f1: 0.8455\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.6265 - acc: 0.6251 - f1: 0.6915 - val_loss: 0.5921 - val_acc: 0.8416 - val_f1: 0.8442\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 102us/sample - loss: 0.6223 - acc: 0.6298 - f1: 0.6958 - val_loss: 0.5875 - val_acc: 0.8456 - val_f1: 0.8495\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 110us/sample - loss: 0.6182 - acc: 0.6351 - f1: 0.6979 - val_loss: 0.5832 - val_acc: 0.8456 - val_f1: 0.8476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 2s 120us/sample - loss: 0.6182 - acc: 0.6277 - f1: 0.6935 - val_loss: 0.5794 - val_acc: 0.8453 - val_f1: 0.8485\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 2s 130us/sample - loss: 0.6174 - acc: 0.6282 - f1: 0.6932 - val_loss: 0.5757 - val_acc: 0.8484 - val_f1: 0.8542\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 2s 144us/sample - loss: 0.6159 - acc: 0.6305 - f1: 0.6984 - val_loss: 0.5720 - val_acc: 0.8487 - val_f1: 0.8529\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 101us/sample - loss: 0.6115 - acc: 0.6327 - f1: 0.6972 - val_loss: 0.5682 - val_acc: 0.8516 - val_f1: 0.8567\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.6083 - acc: 0.6322 - f1: 0.6997 - val_loss: 0.5644 - val_acc: 0.8519 - val_f1: 0.8565\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.6030 - acc: 0.6395 - f1: 0.7037 - val_loss: 0.5598 - val_acc: 0.8516 - val_f1: 0.8568\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 2s 124us/sample - loss: 0.6017 - acc: 0.6430 - f1: 0.7089 - val_loss: 0.5556 - val_acc: 0.8519 - val_f1: 0.8573\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 2s 120us/sample - loss: 0.5981 - acc: 0.6416 - f1: 0.7070 - val_loss: 0.5513 - val_acc: 0.8516 - val_f1: 0.8553\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 110us/sample - loss: 0.5908 - acc: 0.6507 - f1: 0.7127 - val_loss: 0.5460 - val_acc: 0.8541 - val_f1: 0.8588\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 108us/sample - loss: 0.5917 - acc: 0.6491 - f1: 0.7124 - val_loss: 0.5419 - val_acc: 0.8550 - val_f1: 0.8592\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 2s 159us/sample - loss: 0.5931 - acc: 0.6415 - f1: 0.7070 - val_loss: 0.5384 - val_acc: 0.8575 - val_f1: 0.8621\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 2s 143us/sample - loss: 0.5830 - acc: 0.6545 - f1: 0.7176 - val_loss: 0.5334 - val_acc: 0.8553 - val_f1: 0.8594\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 3s 209us/sample - loss: 0.6769 - acc: 0.5521 - f1: 0.6503 - val_loss: 0.6144 - val_acc: 0.8372 - val_f1: 0.8495\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.5962 - acc: 0.7163 - f1: 0.7110 - val_loss: 0.4899 - val_acc: 0.8872 - val_f1: 0.8948\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.5269 - acc: 0.7812 - f1: 0.7658 - val_loss: 0.4478 - val_acc: 0.9084 - val_f1: 0.9067\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 2s 137us/sample - loss: 0.5036 - acc: 0.7930 - f1: 0.7709 - val_loss: 0.4163 - val_acc: 0.9150 - val_f1: 0.9139\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.4719 - acc: 0.8123 - f1: 0.7937 - val_loss: 0.3736 - val_acc: 0.9328 - val_f1: 0.9335\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4617 - acc: 0.8141 - f1: 0.7915 - val_loss: 0.3555 - val_acc: 0.9384 - val_f1: 0.9387\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4523 - acc: 0.8145 - f1: 0.7919 - val_loss: 0.3888 - val_acc: 0.9025 - val_f1: 0.8971\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4466 - acc: 0.8162 - f1: 0.7923 - val_loss: 0.3220 - val_acc: 0.9444 - val_f1: 0.9462\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4469 - acc: 0.8082 - f1: 0.7821 - val_loss: 0.3261 - val_acc: 0.9384 - val_f1: 0.9387\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.4325 - acc: 0.8203 - f1: 0.7973 - val_loss: 0.3087 - val_acc: 0.9453 - val_f1: 0.9461\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 101us/sample - loss: 0.4301 - acc: 0.8219 - f1: 0.7996 - val_loss: 0.3039 - val_acc: 0.9438 - val_f1: 0.9443\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.4155 - acc: 0.8309 - f1: 0.8116 - val_loss: 0.2996 - val_acc: 0.9444 - val_f1: 0.9444\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4163 - acc: 0.8244 - f1: 0.8021 - val_loss: 0.2880 - val_acc: 0.9456 - val_f1: 0.9455\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.4173 - acc: 0.8255 - f1: 0.8038 - val_loss: 0.2758 - val_acc: 0.9519 - val_f1: 0.9529\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4201 - acc: 0.8169 - f1: 0.7920 - val_loss: 0.2769 - val_acc: 0.9472 - val_f1: 0.9502\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.4161 - acc: 0.8230 - f1: 0.8008 - val_loss: 0.3485 - val_acc: 0.8913 - val_f1: 0.8831\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.4104 - acc: 0.8269 - f1: 0.8049 - val_loss: 0.2767 - val_acc: 0.9428 - val_f1: 0.9428\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4086 - acc: 0.8280 - f1: 0.8059 - val_loss: 0.2653 - val_acc: 0.9463 - val_f1: 0.9466\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4102 - acc: 0.8263 - f1: 0.8050 - val_loss: 0.3062 - val_acc: 0.9150 - val_f1: 0.9113\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.4038 - acc: 0.8280 - f1: 0.8056 - val_loss: 0.2485 - val_acc: 0.9525 - val_f1: 0.9540\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.3992 - acc: 0.8309 - f1: 0.8103 - val_loss: 0.2457 - val_acc: 0.9538 - val_f1: 0.9553\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.3862 - acc: 0.8395 - f1: 0.8216 - val_loss: 0.2432 - val_acc: 0.9525 - val_f1: 0.9536\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4049 - acc: 0.8259 - f1: 0.8038 - val_loss: 0.2394 - val_acc: 0.9544 - val_f1: 0.9558\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.4012 - acc: 0.8296 - f1: 0.8083 - val_loss: 0.2546 - val_acc: 0.9438 - val_f1: 0.9438\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 101us/sample - loss: 0.3978 - acc: 0.8316 - f1: 0.8115 - val_loss: 0.2353 - val_acc: 0.9556 - val_f1: 0.9573\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.3974 - acc: 0.8323 - f1: 0.8116 - val_loss: 0.2318 - val_acc: 0.9556 - val_f1: 0.9568\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.3978 - acc: 0.8296 - f1: 0.8082 - val_loss: 0.2318 - val_acc: 0.9544 - val_f1: 0.9547\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.3955 - acc: 0.8327 - f1: 0.8122 - val_loss: 0.2330 - val_acc: 0.9519 - val_f1: 0.9517\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.3926 - acc: 0.8330 - f1: 0.8135 - val_loss: 0.2352 - val_acc: 0.9509 - val_f1: 0.9517\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.3967 - acc: 0.8324 - f1: 0.8117 - val_loss: 0.2271 - val_acc: 0.9556 - val_f1: 0.9584\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4011 - acc: 0.8267 - f1: 0.8045 - val_loss: 0.2401 - val_acc: 0.9475 - val_f1: 0.9468\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.3979 - acc: 0.8287 - f1: 0.8067 - val_loss: 0.2241 - val_acc: 0.9566 - val_f1: 0.9571\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.3943 - acc: 0.8300 - f1: 0.8086 - val_loss: 0.2308 - val_acc: 0.9528 - val_f1: 0.9534\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.3897 - acc: 0.8374 - f1: 0.8183 - val_loss: 0.2197 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.3893 - acc: 0.8335 - f1: 0.8125 - val_loss: 0.2246 - val_acc: 0.9597 - val_f1: 0.9607\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.4002 - acc: 0.8282 - f1: 0.8062 - val_loss: 0.2303 - val_acc: 0.9500 - val_f1: 0.9496\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.3884 - acc: 0.8359 - f1: 0.8152 - val_loss: 0.2177 - val_acc: 0.9572 - val_f1: 0.9586\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 96us/sample - loss: 0.3859 - acc: 0.8395 - f1: 0.8207 - val_loss: 0.2321 - val_acc: 0.9513 - val_f1: 0.9517\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.3935 - acc: 0.8321 - f1: 0.8121 - val_loss: 0.2537 - val_acc: 0.9353 - val_f1: 0.9337\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3907 - acc: 0.8337 - f1: 0.8139 - val_loss: 0.2765 - val_acc: 0.9194 - val_f1: 0.9166\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3973 - acc: 0.8302 - f1: 0.8096 - val_loss: 0.2178 - val_acc: 0.9588 - val_f1: 0.9600\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.3870 - acc: 0.8345 - f1: 0.8152 - val_loss: 0.2199 - val_acc: 0.9550 - val_f1: 0.9551\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.3912 - acc: 0.8341 - f1: 0.8135 - val_loss: 0.2303 - val_acc: 0.9497 - val_f1: 0.9524\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3840 - acc: 0.8383 - f1: 0.8201 - val_loss: 0.2156 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3816 - acc: 0.8388 - f1: 0.8203 - val_loss: 0.2155 - val_acc: 0.9606 - val_f1: 0.9615\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3892 - acc: 0.8334 - f1: 0.8135 - val_loss: 0.2136 - val_acc: 0.9584 - val_f1: 0.9591\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.3870 - acc: 0.8348 - f1: 0.8151 - val_loss: 0.2168 - val_acc: 0.9584 - val_f1: 0.9602\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3886 - acc: 0.8346 - f1: 0.8140 - val_loss: 0.2226 - val_acc: 0.9550 - val_f1: 0.9554\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3845 - acc: 0.8386 - f1: 0.8198 - val_loss: 0.2459 - val_acc: 0.9406 - val_f1: 0.9390\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3743 - acc: 0.8441 - f1: 0.8261 - val_loss: 0.2191 - val_acc: 0.9566 - val_f1: 0.9582\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3837 - acc: 0.8384 - f1: 0.8185 - val_loss: 0.2366 - val_acc: 0.9419 - val_f1: 0.9397\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.3892 - acc: 0.8350 - f1: 0.8155 - val_loss: 0.2118 - val_acc: 0.9584 - val_f1: 0.9588\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.3815 - acc: 0.8384 - f1: 0.8200 - val_loss: 0.2149 - val_acc: 0.9572 - val_f1: 0.9578\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3808 - acc: 0.8398 - f1: 0.8212 - val_loss: 0.2118 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3829 - acc: 0.8381 - f1: 0.8185 - val_loss: 0.2151 - val_acc: 0.9613 - val_f1: 0.9621\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.3830 - acc: 0.8382 - f1: 0.8190 - val_loss: 0.2097 - val_acc: 0.9584 - val_f1: 0.9596\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.3843 - acc: 0.8382 - f1: 0.8192 - val_loss: 0.2116 - val_acc: 0.9588 - val_f1: 0.9598\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3766 - acc: 0.8410 - f1: 0.8232 - val_loss: 0.2164 - val_acc: 0.9572 - val_f1: 0.9571\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.3824 - acc: 0.8388 - f1: 0.8189 - val_loss: 0.2425 - val_acc: 0.9381 - val_f1: 0.9361\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 83us/sample - loss: 0.3867 - acc: 0.8355 - f1: 0.8157 - val_loss: 0.2085 - val_acc: 0.9600 - val_f1: 0.9604\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 2s 183us/sample - loss: 0.6928 - acc: 0.5182 - f1: 0.6747 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6826\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 84us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6819 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6825 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6818 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6818\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6815\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6927 - acc: 0.5192 - f1: 0.6815 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6814\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6924 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6820\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6824 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6818 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6826\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6825 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6820\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6814\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6823\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6924 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6819 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6822\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6927 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6823\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 87us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6823\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 85us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 86us/sample - loss: 0.6926 - acc: 0.5164 - f1: 0.6494 - val_loss: 0.6927 - val_acc: 0.5191 - val_f1: 0.6822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 88us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6817 - val_loss: 0.6931 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 93us/sample - loss: 0.6927 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6809\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 97us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 2s 146us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 110us/sample - loss: 0.6927 - acc: 0.5136 - f1: 0.6539 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 99us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6827\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 2s 123us/sample - loss: 0.6927 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 109us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6820\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 2s 124us/sample - loss: 0.6924 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6929 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 115us/sample - loss: 0.6924 - acc: 0.5167 - f1: 0.5353 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 2s 127us/sample - loss: 0.6927 - acc: 0.5192 - f1: 0.6817 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 104us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6817 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6822\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 2s 126us/sample - loss: 0.6923 - acc: 0.5192 - f1: 0.6824 - val_loss: 0.6928 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 2s 123us/sample - loss: 0.6927 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 2s 121us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 2s 136us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6817 - val_loss: 0.6927 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 2s 141us/sample - loss: 0.6924 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6827\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 2s 118us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6822\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 95us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6817 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6820\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 94us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6818 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 107us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 2s 145us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 92us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 2s 128us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6820\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 114us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6824 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6818\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6824\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6818\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6822 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6823\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 89us/sample - loss: 0.6925 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6814\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 90us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6820 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6822\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 2s 125us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6821 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 98us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6823 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.6926 - acc: 0.5192 - f1: 0.6819 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6815\n"
     ]
    }
   ],
   "source": [
    "################################## Learning rate                                                                                                                                     \n",
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "l_rate_range = [0.00001,0.0005,0.01]\n",
    "\n",
    "# Suppression de la dernière étude d'hyperparamètre\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    shutil.rmtree('./logs')\n",
    "except:\n",
    "    print(\"nothing to delete\")\n",
    "\n",
    "# Callbacks pour affichage des performances dans tensorflow : 1 callback pour chaque hyperparamètre\n",
    "tensorboard_callback = []\n",
    "for i in range(3):\n",
    "    tensorboard_callback.append(TensorBoard(log_dir=\"logs\\{}\".format(i)))#time.time())))\n",
    "# Par invité de commande : \n",
    "# tensorboard --logdir=\"./logs\" --port 6006\n",
    "cpt = 0\n",
    "for l_rate in l_rate_range:\n",
    "    model = RN_model(layer_sizes, dropout, l_rate)\n",
    "    #### Apprentissage\n",
    "    start = time.time()\n",
    "    #model.fit(X_train, Y_train, batch_size = 100, epochs = 60)\n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test), callbacks = [tensorboard_callback[cpt]])\n",
    "    end = time.time()\n",
    "    training_delay_RN.append(end - start)\n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction\n",
    "    start = time.time()\n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)\n",
    "\n",
    "    end = time.time()\n",
    "    predicting_delay_RN.append(end - start)\n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Traitement pour affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "                                                                                                                                      \n",
    "leg = [str(i) for i in l_rate_range]                                                                                                                                                \n",
    "                                                                                                                                    \n",
    "titre = \"RN : HyperParam = learning rate\"                                                                                                                                           \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici nous étudions l'influence du learning rate. Nous remarquons que nous devons trouver un compromis dans la valeur du learning rate pour avoir une étude dont les performances sont bonnes. Il semble que la valeur de learning rate qui optimise ces résultats se trouve à 0.0005. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons ici que c'est la valeur de 0.0005 qui nous apporte les meilleures performances en termes de temps bien que l'ordre de grandeur est similaire (70sec-80sec), ce qui constitue donc le meilleur compromis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ici, nous allons faire varier le nombre d'epochs. Nous allons notament visualiser le phénomène de surapprentissage en paramétrant un nombre d'epochs très grand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/30\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.6914 - acc: 0.5196 - f1: 0.5394 - val_loss: 0.6674 - val_acc: 0.6288 - val_f1: 0.7314\n",
      "Epoch 2/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.6181 - acc: 0.6126 - f1: 0.6093 - val_loss: 0.4916 - val_acc: 0.8550 - val_f1: 0.8533\n",
      "Epoch 3/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.5316 - acc: 0.6757 - f1: 0.5877 - val_loss: 0.3570 - val_acc: 0.9041 - val_f1: 0.9079\n",
      "Epoch 4/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4955 - acc: 0.6856 - f1: 0.5981 - val_loss: 0.3395 - val_acc: 0.8966 - val_f1: 0.8922\n",
      "Epoch 5/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4658 - acc: 0.6995 - f1: 0.6151 - val_loss: 0.2713 - val_acc: 0.9325 - val_f1: 0.9354\n",
      "Epoch 6/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4485 - acc: 0.7016 - f1: 0.6162 - val_loss: 0.2564 - val_acc: 0.9266 - val_f1: 0.9251\n",
      "Epoch 7/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4474 - acc: 0.7170 - f1: 0.7582 - val_loss: 0.2378 - val_acc: 0.9413 - val_f1: 0.9441\n",
      "Epoch 8/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4422 - acc: 0.7257 - f1: 0.7818 - val_loss: 0.2394 - val_acc: 0.9359 - val_f1: 0.9359\n",
      "Epoch 9/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4318 - acc: 0.7313 - f1: 0.7868 - val_loss: 0.2380 - val_acc: 0.9362 - val_f1: 0.9368\n",
      "Epoch 10/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4315 - acc: 0.7325 - f1: 0.7877 - val_loss: 0.2053 - val_acc: 0.9469 - val_f1: 0.9481\n",
      "Epoch 11/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4235 - acc: 0.7335 - f1: 0.7886 - val_loss: 0.1909 - val_acc: 0.9478 - val_f1: 0.9506\n",
      "Epoch 12/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4229 - acc: 0.7327 - f1: 0.7888 - val_loss: 0.2138 - val_acc: 0.9375 - val_f1: 0.9373\n",
      "Epoch 13/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4310 - acc: 0.7237 - f1: 0.7824 - val_loss: 0.2130 - val_acc: 0.9434 - val_f1: 0.9474\n",
      "Epoch 14/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4252 - acc: 0.7325 - f1: 0.7886 - val_loss: 0.1942 - val_acc: 0.9481 - val_f1: 0.9508\n",
      "Epoch 15/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4227 - acc: 0.7320 - f1: 0.7884 - val_loss: 0.2159 - val_acc: 0.9463 - val_f1: 0.9464\n",
      "Epoch 16/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4234 - acc: 0.7300 - f1: 0.7874 - val_loss: 0.2117 - val_acc: 0.9278 - val_f1: 0.9254\n",
      "Epoch 17/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4217 - acc: 0.7298 - f1: 0.7870 - val_loss: 0.1834 - val_acc: 0.9516 - val_f1: 0.9533\n",
      "Epoch 18/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4222 - acc: 0.7270 - f1: 0.7854 - val_loss: 0.1798 - val_acc: 0.9528 - val_f1: 0.9548\n",
      "Epoch 19/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4129 - acc: 0.7391 - f1: 0.7928 - val_loss: 0.1804 - val_acc: 0.9522 - val_f1: 0.9528\n",
      "Epoch 20/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4176 - acc: 0.7307 - f1: 0.7880 - val_loss: 0.1632 - val_acc: 0.9553 - val_f1: 0.9569\n",
      "Epoch 21/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4153 - acc: 0.7330 - f1: 0.7896 - val_loss: 0.1730 - val_acc: 0.9494 - val_f1: 0.9520\n",
      "Epoch 22/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4155 - acc: 0.7350 - f1: 0.7906 - val_loss: 0.2071 - val_acc: 0.9337 - val_f1: 0.9322\n",
      "Epoch 23/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4193 - acc: 0.7335 - f1: 0.7892 - val_loss: 0.1755 - val_acc: 0.9506 - val_f1: 0.9525\n",
      "Epoch 24/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4141 - acc: 0.7368 - f1: 0.7927 - val_loss: 0.1682 - val_acc: 0.9503 - val_f1: 0.9510\n",
      "Epoch 25/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4122 - acc: 0.7355 - f1: 0.7905 - val_loss: 0.1561 - val_acc: 0.9525 - val_f1: 0.9542\n",
      "Epoch 26/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4137 - acc: 0.7309 - f1: 0.7885 - val_loss: 0.1567 - val_acc: 0.9569 - val_f1: 0.9580\n",
      "Epoch 27/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4147 - acc: 0.7339 - f1: 0.7911 - val_loss: 0.1680 - val_acc: 0.9544 - val_f1: 0.9551\n",
      "Epoch 28/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4083 - acc: 0.7375 - f1: 0.7932 - val_loss: 0.1620 - val_acc: 0.9544 - val_f1: 0.9562\n",
      "Epoch 29/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4111 - acc: 0.7351 - f1: 0.7915 - val_loss: 0.1648 - val_acc: 0.9566 - val_f1: 0.9580\n",
      "Epoch 30/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4148 - acc: 0.7369 - f1: 0.7924 - val_loss: 0.1572 - val_acc: 0.9563 - val_f1: 0.9577\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 36us/sample - loss: 0.6791 - acc: 0.5435 - f1: 0.5851 - val_loss: 0.6254 - val_acc: 0.8259 - val_f1: 0.8365\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5923 - acc: 0.7173 - f1: 0.7109 - val_loss: 0.5351 - val_acc: 0.8628 - val_f1: 0.8569\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5307 - acc: 0.7768 - f1: 0.7586 - val_loss: 0.4271 - val_acc: 0.9053 - val_f1: 0.9116\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4985 - acc: 0.7922 - f1: 0.7702 - val_loss: 0.3911 - val_acc: 0.9078 - val_f1: 0.9135\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4779 - acc: 0.8046 - f1: 0.7820 - val_loss: 0.3639 - val_acc: 0.9316 - val_f1: 0.9348\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4637 - acc: 0.8102 - f1: 0.7879 - val_loss: 0.3501 - val_acc: 0.9409 - val_f1: 0.9420\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4511 - acc: 0.8146 - f1: 0.7917 - val_loss: 0.3378 - val_acc: 0.9431 - val_f1: 0.9441\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4471 - acc: 0.8169 - f1: 0.7955 - val_loss: 0.3270 - val_acc: 0.9422 - val_f1: 0.9428\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4342 - acc: 0.8204 - f1: 0.7989 - val_loss: 0.3581 - val_acc: 0.9109 - val_f1: 0.9073\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4238 - acc: 0.8249 - f1: 0.8042 - val_loss: 0.3014 - val_acc: 0.9463 - val_f1: 0.9468\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4206 - acc: 0.8243 - f1: 0.8022 - val_loss: 0.3258 - val_acc: 0.9269 - val_f1: 0.9251\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4239 - acc: 0.8213 - f1: 0.7989 - val_loss: 0.2911 - val_acc: 0.9456 - val_f1: 0.9463\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4278 - acc: 0.8186 - f1: 0.7946 - val_loss: 0.2794 - val_acc: 0.9506 - val_f1: 0.9520\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4140 - acc: 0.8252 - f1: 0.8044 - val_loss: 0.2766 - val_acc: 0.9491 - val_f1: 0.9517\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4120 - acc: 0.8266 - f1: 0.8058 - val_loss: 0.3027 - val_acc: 0.9322 - val_f1: 0.9304\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4037 - acc: 0.8320 - f1: 0.8121 - val_loss: 0.2758 - val_acc: 0.9456 - val_f1: 0.9457\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4036 - acc: 0.8320 - f1: 0.8120 - val_loss: 0.2561 - val_acc: 0.9547 - val_f1: 0.9552\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4057 - acc: 0.8272 - f1: 0.8056 - val_loss: 0.2518 - val_acc: 0.9547 - val_f1: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3978 - acc: 0.8338 - f1: 0.8147 - val_loss: 0.2567 - val_acc: 0.9519 - val_f1: 0.9532\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4058 - acc: 0.8241 - f1: 0.8023 - val_loss: 0.2704 - val_acc: 0.9378 - val_f1: 0.9363\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3990 - acc: 0.8291 - f1: 0.8078 - val_loss: 0.2408 - val_acc: 0.9569 - val_f1: 0.9584\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4000 - acc: 0.8280 - f1: 0.8068 - val_loss: 0.2412 - val_acc: 0.9544 - val_f1: 0.9552\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3924 - acc: 0.8316 - f1: 0.8107 - val_loss: 0.2397 - val_acc: 0.9544 - val_f1: 0.9554\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4002 - acc: 0.8291 - f1: 0.8078 - val_loss: 0.2452 - val_acc: 0.9513 - val_f1: 0.9507\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3977 - acc: 0.8305 - f1: 0.8093 - val_loss: 0.2909 - val_acc: 0.9147 - val_f1: 0.9100\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3983 - acc: 0.8305 - f1: 0.8099 - val_loss: 0.2298 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3918 - acc: 0.8316 - f1: 0.8116 - val_loss: 0.2383 - val_acc: 0.9500 - val_f1: 0.9502\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4053 - acc: 0.8255 - f1: 0.8027 - val_loss: 0.2258 - val_acc: 0.9575 - val_f1: 0.9581\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3911 - acc: 0.8341 - f1: 0.8138 - val_loss: 0.2366 - val_acc: 0.9478 - val_f1: 0.9481\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4002 - acc: 0.8279 - f1: 0.8064 - val_loss: 0.2527 - val_acc: 0.9384 - val_f1: 0.9377\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3949 - acc: 0.8297 - f1: 0.8086 - val_loss: 0.2302 - val_acc: 0.9541 - val_f1: 0.9542\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3970 - acc: 0.8302 - f1: 0.8089 - val_loss: 0.2194 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4016 - acc: 0.8258 - f1: 0.8027 - val_loss: 0.2378 - val_acc: 0.9500 - val_f1: 0.9503\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3874 - acc: 0.8355 - f1: 0.8162 - val_loss: 0.2209 - val_acc: 0.9569 - val_f1: 0.9587\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3967 - acc: 0.8283 - f1: 0.8067 - val_loss: 0.2354 - val_acc: 0.9500 - val_f1: 0.9502\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3901 - acc: 0.8344 - f1: 0.8147 - val_loss: 0.2615 - val_acc: 0.9312 - val_f1: 0.9300\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3884 - acc: 0.8330 - f1: 0.8123 - val_loss: 0.2177 - val_acc: 0.9594 - val_f1: 0.9602\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3933 - acc: 0.8352 - f1: 0.8158 - val_loss: 0.2136 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3907 - acc: 0.8338 - f1: 0.8137 - val_loss: 0.2174 - val_acc: 0.9578 - val_f1: 0.9595\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3867 - acc: 0.8353 - f1: 0.8154 - val_loss: 0.2335 - val_acc: 0.9491 - val_f1: 0.9483\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3872 - acc: 0.8354 - f1: 0.8160 - val_loss: 0.2133 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3900 - acc: 0.8340 - f1: 0.8142 - val_loss: 0.2182 - val_acc: 0.9578 - val_f1: 0.9594\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3888 - acc: 0.8341 - f1: 0.8137 - val_loss: 0.2131 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3847 - acc: 0.8383 - f1: 0.8192 - val_loss: 0.2222 - val_acc: 0.9575 - val_f1: 0.9582\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3848 - acc: 0.8363 - f1: 0.8161 - val_loss: 0.2175 - val_acc: 0.9566 - val_f1: 0.9569\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3890 - acc: 0.8338 - f1: 0.8141 - val_loss: 0.2103 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3914 - acc: 0.8329 - f1: 0.8125 - val_loss: 0.2128 - val_acc: 0.9609 - val_f1: 0.9616\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3773 - acc: 0.8409 - f1: 0.8233 - val_loss: 0.2119 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3856 - acc: 0.8354 - f1: 0.8152 - val_loss: 0.2095 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3837 - acc: 0.8377 - f1: 0.8170 - val_loss: 0.2298 - val_acc: 0.9475 - val_f1: 0.9479\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3823 - acc: 0.8381 - f1: 0.8185 - val_loss: 0.2094 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3802 - acc: 0.8409 - f1: 0.8236 - val_loss: 0.2090 - val_acc: 0.9591 - val_f1: 0.9598\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3882 - acc: 0.8341 - f1: 0.8134 - val_loss: 0.2727 - val_acc: 0.9244 - val_f1: 0.9221\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3870 - acc: 0.8355 - f1: 0.8152 - val_loss: 0.2119 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3820 - acc: 0.8387 - f1: 0.8201 - val_loss: 0.2115 - val_acc: 0.9606 - val_f1: 0.9612\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3791 - acc: 0.8398 - f1: 0.8214 - val_loss: 0.2079 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3769 - acc: 0.8408 - f1: 0.8219 - val_loss: 0.2156 - val_acc: 0.9575 - val_f1: 0.9580\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3901 - acc: 0.8340 - f1: 0.8138 - val_loss: 0.2057 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3846 - acc: 0.8366 - f1: 0.8163 - val_loss: 0.2338 - val_acc: 0.9472 - val_f1: 0.9471\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3884 - acc: 0.8312 - f1: 0.8100 - val_loss: 0.2197 - val_acc: 0.9559 - val_f1: 0.9558\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/5000\n",
      "12800/12800 [==============================] - 0s 38us/sample - loss: 0.6835 - acc: 0.5594 - f1: 0.6350 - val_loss: 0.6208 - val_acc: 0.7309 - val_f1: 0.7025\n",
      "Epoch 2/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5963 - acc: 0.7306 - f1: 0.7546 - val_loss: 0.5075 - val_acc: 0.8872 - val_f1: 0.8950\n",
      "Epoch 3/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5336 - acc: 0.7848 - f1: 0.8129 - val_loss: 0.4412 - val_acc: 0.9041 - val_f1: 0.9100\n",
      "Epoch 4/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5098 - acc: 0.8003 - f1: 0.8279 - val_loss: 0.4109 - val_acc: 0.9131 - val_f1: 0.9173\n",
      "Epoch 5/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4841 - acc: 0.8131 - f1: 0.8399 - val_loss: 0.3830 - val_acc: 0.9241 - val_f1: 0.9286\n",
      "Epoch 6/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4714 - acc: 0.8163 - f1: 0.8430 - val_loss: 0.3656 - val_acc: 0.9225 - val_f1: 0.9233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4668 - acc: 0.8155 - f1: 0.8425 - val_loss: 0.3501 - val_acc: 0.9362 - val_f1: 0.9390\n",
      "Epoch 8/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4544 - acc: 0.8248 - f1: 0.8497 - val_loss: 0.3380 - val_acc: 0.9344 - val_f1: 0.9373\n",
      "Epoch 9/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4514 - acc: 0.8207 - f1: 0.8469 - val_loss: 0.3306 - val_acc: 0.9362 - val_f1: 0.9384\n",
      "Epoch 10/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4338 - acc: 0.8320 - f1: 0.8548 - val_loss: 0.3279 - val_acc: 0.9375 - val_f1: 0.9416\n",
      "Epoch 11/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4344 - acc: 0.8300 - f1: 0.8540 - val_loss: 0.3064 - val_acc: 0.9394 - val_f1: 0.9415\n",
      "Epoch 12/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4189 - acc: 0.8359 - f1: 0.8589 - val_loss: 0.3015 - val_acc: 0.9431 - val_f1: 0.9448\n",
      "Epoch 13/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4269 - acc: 0.8279 - f1: 0.8521 - val_loss: 0.3102 - val_acc: 0.9291 - val_f1: 0.9288\n",
      "Epoch 14/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4287 - acc: 0.8257 - f1: 0.8512 - val_loss: 0.2927 - val_acc: 0.9428 - val_f1: 0.9459\n",
      "Epoch 15/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4065 - acc: 0.8405 - f1: 0.8624 - val_loss: 0.2777 - val_acc: 0.9441 - val_f1: 0.9444\n",
      "Epoch 16/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4081 - acc: 0.8370 - f1: 0.8595 - val_loss: 0.2820 - val_acc: 0.9406 - val_f1: 0.9435\n",
      "Epoch 17/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4008 - acc: 0.8424 - f1: 0.8638 - val_loss: 0.2645 - val_acc: 0.9459 - val_f1: 0.9479\n",
      "Epoch 18/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4027 - acc: 0.8384 - f1: 0.8603 - val_loss: 0.2598 - val_acc: 0.9475 - val_f1: 0.9500\n",
      "Epoch 19/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4028 - acc: 0.8377 - f1: 0.8603 - val_loss: 0.2855 - val_acc: 0.9325 - val_f1: 0.9381\n",
      "Epoch 20/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3999 - acc: 0.8370 - f1: 0.8597 - val_loss: 0.2550 - val_acc: 0.9475 - val_f1: 0.9478\n",
      "Epoch 21/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4015 - acc: 0.8375 - f1: 0.8600 - val_loss: 0.2568 - val_acc: 0.9484 - val_f1: 0.9514\n",
      "Epoch 22/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3898 - acc: 0.8420 - f1: 0.8640 - val_loss: 0.2615 - val_acc: 0.9419 - val_f1: 0.9451\n",
      "Epoch 23/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3966 - acc: 0.8360 - f1: 0.8595 - val_loss: 0.2412 - val_acc: 0.9478 - val_f1: 0.9503\n",
      "Epoch 24/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4031 - acc: 0.8305 - f1: 0.8545 - val_loss: 0.2500 - val_acc: 0.9428 - val_f1: 0.9464\n",
      "Epoch 25/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4024 - acc: 0.8327 - f1: 0.8567 - val_loss: 0.2534 - val_acc: 0.9419 - val_f1: 0.9458\n",
      "Epoch 26/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3964 - acc: 0.8367 - f1: 0.8594 - val_loss: 0.2767 - val_acc: 0.9278 - val_f1: 0.9334\n",
      "Epoch 27/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3912 - acc: 0.8438 - f1: 0.8650 - val_loss: 0.2322 - val_acc: 0.9519 - val_f1: 0.9540\n",
      "Epoch 28/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3881 - acc: 0.8403 - f1: 0.8621 - val_loss: 0.2369 - val_acc: 0.9466 - val_f1: 0.9498\n",
      "Epoch 29/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3850 - acc: 0.8440 - f1: 0.8651 - val_loss: 0.2572 - val_acc: 0.9334 - val_f1: 0.9378\n",
      "Epoch 30/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3921 - acc: 0.8379 - f1: 0.8611 - val_loss: 0.2391 - val_acc: 0.9441 - val_f1: 0.9479\n",
      "Epoch 31/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3852 - acc: 0.8439 - f1: 0.8658 - val_loss: 0.2189 - val_acc: 0.9550 - val_f1: 0.9565\n",
      "Epoch 32/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3852 - acc: 0.8423 - f1: 0.8642 - val_loss: 0.2204 - val_acc: 0.9556 - val_f1: 0.9572\n",
      "Epoch 33/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3903 - acc: 0.8408 - f1: 0.8633 - val_loss: 0.2392 - val_acc: 0.9419 - val_f1: 0.9458\n",
      "Epoch 34/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3884 - acc: 0.8405 - f1: 0.8620 - val_loss: 0.2345 - val_acc: 0.9406 - val_f1: 0.9450\n",
      "Epoch 35/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3832 - acc: 0.8410 - f1: 0.8629 - val_loss: 0.2208 - val_acc: 0.9506 - val_f1: 0.9528\n",
      "Epoch 36/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3858 - acc: 0.8405 - f1: 0.8632 - val_loss: 0.2138 - val_acc: 0.9547 - val_f1: 0.9560\n",
      "Epoch 37/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3859 - acc: 0.8427 - f1: 0.8649 - val_loss: 0.2200 - val_acc: 0.9544 - val_f1: 0.9562\n",
      "Epoch 38/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3839 - acc: 0.8440 - f1: 0.8654 - val_loss: 0.2147 - val_acc: 0.9547 - val_f1: 0.9571\n",
      "Epoch 39/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3835 - acc: 0.8424 - f1: 0.8644 - val_loss: 0.2118 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 40/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8449 - f1: 0.8667 - val_loss: 0.2181 - val_acc: 0.9528 - val_f1: 0.9561\n",
      "Epoch 41/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3799 - acc: 0.8448 - f1: 0.8660 - val_loss: 0.2280 - val_acc: 0.9434 - val_f1: 0.9475\n",
      "Epoch 42/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3784 - acc: 0.8462 - f1: 0.8675 - val_loss: 0.2160 - val_acc: 0.9538 - val_f1: 0.9569\n",
      "Epoch 43/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3821 - acc: 0.8427 - f1: 0.8645 - val_loss: 0.2072 - val_acc: 0.9563 - val_f1: 0.9569\n",
      "Epoch 44/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3831 - acc: 0.8432 - f1: 0.8649 - val_loss: 0.2121 - val_acc: 0.9575 - val_f1: 0.9596\n",
      "Epoch 45/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8478 - f1: 0.8685 - val_loss: 0.2090 - val_acc: 0.9553 - val_f1: 0.9565\n",
      "Epoch 46/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3796 - acc: 0.8456 - f1: 0.8673 - val_loss: 0.2067 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 47/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3761 - acc: 0.8456 - f1: 0.8667 - val_loss: 0.2039 - val_acc: 0.9597 - val_f1: 0.9611\n",
      "Epoch 48/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3685 - acc: 0.8514 - f1: 0.8714 - val_loss: 0.2046 - val_acc: 0.9581 - val_f1: 0.9587\n",
      "Epoch 49/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8457 - f1: 0.8673 - val_loss: 0.2266 - val_acc: 0.9425 - val_f1: 0.9463\n",
      "Epoch 50/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3827 - acc: 0.8429 - f1: 0.8654 - val_loss: 0.2062 - val_acc: 0.9578 - val_f1: 0.9593\n",
      "Epoch 51/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3834 - acc: 0.8434 - f1: 0.8651 - val_loss: 0.2125 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 52/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3816 - acc: 0.8441 - f1: 0.8651 - val_loss: 0.2121 - val_acc: 0.9516 - val_f1: 0.9519\n",
      "Epoch 53/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3807 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2320 - val_acc: 0.9375 - val_f1: 0.9422\n",
      "Epoch 54/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8441 - f1: 0.8658 - val_loss: 0.2118 - val_acc: 0.9559 - val_f1: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3771 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2483 - val_acc: 0.9353 - val_f1: 0.9407\n",
      "Epoch 56/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3681 - acc: 0.8505 - f1: 0.8710 - val_loss: 0.2095 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 57/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3770 - acc: 0.8467 - f1: 0.8675 - val_loss: 0.2199 - val_acc: 0.9472 - val_f1: 0.9505\n",
      "Epoch 58/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3778 - acc: 0.8461 - f1: 0.8675 - val_loss: 0.2065 - val_acc: 0.9578 - val_f1: 0.9591\n",
      "Epoch 59/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3802 - acc: 0.8440 - f1: 0.8660 - val_loss: 0.2077 - val_acc: 0.9572 - val_f1: 0.9580\n",
      "Epoch 60/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3676 - acc: 0.8542 - f1: 0.8736 - val_loss: 0.2079 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 61/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3691 - acc: 0.8511 - f1: 0.8715 - val_loss: 0.2110 - val_acc: 0.9519 - val_f1: 0.9547\n",
      "Epoch 62/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3770 - acc: 0.8462 - f1: 0.8675 - val_loss: 0.1991 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 63/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3714 - acc: 0.8503 - f1: 0.8708 - val_loss: 0.2180 - val_acc: 0.9478 - val_f1: 0.9512\n",
      "Epoch 64/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3711 - acc: 0.8489 - f1: 0.8699 - val_loss: 0.2142 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 65/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3700 - acc: 0.8496 - f1: 0.8703 - val_loss: 0.2031 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 66/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3750 - acc: 0.8486 - f1: 0.8692 - val_loss: 0.2080 - val_acc: 0.9547 - val_f1: 0.9557\n",
      "Epoch 67/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3716 - acc: 0.8504 - f1: 0.8711 - val_loss: 0.2561 - val_acc: 0.9256 - val_f1: 0.9322\n",
      "Epoch 68/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3728 - acc: 0.8482 - f1: 0.8685 - val_loss: 0.1979 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 69/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3835 - acc: 0.8427 - f1: 0.8648 - val_loss: 0.2036 - val_acc: 0.9559 - val_f1: 0.9570\n",
      "Epoch 70/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8477 - f1: 0.8688 - val_loss: 0.2008 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 71/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3779 - acc: 0.8450 - f1: 0.8662 - val_loss: 0.2050 - val_acc: 0.9563 - val_f1: 0.9571\n",
      "Epoch 72/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3714 - acc: 0.8493 - f1: 0.8699 - val_loss: 0.2074 - val_acc: 0.9550 - val_f1: 0.9566\n",
      "Epoch 73/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3697 - acc: 0.8498 - f1: 0.8705 - val_loss: 0.2015 - val_acc: 0.9591 - val_f1: 0.9596\n",
      "Epoch 74/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3708 - acc: 0.8498 - f1: 0.8707 - val_loss: 0.2119 - val_acc: 0.9528 - val_f1: 0.9556\n",
      "Epoch 75/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3736 - acc: 0.8484 - f1: 0.8685 - val_loss: 0.2417 - val_acc: 0.9381 - val_f1: 0.9426\n",
      "Epoch 76/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3757 - acc: 0.8474 - f1: 0.8684 - val_loss: 0.2050 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 77/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8495 - f1: 0.8700 - val_loss: 0.2006 - val_acc: 0.9594 - val_f1: 0.9603\n",
      "Epoch 78/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3713 - acc: 0.8491 - f1: 0.8698 - val_loss: 0.2217 - val_acc: 0.9438 - val_f1: 0.9478\n",
      "Epoch 79/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8501 - f1: 0.8705 - val_loss: 0.2002 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 80/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3792 - acc: 0.8461 - f1: 0.8676 - val_loss: 0.1979 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 81/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2029 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 82/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3735 - acc: 0.8496 - f1: 0.8701 - val_loss: 0.1990 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 83/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3739 - acc: 0.8474 - f1: 0.8682 - val_loss: 0.1985 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 84/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3740 - acc: 0.8470 - f1: 0.8684 - val_loss: 0.2028 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 85/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3697 - acc: 0.8491 - f1: 0.8701 - val_loss: 0.2159 - val_acc: 0.9500 - val_f1: 0.9530\n",
      "Epoch 86/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3712 - acc: 0.8503 - f1: 0.8706 - val_loss: 0.1968 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 87/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8502 - f1: 0.8707 - val_loss: 0.2014 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 88/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8552 - f1: 0.8746 - val_loss: 0.2195 - val_acc: 0.9478 - val_f1: 0.9512\n",
      "Epoch 89/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3575 - acc: 0.8567 - f1: 0.8762 - val_loss: 0.2225 - val_acc: 0.9469 - val_f1: 0.9503\n",
      "Epoch 90/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8514 - f1: 0.8717 - val_loss: 0.1978 - val_acc: 0.9588 - val_f1: 0.9613\n",
      "Epoch 91/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3672 - acc: 0.8509 - f1: 0.8716 - val_loss: 0.2056 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 92/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8534 - f1: 0.8726 - val_loss: 0.1968 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 93/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3643 - acc: 0.8520 - f1: 0.8718 - val_loss: 0.2083 - val_acc: 0.9525 - val_f1: 0.9554\n",
      "Epoch 94/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3751 - acc: 0.8478 - f1: 0.8686 - val_loss: 0.1975 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 95/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3693 - acc: 0.8513 - f1: 0.8722 - val_loss: 0.2022 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 96/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8499 - f1: 0.8703 - val_loss: 0.2025 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 97/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8544 - f1: 0.8743 - val_loss: 0.2397 - val_acc: 0.9334 - val_f1: 0.9393\n",
      "Epoch 98/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8527 - f1: 0.8728 - val_loss: 0.1953 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 99/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3703 - acc: 0.8497 - f1: 0.8706 - val_loss: 0.1972 - val_acc: 0.9584 - val_f1: 0.9600\n",
      "Epoch 100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3619 - acc: 0.8563 - f1: 0.8756 - val_loss: 0.1963 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3673 - acc: 0.8509 - f1: 0.8714 - val_loss: 0.2137 - val_acc: 0.9503 - val_f1: 0.9534\n",
      "Epoch 102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3758 - acc: 0.8463 - f1: 0.8676 - val_loss: 0.1952 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8527 - f1: 0.8727 - val_loss: 0.1943 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3718 - acc: 0.8477 - f1: 0.8685 - val_loss: 0.2003 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3661 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.2049 - val_acc: 0.9538 - val_f1: 0.9570\n",
      "Epoch 106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3646 - acc: 0.8513 - f1: 0.8720 - val_loss: 0.1983 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3662 - acc: 0.8521 - f1: 0.8720 - val_loss: 0.2004 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3624 - acc: 0.8541 - f1: 0.8734 - val_loss: 0.1929 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3594 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.1985 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3639 - acc: 0.8538 - f1: 0.8742 - val_loss: 0.1937 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3641 - acc: 0.8545 - f1: 0.8744 - val_loss: 0.2114 - val_acc: 0.9500 - val_f1: 0.9531\n",
      "Epoch 112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3591 - acc: 0.8543 - f1: 0.8747 - val_loss: 0.2183 - val_acc: 0.9469 - val_f1: 0.9506\n",
      "Epoch 113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8542 - f1: 0.8740 - val_loss: 0.1992 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3621 - acc: 0.8542 - f1: 0.8745 - val_loss: 0.2116 - val_acc: 0.9488 - val_f1: 0.9522\n",
      "Epoch 115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8505 - f1: 0.8710 - val_loss: 0.2225 - val_acc: 0.9453 - val_f1: 0.9491\n",
      "Epoch 116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3693 - acc: 0.8490 - f1: 0.8706 - val_loss: 0.1971 - val_acc: 0.9597 - val_f1: 0.9604\n",
      "Epoch 117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3667 - acc: 0.8507 - f1: 0.8712 - val_loss: 0.1958 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.1960 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8535 - f1: 0.8730 - val_loss: 0.2118 - val_acc: 0.9559 - val_f1: 0.9569\n",
      "Epoch 120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3745 - acc: 0.8462 - f1: 0.8678 - val_loss: 0.1980 - val_acc: 0.9563 - val_f1: 0.9589\n",
      "Epoch 121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3638 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.1983 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3672 - acc: 0.8495 - f1: 0.8705 - val_loss: 0.1966 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3622 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.1973 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3648 - acc: 0.8512 - f1: 0.8716 - val_loss: 0.1955 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3628 - acc: 0.8532 - f1: 0.8735 - val_loss: 0.1951 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8547 - f1: 0.8744 - val_loss: 0.1976 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3611 - acc: 0.8525 - f1: 0.8726 - val_loss: 0.1935 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3570 - acc: 0.8546 - f1: 0.8744 - val_loss: 0.1922 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8552 - f1: 0.8754 - val_loss: 0.1982 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3558 - acc: 0.8555 - f1: 0.8753 - val_loss: 0.1979 - val_acc: 0.9594 - val_f1: 0.9604\n",
      "Epoch 131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3642 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.1940 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3665 - acc: 0.8494 - f1: 0.8697 - val_loss: 0.2251 - val_acc: 0.9409 - val_f1: 0.9444\n",
      "Epoch 133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3652 - acc: 0.8540 - f1: 0.8743 - val_loss: 0.1999 - val_acc: 0.9603 - val_f1: 0.9613\n",
      "Epoch 134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3640 - acc: 0.8530 - f1: 0.8734 - val_loss: 0.1994 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8530 - f1: 0.8734 - val_loss: 0.1930 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3702 - acc: 0.8469 - f1: 0.8680 - val_loss: 0.1974 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3505 - acc: 0.8609 - f1: 0.8794 - val_loss: 0.1999 - val_acc: 0.9569 - val_f1: 0.9587\n",
      "Epoch 138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3649 - acc: 0.8527 - f1: 0.8730 - val_loss: 0.2098 - val_acc: 0.9550 - val_f1: 0.9569\n",
      "Epoch 139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8498 - f1: 0.8712 - val_loss: 0.2051 - val_acc: 0.9538 - val_f1: 0.9562\n",
      "Epoch 140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3569 - acc: 0.8550 - f1: 0.8744 - val_loss: 0.1949 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8502 - f1: 0.8710 - val_loss: 0.1959 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3707 - acc: 0.8484 - f1: 0.8699 - val_loss: 0.2571 - val_acc: 0.9272 - val_f1: 0.9333\n",
      "Epoch 143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3682 - acc: 0.8493 - f1: 0.8701 - val_loss: 0.1935 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8538 - f1: 0.8737 - val_loss: 0.1959 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8579 - f1: 0.8764 - val_loss: 0.1991 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8541 - f1: 0.8743 - val_loss: 0.2022 - val_acc: 0.9606 - val_f1: 0.9614\n",
      "Epoch 147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.2013 - val_acc: 0.9597 - val_f1: 0.9608\n",
      "Epoch 148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3720 - acc: 0.8488 - f1: 0.8699 - val_loss: 0.1927 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 149/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3609 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.2022 - val_acc: 0.9547 - val_f1: 0.9576\n",
      "Epoch 150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3676 - acc: 0.8499 - f1: 0.8709 - val_loss: 0.2003 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3573 - acc: 0.8559 - f1: 0.8760 - val_loss: 0.2017 - val_acc: 0.9547 - val_f1: 0.9566\n",
      "Epoch 152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8558 - f1: 0.8748 - val_loss: 0.1992 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.1945 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8530 - f1: 0.8730 - val_loss: 0.1915 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8590 - f1: 0.8779 - val_loss: 0.1992 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3662 - acc: 0.8524 - f1: 0.8729 - val_loss: 0.1997 - val_acc: 0.9566 - val_f1: 0.9592\n",
      "Epoch 157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3621 - acc: 0.8545 - f1: 0.8742 - val_loss: 0.1962 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3625 - acc: 0.8527 - f1: 0.8726 - val_loss: 0.2021 - val_acc: 0.9553 - val_f1: 0.9574\n",
      "Epoch 159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3644 - acc: 0.8524 - f1: 0.8728 - val_loss: 0.1991 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3553 - acc: 0.8591 - f1: 0.8778 - val_loss: 0.1984 - val_acc: 0.9606 - val_f1: 0.9632\n",
      "Epoch 161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3595 - acc: 0.8549 - f1: 0.8751 - val_loss: 0.2330 - val_acc: 0.9397 - val_f1: 0.9442\n",
      "Epoch 162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8496 - f1: 0.8709 - val_loss: 0.2145 - val_acc: 0.9494 - val_f1: 0.9528\n",
      "Epoch 163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8555 - f1: 0.8752 - val_loss: 0.2330 - val_acc: 0.9384 - val_f1: 0.9432\n",
      "Epoch 164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8578 - f1: 0.8761 - val_loss: 0.1979 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8580 - f1: 0.8769 - val_loss: 0.2038 - val_acc: 0.9547 - val_f1: 0.9574\n",
      "Epoch 166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8517 - f1: 0.8722 - val_loss: 0.1938 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3630 - acc: 0.8534 - f1: 0.8740 - val_loss: 0.1958 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8621 - f1: 0.8807 - val_loss: 0.1950 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8571 - f1: 0.8763 - val_loss: 0.1922 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3544 - acc: 0.8575 - f1: 0.8771 - val_loss: 0.2037 - val_acc: 0.9553 - val_f1: 0.9582\n",
      "Epoch 171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8520 - f1: 0.8725 - val_loss: 0.2044 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8516 - f1: 0.8724 - val_loss: 0.2051 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3626 - acc: 0.8536 - f1: 0.8737 - val_loss: 0.1951 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3596 - acc: 0.8548 - f1: 0.8745 - val_loss: 0.1927 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3607 - acc: 0.8545 - f1: 0.8742 - val_loss: 0.2081 - val_acc: 0.9538 - val_f1: 0.9567\n",
      "Epoch 176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3625 - acc: 0.8538 - f1: 0.8739 - val_loss: 0.2036 - val_acc: 0.9556 - val_f1: 0.9583\n",
      "Epoch 177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8578 - f1: 0.8769 - val_loss: 0.1955 - val_acc: 0.9603 - val_f1: 0.9628\n",
      "Epoch 178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3503 - acc: 0.8606 - f1: 0.8793 - val_loss: 0.1928 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.2012 - val_acc: 0.9559 - val_f1: 0.9586\n",
      "Epoch 180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8573 - f1: 0.8766 - val_loss: 0.1942 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8590 - f1: 0.8778 - val_loss: 0.1939 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8553 - f1: 0.8754 - val_loss: 0.1939 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3623 - acc: 0.8529 - f1: 0.8732 - val_loss: 0.1945 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3602 - acc: 0.8534 - f1: 0.8737 - val_loss: 0.2036 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3577 - acc: 0.8554 - f1: 0.8746 - val_loss: 0.2154 - val_acc: 0.9491 - val_f1: 0.9526\n",
      "Epoch 186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3609 - acc: 0.8516 - f1: 0.8725 - val_loss: 0.2007 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8601 - f1: 0.8790 - val_loss: 0.1953 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3605 - acc: 0.8537 - f1: 0.8738 - val_loss: 0.1936 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8535 - f1: 0.8735 - val_loss: 0.2287 - val_acc: 0.9422 - val_f1: 0.9462\n",
      "Epoch 190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3623 - acc: 0.8521 - f1: 0.8727 - val_loss: 0.2022 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3554 - acc: 0.8567 - f1: 0.8760 - val_loss: 0.1915 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3604 - acc: 0.8534 - f1: 0.8734 - val_loss: 0.1974 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8527 - f1: 0.8727 - val_loss: 0.1956 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3618 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.1956 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3535 - acc: 0.8591 - f1: 0.8782 - val_loss: 0.2101 - val_acc: 0.9575 - val_f1: 0.9589\n",
      "Epoch 196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8582 - f1: 0.8775 - val_loss: 0.1949 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3539 - acc: 0.8577 - f1: 0.8771 - val_loss: 0.1946 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8539 - f1: 0.8741 - val_loss: 0.1964 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.1910 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8600 - f1: 0.8791 - val_loss: 0.2062 - val_acc: 0.9522 - val_f1: 0.9548\n",
      "Epoch 201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3563 - acc: 0.8564 - f1: 0.8757 - val_loss: 0.1924 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3602 - acc: 0.8542 - f1: 0.8746 - val_loss: 0.2406 - val_acc: 0.9325 - val_f1: 0.9383\n",
      "Epoch 203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3603 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.1977 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3654 - acc: 0.8520 - f1: 0.8723 - val_loss: 0.1998 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8550 - f1: 0.8751 - val_loss: 0.1920 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3627 - acc: 0.8525 - f1: 0.8733 - val_loss: 0.1943 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3510 - acc: 0.8585 - f1: 0.8777 - val_loss: 0.2053 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3605 - acc: 0.8559 - f1: 0.8757 - val_loss: 0.1954 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3618 - acc: 0.8539 - f1: 0.8739 - val_loss: 0.1951 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8596 - f1: 0.8787 - val_loss: 0.2144 - val_acc: 0.9491 - val_f1: 0.9521\n",
      "Epoch 211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8549 - f1: 0.8750 - val_loss: 0.2054 - val_acc: 0.9547 - val_f1: 0.9575\n",
      "Epoch 212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3584 - acc: 0.8552 - f1: 0.8751 - val_loss: 0.1978 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3548 - acc: 0.8568 - f1: 0.8767 - val_loss: 0.1965 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8562 - f1: 0.8757 - val_loss: 0.1974 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.1924 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8567 - f1: 0.8764 - val_loss: 0.2011 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3707 - acc: 0.8487 - f1: 0.8703 - val_loss: 0.1957 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8585 - f1: 0.8778 - val_loss: 0.1933 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8570 - f1: 0.8764 - val_loss: 0.1959 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3514 - acc: 0.8596 - f1: 0.8785 - val_loss: 0.1953 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8516 - f1: 0.8724 - val_loss: 0.1948 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3528 - acc: 0.8600 - f1: 0.8788 - val_loss: 0.1910 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8520 - f1: 0.8729 - val_loss: 0.1951 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8564 - f1: 0.8762 - val_loss: 0.2045 - val_acc: 0.9566 - val_f1: 0.9591\n",
      "Epoch 225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8567 - f1: 0.8764 - val_loss: 0.2000 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3668 - acc: 0.8510 - f1: 0.8716 - val_loss: 0.2015 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3545 - acc: 0.8573 - f1: 0.8768 - val_loss: 0.2254 - val_acc: 0.9478 - val_f1: 0.9518\n",
      "Epoch 228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8581 - f1: 0.8777 - val_loss: 0.2003 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3573 - acc: 0.8545 - f1: 0.8750 - val_loss: 0.2016 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8585 - f1: 0.8773 - val_loss: 0.1982 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8577 - f1: 0.8770 - val_loss: 0.1937 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8542 - f1: 0.8748 - val_loss: 0.2024 - val_acc: 0.9581 - val_f1: 0.9596\n",
      "Epoch 233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3546 - acc: 0.8566 - f1: 0.8764 - val_loss: 0.2035 - val_acc: 0.9588 - val_f1: 0.9611\n",
      "Epoch 234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3689 - acc: 0.8502 - f1: 0.8715 - val_loss: 0.2398 - val_acc: 0.9316 - val_f1: 0.9373\n",
      "Epoch 235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3633 - acc: 0.8537 - f1: 0.8737 - val_loss: 0.2044 - val_acc: 0.9550 - val_f1: 0.9574\n",
      "Epoch 236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3525 - acc: 0.8573 - f1: 0.8768 - val_loss: 0.1930 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.2093 - val_acc: 0.9531 - val_f1: 0.9564\n",
      "Epoch 238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8616 - f1: 0.8797 - val_loss: 0.2008 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8517 - f1: 0.8725 - val_loss: 0.1983 - val_acc: 0.9591 - val_f1: 0.9609\n",
      "Epoch 240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3574 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.1966 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8563 - f1: 0.8762 - val_loss: 0.2380 - val_acc: 0.9350 - val_f1: 0.9406\n",
      "Epoch 242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8591 - f1: 0.8780 - val_loss: 0.2096 - val_acc: 0.9522 - val_f1: 0.9550\n",
      "Epoch 243/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3627 - acc: 0.8514 - f1: 0.8723 - val_loss: 0.2042 - val_acc: 0.9563 - val_f1: 0.9589\n",
      "Epoch 244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1992 - val_acc: 0.9613 - val_f1: 0.9639\n",
      "Epoch 245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2264 - val_acc: 0.9422 - val_f1: 0.9460\n",
      "Epoch 246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8594 - f1: 0.8785 - val_loss: 0.1938 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3482 - acc: 0.8616 - f1: 0.8795 - val_loss: 0.1965 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3535 - acc: 0.8582 - f1: 0.8774 - val_loss: 0.2144 - val_acc: 0.9450 - val_f1: 0.9491\n",
      "Epoch 249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8568 - f1: 0.8766 - val_loss: 0.1967 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3599 - acc: 0.8545 - f1: 0.8749 - val_loss: 0.2032 - val_acc: 0.9594 - val_f1: 0.9592\n",
      "Epoch 251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8609 - f1: 0.8795 - val_loss: 0.1893 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8608 - f1: 0.8795 - val_loss: 0.1913 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3559 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.1871 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.1932 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8571 - f1: 0.8766 - val_loss: 0.2118 - val_acc: 0.9506 - val_f1: 0.9543\n",
      "Epoch 256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8514 - f1: 0.8722 - val_loss: 0.1922 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8586 - f1: 0.8780 - val_loss: 0.1966 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8547 - f1: 0.8745 - val_loss: 0.2010 - val_acc: 0.9597 - val_f1: 0.9604\n",
      "Epoch 259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8601 - f1: 0.8786 - val_loss: 0.2023 - val_acc: 0.9550 - val_f1: 0.9580\n",
      "Epoch 260/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3583 - acc: 0.8548 - f1: 0.8748 - val_loss: 0.1953 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8562 - f1: 0.8756 - val_loss: 0.1912 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3574 - acc: 0.8546 - f1: 0.8746 - val_loss: 0.2043 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3561 - acc: 0.8571 - f1: 0.8769 - val_loss: 0.1948 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8560 - f1: 0.8755 - val_loss: 0.1990 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 265/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3541 - acc: 0.8577 - f1: 0.8768 - val_loss: 0.2037 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8535 - f1: 0.8744 - val_loss: 0.2014 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3590 - acc: 0.8553 - f1: 0.8753 - val_loss: 0.1965 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3606 - acc: 0.8530 - f1: 0.8729 - val_loss: 0.1957 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8557 - f1: 0.8758 - val_loss: 0.2070 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8602 - f1: 0.8788 - val_loss: 0.1975 - val_acc: 0.9638 - val_f1: 0.9661\n",
      "Epoch 271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8574 - f1: 0.8768 - val_loss: 0.2003 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8584 - f1: 0.8773 - val_loss: 0.1966 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8562 - f1: 0.8764 - val_loss: 0.2154 - val_acc: 0.9584 - val_f1: 0.9597\n",
      "Epoch 274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8531 - f1: 0.8733 - val_loss: 0.2032 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8518 - f1: 0.8724 - val_loss: 0.1956 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 276/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3578 - acc: 0.8552 - f1: 0.8755 - val_loss: 0.1942 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 277/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3485 - acc: 0.8608 - f1: 0.8794 - val_loss: 0.2089 - val_acc: 0.9528 - val_f1: 0.9559\n",
      "Epoch 278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8573 - f1: 0.8766 - val_loss: 0.1949 - val_acc: 0.9653 - val_f1: 0.9675\n",
      "Epoch 279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.1919 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 280/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3513 - acc: 0.8593 - f1: 0.8784 - val_loss: 0.1941 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8570 - f1: 0.8769 - val_loss: 0.2006 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 282/5000\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3470 - acc: 0.8625 - f1: 0.8807 - val_loss: 0.1956 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8582 - f1: 0.8768 - val_loss: 0.1939 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3612 - acc: 0.8527 - f1: 0.8737 - val_loss: 0.1926 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3590 - acc: 0.8537 - f1: 0.8740 - val_loss: 0.2080 - val_acc: 0.9519 - val_f1: 0.9554\n",
      "Epoch 286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8570 - f1: 0.8764 - val_loss: 0.1975 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8573 - f1: 0.8764 - val_loss: 0.1975 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8573 - f1: 0.8765 - val_loss: 0.2046 - val_acc: 0.9588 - val_f1: 0.9617\n",
      "Epoch 289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8600 - f1: 0.8792 - val_loss: 0.1953 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.1988 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8602 - f1: 0.8789 - val_loss: 0.1943 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3570 - acc: 0.8546 - f1: 0.8742 - val_loss: 0.2023 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8517 - f1: 0.8725 - val_loss: 0.1973 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8577 - f1: 0.8774 - val_loss: 0.2019 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8615 - f1: 0.8802 - val_loss: 0.1970 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8620 - f1: 0.8803 - val_loss: 0.1956 - val_acc: 0.9666 - val_f1: 0.9683\n",
      "Epoch 297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.2058 - val_acc: 0.9522 - val_f1: 0.9548\n",
      "Epoch 298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3568 - acc: 0.8562 - f1: 0.8761 - val_loss: 0.1998 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8615 - f1: 0.8801 - val_loss: 0.1975 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.2118 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2068 - val_acc: 0.9606 - val_f1: 0.9610\n",
      "Epoch 302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1991 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3553 - acc: 0.8582 - f1: 0.8780 - val_loss: 0.1916 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3557 - acc: 0.8569 - f1: 0.8761 - val_loss: 0.1981 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8556 - f1: 0.8757 - val_loss: 0.2030 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8594 - f1: 0.8789 - val_loss: 0.1954 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8610 - f1: 0.8797 - val_loss: 0.1979 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8614 - f1: 0.8800 - val_loss: 0.2108 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8589 - f1: 0.8780 - val_loss: 0.1973 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8586 - f1: 0.8778 - val_loss: 0.1992 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8609 - f1: 0.8796 - val_loss: 0.2013 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8599 - f1: 0.8790 - val_loss: 0.2078 - val_acc: 0.9541 - val_f1: 0.9572\n",
      "Epoch 313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3481 - acc: 0.8615 - f1: 0.8802 - val_loss: 0.1964 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8555 - f1: 0.8754 - val_loss: 0.2027 - val_acc: 0.9603 - val_f1: 0.9611\n",
      "Epoch 315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8559 - f1: 0.8751 - val_loss: 0.2140 - val_acc: 0.9497 - val_f1: 0.9532\n",
      "Epoch 316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3582 - acc: 0.8545 - f1: 0.8749 - val_loss: 0.2001 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3586 - acc: 0.8572 - f1: 0.8765 - val_loss: 0.1966 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3582 - acc: 0.8562 - f1: 0.8760 - val_loss: 0.1962 - val_acc: 0.9691 - val_f1: 0.9704\n",
      "Epoch 319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8585 - f1: 0.8782 - val_loss: 0.2013 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8646 - f1: 0.8823 - val_loss: 0.2010 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8572 - f1: 0.8766 - val_loss: 0.1982 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8582 - f1: 0.8782 - val_loss: 0.2072 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8581 - f1: 0.8773 - val_loss: 0.2186 - val_acc: 0.9469 - val_f1: 0.9504\n",
      "Epoch 324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.2011 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8596 - f1: 0.8779 - val_loss: 0.1957 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8570 - f1: 0.8769 - val_loss: 0.2155 - val_acc: 0.9531 - val_f1: 0.9563\n",
      "Epoch 327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8641 - f1: 0.8817 - val_loss: 0.1979 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8592 - f1: 0.8787 - val_loss: 0.1989 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8588 - f1: 0.8781 - val_loss: 0.2039 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3529 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2010 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8550 - f1: 0.8749 - val_loss: 0.2158 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8575 - f1: 0.8767 - val_loss: 0.2015 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8575 - f1: 0.8765 - val_loss: 0.2078 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.1983 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3544 - acc: 0.8562 - f1: 0.8764 - val_loss: 0.2037 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8602 - f1: 0.8791 - val_loss: 0.2017 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 337/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3594 - acc: 0.8540 - f1: 0.8741 - val_loss: 0.2015 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.1952 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8598 - f1: 0.8787 - val_loss: 0.2082 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3452 - acc: 0.8619 - f1: 0.8802 - val_loss: 0.2034 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8548 - f1: 0.8751 - val_loss: 0.2038 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8651 - f1: 0.8831 - val_loss: 0.1966 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3599 - acc: 0.8550 - f1: 0.8752 - val_loss: 0.2008 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8570 - f1: 0.8765 - val_loss: 0.2052 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 345/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3505 - acc: 0.8579 - f1: 0.8773 - val_loss: 0.2027 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3539 - acc: 0.8570 - f1: 0.8771 - val_loss: 0.2008 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3485 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.1981 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8612 - f1: 0.8798 - val_loss: 0.1965 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3559 - acc: 0.8551 - f1: 0.8751 - val_loss: 0.2153 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3528 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2009 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3514 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.2195 - val_acc: 0.9453 - val_f1: 0.9499\n",
      "Epoch 352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8560 - f1: 0.8760 - val_loss: 0.2395 - val_acc: 0.9362 - val_f1: 0.9416\n",
      "Epoch 353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3529 - acc: 0.8586 - f1: 0.8783 - val_loss: 0.2024 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8589 - f1: 0.8774 - val_loss: 0.1994 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8608 - f1: 0.8795 - val_loss: 0.1975 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8634 - f1: 0.8817 - val_loss: 0.1958 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3541 - acc: 0.8572 - f1: 0.8767 - val_loss: 0.1986 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8623 - f1: 0.8810 - val_loss: 0.2013 - val_acc: 0.9622 - val_f1: 0.9626\n",
      "Epoch 359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8581 - f1: 0.8775 - val_loss: 0.1959 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8569 - f1: 0.8766 - val_loss: 0.1932 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8572 - f1: 0.8772 - val_loss: 0.2014 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8561 - f1: 0.8756 - val_loss: 0.2026 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3556 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1954 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.1986 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3451 - acc: 0.8601 - f1: 0.8788 - val_loss: 0.1977 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8589 - f1: 0.8784 - val_loss: 0.2021 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3562 - acc: 0.8564 - f1: 0.8762 - val_loss: 0.2154 - val_acc: 0.9513 - val_f1: 0.9545\n",
      "Epoch 368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3604 - acc: 0.8555 - f1: 0.8756 - val_loss: 0.2056 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3538 - acc: 0.8572 - f1: 0.8769 - val_loss: 0.2010 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8609 - f1: 0.8795 - val_loss: 0.1954 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8591 - f1: 0.8783 - val_loss: 0.2113 - val_acc: 0.9538 - val_f1: 0.9563\n",
      "Epoch 372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8667 - f1: 0.8841 - val_loss: 0.2029 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3578 - acc: 0.8552 - f1: 0.8756 - val_loss: 0.2061 - val_acc: 0.9519 - val_f1: 0.9545\n",
      "Epoch 374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8620 - f1: 0.8803 - val_loss: 0.2025 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8564 - f1: 0.8763 - val_loss: 0.1999 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8606 - f1: 0.8791 - val_loss: 0.2240 - val_acc: 0.9453 - val_f1: 0.9489\n",
      "Epoch 377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8620 - f1: 0.8804 - val_loss: 0.2032 - val_acc: 0.9581 - val_f1: 0.9607\n",
      "Epoch 378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.1953 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8583 - f1: 0.8775 - val_loss: 0.1953 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8637 - f1: 0.8818 - val_loss: 0.2075 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8578 - f1: 0.8778 - val_loss: 0.1932 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3496 - acc: 0.8591 - f1: 0.8781 - val_loss: 0.2084 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.1971 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8611 - f1: 0.8802 - val_loss: 0.1998 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8657 - f1: 0.8838 - val_loss: 0.2070 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.1938 - val_acc: 0.9659 - val_f1: 0.9681\n",
      "Epoch 387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8610 - f1: 0.8796 - val_loss: 0.2109 - val_acc: 0.9572 - val_f1: 0.9592\n",
      "Epoch 388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8575 - f1: 0.8773 - val_loss: 0.2180 - val_acc: 0.9513 - val_f1: 0.9546\n",
      "Epoch 389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8533 - f1: 0.8739 - val_loss: 0.1977 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8614 - f1: 0.8801 - val_loss: 0.1976 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8559 - f1: 0.8757 - val_loss: 0.1984 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8662 - f1: 0.8837 - val_loss: 0.1989 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8584 - f1: 0.8772 - val_loss: 0.2089 - val_acc: 0.9575 - val_f1: 0.9602\n",
      "Epoch 394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8574 - f1: 0.8765 - val_loss: 0.1981 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2036 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3659 - acc: 0.8505 - f1: 0.8712 - val_loss: 0.2004 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8559 - f1: 0.8754 - val_loss: 0.1972 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8579 - f1: 0.8772 - val_loss: 0.1956 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8641 - f1: 0.8822 - val_loss: 0.1955 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8611 - f1: 0.8800 - val_loss: 0.1964 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2079 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8628 - f1: 0.8811 - val_loss: 0.1996 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8604 - f1: 0.8794 - val_loss: 0.1952 - val_acc: 0.9691 - val_f1: 0.9705\n",
      "Epoch 404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8590 - f1: 0.8780 - val_loss: 0.1966 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8594 - f1: 0.8777 - val_loss: 0.2066 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8636 - f1: 0.8818 - val_loss: 0.1997 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8595 - f1: 0.8788 - val_loss: 0.2028 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8583 - f1: 0.8775 - val_loss: 0.1998 - val_acc: 0.9609 - val_f1: 0.9631\n",
      "Epoch 409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8557 - f1: 0.8756 - val_loss: 0.2010 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8579 - f1: 0.8779 - val_loss: 0.2112 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.2031 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8591 - f1: 0.8780 - val_loss: 0.2012 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2008 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8572 - f1: 0.8770 - val_loss: 0.1989 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8612 - f1: 0.8794 - val_loss: 0.1989 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8574 - f1: 0.8769 - val_loss: 0.2002 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8614 - f1: 0.8799 - val_loss: 0.2083 - val_acc: 0.9575 - val_f1: 0.9594\n",
      "Epoch 418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.1999 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8596 - f1: 0.8791 - val_loss: 0.1941 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8614 - f1: 0.8799 - val_loss: 0.1986 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2185 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8623 - f1: 0.8807 - val_loss: 0.1989 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8555 - f1: 0.8759 - val_loss: 0.2022 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8590 - f1: 0.8786 - val_loss: 0.2065 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8577 - f1: 0.8775 - val_loss: 0.1992 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2036 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8802 - val_loss: 0.1969 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8593 - f1: 0.8788 - val_loss: 0.1946 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2006 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8616 - f1: 0.8805 - val_loss: 0.2026 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 431/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8589 - f1: 0.8786 - val_loss: 0.1964 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8805 - val_loss: 0.2115 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8579 - f1: 0.8771 - val_loss: 0.2042 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8627 - f1: 0.8808 - val_loss: 0.2059 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8587 - f1: 0.8776 - val_loss: 0.2047 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8580 - f1: 0.8772 - val_loss: 0.2024 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8646 - f1: 0.8824 - val_loss: 0.2053 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2126 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2084 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8612 - f1: 0.8792 - val_loss: 0.2349 - val_acc: 0.9403 - val_f1: 0.9451\n",
      "Epoch 441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8616 - f1: 0.8805 - val_loss: 0.2032 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8595 - f1: 0.8786 - val_loss: 0.2012 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8607 - f1: 0.8794 - val_loss: 0.1998 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8643 - f1: 0.8824 - val_loss: 0.2110 - val_acc: 0.9566 - val_f1: 0.9585\n",
      "Epoch 445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2083 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8611 - f1: 0.8795 - val_loss: 0.1992 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8588 - f1: 0.8779 - val_loss: 0.1966 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8623 - f1: 0.8806 - val_loss: 0.2007 - val_acc: 0.9606 - val_f1: 0.9635\n",
      "Epoch 449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8576 - f1: 0.8770 - val_loss: 0.1946 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8586 - f1: 0.8778 - val_loss: 0.1935 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.1989 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8587 - f1: 0.8784 - val_loss: 0.2059 - val_acc: 0.9588 - val_f1: 0.9614\n",
      "Epoch 453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3545 - acc: 0.8571 - f1: 0.8769 - val_loss: 0.2146 - val_acc: 0.9522 - val_f1: 0.9547\n",
      "Epoch 454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.1980 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8624 - f1: 0.8807 - val_loss: 0.1935 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8580 - f1: 0.8776 - val_loss: 0.2096 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3478 - acc: 0.8599 - f1: 0.8788 - val_loss: 0.2154 - val_acc: 0.9613 - val_f1: 0.9621\n",
      "Epoch 458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2109 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8570 - f1: 0.8766 - val_loss: 0.2008 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8650 - f1: 0.8828 - val_loss: 0.2016 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8542 - f1: 0.8745 - val_loss: 0.2080 - val_acc: 0.9569 - val_f1: 0.9596\n",
      "Epoch 462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8616 - f1: 0.8803 - val_loss: 0.2076 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2031 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2049 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8617 - f1: 0.8808 - val_loss: 0.2013 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8613 - f1: 0.8800 - val_loss: 0.2052 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8796 - val_loss: 0.2074 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8613 - f1: 0.8801 - val_loss: 0.2172 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8611 - f1: 0.8799 - val_loss: 0.2010 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8608 - f1: 0.8792 - val_loss: 0.2047 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8549 - f1: 0.8750 - val_loss: 0.2018 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8593 - f1: 0.8784 - val_loss: 0.2042 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8658 - f1: 0.8832 - val_loss: 0.1973 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8576 - f1: 0.8771 - val_loss: 0.2175 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8602 - f1: 0.8788 - val_loss: 0.2049 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.1957 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8600 - f1: 0.8789 - val_loss: 0.2041 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8633 - f1: 0.8809 - val_loss: 0.2113 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8602 - f1: 0.8795 - val_loss: 0.1948 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2118 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.2016 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8641 - f1: 0.8819 - val_loss: 0.2008 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8678 - f1: 0.8854 - val_loss: 0.2019 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8620 - f1: 0.8812 - val_loss: 0.2003 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.2038 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2101 - val_acc: 0.9578 - val_f1: 0.9600\n",
      "Epoch 487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2001 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8612 - f1: 0.8802 - val_loss: 0.2075 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2051 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8614 - f1: 0.8803 - val_loss: 0.2002 - val_acc: 0.9669 - val_f1: 0.9688\n",
      "Epoch 491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8612 - f1: 0.8798 - val_loss: 0.2093 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8580 - f1: 0.8772 - val_loss: 0.2113 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8554 - f1: 0.8753 - val_loss: 0.2056 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8588 - f1: 0.8786 - val_loss: 0.2068 - val_acc: 0.9631 - val_f1: 0.9651\n",
      "Epoch 495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2139 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.2068 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2216 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 498/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3452 - acc: 0.8617 - f1: 0.8804 - val_loss: 0.2105 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8632 - f1: 0.8812 - val_loss: 0.2116 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 500/5000\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3439 - acc: 0.8609 - f1: 0.8801 - val_loss: 0.2090 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 501/5000\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3478 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.2111 - val_acc: 0.9556 - val_f1: 0.9583\n",
      "Epoch 502/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3544 - acc: 0.8565 - f1: 0.8759 - val_loss: 0.2189 - val_acc: 0.9503 - val_f1: 0.9537\n",
      "Epoch 503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2060 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8660 - f1: 0.8833 - val_loss: 0.2015 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8608 - f1: 0.8797 - val_loss: 0.2121 - val_acc: 0.9591 - val_f1: 0.9608\n",
      "Epoch 506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2090 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8607 - f1: 0.8794 - val_loss: 0.2160 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8798 - val_loss: 0.2045 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8590 - f1: 0.8785 - val_loss: 0.2040 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 510/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2040 - val_acc: 0.9600 - val_f1: 0.9623\n",
      "Epoch 511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2031 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8644 - f1: 0.8826 - val_loss: 0.2039 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8598 - f1: 0.8792 - val_loss: 0.2109 - val_acc: 0.9553 - val_f1: 0.9578\n",
      "Epoch 514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8596 - f1: 0.8786 - val_loss: 0.2077 - val_acc: 0.9591 - val_f1: 0.9616\n",
      "Epoch 515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8597 - f1: 0.8788 - val_loss: 0.2026 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8659 - f1: 0.8832 - val_loss: 0.2062 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3518 - acc: 0.8566 - f1: 0.8761 - val_loss: 0.2031 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2143 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 519/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3435 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2132 - val_acc: 0.9531 - val_f1: 0.9557\n",
      "Epoch 520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8610 - f1: 0.8802 - val_loss: 0.2189 - val_acc: 0.9550 - val_f1: 0.9568\n",
      "Epoch 521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8651 - f1: 0.8826 - val_loss: 0.2039 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 522/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8627 - f1: 0.8807 - val_loss: 0.2058 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8572 - f1: 0.8772 - val_loss: 0.2015 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8615 - f1: 0.8801 - val_loss: 0.2177 - val_acc: 0.9541 - val_f1: 0.9563\n",
      "Epoch 525/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3492 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2025 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8547 - f1: 0.8747 - val_loss: 0.2074 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 527/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8622 - f1: 0.8811 - val_loss: 0.2019 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2049 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8624 - f1: 0.8813 - val_loss: 0.2188 - val_acc: 0.9506 - val_f1: 0.9535\n",
      "Epoch 530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2052 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8571 - f1: 0.8770 - val_loss: 0.1971 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8647 - f1: 0.8827 - val_loss: 0.2015 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8646 - f1: 0.8830 - val_loss: 0.2027 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2199 - val_acc: 0.9491 - val_f1: 0.9526\n",
      "Epoch 535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8603 - f1: 0.8795 - val_loss: 0.1990 - val_acc: 0.9631 - val_f1: 0.9654\n",
      "Epoch 536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8606 - f1: 0.8798 - val_loss: 0.2063 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3494 - acc: 0.8592 - f1: 0.8788 - val_loss: 0.2045 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2063 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3452 - acc: 0.8600 - f1: 0.8789 - val_loss: 0.2049 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 540/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3405 - acc: 0.8645 - f1: 0.8825 - val_loss: 0.2201 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 541/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3426 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2110 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 542/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3461 - acc: 0.8618 - f1: 0.8804 - val_loss: 0.2094 - val_acc: 0.9578 - val_f1: 0.9600\n",
      "Epoch 543/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8650 - f1: 0.8827 - val_loss: 0.2057 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8575 - f1: 0.8772 - val_loss: 0.2201 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3577 - acc: 0.8556 - f1: 0.8755 - val_loss: 0.2020 - val_acc: 0.9644 - val_f1: 0.9665\n",
      "Epoch 546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8571 - f1: 0.8768 - val_loss: 0.2058 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2086 - val_acc: 0.9559 - val_f1: 0.9581\n",
      "Epoch 548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8618 - f1: 0.8806 - val_loss: 0.2069 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2031 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8633 - f1: 0.8819 - val_loss: 0.2202 - val_acc: 0.9534 - val_f1: 0.9569\n",
      "Epoch 551/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3542 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2009 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8607 - f1: 0.8799 - val_loss: 0.2132 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8628 - f1: 0.8815 - val_loss: 0.2056 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8584 - f1: 0.8781 - val_loss: 0.2008 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8611 - f1: 0.8803 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8631 - f1: 0.8816 - val_loss: 0.2142 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2049 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8578 - f1: 0.8769 - val_loss: 0.2080 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8612 - f1: 0.8797 - val_loss: 0.2189 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8659 - f1: 0.8835 - val_loss: 0.2036 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8609 - f1: 0.8796 - val_loss: 0.2057 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8581 - f1: 0.8771 - val_loss: 0.2082 - val_acc: 0.9681 - val_f1: 0.9699\n",
      "Epoch 563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8625 - f1: 0.8808 - val_loss: 0.2112 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8607 - f1: 0.8792 - val_loss: 0.2103 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8588 - f1: 0.8788 - val_loss: 0.2126 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3541 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.2026 - val_acc: 0.9691 - val_f1: 0.9709\n",
      "Epoch 567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.2154 - val_acc: 0.9544 - val_f1: 0.9572\n",
      "Epoch 568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3450 - acc: 0.8601 - f1: 0.8796 - val_loss: 0.2026 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8613 - f1: 0.8803 - val_loss: 0.2060 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8664 - f1: 0.8841 - val_loss: 0.2095 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8573 - f1: 0.8769 - val_loss: 0.2081 - val_acc: 0.9609 - val_f1: 0.9632\n",
      "Epoch 572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2088 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8645 - f1: 0.8826 - val_loss: 0.2153 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8609 - f1: 0.8801 - val_loss: 0.2102 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3543 - acc: 0.8557 - f1: 0.8760 - val_loss: 0.1987 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2018 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2080 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.2098 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2064 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8811 - val_loss: 0.1959 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2075 - val_acc: 0.9566 - val_f1: 0.9589\n",
      "Epoch 582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8609 - f1: 0.8798 - val_loss: 0.2078 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8672 - f1: 0.8847 - val_loss: 0.2204 - val_acc: 0.9603 - val_f1: 0.9618\n",
      "Epoch 584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8572 - f1: 0.8771 - val_loss: 0.2025 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2077 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2150 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8581 - f1: 0.8777 - val_loss: 0.2049 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8583 - f1: 0.8779 - val_loss: 0.2027 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8608 - f1: 0.8800 - val_loss: 0.2020 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8597 - f1: 0.8785 - val_loss: 0.2018 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2160 - val_acc: 0.9500 - val_f1: 0.9527\n",
      "Epoch 592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8575 - f1: 0.8774 - val_loss: 0.2175 - val_acc: 0.9544 - val_f1: 0.9571\n",
      "Epoch 593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8826 - val_loss: 0.2176 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3482 - acc: 0.8588 - f1: 0.8782 - val_loss: 0.2063 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8595 - f1: 0.8793 - val_loss: 0.2049 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.2066 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3509 - acc: 0.8563 - f1: 0.8763 - val_loss: 0.2093 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2128 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2201 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8611 - f1: 0.8796 - val_loss: 0.2020 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8627 - f1: 0.8812 - val_loss: 0.2145 - val_acc: 0.9559 - val_f1: 0.9581\n",
      "Epoch 603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2090 - val_acc: 0.9622 - val_f1: 0.9646\n",
      "Epoch 604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2032 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8643 - f1: 0.8823 - val_loss: 0.2001 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2128 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3556 - acc: 0.8575 - f1: 0.8772 - val_loss: 0.2096 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8585 - f1: 0.8779 - val_loss: 0.2016 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8674 - f1: 0.8849 - val_loss: 0.1988 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8654 - f1: 0.8834 - val_loss: 0.2065 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8673 - f1: 0.8845 - val_loss: 0.2080 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3439 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2001 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2049 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8673 - f1: 0.8841 - val_loss: 0.2108 - val_acc: 0.9525 - val_f1: 0.9554\n",
      "Epoch 615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.1988 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8642 - f1: 0.8825 - val_loss: 0.2109 - val_acc: 0.9541 - val_f1: 0.9574\n",
      "Epoch 617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8610 - f1: 0.8802 - val_loss: 0.2082 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8650 - f1: 0.8829 - val_loss: 0.2112 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8636 - f1: 0.8821 - val_loss: 0.2054 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8599 - f1: 0.8795 - val_loss: 0.2136 - val_acc: 0.9581 - val_f1: 0.9607\n",
      "Epoch 621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8612 - f1: 0.8800 - val_loss: 0.2098 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8650 - f1: 0.8830 - val_loss: 0.2060 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8598 - f1: 0.8791 - val_loss: 0.2014 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8655 - f1: 0.8835 - val_loss: 0.2140 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2090 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8827 - val_loss: 0.2127 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8560 - f1: 0.8760 - val_loss: 0.2078 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8628 - f1: 0.8818 - val_loss: 0.2063 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8613 - f1: 0.8805 - val_loss: 0.2118 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2108 - val_acc: 0.9581 - val_f1: 0.9597\n",
      "Epoch 631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2102 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8644 - f1: 0.8827 - val_loss: 0.2183 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8569 - f1: 0.8767 - val_loss: 0.2106 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2122 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8583 - f1: 0.8777 - val_loss: 0.2080 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8610 - f1: 0.8797 - val_loss: 0.2053 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8661 - f1: 0.8837 - val_loss: 0.2012 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8664 - f1: 0.8839 - val_loss: 0.2056 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2093 - val_acc: 0.9597 - val_f1: 0.9621\n",
      "Epoch 640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8637 - f1: 0.8819 - val_loss: 0.2113 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8611 - f1: 0.8800 - val_loss: 0.2075 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8609 - f1: 0.8798 - val_loss: 0.2157 - val_acc: 0.9556 - val_f1: 0.9579\n",
      "Epoch 643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2103 - val_acc: 0.9569 - val_f1: 0.9595\n",
      "Epoch 644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8605 - f1: 0.8800 - val_loss: 0.2059 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2052 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8631 - f1: 0.8817 - val_loss: 0.2182 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8595 - f1: 0.8788 - val_loss: 0.2089 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2093 - val_acc: 0.9566 - val_f1: 0.9594\n",
      "Epoch 649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8634 - f1: 0.8809 - val_loss: 0.2094 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2016 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3505 - acc: 0.8571 - f1: 0.8770 - val_loss: 0.2094 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 652/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2180 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2090 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3465 - acc: 0.8595 - f1: 0.8784 - val_loss: 0.2023 - val_acc: 0.9684 - val_f1: 0.9696\n",
      "Epoch 655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3465 - acc: 0.8618 - f1: 0.8802 - val_loss: 0.2176 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 656/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.2065 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2076 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 658/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2153 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3509 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2004 - val_acc: 0.9691 - val_f1: 0.9705\n",
      "Epoch 660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2033 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 661/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3436 - acc: 0.8617 - f1: 0.8804 - val_loss: 0.2092 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 662/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3502 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2066 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8634 - f1: 0.8815 - val_loss: 0.2229 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8679 - f1: 0.8852 - val_loss: 0.2098 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8613 - f1: 0.8807 - val_loss: 0.2049 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 666/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3454 - acc: 0.8637 - f1: 0.8820 - val_loss: 0.2056 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 667/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.2041 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2101 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2064 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 670/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2063 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8607 - f1: 0.8795 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 672/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8620 - f1: 0.8802 - val_loss: 0.2204 - val_acc: 0.9547 - val_f1: 0.9575\n",
      "Epoch 673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8575 - f1: 0.8769 - val_loss: 0.2173 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8576 - f1: 0.8772 - val_loss: 0.2086 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8600 - f1: 0.8795 - val_loss: 0.2181 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 676/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3476 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2124 - val_acc: 0.9563 - val_f1: 0.9584\n",
      "Epoch 677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8642 - f1: 0.8823 - val_loss: 0.2179 - val_acc: 0.9528 - val_f1: 0.9553\n",
      "Epoch 678/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3570 - acc: 0.8548 - f1: 0.8750 - val_loss: 0.2123 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8660 - f1: 0.8838 - val_loss: 0.2081 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.2117 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 681/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3349 - acc: 0.8668 - f1: 0.8844 - val_loss: 0.2094 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 682/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8689 - f1: 0.8858 - val_loss: 0.2081 - val_acc: 0.9575 - val_f1: 0.9597\n",
      "Epoch 683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3578 - acc: 0.8533 - f1: 0.8747 - val_loss: 0.2173 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8594 - f1: 0.8791 - val_loss: 0.2300 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8614 - f1: 0.8805 - val_loss: 0.2108 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2322 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2027 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8605 - f1: 0.8798 - val_loss: 0.2026 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2111 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2281 - val_acc: 0.9606 - val_f1: 0.9611\n",
      "Epoch 691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2058 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2043 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8593 - f1: 0.8779 - val_loss: 0.2106 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8611 - f1: 0.8798 - val_loss: 0.2048 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8642 - f1: 0.8823 - val_loss: 0.2227 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 696/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3451 - acc: 0.8612 - f1: 0.8806 - val_loss: 0.2143 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 697/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2110 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8580 - f1: 0.8779 - val_loss: 0.2070 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8658 - f1: 0.8835 - val_loss: 0.2074 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8619 - f1: 0.8811 - val_loss: 0.2116 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8657 - f1: 0.8838 - val_loss: 0.2120 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8606 - f1: 0.8802 - val_loss: 0.2116 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 703/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2088 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8564 - f1: 0.8765 - val_loss: 0.2055 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 705/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3441 - acc: 0.8609 - f1: 0.8806 - val_loss: 0.2096 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8808 - val_loss: 0.2129 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 707/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2059 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2105 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 709/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3380 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2103 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2087 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8635 - f1: 0.8818 - val_loss: 0.2162 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8591 - f1: 0.8783 - val_loss: 0.2061 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 713/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8632 - f1: 0.8812 - val_loss: 0.2132 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2092 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8612 - f1: 0.8800 - val_loss: 0.2099 - val_acc: 0.9578 - val_f1: 0.9607\n",
      "Epoch 716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8598 - f1: 0.8794 - val_loss: 0.2114 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 717/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3441 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2126 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8594 - f1: 0.8787 - val_loss: 0.2161 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2010 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2086 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2229 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8631 - f1: 0.8818 - val_loss: 0.2143 - val_acc: 0.9609 - val_f1: 0.9634\n",
      "Epoch 723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8567 - f1: 0.8771 - val_loss: 0.2132 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8595 - f1: 0.8783 - val_loss: 0.2040 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2056 - val_acc: 0.9656 - val_f1: 0.9677\n",
      "Epoch 726/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3358 - acc: 0.8646 - f1: 0.88 - 0s 16us/sample - loss: 0.3361 - acc: 0.8646 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3379 - acc: 0.8649 - f1: 0.8828 - val_loss: 0.2113 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 728/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3466 - acc: 0.8602 - f1: 0.8791 - val_loss: 0.2064 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 729/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3473 - acc: 0.8599 - f1: 0.88 - 0s 16us/sample - loss: 0.3463 - acc: 0.8598 - f1: 0.8795 - val_loss: 0.2076 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2140 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2138 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8650 - f1: 0.8829 - val_loss: 0.2074 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8629 - f1: 0.8817 - val_loss: 0.2089 - val_acc: 0.9553 - val_f1: 0.9575\n",
      "Epoch 734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2130 - val_acc: 0.9663 - val_f1: 0.9664\n",
      "Epoch 735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8608 - f1: 0.8797 - val_loss: 0.2120 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2150 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 737/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3505 - acc: 0.8591 - f1: 0.8785 - val_loss: 0.2220 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 738/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8628 - f1: 0.8814 - val_loss: 0.2072 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8613 - f1: 0.8801 - val_loss: 0.2090 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 740/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3383 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2016 - val_acc: 0.9606 - val_f1: 0.9632\n",
      "Epoch 741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8630 - f1: 0.8813 - val_loss: 0.2057 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8570 - f1: 0.8772 - val_loss: 0.2088 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8577 - f1: 0.8772 - val_loss: 0.2099 - val_acc: 0.9638 - val_f1: 0.9660\n",
      "Epoch 744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8810 - val_loss: 0.2114 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8645 - f1: 0.8825 - val_loss: 0.2222 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3398 - acc: 0.8653 - f1: 0.8829 - val_loss: 0.2226 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2126 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2273 - val_acc: 0.9447 - val_f1: 0.9485\n",
      "Epoch 749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8652 - f1: 0.8826 - val_loss: 0.2140 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8607 - f1: 0.8797 - val_loss: 0.2130 - val_acc: 0.9634 - val_f1: 0.9640\n",
      "Epoch 751/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8641 - f1: 0.8822 - val_loss: 0.2094 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 752/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2082 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2090 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 754/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3368 - acc: 0.8649 - f1: 0.8830 - val_loss: 0.2142 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2098 - val_acc: 0.9688 - val_f1: 0.9706\n",
      "Epoch 756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8660 - f1: 0.8836 - val_loss: 0.2222 - val_acc: 0.9531 - val_f1: 0.9560\n",
      "Epoch 757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.2150 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 758/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3536 - acc: 0.8563 - f1: 0.8762 - val_loss: 0.2097 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2199 - val_acc: 0.9522 - val_f1: 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8642 - f1: 0.8824 - val_loss: 0.2088 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 761/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3380 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2097 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 762/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3370 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2050 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2122 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 764/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2053 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 765/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2059 - val_acc: 0.9584 - val_f1: 0.9600\n",
      "Epoch 766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8611 - f1: 0.8801 - val_loss: 0.2278 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8638 - f1: 0.8819 - val_loss: 0.2096 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8593 - f1: 0.8791 - val_loss: 0.2141 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8639 - f1: 0.8815 - val_loss: 0.2209 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8669 - f1: 0.8850 - val_loss: 0.2400 - val_acc: 0.9606 - val_f1: 0.9614\n",
      "Epoch 773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8692 - f1: 0.8862 - val_loss: 0.2163 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2201 - val_acc: 0.9553 - val_f1: 0.9577\n",
      "Epoch 775/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3411 - acc: 0.8639 - f1: 0.8821 - val_loss: 0.2156 - val_acc: 0.9522 - val_f1: 0.9550\n",
      "Epoch 776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8615 - f1: 0.8803 - val_loss: 0.2063 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8602 - f1: 0.8794 - val_loss: 0.2038 - val_acc: 0.9669 - val_f1: 0.9688\n",
      "Epoch 778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.2095 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2147 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8607 - f1: 0.8798 - val_loss: 0.2081 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8625 - f1: 0.8812 - val_loss: 0.2057 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2053 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8647 - f1: 0.8828 - val_loss: 0.2080 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2075 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8628 - f1: 0.8817 - val_loss: 0.2137 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2162 - val_acc: 0.9556 - val_f1: 0.9576\n",
      "Epoch 787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8603 - f1: 0.8797 - val_loss: 0.2202 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2110 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2072 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3503 - acc: 0.8570 - f1: 0.8772 - val_loss: 0.2230 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8612 - f1: 0.8802 - val_loss: 0.2142 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8618 - f1: 0.8809 - val_loss: 0.2155 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3530 - acc: 0.8580 - f1: 0.8771 - val_loss: 0.2197 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2045 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2081 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 796/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3406 - acc: 0.8624 - f1: 0.88 - 0s 16us/sample - loss: 0.3411 - acc: 0.8625 - f1: 0.8815 - val_loss: 0.2230 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 797/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8642 - f1: 0.8821 - val_loss: 0.2250 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 798/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3457 - acc: 0.8612 - f1: 0.8806 - val_loss: 0.2124 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 799/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3485 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.2104 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 800/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3477 - acc: 0.8592 - f1: 0.8787 - val_loss: 0.2077 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8618 - f1: 0.8802 - val_loss: 0.2086 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8654 - f1: 0.8827 - val_loss: 0.2181 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2177 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8622 - f1: 0.8815 - val_loss: 0.2085 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2235 - val_acc: 0.9484 - val_f1: 0.9518\n",
      "Epoch 806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2035 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 807/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3477 - acc: 0.8590 - f1: 0.8788 - val_loss: 0.2070 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2040 - val_acc: 0.9672 - val_f1: 0.9691\n",
      "Epoch 809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2304 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2091 - val_acc: 0.9609 - val_f1: 0.9625\n",
      "Epoch 811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8640 - f1: 0.8822 - val_loss: 0.2075 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8655 - f1: 0.8831 - val_loss: 0.2062 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2082 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8597 - f1: 0.8790 - val_loss: 0.2084 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2139 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8703 - f1: 0.8874 - val_loss: 0.2156 - val_acc: 0.9522 - val_f1: 0.9553\n",
      "Epoch 817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2122 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8832 - val_loss: 0.2247 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8624 - f1: 0.8812 - val_loss: 0.2135 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2096 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8562 - f1: 0.8766 - val_loss: 0.2279 - val_acc: 0.9631 - val_f1: 0.9637\n",
      "Epoch 822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2076 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2027 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8675 - f1: 0.8851 - val_loss: 0.2136 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8665 - f1: 0.8843 - val_loss: 0.2218 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2100 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2113 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2112 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8610 - f1: 0.8801 - val_loss: 0.2111 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2076 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8637 - f1: 0.8821 - val_loss: 0.2091 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8580 - f1: 0.8776 - val_loss: 0.2191 - val_acc: 0.9491 - val_f1: 0.9523\n",
      "Epoch 833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3511 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.2082 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2126 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8595 - f1: 0.8784 - val_loss: 0.2131 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2081 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2064 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8658 - f1: 0.8835 - val_loss: 0.2091 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8660 - f1: 0.8839 - val_loss: 0.2087 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2195 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2085 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2164 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8653 - f1: 0.8832 - val_loss: 0.2078 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8696 - f1: 0.8865 - val_loss: 0.2097 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2131 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 846/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3324 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2106 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8636 - f1: 0.8823 - val_loss: 0.2289 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8641 - f1: 0.8832 - val_loss: 0.2114 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2048 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2151 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8624 - f1: 0.8814 - val_loss: 0.2127 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2320 - val_acc: 0.9416 - val_f1: 0.9453\n",
      "Epoch 853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8622 - f1: 0.8808 - val_loss: 0.2040 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2001 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2069 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2059 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 857/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3299 - acc: 0.8702 - f1: 0.8868 - val_loss: 0.2129 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2077 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2136 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3587 - acc: 0.8528 - f1: 0.8736 - val_loss: 0.2071 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8636 - f1: 0.8818 - val_loss: 0.2133 - val_acc: 0.9547 - val_f1: 0.9572\n",
      "Epoch 862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8637 - f1: 0.8821 - val_loss: 0.2138 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 863/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3385 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2092 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8651 - f1: 0.8830 - val_loss: 0.2166 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 865/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2090 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8576 - f1: 0.8776 - val_loss: 0.2155 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3450 - acc: 0.8610 - f1: 0.8803 - val_loss: 0.2127 - val_acc: 0.9566 - val_f1: 0.9592\n",
      "Epoch 868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2094 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2103 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2135 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8621 - f1: 0.8810 - val_loss: 0.2117 - val_acc: 0.9550 - val_f1: 0.9572\n",
      "Epoch 872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8824 - val_loss: 0.2041 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 874/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2158 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 875/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2085 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8598 - f1: 0.8792 - val_loss: 0.2175 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2076 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8657 - f1: 0.8835 - val_loss: 0.2035 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2065 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2132 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8630 - f1: 0.8816 - val_loss: 0.2087 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2134 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8625 - f1: 0.8809 - val_loss: 0.2155 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2148 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2128 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8677 - f1: 0.8850 - val_loss: 0.2080 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 887/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3317 - acc: 0.8692 - f1: 0.8859 - val_loss: 0.2132 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 888/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3427 - acc: 0.8616 - f1: 0.8801 - val_loss: 0.2244 - val_acc: 0.9497 - val_f1: 0.9526\n",
      "Epoch 889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8629 - f1: 0.8816 - val_loss: 0.2104 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 890/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3345 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2160 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 891/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2162 - val_acc: 0.9531 - val_f1: 0.9563\n",
      "Epoch 892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2247 - val_acc: 0.9541 - val_f1: 0.9567\n",
      "Epoch 893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8612 - f1: 0.8804 - val_loss: 0.2075 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8661 - f1: 0.8842 - val_loss: 0.2240 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 895/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3366 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2052 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2110 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2119 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 898/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3402 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 899/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3426 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2352 - val_acc: 0.9447 - val_f1: 0.9486\n",
      "Epoch 900/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3357 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2103 - val_acc: 0.9566 - val_f1: 0.9593\n",
      "Epoch 901/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8607 - f1: 0.8799 - val_loss: 0.2154 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2099 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2529 - val_acc: 0.9613 - val_f1: 0.9617\n",
      "Epoch 904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8667 - f1: 0.8842 - val_loss: 0.2133 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8637 - f1: 0.8818 - val_loss: 0.2169 - val_acc: 0.9650 - val_f1: 0.9652\n",
      "Epoch 906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2198 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2204 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 908/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3452 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2270 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2188 - val_acc: 0.9572 - val_f1: 0.9595\n",
      "Epoch 910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8614 - f1: 0.8800 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 911/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3376 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2088 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8631 - f1: 0.8822 - val_loss: 0.2185 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2064 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2128 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2093 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 916/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3344 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2122 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 917/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3375 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2089 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 918/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8835 - val_loss: 0.1988 - val_acc: 0.9659 - val_f1: 0.9682\n",
      "Epoch 919/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8672 - f1: 0.8848 - val_loss: 0.2133 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8615 - f1: 0.8805 - val_loss: 0.2094 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8639 - f1: 0.8829 - val_loss: 0.2173 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 922/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2189 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 923/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2109 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 924/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3421 - acc: 0.8624 - f1: 0.8813 - val_loss: 0.2227 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8661 - f1: 0.8843 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 926/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8643 - f1: 0.8829 - val_loss: 0.2102 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8638 - f1: 0.8815 - val_loss: 0.2134 - val_acc: 0.9625 - val_f1: 0.9647\n",
      "Epoch 928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2140 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2123 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8698 - f1: 0.8865 - val_loss: 0.2170 - val_acc: 0.9594 - val_f1: 0.9619\n",
      "Epoch 931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2073 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8584 - f1: 0.8781 - val_loss: 0.2229 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2261 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2149 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8638 - f1: 0.8827 - val_loss: 0.2068 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 936/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3396 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2207 - val_acc: 0.9600 - val_f1: 0.9609\n",
      "Epoch 937/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3526 - acc: 0.8566 - f1: 0.8772 - val_loss: 0.2285 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2183 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 939/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3472 - acc: 0.8588 - f1: 0.8778 - val_loss: 0.2154 - val_acc: 0.9575 - val_f1: 0.9600\n",
      "Epoch 940/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2146 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 941/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3385 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2240 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 942/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2185 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 943/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2053 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 944/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3427 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2391 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8648 - f1: 0.8839 - val_loss: 0.2041 - val_acc: 0.9647 - val_f1: 0.9666\n",
      "Epoch 946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2098 - val_acc: 0.9650 - val_f1: 0.9670\n",
      "Epoch 947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8624 - f1: 0.8812 - val_loss: 0.2168 - val_acc: 0.9556 - val_f1: 0.9577\n",
      "Epoch 948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8639 - f1: 0.8824 - val_loss: 0.2062 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8631 - f1: 0.8817 - val_loss: 0.2055 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8630 - f1: 0.8814 - val_loss: 0.2101 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 951/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3389 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2218 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2168 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3511 - acc: 0.8569 - f1: 0.8773 - val_loss: 0.2132 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2253 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2144 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 956/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3431 - acc: 0.8630 - f1: 0.8815 - val_loss: 0.2186 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 957/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3378 - acc: 0.8658 - f1: 0.8839 - val_loss: 0.2118 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8667 - f1: 0.8842 - val_loss: 0.2139 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8652 - f1: 0.8830 - val_loss: 0.2045 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2232 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8625 - f1: 0.8813 - val_loss: 0.2221 - val_acc: 0.9522 - val_f1: 0.9555\n",
      "Epoch 962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8630 - f1: 0.8816 - val_loss: 0.2143 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2073 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2114 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8635 - f1: 0.8821 - val_loss: 0.2103 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8602 - f1: 0.8794 - val_loss: 0.2117 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2071 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2049 - val_acc: 0.9669 - val_f1: 0.9689\n",
      "Epoch 969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2130 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 970/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3407 - acc: 0.8640 - f1: 0.8823 - val_loss: 0.2119 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 971/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2119 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 972/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3333 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2065 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 973/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3371 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2113 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 974/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2157 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8689 - f1: 0.8858 - val_loss: 0.2111 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8648 - f1: 0.8827 - val_loss: 0.2075 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8651 - f1: 0.8832 - val_loss: 0.2176 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 978/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2102 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 979/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8700 - f1: 0.8871 - val_loss: 0.2106 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2030 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 981/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3411 - acc: 0.8625 - f1: 0.88 - 0s 16us/sample - loss: 0.3374 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2078 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8806 - val_loss: 0.2087 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8571 - f1: 0.8775 - val_loss: 0.2237 - val_acc: 0.9438 - val_f1: 0.9476\n",
      "Epoch 984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2006 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8677 - f1: 0.8847 - val_loss: 0.2067 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2196 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2164 - val_acc: 0.9550 - val_f1: 0.9575\n",
      "Epoch 988/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3366 - acc: 0.8650 - f1: 0.8833 - val_loss: 0.2244 - val_acc: 0.9606 - val_f1: 0.9616\n",
      "Epoch 989/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2208 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 990/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2069 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2128 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2167 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8625 - f1: 0.8813 - val_loss: 0.2276 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 994/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3361 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2132 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 995/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8645 - f1: 0.8834 - val_loss: 0.2136 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8616 - f1: 0.8808 - val_loss: 0.2107 - val_acc: 0.9659 - val_f1: 0.9679\n",
      "Epoch 997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8673 - f1: 0.8848 - val_loss: 0.2336 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2525 - val_acc: 0.9522 - val_f1: 0.9533\n",
      "Epoch 999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8580 - f1: 0.8781 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2112 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2316 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8857 - val_loss: 0.2244 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2152 - val_acc: 0.9566 - val_f1: 0.9585\n",
      "Epoch 1004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8631 - f1: 0.8818 - val_loss: 0.2248 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 1005/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3364 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2246 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2173 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 1007/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3514 - acc: 0.8582 - f1: 0.8775 - val_loss: 0.2212 - val_acc: 0.9663 - val_f1: 0.9666\n",
      "Epoch 1008/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2345 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1009/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8686 - f1: 0.8859 - val_loss: 0.2108 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1010/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2110 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8643 - f1: 0.8830 - val_loss: 0.2078 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2063 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 1013/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3368 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2287 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2173 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2051 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2076 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Epoch 1017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8809 - val_loss: 0.2058 - val_acc: 0.9659 - val_f1: 0.9681\n",
      "Epoch 1018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2252 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8603 - f1: 0.8796 - val_loss: 0.2113 - val_acc: 0.9566 - val_f1: 0.9590\n",
      "Epoch 1020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8584 - f1: 0.8782 - val_loss: 0.2300 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8696 - f1: 0.8867 - val_loss: 0.2123 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 1022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2098 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 1023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2130 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8659 - f1: 0.8836 - val_loss: 0.2065 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8665 - f1: 0.8850 - val_loss: 0.2196 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8654 - f1: 0.8833 - val_loss: 0.2175 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1027/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3542 - acc: 0.8573 - f1: 0.8767 - val_loss: 0.2257 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 1028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2124 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 1029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2115 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 1030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8615 - f1: 0.8805 - val_loss: 0.2561 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 1031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2212 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2313 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 1033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8655 - f1: 0.8833 - val_loss: 0.2161 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2187 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 1035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8684 - f1: 0.8858 - val_loss: 0.2098 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 1036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2107 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2041 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8593 - f1: 0.8791 - val_loss: 0.2216 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8607 - f1: 0.8800 - val_loss: 0.2201 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 1040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8632 - f1: 0.8813 - val_loss: 0.2124 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2094 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2144 - val_acc: 0.9703 - val_f1: 0.9719\n",
      "Epoch 1043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2378 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2077 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8668 - f1: 0.8843 - val_loss: 0.2251 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8640 - f1: 0.8826 - val_loss: 0.2181 - val_acc: 0.9634 - val_f1: 0.9659\n",
      "Epoch 1047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8579 - f1: 0.8778 - val_loss: 0.2189 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8678 - f1: 0.8854 - val_loss: 0.2064 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 1049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8848 - val_loss: 0.2027 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 1050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2092 - val_acc: 0.9625 - val_f1: 0.9645\n",
      "Epoch 1051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2124 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 1052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2210 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 1053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2125 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8613 - f1: 0.8803 - val_loss: 0.2142 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2062 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 1056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8668 - f1: 0.8843 - val_loss: 0.2061 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2128 - val_acc: 0.9547 - val_f1: 0.9573\n",
      "Epoch 1058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3525 - acc: 0.8567 - f1: 0.8766 - val_loss: 0.2255 - val_acc: 0.9556 - val_f1: 0.9567\n",
      "Epoch 1059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2240 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2108 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 1062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8620 - f1: 0.8808 - val_loss: 0.2197 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8665 - f1: 0.8839 - val_loss: 0.2186 - val_acc: 0.9566 - val_f1: 0.9582\n",
      "Epoch 1064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8635 - f1: 0.8824 - val_loss: 0.2088 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2177 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2234 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 1067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8616 - f1: 0.8811 - val_loss: 0.2157 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 1068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2170 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3451 - acc: 0.8610 - f1: 0.8804 - val_loss: 0.2105 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 1070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8629 - f1: 0.8812 - val_loss: 0.2056 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 1071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8698 - f1: 0.8864 - val_loss: 0.2192 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 1072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2097 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8708 - f1: 0.8875 - val_loss: 0.2136 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1074/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8636 - f1: 0.8823 - val_loss: 0.2186 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 1075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8851 - val_loss: 0.2213 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2127 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1077/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2265 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2066 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8669 - f1: 0.8847 - val_loss: 0.2190 - val_acc: 0.9550 - val_f1: 0.9570\n",
      "Epoch 1080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2061 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2148 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8648 - f1: 0.8829 - val_loss: 0.2395 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8675 - f1: 0.8849 - val_loss: 0.2078 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 1084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2106 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1085/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8602 - f1: 0.8799 - val_loss: 0.2149 - val_acc: 0.9609 - val_f1: 0.9625\n",
      "Epoch 1086/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2120 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1087/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2184 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1088/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2068 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1089/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8632 - f1: 0.8819 - val_loss: 0.2302 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2252 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 1091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8646 - f1: 0.8833 - val_loss: 0.2329 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 1092/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8599 - f1: 0.8794 - val_loss: 0.2165 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 1093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8634 - f1: 0.8819 - val_loss: 0.2128 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 1094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2141 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 1095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2159 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2221 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1097/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8646 - f1: 0.8832 - val_loss: 0.2232 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8676 - f1: 0.8851 - val_loss: 0.2191 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2176 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8865 - val_loss: 0.2100 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2266 - val_acc: 0.9566 - val_f1: 0.9579\n",
      "Epoch 1102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2236 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8653 - f1: 0.8833 - val_loss: 0.2189 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8696 - f1: 0.8867 - val_loss: 0.2198 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 1105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2140 - val_acc: 0.9666 - val_f1: 0.9684\n",
      "Epoch 1106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8646 - f1: 0.8829 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8845 - val_loss: 0.2137 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2221 - val_acc: 0.9553 - val_f1: 0.9580\n",
      "Epoch 1109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8630 - f1: 0.8815 - val_loss: 0.2187 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 1111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2247 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2221 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2175 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2201 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2196 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8645 - f1: 0.8828 - val_loss: 0.2395 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 1118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8648 - f1: 0.8834 - val_loss: 0.2308 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2294 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2118 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8632 - f1: 0.8819 - val_loss: 0.2179 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 1122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2288 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2326 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8640 - f1: 0.8826 - val_loss: 0.2198 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2159 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8599 - f1: 0.8793 - val_loss: 0.2210 - val_acc: 0.9519 - val_f1: 0.9545\n",
      "Epoch 1127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8640 - f1: 0.8820 - val_loss: 0.2124 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8640 - f1: 0.8822 - val_loss: 0.2153 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8629 - f1: 0.8816 - val_loss: 0.2129 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8656 - f1: 0.8834 - val_loss: 0.2102 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 1131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2168 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 1132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8665 - f1: 0.8843 - val_loss: 0.2119 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 1133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8603 - f1: 0.8800 - val_loss: 0.2174 - val_acc: 0.9575 - val_f1: 0.9594\n",
      "Epoch 1134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8843 - val_loss: 0.2221 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2392 - val_acc: 0.9616 - val_f1: 0.9623\n",
      "Epoch 1136/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2197 - val_acc: 0.9534 - val_f1: 0.9563\n",
      "Epoch 1137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2073 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 1138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8623 - f1: 0.8814 - val_loss: 0.2210 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8737 - f1: 0.8898 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8643 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8610 - f1: 0.8800 - val_loss: 0.2251 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1142/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3346 - acc: 0.8685 - f1: 0.8858 - val_loss: 0.2358 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1143/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2309 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 1144/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8627 - f1: 0.8815 - val_loss: 0.2147 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2114 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8720 - f1: 0.8886 - val_loss: 0.2137 - val_acc: 0.9597 - val_f1: 0.9619\n",
      "Epoch 1147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8674 - f1: 0.8849 - val_loss: 0.2125 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 1148/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2288 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 1149/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8851 - val_loss: 0.2166 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1150/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2220 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 1151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2019 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2125 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1153/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3471 - acc: 0.8595 - f1: 0.8793 - val_loss: 0.2061 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1154/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3435 - acc: 0.8602 - f1: 0.8797 - val_loss: 0.2257 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8642 - f1: 0.8820 - val_loss: 0.2190 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1156/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8851 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9670\n",
      "Epoch 1157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8647 - f1: 0.8828 - val_loss: 0.2174 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1158/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8816 - val_loss: 0.2212 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1159/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3443 - acc: 0.8606 - f1: 0.8800 - val_loss: 0.2117 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 1160/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8644 - f1: 0.8825 - val_loss: 0.2312 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2164 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1162/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8650 - f1: 0.8830 - val_loss: 0.2250 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8704 - f1: 0.8873 - val_loss: 0.2145 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 1164/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8638 - f1: 0.8824 - val_loss: 0.2189 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 1165/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2427 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 1166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2156 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8651 - f1: 0.8830 - val_loss: 0.2142 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1168/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3360 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2251 - val_acc: 0.9588 - val_f1: 0.9612\n",
      "Epoch 1169/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3431 - acc: 0.8622 - f1: 0.8815 - val_loss: 0.2178 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 1170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2186 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1171/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3301 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2127 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 1172/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2163 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1173/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3419 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2104 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1174/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3447 - acc: 0.8605 - f1: 0.8807 - val_loss: 0.2120 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2488 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 1176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2242 - val_acc: 0.9669 - val_f1: 0.9672\n",
      "Epoch 1177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2262 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 1178/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2293 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1179/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2405 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 1180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8627 - f1: 0.8817 - val_loss: 0.2534 - val_acc: 0.9606 - val_f1: 0.9615\n",
      "Epoch 1181/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3391 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2076 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 1182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2142 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 1183/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2178 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1185/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8728 - f1: 0.8893 - val_loss: 0.2366 - val_acc: 0.9394 - val_f1: 0.9437\n",
      "Epoch 1186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3496 - acc: 0.8601 - f1: 0.8791 - val_loss: 0.2057 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2121 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 1188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2154 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 1189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8672 - f1: 0.8850 - val_loss: 0.2305 - val_acc: 0.9531 - val_f1: 0.9551\n",
      "Epoch 1190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2334 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 1191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2286 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8657 - f1: 0.8834 - val_loss: 0.2281 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 1193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2073 - val_acc: 0.9572 - val_f1: 0.9594\n",
      "Epoch 1194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8618 - f1: 0.8808 - val_loss: 0.2194 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2226 - val_acc: 0.9578 - val_f1: 0.9593\n",
      "Epoch 1196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8624 - f1: 0.8814 - val_loss: 0.2193 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2159 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 1198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8593 - f1: 0.8793 - val_loss: 0.2155 - val_acc: 0.9522 - val_f1: 0.9557\n",
      "Epoch 1199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2199 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8671 - f1: 0.8854 - val_loss: 0.2160 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2199 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8654 - f1: 0.8834 - val_loss: 0.2221 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2282 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2287 - val_acc: 0.9550 - val_f1: 0.9579\n",
      "Epoch 1205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2341 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 1206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2214 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 1207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2193 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2279 - val_acc: 0.9678 - val_f1: 0.9683\n",
      "Epoch 1209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.2169 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 1210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2225 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2111 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 1212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2109 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2703 - val_acc: 0.9581 - val_f1: 0.9582\n",
      "Epoch 1214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8600 - f1: 0.8794 - val_loss: 0.2094 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2225 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2213 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 1217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2226 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8642 - f1: 0.8822 - val_loss: 0.2210 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2406 - val_acc: 0.9609 - val_f1: 0.9618\n",
      "Epoch 1220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2134 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8652 - f1: 0.8837 - val_loss: 0.2159 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8655 - f1: 0.8833 - val_loss: 0.2170 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 1224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2321 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2106 - val_acc: 0.9656 - val_f1: 0.9677\n",
      "Epoch 1226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2276 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 1227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8646 - f1: 0.8827 - val_loss: 0.2147 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8849 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9658\n",
      "Epoch 1229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2216 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8689 - f1: 0.8861 - val_loss: 0.2229 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2182 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2390 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 1234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2164 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1235/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3395 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2357 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 1236/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3381 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2247 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8672 - f1: 0.8843 - val_loss: 0.2493 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 1238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2185 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 1239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2233 - val_acc: 0.9563 - val_f1: 0.9587\n",
      "Epoch 1240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2233 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2392 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 1242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2101 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 1243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2529 - val_acc: 0.9563 - val_f1: 0.9568\n",
      "Epoch 1244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8640 - f1: 0.8821 - val_loss: 0.2147 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8704 - f1: 0.8873 - val_loss: 0.2240 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2144 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 1247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2223 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 1248/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3422 - acc: 0.8620 - f1: 0.8806 - val_loss: 0.2153 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 1249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2300 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 1250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2095 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2089 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2121 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2135 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2207 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2377 - val_acc: 0.9397 - val_f1: 0.9442\n",
      "Epoch 1256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8577 - f1: 0.8775 - val_loss: 0.2194 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1257/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8640 - f1: 0.8830 - val_loss: 0.2110 - val_acc: 0.9591 - val_f1: 0.9617\n",
      "Epoch 1258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2319 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 1259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2099 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 1260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2118 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 1261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8704 - f1: 0.8868 - val_loss: 0.2180 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 1262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8636 - f1: 0.8825 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1264/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2240 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8627 - f1: 0.8809 - val_loss: 0.2127 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2069 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 1267/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3429 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2109 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2128 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1269/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2286 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2286 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2396 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2121 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1273/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3444 - acc: 0.8602 - f1: 0.8797 - val_loss: 0.2106 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 1274/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3357 - acc: 0.8651 - f1: 0.8834 - val_loss: 0.2204 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1275/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3369 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2423 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 1276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8561 - f1: 0.8762 - val_loss: 0.2129 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1277/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2158 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8639 - f1: 0.8824 - val_loss: 0.2336 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 1279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8820 - val_loss: 0.2163 - val_acc: 0.9581 - val_f1: 0.9608\n",
      "Epoch 1280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8694 - f1: 0.8863 - val_loss: 0.2039 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2183 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 1282/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8635 - f1: 0.8825 - val_loss: 0.2298 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2129 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2467 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2172 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8696 - f1: 0.8868 - val_loss: 0.2132 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2235 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2117 - val_acc: 0.9613 - val_f1: 0.9636\n",
      "Epoch 1289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2321 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2234 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 1291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2353 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2118 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2224 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 1294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2081 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 1295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2105 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 1296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2066 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 1297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8639 - f1: 0.8827 - val_loss: 0.2216 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2334 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 1299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2101 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2152 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 1302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2069 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2116 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 1304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8681 - f1: 0.8855 - val_loss: 0.2288 - val_acc: 0.9494 - val_f1: 0.9530\n",
      "Epoch 1305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2117 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2208 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8716 - f1: 0.8881 - val_loss: 0.2210 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2177 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 1309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2188 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2282 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2225 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2398 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2090 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 1314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2489 - val_acc: 0.9319 - val_f1: 0.9371\n",
      "Epoch 1315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3564 - acc: 0.8551 - f1: 0.8752 - val_loss: 0.2128 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2324 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 1317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2302 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 1318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2228 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8650 - f1: 0.8828 - val_loss: 0.2155 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2133 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2259 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8638 - f1: 0.8824 - val_loss: 0.2269 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2105 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 1324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2173 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2259 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 1327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2199 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8622 - f1: 0.8814 - val_loss: 0.2213 - val_acc: 0.9578 - val_f1: 0.9605\n",
      "Epoch 1329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8810 - val_loss: 0.2132 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2233 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2108 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2224 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2202 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 1334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2136 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8693 - f1: 0.8865 - val_loss: 0.2256 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8611 - f1: 0.8803 - val_loss: 0.2350 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 1337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2177 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2076 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 1339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2403 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 1340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2291 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2237 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2368 - val_acc: 0.9475 - val_f1: 0.9504\n",
      "Epoch 1343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8558 - f1: 0.8769 - val_loss: 0.2143 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2156 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2115 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8705 - f1: 0.8872 - val_loss: 0.2303 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8874 - val_loss: 0.2134 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8693 - f1: 0.8863 - val_loss: 0.2177 - val_acc: 0.9534 - val_f1: 0.9560\n",
      "Epoch 1349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2147 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 1350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2106 - val_acc: 0.9625 - val_f1: 0.9648\n",
      "Epoch 1351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8665 - f1: 0.8842 - val_loss: 0.2227 - val_acc: 0.9553 - val_f1: 0.9584\n",
      "Epoch 1352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2178 - val_acc: 0.9519 - val_f1: 0.9544\n",
      "Epoch 1353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2158 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2435 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8649 - f1: 0.8830 - val_loss: 0.2434 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8624 - f1: 0.8809 - val_loss: 0.2112 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2215 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 1358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8633 - f1: 0.8824 - val_loss: 0.2139 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2336 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 1361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2181 - val_acc: 0.9675 - val_f1: 0.9693\n",
      "Epoch 1362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8714 - f1: 0.8880 - val_loss: 0.2357 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 1363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2111 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2137 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2438 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 1366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2292 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 1367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2189 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8845 - val_loss: 0.2269 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8660 - f1: 0.8840 - val_loss: 0.2255 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2358 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1371/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2209 - val_acc: 0.9572 - val_f1: 0.9589\n",
      "Epoch 1372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2198 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2141 - val_acc: 0.9594 - val_f1: 0.9619\n",
      "Epoch 1374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8670 - f1: 0.8854 - val_loss: 0.2241 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8656 - f1: 0.8842 - val_loss: 0.2109 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 1376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2282 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8668 - f1: 0.8845 - val_loss: 0.2249 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8656 - f1: 0.8836 - val_loss: 0.2137 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 1379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8635 - f1: 0.8824 - val_loss: 0.2323 - val_acc: 0.9431 - val_f1: 0.9475\n",
      "Epoch 1380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8632 - f1: 0.8818 - val_loss: 0.2120 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2156 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2422 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8627 - f1: 0.8817 - val_loss: 0.2187 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 1384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8646 - f1: 0.8826 - val_loss: 0.2221 - val_acc: 0.9588 - val_f1: 0.9614\n",
      "Epoch 1385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2163 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 1387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8615 - f1: 0.8804 - val_loss: 0.2265 - val_acc: 0.9478 - val_f1: 0.9513\n",
      "Epoch 1388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2388 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 1389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2274 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2256 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 1391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2201 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 1392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2183 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8675 - f1: 0.8849 - val_loss: 0.2152 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 1394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8672 - f1: 0.8848 - val_loss: 0.2128 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 1395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2736 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 1396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8627 - f1: 0.8815 - val_loss: 0.2214 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2192 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 1398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2270 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8649 - f1: 0.8838 - val_loss: 0.2127 - val_acc: 0.9597 - val_f1: 0.9620\n",
      "Epoch 1400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2325 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2311 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 1402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8644 - f1: 0.8833 - val_loss: 0.2056 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 1403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8674 - f1: 0.8848 - val_loss: 0.2149 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2462 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2281 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 1406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2229 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2073 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2213 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2213 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8653 - f1: 0.8839 - val_loss: 0.2257 - val_acc: 0.9578 - val_f1: 0.9594\n",
      "Epoch 1411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2125 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 1412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8755 - f1: 0.8916 - val_loss: 0.2099 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2129 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8633 - f1: 0.8818 - val_loss: 0.2094 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2146 - val_acc: 0.9644 - val_f1: 0.9665\n",
      "Epoch 1416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8652 - f1: 0.8836 - val_loss: 0.2290 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2232 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8640 - f1: 0.8827 - val_loss: 0.2134 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 1419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8633 - f1: 0.8824 - val_loss: 0.2203 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 1420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2193 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8629 - f1: 0.8822 - val_loss: 0.2087 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2298 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8671 - f1: 0.8858 - val_loss: 0.2125 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 1424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8721 - f1: 0.8888 - val_loss: 0.2129 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 1425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8622 - f1: 0.8813 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2184 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 1427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8604 - f1: 0.8798 - val_loss: 0.2410 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2160 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 1429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8679 - f1: 0.8856 - val_loss: 0.2327 - val_acc: 0.9569 - val_f1: 0.9586\n",
      "Epoch 1430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8623 - f1: 0.8813 - val_loss: 0.2231 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2214 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 1432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8667 - f1: 0.8848 - val_loss: 0.2385 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1433/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2181 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 1434/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3394 - acc: 0.8643 - f1: 0.8828 - val_loss: 0.2336 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1435/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2161 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1436/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2195 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 1437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8674 - f1: 0.8858 - val_loss: 0.2270 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1438/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8711 - f1: 0.8876 - val_loss: 0.2447 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8634 - f1: 0.8824 - val_loss: 0.2582 - val_acc: 0.9616 - val_f1: 0.9619\n",
      "Epoch 1440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8653 - f1: 0.8838 - val_loss: 0.2498 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 1441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8687 - f1: 0.8857 - val_loss: 0.2177 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2191 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 1443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2263 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 1444/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3469 - acc: 0.8604 - f1: 0.8800 - val_loss: 0.2338 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8659 - f1: 0.8834 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2188 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2316 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 1448/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3280 - acc: 0.8706 - f1: 0.8876 - val_loss: 0.2256 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2478 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8606 - f1: 0.8799 - val_loss: 0.2159 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8640 - f1: 0.8825 - val_loss: 0.2134 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2145 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1453/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3279 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2283 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1454/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2304 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2420 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 1456/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3255 - acc: 0.8721 - f1: 0.8886 - val_loss: 0.2293 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 1457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2244 - val_acc: 0.9513 - val_f1: 0.9545\n",
      "Epoch 1458/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8612 - f1: 0.8803 - val_loss: 0.2116 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8710 - f1: 0.8877 - val_loss: 0.2216 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 1460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2245 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1461/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2336 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 1462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2238 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 1463/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8694 - f1: 0.8866 - val_loss: 0.2096 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 1465/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8849 - val_loss: 0.2183 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8655 - f1: 0.8834 - val_loss: 0.2232 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8641 - f1: 0.8831 - val_loss: 0.2172 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 1468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8648 - f1: 0.8835 - val_loss: 0.2143 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2248 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2277 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 1472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2175 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 1473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8851 - val_loss: 0.2258 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2165 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 1475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2136 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 1476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2150 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 1477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2213 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2293 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2255 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2332 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8637 - f1: 0.8826 - val_loss: 0.2273 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8748 - f1: 0.8904 - val_loss: 0.2274 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2413 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 1484/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3391 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2300 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 1485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2214 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 1486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2234 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 1487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2191 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 1488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2213 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2144 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2285 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2110 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2112 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 1493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2233 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 1494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2159 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2135 - val_acc: 0.9581 - val_f1: 0.9608\n",
      "Epoch 1496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2331 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 1497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8676 - f1: 0.8851 - val_loss: 0.2158 - val_acc: 0.9594 - val_f1: 0.9607\n",
      "Epoch 1498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8637 - f1: 0.8830 - val_loss: 0.2268 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8632 - f1: 0.8818 - val_loss: 0.2176 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 1500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2268 - val_acc: 0.9591 - val_f1: 0.9605\n",
      "Epoch 1501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8640 - f1: 0.8831 - val_loss: 0.2369 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8688 - f1: 0.8860 - val_loss: 0.2293 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2396 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2296 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2248 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8622 - f1: 0.8812 - val_loss: 0.2265 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 1507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2359 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2106 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 1509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2207 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 1510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2149 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2243 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2232 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2208 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 1514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8708 - f1: 0.8874 - val_loss: 0.2259 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 1515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2354 - val_acc: 0.9456 - val_f1: 0.9494\n",
      "Epoch 1516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8614 - f1: 0.8805 - val_loss: 0.2125 - val_acc: 0.9597 - val_f1: 0.9620\n",
      "Epoch 1517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2218 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2248 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 1519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8672 - f1: 0.8855 - val_loss: 0.2471 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2162 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8653 - f1: 0.8835 - val_loss: 0.2199 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8633 - f1: 0.8823 - val_loss: 0.2209 - val_acc: 0.9544 - val_f1: 0.9572\n",
      "Epoch 1523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2365 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2134 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2265 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 1526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2294 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2256 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 1528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2342 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2238 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 1531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2547 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 1532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2130 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8761 - f1: 0.8916 - val_loss: 0.2177 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2055 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 1535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2100 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 1537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8754 - f1: 0.8917 - val_loss: 0.2399 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8689 - f1: 0.8868 - val_loss: 0.2245 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 1539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2497 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2255 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 1541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8628 - f1: 0.8817 - val_loss: 0.2183 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2216 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2273 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 1544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8656 - f1: 0.8843 - val_loss: 0.2229 - val_acc: 0.9559 - val_f1: 0.9580\n",
      "Epoch 1545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2383 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 1546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2363 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 1547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2193 - val_acc: 0.9556 - val_f1: 0.9580\n",
      "Epoch 1549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8651 - f1: 0.8841 - val_loss: 0.2337 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2195 - val_acc: 0.9603 - val_f1: 0.9630\n",
      "Epoch 1551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2195 - val_acc: 0.9578 - val_f1: 0.9606\n",
      "Epoch 1552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8672 - f1: 0.8851 - val_loss: 0.2331 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 1553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2481 - val_acc: 0.9381 - val_f1: 0.9425\n",
      "Epoch 1554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2060 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8617 - f1: 0.8807 - val_loss: 0.2180 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 1556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8619 - f1: 0.8809 - val_loss: 0.2264 - val_acc: 0.9691 - val_f1: 0.9697\n",
      "Epoch 1557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2302 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 1558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2138 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1559/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2175 - val_acc: 0.9594 - val_f1: 0.9615\n",
      "Epoch 1560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8585 - f1: 0.8783 - val_loss: 0.2077 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 1561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2395 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8864 - val_loss: 0.2416 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 1563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8677 - f1: 0.8860 - val_loss: 0.2112 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2387 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2179 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2321 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2371 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2416 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2158 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 1570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8652 - f1: 0.8830 - val_loss: 0.2166 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2165 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2273 - val_acc: 0.9647 - val_f1: 0.9668\n",
      "Epoch 1573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8676 - f1: 0.8857 - val_loss: 0.2180 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2318 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2128 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2323 - val_acc: 0.9703 - val_f1: 0.9714\n",
      "Epoch 1577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2269 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2331 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8644 - f1: 0.8830 - val_loss: 0.2332 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2124 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2222 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2211 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8813 - val_loss: 0.2419 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 1584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2124 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 1586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2299 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 1587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2191 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 1588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8631 - f1: 0.8816 - val_loss: 0.2300 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2100 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2321 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 1591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2214 - val_acc: 0.9538 - val_f1: 0.9566\n",
      "Epoch 1592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2165 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2255 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2152 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2185 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2085 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2209 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2530 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 1599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2384 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2184 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2232 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2334 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2392 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2238 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 1605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2390 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2275 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 1607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8836 - val_loss: 0.2356 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2136 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8640 - f1: 0.8825 - val_loss: 0.2092 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2366 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2272 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2150 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2209 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 1614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2223 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 1615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2365 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 1616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2206 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2106 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2333 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 1619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2288 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2243 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8739 - f1: 0.8903 - val_loss: 0.2204 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2417 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 1623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8654 - f1: 0.8839 - val_loss: 0.2328 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 1624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2386 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2206 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2220 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2116 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8606 - f1: 0.8801 - val_loss: 0.2360 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2126 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8743 - f1: 0.8908 - val_loss: 0.2186 - val_acc: 0.9703 - val_f1: 0.9715\n",
      "Epoch 1631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2175 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2372 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8668 - f1: 0.8851 - val_loss: 0.2409 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 1634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2163 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2260 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 1636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2193 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 1637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2325 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 1638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2287 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 1639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2247 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 1640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2195 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2247 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2213 - val_acc: 0.9531 - val_f1: 0.9556\n",
      "Epoch 1643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2325 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8696 - f1: 0.8873 - val_loss: 0.2197 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8602 - f1: 0.8793 - val_loss: 0.2196 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 1646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2202 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 1647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8752 - f1: 0.8912 - val_loss: 0.2375 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2198 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2562 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8655 - f1: 0.8834 - val_loss: 0.2223 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2368 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 1652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2247 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1653/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2224 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8613 - f1: 0.8807 - val_loss: 0.2118 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2268 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 1656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8631 - f1: 0.8820 - val_loss: 0.2256 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2236 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 1658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8662 - f1: 0.8848 - val_loss: 0.2204 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 1659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2157 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 1660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2246 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8671 - f1: 0.8845 - val_loss: 0.2069 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8662 - f1: 0.8849 - val_loss: 0.2339 - val_acc: 0.9688 - val_f1: 0.9692\n",
      "Epoch 1663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2142 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2892 - val_acc: 0.9603 - val_f1: 0.9612\n",
      "Epoch 1665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8552 - f1: 0.8757 - val_loss: 0.2222 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2119 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 1667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2097 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2165 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 1669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2250 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2226 - val_acc: 0.9616 - val_f1: 0.9642\n",
      "Epoch 1671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2412 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2246 - val_acc: 0.9628 - val_f1: 0.9650\n",
      "Epoch 1673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2255 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1674/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8627 - f1: 0.8818 - val_loss: 0.2273 - val_acc: 0.9631 - val_f1: 0.9636\n",
      "Epoch 1675/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2338 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 1676/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2170 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2221 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8745 - f1: 0.8904 - val_loss: 0.2453 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 1679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2189 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 1680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2090 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8585 - f1: 0.8783 - val_loss: 0.2215 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 1682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2490 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 1683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2389 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8753 - f1: 0.8911 - val_loss: 0.2358 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2243 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2357 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2477 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 1689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2394 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8631 - f1: 0.8821 - val_loss: 0.2216 - val_acc: 0.9575 - val_f1: 0.9593\n",
      "Epoch 1691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8634 - f1: 0.8816 - val_loss: 0.2293 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 1692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2250 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8618 - f1: 0.8812 - val_loss: 0.2183 - val_acc: 0.9534 - val_f1: 0.9564\n",
      "Epoch 1694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8629 - f1: 0.8820 - val_loss: 0.2289 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 1695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8706 - f1: 0.8882 - val_loss: 0.2308 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8657 - f1: 0.8836 - val_loss: 0.2339 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2291 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 1699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2288 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2267 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1701/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3294 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2173 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 1702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8589 - f1: 0.8793 - val_loss: 0.2277 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8675 - f1: 0.8850 - val_loss: 0.2327 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2338 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2487 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 1706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2239 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 1707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2456 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2422 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1709/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3352 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2287 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1710/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3363 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2416 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1711/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2177 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 1712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2177 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 1713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2262 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8594 - f1: 0.8785 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8653 - f1: 0.8840 - val_loss: 0.2189 - val_acc: 0.9681 - val_f1: 0.9684\n",
      "Epoch 1716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2269 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2187 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2258 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2168 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8698 - f1: 0.8877 - val_loss: 0.2367 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 1721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2162 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 1722/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2156 - val_acc: 0.9672 - val_f1: 0.9690\n",
      "Epoch 1723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8705 - f1: 0.8871 - val_loss: 0.2068 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 1724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8650 - f1: 0.8835 - val_loss: 0.2196 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2294 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2200 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 1727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2099 - val_acc: 0.9606 - val_f1: 0.9629\n",
      "Epoch 1728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8700 - f1: 0.8869 - val_loss: 0.2249 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8669 - f1: 0.8845 - val_loss: 0.2323 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 1730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2274 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2378 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2556 - val_acc: 0.9572 - val_f1: 0.9585\n",
      "Epoch 1733/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2125 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8663 - f1: 0.8840 - val_loss: 0.2191 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2147 - val_acc: 0.9625 - val_f1: 0.9645\n",
      "Epoch 1736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2478 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 1737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2251 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2281 - val_acc: 0.9591 - val_f1: 0.9606\n",
      "Epoch 1739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8707 - f1: 0.8876 - val_loss: 0.2308 - val_acc: 0.9547 - val_f1: 0.9571\n",
      "Epoch 1740/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8629 - f1: 0.8814 - val_loss: 0.2273 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1741/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3356 - acc: 0.8657 - f1: 0.8842 - val_loss: 0.2245 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1742/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3247 - acc: 0.8728 - f1: 0.88 - 0s 16us/sample - loss: 0.3268 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2193 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2257 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 1744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2493 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1745/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8618 - f1: 0.8812 - val_loss: 0.2256 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3213 - acc: 0.8738 - f1: 0.8898 - val_loss: 0.2323 - val_acc: 0.9663 - val_f1: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8640 - f1: 0.8827 - val_loss: 0.2190 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2366 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 1749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2214 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 1750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8631 - f1: 0.8824 - val_loss: 0.2145 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 1751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8627 - f1: 0.8814 - val_loss: 0.2580 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2121 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 1753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2260 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2169 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2275 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 1756/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2125 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1758/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8655 - f1: 0.8840 - val_loss: 0.2201 - val_acc: 0.9619 - val_f1: 0.9642\n",
      "Epoch 1759/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3296 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2196 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 1760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2189 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 1761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2192 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1762/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2358 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2238 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1764/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2351 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1765/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2459 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1766/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2299 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1767/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3277 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2417 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1768/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2342 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1769/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8634 - f1: 0.8827 - val_loss: 0.2302 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 1770/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3353 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2266 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 1771/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2349 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 1772/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2241 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1773/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2490 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 1774/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3334 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2234 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 1775/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2215 - val_acc: 0.9594 - val_f1: 0.9609\n",
      "Epoch 1776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2149 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1777/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2226 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2238 - val_acc: 0.9550 - val_f1: 0.9574\n",
      "Epoch 1779/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2233 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 1780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8703 - f1: 0.8868 - val_loss: 0.2537 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1781/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8634 - f1: 0.8824 - val_loss: 0.2176 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1782/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8620 - f1: 0.8808 - val_loss: 0.2168 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 1783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2245 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2226 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 1785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2387 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 1786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2241 - val_acc: 0.9509 - val_f1: 0.9538\n",
      "Epoch 1787/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8871 - val_loss: 0.2407 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 1788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2483 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2213 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2249 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1791/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2342 - val_acc: 0.9684 - val_f1: 0.9692\n",
      "Epoch 1792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2567 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 1793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2210 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1794/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8679 - f1: 0.8853 - val_loss: 0.2136 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2301 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2234 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 1797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2291 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 1798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2192 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2364 - val_acc: 0.9675 - val_f1: 0.9692\n",
      "Epoch 1801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8718 - f1: 0.8883 - val_loss: 0.2186 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 1802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8637 - f1: 0.8827 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8640 - f1: 0.8828 - val_loss: 0.2135 - val_acc: 0.9659 - val_f1: 0.9663\n",
      "Epoch 1804/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2186 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1805/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2217 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1806/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3285 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2200 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1807/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2300 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2283 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8679 - f1: 0.8858 - val_loss: 0.2290 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1810/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2144 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1811/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2299 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2196 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 1813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3478 - acc: 0.8595 - f1: 0.8790 - val_loss: 0.2155 - val_acc: 0.9603 - val_f1: 0.9618\n",
      "Epoch 1814/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2331 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 1815/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2216 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1816/5000\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2329 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1817/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3369 - acc: 0.8661 - f1: 0.8842 - val_loss: 0.2213 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1818/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2250 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2213 - val_acc: 0.9453 - val_f1: 0.9491\n",
      "Epoch 1821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2273 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 1822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2203 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2351 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 1824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2249 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1825/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3354 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2346 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1826/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2285 - val_acc: 0.9581 - val_f1: 0.9596\n",
      "Epoch 1827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2128 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 1828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2270 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2198 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1830/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2181 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2540 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2375 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 1833/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2231 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2206 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2346 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 1836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8619 - f1: 0.8814 - val_loss: 0.2199 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2379 - val_acc: 0.9681 - val_f1: 0.9687\n",
      "Epoch 1838/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3301 - acc: 0.8681 - f1: 0.8854 - val_loss: 0.2363 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 1839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2192 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2295 - val_acc: 0.9478 - val_f1: 0.9515\n",
      "Epoch 1841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2138 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2224 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1843/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3225 - acc: 0.8746 - f1: 0.8906 - val_loss: 0.2281 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1844/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2265 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2263 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1846/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2300 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2148 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 1848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2142 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8674 - f1: 0.8850 - val_loss: 0.2174 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 1850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8659 - f1: 0.8847 - val_loss: 0.2388 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1851/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2424 - val_acc: 0.9666 - val_f1: 0.9667\n",
      "Epoch 1852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2264 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 1853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2393 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2300 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 1855/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3344 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2272 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 1856/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8613 - f1: 0.8806 - val_loss: 0.2274 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 1857/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3276 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2311 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1858/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3258 - acc: 0.8710 - f1: 0.8878 - val_loss: 0.2286 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1859/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8694 - f1: 0.8866 - val_loss: 0.2144 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 1860/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3270 - acc: 0.8706 - f1: 0.88 - 0s 15us/sample - loss: 0.3287 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2375 - val_acc: 0.9688 - val_f1: 0.9703\n",
      "Epoch 1861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2388 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2536 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 1863/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2269 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1864/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2290 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 1865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2181 - val_acc: 0.9650 - val_f1: 0.9673\n",
      "Epoch 1866/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3361 - acc: 0.8665 - f1: 0.8845 - val_loss: 0.2134 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1867/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2345 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1868/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3356 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2138 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 1869/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2459 - val_acc: 0.9669 - val_f1: 0.9686\n",
      "Epoch 1870/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3305 - acc: 0.8686 - f1: 0.8866 - val_loss: 0.2208 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1871/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8845 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 1872/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2123 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2264 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8641 - f1: 0.8823 - val_loss: 0.2191 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 1875/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2167 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 1876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2158 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2272 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 1878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2256 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2296 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 1880/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3388 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2124 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2301 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2444 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2349 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 1885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2336 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 1886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2204 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2462 - val_acc: 0.9663 - val_f1: 0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2498 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 1889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2320 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2290 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2467 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1892/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2222 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 1893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8635 - f1: 0.8823 - val_loss: 0.2166 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2300 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1896/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2272 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1897/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2258 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 1898/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8645 - f1: 0.8834 - val_loss: 0.2238 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1899/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3341 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2347 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2235 - val_acc: 0.9625 - val_f1: 0.9627\n",
      "Epoch 1901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2072 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2328 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1903/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2314 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 1904/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2276 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 1905/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8881 - val_loss: 0.2271 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 1906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2183 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8876 - val_loss: 0.2348 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2236 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 1909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2656 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2340 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1911/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2314 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1912/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8693 - f1: 0.8863 - val_loss: 0.2347 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 1913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8650 - f1: 0.8838 - val_loss: 0.2283 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 1914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2400 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2278 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 1916/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2156 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 1917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2257 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2324 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2245 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2269 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2429 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2401 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2304 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2743 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 1925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8658 - f1: 0.8843 - val_loss: 0.2212 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2235 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2378 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8658 - f1: 0.8836 - val_loss: 0.2560 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2368 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 1930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2258 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 1931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2260 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 1932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2173 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2236 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 1934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2390 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1935/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2241 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2220 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2213 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2243 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2199 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2167 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 1941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2550 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1942/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8610 - f1: 0.8800 - val_loss: 0.2135 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2182 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8697 - f1: 0.8871 - val_loss: 0.2526 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 1945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2176 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2378 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 1947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2292 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1948/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8738 - f1: 0.8901 - val_loss: 0.2562 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2273 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2253 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 1951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2157 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 1952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8711 - f1: 0.8876 - val_loss: 0.2234 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2242 - val_acc: 0.9653 - val_f1: 0.9674\n",
      "Epoch 1954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2319 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2322 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2217 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 1957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8600 - f1: 0.8787 - val_loss: 0.2094 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 1958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8651 - f1: 0.8832 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2305 - val_acc: 0.9697 - val_f1: 0.9710\n",
      "Epoch 1960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2727 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 1961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8642 - f1: 0.8826 - val_loss: 0.2464 - val_acc: 0.9600 - val_f1: 0.9611\n",
      "Epoch 1962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2319 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2215 - val_acc: 0.9550 - val_f1: 0.9573\n",
      "Epoch 1965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8598 - f1: 0.8798 - val_loss: 0.2575 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8750 - f1: 0.8914 - val_loss: 0.2296 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2484 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2346 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2318 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2321 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1972/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2147 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2341 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2250 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2509 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2221 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2098 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2474 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1980/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3420 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2141 - val_acc: 0.9575 - val_f1: 0.9602\n",
      "Epoch 1981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2267 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 1982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2060 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 1983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2195 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2563 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 1985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8739 - f1: 0.8906 - val_loss: 0.2317 - val_acc: 0.9488 - val_f1: 0.9519\n",
      "Epoch 1986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8667 - f1: 0.8844 - val_loss: 0.2335 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2323 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 1988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2297 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2333 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2213 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 1991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 1992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2173 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 1993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8661 - f1: 0.8845 - val_loss: 0.2433 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 1994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2107 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2651 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2279 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 1997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2408 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2340 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2315 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2241 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8719 - f1: 0.8885 - val_loss: 0.2183 - val_acc: 0.9634 - val_f1: 0.9657\n",
      "Epoch 2002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2428 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2181 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2239 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2005/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2360 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 2006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2365 - val_acc: 0.9681 - val_f1: 0.9687\n",
      "Epoch 2007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2437 - val_acc: 0.9566 - val_f1: 0.9588\n",
      "Epoch 2008/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2316 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2325 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 2010/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8669 - f1: 0.8851 - val_loss: 0.2097 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2363 - val_acc: 0.9691 - val_f1: 0.9707\n",
      "Epoch 2012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2331 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 2013/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2139 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 2014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2276 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2324 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2276 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2137 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 2018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2245 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2290 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2470 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 2021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2259 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2230 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 2023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2323 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8672 - f1: 0.8846 - val_loss: 0.2383 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8700 - f1: 0.8870 - val_loss: 0.2201 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8690 - f1: 0.8871 - val_loss: 0.2320 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2521 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2463 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2029/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8647 - f1: 0.8835 - val_loss: 0.2374 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8647 - f1: 0.8834 - val_loss: 0.2297 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2173 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8746 - f1: 0.8910 - val_loss: 0.2166 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8887 - val_loss: 0.2293 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8775 - f1: 0.8932 - val_loss: 0.2545 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2389 - val_acc: 0.9638 - val_f1: 0.9641\n",
      "Epoch 2036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2295 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2256 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2514 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2253 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 2040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9672\n",
      "Epoch 2041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2302 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2873 - val_acc: 0.9625 - val_f1: 0.9631\n",
      "Epoch 2043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8670 - f1: 0.8855 - val_loss: 0.2308 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 2044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2151 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2242 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2284 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2216 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2343 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8722 - f1: 0.8890 - val_loss: 0.2239 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2484 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 2051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2214 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2373 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2400 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2376 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2385 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8746 - f1: 0.8908 - val_loss: 0.2319 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 2057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2173 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8707 - f1: 0.8875 - val_loss: 0.2111 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 2059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2274 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2258 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8748 - f1: 0.8905 - val_loss: 0.2210 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 2062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8671 - f1: 0.8850 - val_loss: 0.2434 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 2063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2608 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 2064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8832 - val_loss: 0.2549 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2065/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3225 - acc: 0.8735 - f1: 0.89 - 0s 16us/sample - loss: 0.3211 - acc: 0.8736 - f1: 0.8898 - val_loss: 0.2286 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 2066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2267 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2665 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2260 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8740 - f1: 0.8907 - val_loss: 0.2352 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2169 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 2071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2519 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8654 - f1: 0.8840 - val_loss: 0.2240 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 2073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2182 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2074/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2405 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8683 - f1: 0.8863 - val_loss: 0.2267 - val_acc: 0.9616 - val_f1: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8715 - f1: 0.8880 - val_loss: 0.2219 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2077/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2246 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2230 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2268 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 2080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2286 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2133 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2871 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 2083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2338 - val_acc: 0.9681 - val_f1: 0.9686\n",
      "Epoch 2084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2131 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 2085/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2332 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2086/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2188 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2087/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2369 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 2088/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8684 - f1: 0.8852 - val_loss: 0.2194 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2089/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2428 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2169 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2354 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 2092/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3348 - acc: 0.8657 - f1: 0.8844 - val_loss: 0.2246 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 2093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2393 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2276 - val_acc: 0.9556 - val_f1: 0.9586\n",
      "Epoch 2095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2333 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2096/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8740 - f1: 0.8906 - val_loss: 0.2591 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2097/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2080 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 2098/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3269 - acc: 0.8708 - f1: 0.88 - 0s 16us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2090 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2099/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2242 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8740 - f1: 0.8910 - val_loss: 0.2655 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8677 - f1: 0.8850 - val_loss: 0.2380 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 2103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8697 - f1: 0.8876 - val_loss: 0.2317 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8857 - val_loss: 0.2352 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2429 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2340 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2107/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3189 - acc: 0.8755 - f1: 0.8919 - val_loss: 0.2388 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2108/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3319 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2368 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 2109/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2701 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 2110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8728 - f1: 0.8893 - val_loss: 0.2221 - val_acc: 0.9597 - val_f1: 0.9622\n",
      "Epoch 2111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8732 - f1: 0.8895 - val_loss: 0.2361 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2112/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2167 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2139 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2227 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 2116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2287 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2268 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2252 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 2119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2336 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2377 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 2121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8619 - f1: 0.8810 - val_loss: 0.2310 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2190 - val_acc: 0.9619 - val_f1: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2575 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2187 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2218 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2306 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2328 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 2128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2193 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 2129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2244 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2130/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8717 - f1: 0.8886 - val_loss: 0.2435 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 2131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8844 - val_loss: 0.2207 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 2132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2421 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2325 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8855 - val_loss: 0.2909 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 2135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2256 - val_acc: 0.9550 - val_f1: 0.9570\n",
      "Epoch 2136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2366 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 2137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8752 - f1: 0.8913 - val_loss: 0.2339 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 2138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2186 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2270 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2140/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2495 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2695 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 2142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2453 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8707 - f1: 0.8876 - val_loss: 0.2621 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8607 - f1: 0.8802 - val_loss: 0.2322 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 2145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2510 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8632 - f1: 0.8823 - val_loss: 0.2264 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 2147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2261 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2148/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3324 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2267 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2123 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2255 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2305 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8873 - val_loss: 0.2483 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 2153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2276 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 2154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2582 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8670 - f1: 0.8854 - val_loss: 0.2435 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2305 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2157/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3223 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2653 - val_acc: 0.9609 - val_f1: 0.9616\n",
      "Epoch 2158/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3319 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2388 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2159/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3312 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2464 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2160/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2491 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2161/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2233 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 2162/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2248 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2163/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3144 - acc: 0.8781 - f1: 0.89 - 0s 16us/sample - loss: 0.3156 - acc: 0.8775 - f1: 0.8931 - val_loss: 0.2299 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 2164/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2398 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 2165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2213 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8608 - f1: 0.8800 - val_loss: 0.2232 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2396 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 2168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2240 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2181 - val_acc: 0.9603 - val_f1: 0.9621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2279 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 2171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3165 - acc: 0.8767 - f1: 0.8927 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2320 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2173/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2422 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 2174/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3273 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2309 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 2175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2301 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2328 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 2177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2319 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2189 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2146 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2479 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8843 - val_loss: 0.2146 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2409 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 2184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8721 - f1: 0.8887 - val_loss: 0.2446 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 2185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2244 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8725 - f1: 0.8892 - val_loss: 0.2379 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8654 - f1: 0.8839 - val_loss: 0.2360 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2236 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8657 - f1: 0.8841 - val_loss: 0.2255 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8848 - val_loss: 0.2281 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 2191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2321 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2192/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2269 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2193/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8846 - val_loss: 0.2254 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2194/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3508 - acc: 0.8584 - f1: 0.8786 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 2195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2335 - val_acc: 0.9688 - val_f1: 0.9694\n",
      "Epoch 2196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2305 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2297 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2330 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 2199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2351 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8691 - f1: 0.8860 - val_loss: 0.2128 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8680 - f1: 0.8854 - val_loss: 0.2249 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 2202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8711 - f1: 0.8880 - val_loss: 0.2351 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2258 - val_acc: 0.9684 - val_f1: 0.9698\n",
      "Epoch 2204/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2299 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2205/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2270 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2206/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2346 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2372 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 2208/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2484 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 2209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2554 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 2210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2262 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2413 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2212/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2198 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 2213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2373 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2214/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2325 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8623 - f1: 0.8816 - val_loss: 0.2209 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2343 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2217/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2239 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2530 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2181 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8640 - f1: 0.8828 - val_loss: 0.2182 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2200 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2232 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2290 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2401 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2230 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8869 - val_loss: 0.2389 - val_acc: 0.9678 - val_f1: 0.9683\n",
      "Epoch 2228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2409 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8640 - f1: 0.8824 - val_loss: 0.2326 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8721 - f1: 0.8888 - val_loss: 0.2351 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 2231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2505 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 2232/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2366 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 2233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2330 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2744 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 2235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2282 - val_acc: 0.9509 - val_f1: 0.9542\n",
      "Epoch 2236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2512 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2226 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2238/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2800 - val_acc: 0.9609 - val_f1: 0.9615\n",
      "Epoch 2239/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3283 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2471 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2353 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2314 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2700 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2243/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8711 - f1: 0.8878 - val_loss: 0.2410 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2668 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2529 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2246/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3326 - acc: 0.8674 - f1: 0.8851 - val_loss: 0.2719 - val_acc: 0.9200 - val_f1: 0.9278\n",
      "Epoch 2247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8612 - f1: 0.8807 - val_loss: 0.2218 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2248/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2359 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2273 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2289 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2684 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 2252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8708 - f1: 0.8873 - val_loss: 0.2557 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 2253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2220 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 2254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2308 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 2255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2329 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 2256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8672 - f1: 0.8853 - val_loss: 0.2211 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 2257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8637 - f1: 0.8825 - val_loss: 0.2238 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2105 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2251 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2504 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 2261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8754 - f1: 0.8915 - val_loss: 0.2451 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2394 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 2263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2384 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 2264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2353 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2492 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 2266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2329 - val_acc: 0.9672 - val_f1: 0.9675\n",
      "Epoch 2267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8621 - f1: 0.8809 - val_loss: 0.2540 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 2268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2305 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 2269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2388 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2121 - val_acc: 0.9603 - val_f1: 0.9631\n",
      "Epoch 2271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8632 - f1: 0.8820 - val_loss: 0.2644 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8650 - f1: 0.8837 - val_loss: 0.2301 - val_acc: 0.9675 - val_f1: 0.9692\n",
      "Epoch 2273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2150 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2508 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8747 - f1: 0.8909 - val_loss: 0.2351 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2274 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2310 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2095 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8696 - f1: 0.8866 - val_loss: 0.2201 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 2280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8681 - f1: 0.8863 - val_loss: 0.2458 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2568 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2282/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2419 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2490 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2161 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8892 - val_loss: 0.2664 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8645 - f1: 0.8828 - val_loss: 0.2367 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 2287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2531 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2135 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 2289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8687 - f1: 0.8860 - val_loss: 0.2222 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2145 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 2291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8634 - f1: 0.8819 - val_loss: 0.2259 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2235 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8879 - val_loss: 0.2386 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8691 - f1: 0.8861 - val_loss: 0.2394 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2282 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2499 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2163 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 2298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8655 - f1: 0.8841 - val_loss: 0.2469 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 2299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2226 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 2300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2221 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2487 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8667 - f1: 0.8844 - val_loss: 0.2663 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 2303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2237 - val_acc: 0.9534 - val_f1: 0.9558\n",
      "Epoch 2304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2114 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 2305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8666 - f1: 0.8844 - val_loss: 0.2800 - val_acc: 0.9616 - val_f1: 0.9620\n",
      "Epoch 2306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2427 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 2307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2532 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8651 - f1: 0.8840 - val_loss: 0.2445 - val_acc: 0.9341 - val_f1: 0.9394\n",
      "Epoch 2309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2204 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8746 - f1: 0.8905 - val_loss: 0.2366 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 2311/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8630 - f1: 0.8819 - val_loss: 0.2150 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2598 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2259 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2287 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2204 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8844 - val_loss: 0.2365 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2327 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 2318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8889 - val_loss: 0.2445 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 2319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2364 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 2320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8854 - val_loss: 0.2420 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 2321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8766 - f1: 0.8925 - val_loss: 0.2212 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8858 - val_loss: 0.2321 - val_acc: 0.9547 - val_f1: 0.9570\n",
      "Epoch 2323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2265 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8758 - f1: 0.8921 - val_loss: 0.2561 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8701 - f1: 0.8868 - val_loss: 0.2156 - val_acc: 0.9553 - val_f1: 0.9579\n",
      "Epoch 2326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8696 - f1: 0.8868 - val_loss: 0.2121 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2347 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 2328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2334 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 2329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2550 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2242 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8637 - f1: 0.8828 - val_loss: 0.2309 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2326 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 2333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2478 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2288 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8718 - f1: 0.8884 - val_loss: 0.2451 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2472 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2350 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2373 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8616 - f1: 0.8809 - val_loss: 0.2437 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 2340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8711 - f1: 0.8877 - val_loss: 0.2346 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 2341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2548 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2242 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2383 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 2344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2400 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2414 - val_acc: 0.9684 - val_f1: 0.9691\n",
      "Epoch 2346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2381 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 2347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2158 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 2348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2240 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2508 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2281 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2371 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 2352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2490 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.2478 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2262 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2179 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 2356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2292 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 2357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2198 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 2358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2477 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 2359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2486 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8882 - val_loss: 0.2447 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2412 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 2363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2917 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 2364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2494 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2417 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8708 - f1: 0.8871 - val_loss: 0.2151 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2353 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8662 - f1: 0.8844 - val_loss: 0.2591 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 2369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2311 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2196 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2302 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2215 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8607 - f1: 0.8811 - val_loss: 0.2167 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2374/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8862 - val_loss: 0.2368 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 2375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2332 - val_acc: 0.9619 - val_f1: 0.9622\n",
      "Epoch 2376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2343 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2271 - val_acc: 0.9528 - val_f1: 0.9554\n",
      "Epoch 2378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2350 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2200 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8636 - f1: 0.8830 - val_loss: 0.2968 - val_acc: 0.9597 - val_f1: 0.9606\n",
      "Epoch 2381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8638 - f1: 0.8825 - val_loss: 0.2285 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 2382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2338 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8752 - f1: 0.8915 - val_loss: 0.2346 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 2384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2361 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 2385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2162 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2480 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 2388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2422 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8884 - val_loss: 0.2400 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 2390/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2204 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2151 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8648 - f1: 0.8835 - val_loss: 0.2252 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8657 - f1: 0.8842 - val_loss: 0.2240 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 2394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8667 - f1: 0.8843 - val_loss: 0.2157 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 2395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2365 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 2396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8626 - f1: 0.8821 - val_loss: 0.2099 - val_acc: 0.9603 - val_f1: 0.9626\n",
      "Epoch 2397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8636 - f1: 0.8824 - val_loss: 0.2124 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2212 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2512 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 2400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2447 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.2428 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 2402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2579 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2334 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2616 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 2405/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8901 - val_loss: 0.2259 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2300 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 2407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2496 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2459 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2270 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8642 - f1: 0.8833 - val_loss: 0.2317 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8646 - f1: 0.8828 - val_loss: 0.2323 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 2413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8678 - f1: 0.8856 - val_loss: 0.2605 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8743 - f1: 0.8909 - val_loss: 0.2479 - val_acc: 0.9644 - val_f1: 0.9646\n",
      "Epoch 2415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2183 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2323 - val_acc: 0.9488 - val_f1: 0.9519\n",
      "Epoch 2417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8591 - f1: 0.8790 - val_loss: 0.2261 - val_acc: 0.9544 - val_f1: 0.9569\n",
      "Epoch 2418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2318 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2419 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2716 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 2421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2521 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2205 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2509 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2704 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 2425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2607 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 2426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2360 - val_acc: 0.9663 - val_f1: 0.9679\n",
      "Epoch 2427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2378 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8648 - f1: 0.8834 - val_loss: 0.2534 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 2429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8563 - f1: 0.8768 - val_loss: 0.2392 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 2430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2332 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 2431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2380 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2232 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8676 - f1: 0.8850 - val_loss: 0.2160 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2351 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 2435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2418 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2676 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 2437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2373 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 2438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2188 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3096 - acc: 0.8813 - f1: 0.8962 - val_loss: 0.2372 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2185 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 2441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2297 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2448 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 2443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2604 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 2444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2291 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 2446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2414 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2300 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8595 - f1: 0.8791 - val_loss: 0.2288 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8672 - f1: 0.8851 - val_loss: 0.2337 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 2450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8639 - f1: 0.8830 - val_loss: 0.2286 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8681 - f1: 0.8855 - val_loss: 0.2447 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2825 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 2453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2189 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 2454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2438 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2420 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2442 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 2458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8850 - val_loss: 0.2293 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 2459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2443 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2164 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 2461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2098 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8855 - val_loss: 0.2464 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8675 - f1: 0.8848 - val_loss: 0.2221 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8689 - f1: 0.8869 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8895 - val_loss: 0.2477 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8696 - f1: 0.8871 - val_loss: 0.2272 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3135 - acc: 0.8789 - f1: 0.8941 - val_loss: 0.2600 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2342 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 2470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2197 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2236 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2232 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2243 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 2474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2289 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2377 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8606 - f1: 0.8799 - val_loss: 0.2384 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 2478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8822 - val_loss: 0.2614 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2462 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 2480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2331 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2349 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8739 - f1: 0.8901 - val_loss: 0.2194 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8600 - f1: 0.8793 - val_loss: 0.2188 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2327 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2404 - val_acc: 0.9669 - val_f1: 0.9672\n",
      "Epoch 2486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2264 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8761 - f1: 0.8922 - val_loss: 0.2507 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 2488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2405 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 2489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2242 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8860 - val_loss: 0.2310 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 2491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2366 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2295 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2459 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2366 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 2495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2622 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8651 - f1: 0.8838 - val_loss: 0.2379 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2455 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2789 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 2499/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8665 - f1: 0.8848 - val_loss: 0.2169 - val_acc: 0.9619 - val_f1: 0.9642\n",
      "Epoch 2500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8680 - f1: 0.8863 - val_loss: 0.2415 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2130 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8642 - f1: 0.8829 - val_loss: 0.2279 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2503/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2311 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2351 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2300 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 2506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2172 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2483 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8717 - f1: 0.8887 - val_loss: 0.2367 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2887 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 2510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3124 - acc: 0.8786 - f1: 0.8941 - val_loss: 0.2596 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2264 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2184 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 2513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2367 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2502 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 2515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2357 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 2516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 2517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8668 - f1: 0.8849 - val_loss: 0.2430 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 2518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2228 - val_acc: 0.9563 - val_f1: 0.9590\n",
      "Epoch 2519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2197 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2469 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2337 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2458 - val_acc: 0.9684 - val_f1: 0.9694\n",
      "Epoch 2524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2339 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 2525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2348 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2263 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2504 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2276 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2315 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 2530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2495 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 2531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2391 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2472 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 2533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2324 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 2534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2348 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2387 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2352 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2624 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 2538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2361 - val_acc: 0.9663 - val_f1: 0.9679\n",
      "Epoch 2539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2384 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2488 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 2541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8646 - f1: 0.8834 - val_loss: 0.2261 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8901 - val_loss: 0.2374 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8762 - f1: 0.8917 - val_loss: 0.2388 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 2544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2303 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 2545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2184 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2238 - val_acc: 0.9538 - val_f1: 0.9567\n",
      "Epoch 2547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2373 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2342 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 2549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2481 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2178 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2667 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2350 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2450 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2435 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8854 - val_loss: 0.2437 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2338 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2261 - val_acc: 0.9569 - val_f1: 0.9592\n",
      "Epoch 2559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2314 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 2560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2264 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2421 - val_acc: 0.9688 - val_f1: 0.9703\n",
      "Epoch 2562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8738 - f1: 0.8900 - val_loss: 0.2299 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2369 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2341 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2571 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2185 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2125 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2301 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2344 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8755 - f1: 0.8916 - val_loss: 0.2139 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 2571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2182 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8709 - f1: 0.8877 - val_loss: 0.2507 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2341 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 2574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2333 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 2575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2160 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2290 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2386 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2947 - val_acc: 0.9616 - val_f1: 0.9617\n",
      "Epoch 2579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2264 - val_acc: 0.9538 - val_f1: 0.9565\n",
      "Epoch 2580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2281 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2968 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2262 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 2583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2234 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 2584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2592 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2080 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 2586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 2587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2241 - val_acc: 0.9594 - val_f1: 0.9610\n",
      "Epoch 2588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2188 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2379 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8884 - val_loss: 0.2306 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8764 - f1: 0.8921 - val_loss: 0.2408 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8643 - f1: 0.8831 - val_loss: 0.2298 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2593/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8723 - f1: 0.8886 - val_loss: 0.2276 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2243 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2378 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2260 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 2597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2398 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8752 - f1: 0.8918 - val_loss: 0.2572 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2337 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2387 - val_acc: 0.9594 - val_f1: 0.9609\n",
      "Epoch 2601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2708 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 2602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2622 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 2603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2252 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 2604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2490 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8724 - f1: 0.8897 - val_loss: 0.2393 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8757 - f1: 0.8911 - val_loss: 0.2363 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2392 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8718 - f1: 0.8884 - val_loss: 0.2381 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 2609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2506 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2374 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2484 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2312 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8729 - f1: 0.8893 - val_loss: 0.2357 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 2614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2480 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2621 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 2616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2496 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 2617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2294 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8602 - f1: 0.8796 - val_loss: 0.2352 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 2619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2230 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8633 - f1: 0.8825 - val_loss: 0.2511 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2772 - val_acc: 0.9591 - val_f1: 0.9603\n",
      "Epoch 2622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2517 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 2623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2290 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2248 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 2625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2276 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 2626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2382 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2552 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 2628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2332 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2482 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 2630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8751 - f1: 0.8916 - val_loss: 0.2232 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8657 - f1: 0.8841 - val_loss: 0.2466 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2375 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8899 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8668 - f1: 0.8850 - val_loss: 0.2519 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2182 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2365 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 2637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2202 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2329 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2505 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2273 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8744 - f1: 0.8911 - val_loss: 0.2448 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2845 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 2644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2348 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 2645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2344 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2326 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 2647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2279 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2625 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 2649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8674 - f1: 0.8857 - val_loss: 0.2200 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 2650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8634 - f1: 0.8822 - val_loss: 0.2270 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2313 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8646 - f1: 0.8830 - val_loss: 0.2439 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2337 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 2654/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2306 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8674 - f1: 0.8851 - val_loss: 0.2415 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2486 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2343 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2360 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2631 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8716 - f1: 0.8883 - val_loss: 0.2362 - val_acc: 0.9694 - val_f1: 0.9710\n",
      "Epoch 2661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8747 - f1: 0.8917 - val_loss: 0.2805 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 2662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2131 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 2663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8706 - f1: 0.8874 - val_loss: 0.2291 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2396 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8652 - f1: 0.8836 - val_loss: 0.2195 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 2666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2466 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2375 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2298 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 2669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8753 - f1: 0.8916 - val_loss: 0.2317 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 2670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2875 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2236 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8651 - f1: 0.8833 - val_loss: 0.2510 - val_acc: 0.9597 - val_f1: 0.9612\n",
      "Epoch 2673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2494 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2615 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 2675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2348 - val_acc: 0.9553 - val_f1: 0.9574\n",
      "Epoch 2676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8685 - f1: 0.8857 - val_loss: 0.2395 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2411 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2307 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2355 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 2680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2596 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.3258 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 2682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2284 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8650 - f1: 0.8840 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2527 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2212 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2313 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2687/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8689 - f1: 0.8863 - val_loss: 0.2531 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 2688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2293 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2184 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 2690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.2368 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2384 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2394 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2384 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8748 - f1: 0.8913 - val_loss: 0.2364 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 2695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2239 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8723 - f1: 0.8887 - val_loss: 0.2361 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2421 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 2701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2364 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2197 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2227 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 2704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2225 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8693 - f1: 0.8865 - val_loss: 0.2520 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8711 - f1: 0.8884 - val_loss: 0.2350 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2333 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2396 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8738 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2546 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2184 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2712/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2357 - val_acc: 0.9594 - val_f1: 0.9601\n",
      "Epoch 2713/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2283 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2714/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2395 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2715/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3335 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2313 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2287 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 2717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2498 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2718/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2350 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2719/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2397 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2720/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3357 - acc: 0.8673 - f1: 0.88 - 0s 16us/sample - loss: 0.3327 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2350 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2188 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2592 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 2723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2589 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 2724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2484 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2293 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 2726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8732 - f1: 0.8903 - val_loss: 0.2396 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 2727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2402 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 2728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8651 - f1: 0.8840 - val_loss: 0.2796 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8844 - val_loss: 0.2424 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2730/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3179 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2329 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2211 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 2732/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3242 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2240 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2486 - val_acc: 0.9678 - val_f1: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8766 - f1: 0.8923 - val_loss: 0.2609 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2309 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 2736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8886 - val_loss: 0.2255 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2193 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2478 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 2739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2524 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2485 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 2741/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2307 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8701 - f1: 0.8877 - val_loss: 0.2374 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2254 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 2744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3392 - acc: 0.8643 - f1: 0.8828 - val_loss: 0.2487 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2432 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 2746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2480 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 2747/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3322 - acc: 0.8686 - f1: 0.8858 - val_loss: 0.2224 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 2748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2749/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3236 - acc: 0.8719 - f1: 0.8894 - val_loss: 0.2335 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2155 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 2751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2130 - val_acc: 0.9597 - val_f1: 0.9619\n",
      "Epoch 2752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2260 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 2753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2470 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2837 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2202 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 2756/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3289 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2215 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8711 - f1: 0.8879 - val_loss: 0.2252 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 2758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2410 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2759/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.3001 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 2760/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2465 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2532 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 2762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2242 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 2763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2670 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 2765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2309 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2766/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2328 - val_acc: 0.9609 - val_f1: 0.9633\n",
      "Epoch 2767/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3310 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2219 - val_acc: 0.9553 - val_f1: 0.9578\n",
      "Epoch 2768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2215 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2105 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 2770/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8865 - val_loss: 0.2296 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2771/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2727 - val_acc: 0.9647 - val_f1: 0.9650\n",
      "Epoch 2772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2203 - val_acc: 0.9631 - val_f1: 0.9651\n",
      "Epoch 2773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2504 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2774/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2460 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 2775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2345 - val_acc: 0.9666 - val_f1: 0.9684\n",
      "Epoch 2776/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2773 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 2777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2397 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2778/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2301 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 2779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2171 - val_acc: 0.9603 - val_f1: 0.9617\n",
      "Epoch 2780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2119 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 2781/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8673 - f1: 0.8847 - val_loss: 0.2284 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2271 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 2783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2650 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2611 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 2785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2269 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Epoch 2786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2258 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 2787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8735 - f1: 0.8905 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 2788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2282 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2267 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2416 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 2791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2521 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2618 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8730 - f1: 0.8894 - val_loss: 0.2503 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8879 - val_loss: 0.2264 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 2795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8709 - f1: 0.8878 - val_loss: 0.2562 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2358 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 2797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2254 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8814 - val_loss: 0.2255 - val_acc: 0.9684 - val_f1: 0.9692\n",
      "Epoch 2799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8639 - f1: 0.8826 - val_loss: 0.2176 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 2800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2307 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2376 - val_acc: 0.9678 - val_f1: 0.9695\n",
      "Epoch 2802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8728 - f1: 0.8898 - val_loss: 0.2323 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2271 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 2804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2458 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2255 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 2806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8684 - f1: 0.8858 - val_loss: 0.2200 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8686 - f1: 0.8859 - val_loss: 0.2240 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 2808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2378 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 2809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2304 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2122 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2198 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2229 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2958 - val_acc: 0.9647 - val_f1: 0.9647\n",
      "Epoch 2815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2297 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8667 - f1: 0.8852 - val_loss: 0.2530 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 2817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2354 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 2818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8760 - f1: 0.8920 - val_loss: 0.2212 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2202 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 2820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2433 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 2821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2444 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8764 - f1: 0.8923 - val_loss: 0.2264 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 2823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2293 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 2824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8896 - val_loss: 0.2310 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2347 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8731 - f1: 0.8895 - val_loss: 0.2458 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2484 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8723 - f1: 0.8887 - val_loss: 0.2579 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2336 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8736 - f1: 0.8899 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8635 - f1: 0.8826 - val_loss: 0.2506 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2472 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.3032 - val_acc: 0.9603 - val_f1: 0.9611\n",
      "Epoch 2836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8649 - f1: 0.8835 - val_loss: 0.2563 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2284 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2188 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 2839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2409 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8666 - f1: 0.8857 - val_loss: 0.2273 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2514 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2190 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2273 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2435 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8615 - f1: 0.8811 - val_loss: 0.2375 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2647 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 2848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8758 - f1: 0.8921 - val_loss: 0.2299 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 2849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2318 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2325 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2499 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8699 - f1: 0.8879 - val_loss: 0.2583 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2446 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2371 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2251 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 2856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2461 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 2857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2405 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2656 - val_acc: 0.9544 - val_f1: 0.9560\n",
      "Epoch 2859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8661 - f1: 0.8840 - val_loss: 0.2322 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2216 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 2861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2293 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2447 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2505 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2382 - val_acc: 0.9688 - val_f1: 0.9695\n",
      "Epoch 2865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2473 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3119 - acc: 0.8793 - f1: 0.8946 - val_loss: 0.2499 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2628 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 2868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2377 - val_acc: 0.9656 - val_f1: 0.9658\n",
      "Epoch 2869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2563 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2436 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 2871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2508 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2404 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8725 - f1: 0.8893 - val_loss: 0.2371 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 2874/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3342 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2364 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2875/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2261 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2485 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8618 - f1: 0.8808 - val_loss: 0.2188 - val_acc: 0.9569 - val_f1: 0.9590\n",
      "Epoch 2879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8692 - f1: 0.8872 - val_loss: 0.2458 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8706 - f1: 0.8883 - val_loss: 0.2534 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2477 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 2882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2266 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2366 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8703 - f1: 0.8874 - val_loss: 0.2462 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 2885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2815 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2469 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 2887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8758 - f1: 0.8919 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8722 - f1: 0.8889 - val_loss: 0.2454 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 2889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2509 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2517 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2312 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2825 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2357 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 2894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2744 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 2895/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8850 - val_loss: 0.2454 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2386 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2337 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2307 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2583 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 2900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2731 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 2901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2655 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2365 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2903/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2441 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2317 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 2905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8742 - f1: 0.8908 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2488 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8699 - f1: 0.8877 - val_loss: 0.2472 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 2908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8644 - f1: 0.8827 - val_loss: 0.2310 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 2909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2299 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2210 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 2911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2395 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8685 - f1: 0.8869 - val_loss: 0.2310 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 2913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 2914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2465 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 2915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2283 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2591 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2464 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2281 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2686 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 2920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2388 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2450 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2303 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 2923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2558 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2366 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 2925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2345 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2367 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2263 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2442 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2794 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 2930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8679 - f1: 0.8861 - val_loss: 0.2317 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2294 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 2932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2526 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8922 - val_loss: 0.2494 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8751 - f1: 0.8918 - val_loss: 0.2266 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2174 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 2936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8766 - f1: 0.8924 - val_loss: 0.2399 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 2937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2609 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2415 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2477 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 2940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2320 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 2941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2869 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2942/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2367 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2302 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 2944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2276 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2838 - val_acc: 0.9634 - val_f1: 0.9637\n",
      "Epoch 2946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2597 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2469 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2518 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 2949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2487 - val_acc: 0.9366 - val_f1: 0.9407\n",
      "Epoch 2950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8621 - f1: 0.8813 - val_loss: 0.2293 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 2951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8863 - val_loss: 0.2511 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 2952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2380 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 2953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2724 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2571 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 2955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2286 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 2956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2247 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2281 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 2958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2282 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 2959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2278 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2498 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 2961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2490 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2471 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2437 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2607 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2539 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 2967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2542 - val_acc: 0.9681 - val_f1: 0.9696\n",
      "Epoch 2968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2566 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 2969/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2427 - val_acc: 0.9531 - val_f1: 0.9555\n",
      "Epoch 2970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2331 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2598 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2481 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 2973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2511 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2635 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2400 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2558 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2577 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8873 - val_loss: 0.2363 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2443 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2462 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2397 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 2982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2346 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 2983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8648 - f1: 0.8837 - val_loss: 0.2388 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8679 - f1: 0.8852 - val_loss: 0.2458 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2420 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2986/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3277 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2169 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 2987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2179 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2320 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 2989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8739 - f1: 0.8902 - val_loss: 0.2808 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2199 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 2991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2513 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2129 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 2993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2320 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 2994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8718 - f1: 0.8885 - val_loss: 0.2654 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2439 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2381 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 2997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2265 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2663 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 2999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2264 - val_acc: 0.9591 - val_f1: 0.9609\n",
      "Epoch 3000/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2377 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 3001/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3182 - acc: 0.8753 - f1: 0.8910 - val_loss: 0.2490 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3002/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2706 - val_acc: 0.9631 - val_f1: 0.9637\n",
      "Epoch 3003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2269 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 3004/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3486 - acc: 0.8616 - f1: 0.8811 - val_loss: 0.2519 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3005/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2752 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2296 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8742 - f1: 0.8908 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3008/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3168 - acc: 0.8760 - f1: 0.8921 - val_loss: 0.2376 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 3009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2502 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3010/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2213 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 3011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2358 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 3012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2317 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3013/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2304 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2487 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 3015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2464 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2454 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 3017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2449 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2408 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8873 - val_loss: 0.2276 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2673 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 3021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2330 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2391 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.3286 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 3024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2289 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2264 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2474 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2287 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2296 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2693 - val_acc: 0.9541 - val_f1: 0.9561\n",
      "Epoch 3030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2468 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3031/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2461 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2401 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2625 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 3034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2207 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3035/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3036/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8912 - val_loss: 0.2166 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3037/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2451 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3038/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2596 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2609 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2340 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2122 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 3042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8637 - f1: 0.8826 - val_loss: 0.2328 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2829 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 3044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2791 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 3045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2379 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3046/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3304 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2330 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 3047/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8899 - val_loss: 0.2304 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3048/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3183 - acc: 0.8754 - f1: 0.8919 - val_loss: 0.2376 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 3049/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2476 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3050/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3257 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2261 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3051/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2218 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 3052/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2439 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 3053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2710 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2669 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3055/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2334 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3056/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8675 - f1: 0.8860 - val_loss: 0.2276 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3057/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2407 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8724 - f1: 0.8893 - val_loss: 0.2467 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2318 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8678 - f1: 0.8862 - val_loss: 0.2423 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8711 - f1: 0.8878 - val_loss: 0.2220 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 3063/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2439 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3173 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2410 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2338 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2386 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2417 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2412 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3069/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8743 - f1: 0.8905 - val_loss: 0.2485 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2506 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2582 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2502 - val_acc: 0.9588 - val_f1: 0.9600\n",
      "Epoch 3073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2504 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3074/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8635 - f1: 0.8823 - val_loss: 0.2749 - val_acc: 0.9663 - val_f1: 0.9664\n",
      "Epoch 3075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2290 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2297 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 3077/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2413 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2840 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 3079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2904 - val_acc: 0.9600 - val_f1: 0.9609\n",
      "Epoch 3080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8624 - f1: 0.8816 - val_loss: 0.2917 - val_acc: 0.9603 - val_f1: 0.9602\n",
      "Epoch 3081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2404 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2486 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8772 - f1: 0.8930 - val_loss: 0.2539 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2652 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3085/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2306 - val_acc: 0.9694 - val_f1: 0.9701\n",
      "Epoch 3086/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2301 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3087/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2647 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3088/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3273 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2386 - val_acc: 0.9709 - val_f1: 0.9722\n",
      "Epoch 3089/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2466 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2709 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 3091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8714 - f1: 0.8880 - val_loss: 0.2239 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 3092/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2485 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2537 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2374 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2270 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 3096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2231 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3097/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2820 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 3098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8868 - val_loss: 0.2486 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2212 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2221 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 3101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8657 - f1: 0.8837 - val_loss: 0.2645 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2340 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8735 - f1: 0.8901 - val_loss: 0.2288 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2464 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8669 - f1: 0.8853 - val_loss: 0.2321 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2366 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2351 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2317 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8858 - val_loss: 0.2453 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 3110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2339 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8725 - f1: 0.8889 - val_loss: 0.2361 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 3112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2175 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 3113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2289 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2458 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 3115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2267 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 3116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2506 - val_acc: 0.9625 - val_f1: 0.9628\n",
      "Epoch 3117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2561 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2358 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 3119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2344 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2363 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8672 - f1: 0.8853 - val_loss: 0.2366 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 3122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8632 - f1: 0.8820 - val_loss: 0.2363 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 3123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2589 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2527 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2501 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 3127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2426 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2302 - val_acc: 0.9578 - val_f1: 0.9602\n",
      "Epoch 3129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2257 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 3130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2429 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8656 - f1: 0.8845 - val_loss: 0.2691 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2570 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8709 - f1: 0.8878 - val_loss: 0.2218 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2452 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 3135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8764 - f1: 0.8928 - val_loss: 0.2474 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2253 - val_acc: 0.9572 - val_f1: 0.9590\n",
      "Epoch 3137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2274 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 3138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2374 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8693 - f1: 0.8866 - val_loss: 0.2279 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2241 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8852 - val_loss: 0.2268 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 3142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2316 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2655 - val_acc: 0.9631 - val_f1: 0.9635\n",
      "Epoch 3146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8704 - f1: 0.8880 - val_loss: 0.2292 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 3147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2171 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2187 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 3149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2392 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 3150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2510 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2424 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 3152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2129 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 3153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8667 - f1: 0.8848 - val_loss: 0.2398 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8754 - f1: 0.8919 - val_loss: 0.2745 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2413 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2255 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3157/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2291 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2573 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8740 - f1: 0.8910 - val_loss: 0.2742 - val_acc: 0.9613 - val_f1: 0.9622\n",
      "Epoch 3160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2449 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2393 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2656 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2504 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2468 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8678 - f1: 0.8862 - val_loss: 0.2509 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2654 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 3167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2659 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8692 - f1: 0.8870 - val_loss: 0.2284 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2637 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2267 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2281 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2707 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2472 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.2506 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2533 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8627 - f1: 0.8821 - val_loss: 0.2392 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 3178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2526 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2507 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3149 - acc: 0.8786 - f1: 0.8944 - val_loss: 0.2459 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8636 - f1: 0.8825 - val_loss: 0.2292 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2348 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2348 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 3184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2444 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2713 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 3186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2767 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2417 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 3188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8731 - f1: 0.8894 - val_loss: 0.2418 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8664 - f1: 0.8848 - val_loss: 0.2606 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 3190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8732 - f1: 0.8896 - val_loss: 0.2490 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2272 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8773 - f1: 0.8927 - val_loss: 0.2336 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2456 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2427 - val_acc: 0.9697 - val_f1: 0.9703\n",
      "Epoch 3195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2495 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 3196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2421 - val_acc: 0.9694 - val_f1: 0.9710\n",
      "Epoch 3197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2122 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2372 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8749 - f1: 0.8909 - val_loss: 0.2665 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2565 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8688 - f1: 0.8867 - val_loss: 0.2423 - val_acc: 0.9656 - val_f1: 0.9660\n",
      "Epoch 3202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2524 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2500 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2643 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2425 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 3206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2498 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 3207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2397 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2247 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8763 - f1: 0.8928 - val_loss: 0.2463 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2293 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2589 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2529 - val_acc: 0.9666 - val_f1: 0.9669\n",
      "Epoch 3213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8691 - f1: 0.8873 - val_loss: 0.2311 - val_acc: 0.9541 - val_f1: 0.9571\n",
      "Epoch 3214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.2193 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 3215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2542 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2392 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2424 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2569 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2338 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2266 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2445 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3222/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3289 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2561 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2354 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 3224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2558 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 3225/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3164 - acc: 0.8765 - f1: 0.8928 - val_loss: 0.2526 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3226/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2211 - val_acc: 0.9616 - val_f1: 0.9640\n",
      "Epoch 3227/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2265 - val_acc: 0.9575 - val_f1: 0.9596\n",
      "Epoch 3228/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2349 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8740 - f1: 0.8906 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3230/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2355 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3231/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2850 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8678 - f1: 0.8851 - val_loss: 0.2251 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2291 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2439 - val_acc: 0.9669 - val_f1: 0.9673\n",
      "Epoch 3235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8868 - val_loss: 0.2200 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2361 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2444 - val_acc: 0.9638 - val_f1: 0.9640\n",
      "Epoch 3238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2223 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3239/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2227 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3240/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3205 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2359 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 3241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2415 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8706 - f1: 0.8881 - val_loss: 0.2312 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 3243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2198 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2379 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8858 - val_loss: 0.2165 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2627 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2278 - val_acc: 0.9547 - val_f1: 0.9570\n",
      "Epoch 3248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2307 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 3249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2453 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2205 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3251/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8871 - val_loss: 0.2364 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 3252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8685 - f1: 0.8857 - val_loss: 0.2288 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2406 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2401 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2280 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 3256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8715 - f1: 0.8883 - val_loss: 0.2755 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2367 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8725 - f1: 0.8899 - val_loss: 0.2589 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2285 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2340 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2386 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 3262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2491 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8882 - val_loss: 0.3088 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2616 - val_acc: 0.9653 - val_f1: 0.9657\n",
      "Epoch 3265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8867 - val_loss: 0.2501 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2607 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3267/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2408 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2218 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 3269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8625 - f1: 0.8815 - val_loss: 0.2655 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3270/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2388 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3271/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3428 - acc: 0.8616 - f1: 0.8812 - val_loss: 0.2577 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 3272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8762 - f1: 0.8918 - val_loss: 0.2508 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 3273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8692 - f1: 0.8872 - val_loss: 0.2175 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2652 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 3276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8702 - f1: 0.8871 - val_loss: 0.2464 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2673 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3278/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2408 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2301 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 3280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2469 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2183 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 3282/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2333 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 3283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2529 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2370 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 3285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8816 - val_loss: 0.2311 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 3286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2546 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 3287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2743 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3288/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2717 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3146 - acc: 0.8781 - f1: 0.8937 - val_loss: 0.2486 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2517 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 3291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2490 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3292/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2805 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3293/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2564 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 3294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8682 - f1: 0.8857 - val_loss: 0.2501 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2389 - val_acc: 0.9663 - val_f1: 0.9685\n",
      "Epoch 3296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2600 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2268 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 3298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2456 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2396 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2496 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2276 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2476 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2444 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8746 - f1: 0.8908 - val_loss: 0.2713 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2694 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 3306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2367 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 3307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2563 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2388 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8656 - f1: 0.8842 - val_loss: 0.2205 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 3310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2505 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2439 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8617 - f1: 0.8803 - val_loss: 0.2239 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2361 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2351 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2108 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2474 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2553 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2688 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 3319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2451 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2595 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2606 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 3323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8718 - f1: 0.8885 - val_loss: 0.2507 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2524 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 3325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2656 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2272 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2314 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2493 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8890 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2411 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2380 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2534 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 3333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2708 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9669\n",
      "Epoch 3335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2606 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2574 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2578 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2335 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2362 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2697 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2716 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2301 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2701 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8750 - f1: 0.8915 - val_loss: 0.2517 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3345/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2356 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 3346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8749 - f1: 0.8910 - val_loss: 0.2380 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8876 - val_loss: 0.2371 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8747 - f1: 0.8915 - val_loss: 0.2381 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8747 - f1: 0.8914 - val_loss: 0.2493 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 3350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2371 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2558 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8821 - val_loss: 0.2407 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2536 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2516 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2309 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2549 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 3357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8673 - f1: 0.8859 - val_loss: 0.2616 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8750 - f1: 0.8913 - val_loss: 0.2437 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 3359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2228 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 3360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2602 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2602 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8750 - f1: 0.8917 - val_loss: 0.2476 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2452 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2601 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2606 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8758 - f1: 0.8920 - val_loss: 0.2824 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 3367/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3280 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2424 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3368/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2579 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2404 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2475 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2432 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2308 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2330 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8839 - val_loss: 0.2618 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 3375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2198 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8651 - f1: 0.8833 - val_loss: 0.2312 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2352 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8748 - f1: 0.8913 - val_loss: 0.2327 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8899 - val_loss: 0.2446 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2276 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2266 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2888 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2360 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 3384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2624 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2574 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 3386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8672 - f1: 0.8850 - val_loss: 0.2953 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 3387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2424 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8769 - f1: 0.8931 - val_loss: 0.2793 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8755 - f1: 0.8915 - val_loss: 0.2370 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2447 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 3391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2248 - val_acc: 0.9584 - val_f1: 0.9602\n",
      "Epoch 3392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2460 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2445 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 3394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2544 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8673 - f1: 0.8857 - val_loss: 0.2483 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2477 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2353 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2386 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 3399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2351 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2401 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2592 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2281 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 3403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8683 - f1: 0.8863 - val_loss: 0.2568 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8909 - val_loss: 0.2331 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2521 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8886 - val_loss: 0.2396 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 3407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2273 - val_acc: 0.9581 - val_f1: 0.9605\n",
      "Epoch 3408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2359 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2526 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2908 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 3411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2391 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8858 - val_loss: 0.2372 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8688 - f1: 0.8866 - val_loss: 0.2603 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2627 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3134 - acc: 0.8794 - f1: 0.8952 - val_loss: 0.2343 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2365 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2392 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2313 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 3419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2524 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2930 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2457 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8646 - f1: 0.8832 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8644 - f1: 0.8835 - val_loss: 0.2722 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2226 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2458 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 3427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8702 - f1: 0.8881 - val_loss: 0.2351 - val_acc: 0.9603 - val_f1: 0.9614\n",
      "Epoch 3428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2490 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 3429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8732 - f1: 0.8896 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2837 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 3431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2554 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2313 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2200 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 3434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2514 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2284 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8761 - f1: 0.8926 - val_loss: 0.2395 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2218 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 3439/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2391 - val_acc: 0.9678 - val_f1: 0.9680\n",
      "Epoch 3440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2671 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 3441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2397 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 3442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8709 - f1: 0.8888 - val_loss: 0.2370 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2593 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8696 - f1: 0.8865 - val_loss: 0.2300 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2461 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2703 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2383 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 3448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2556 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2570 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2503 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8677 - f1: 0.8860 - val_loss: 0.2248 - val_acc: 0.9691 - val_f1: 0.9702\n",
      "Epoch 3452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2549 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8644 - f1: 0.8834 - val_loss: 0.2244 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2452 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 3455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2309 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2305 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 3457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2209 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.3002 - val_acc: 0.9622 - val_f1: 0.9625\n",
      "Epoch 3459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2299 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2479 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2529 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2443 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2640 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2202 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2397 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2714 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2454 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8746 - f1: 0.8910 - val_loss: 0.2255 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8749 - f1: 0.8915 - val_loss: 0.2425 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8756 - f1: 0.8917 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8768 - f1: 0.8927 - val_loss: 0.2661 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2265 - val_acc: 0.9578 - val_f1: 0.9598\n",
      "Epoch 3473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8668 - f1: 0.8842 - val_loss: 0.2375 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 3474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8685 - f1: 0.8869 - val_loss: 0.2553 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2439 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8749 - f1: 0.8914 - val_loss: 0.2517 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2669 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2406 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 3479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2464 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 3480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2377 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 3481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2362 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2423 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 3483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2399 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8872 - val_loss: 0.2134 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 3485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8701 - f1: 0.8878 - val_loss: 0.2753 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2487 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2343 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2297 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 3489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2455 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 3490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8692 - f1: 0.8870 - val_loss: 0.2378 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2440 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 3492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2523 - val_acc: 0.9644 - val_f1: 0.9663\n",
      "Epoch 3493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8668 - f1: 0.8849 - val_loss: 0.2427 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2377 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 3495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2463 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2329 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8685 - f1: 0.8861 - val_loss: 0.2417 - val_acc: 0.9494 - val_f1: 0.9521\n",
      "Epoch 3499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2322 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 3500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2524 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2361 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2699 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2359 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8671 - f1: 0.8850 - val_loss: 0.2565 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2578 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2362 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 3507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2318 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8868 - val_loss: 0.2609 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 3509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8737 - f1: 0.8899 - val_loss: 0.2397 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8693 - f1: 0.8864 - val_loss: 0.2703 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2654 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 3512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8725 - f1: 0.8897 - val_loss: 0.2627 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2894 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 3514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2883 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8729 - f1: 0.8901 - val_loss: 0.2851 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 3516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2787 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 3517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8746 - f1: 0.8913 - val_loss: 0.2900 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 3518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8640 - f1: 0.8830 - val_loss: 0.2870 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8762 - f1: 0.8924 - val_loss: 0.2264 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2341 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 3521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2497 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2407 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2457 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8710 - f1: 0.8888 - val_loss: 0.2239 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 3525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2339 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2376 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 3528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2115 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2438 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8704 - f1: 0.8872 - val_loss: 0.2292 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2711 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3532/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3201 - acc: 0.8741 - f1: 0.8902 - val_loss: 0.2615 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8763 - f1: 0.8920 - val_loss: 0.2612 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3534/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2521 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2406 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 3536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3132 - acc: 0.8782 - f1: 0.8941 - val_loss: 0.2580 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2581 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8882 - val_loss: 0.2382 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 3539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8660 - f1: 0.8843 - val_loss: 0.2589 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2757 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2517 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2838 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 3543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2321 - val_acc: 0.9581 - val_f1: 0.9597\n",
      "Epoch 3544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2498 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2483 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8690 - f1: 0.8870 - val_loss: 0.2662 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8690 - f1: 0.8871 - val_loss: 0.2474 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 3548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8862 - val_loss: 0.2314 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 3549/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3451 - acc: 0.8625 - f1: 0.8812 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3550/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2727 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2297 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 3552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2465 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3553/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8836 - val_loss: 0.2427 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 3554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8757 - f1: 0.8920 - val_loss: 0.2724 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3555/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2468 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 3556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8739 - f1: 0.8903 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3557/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8729 - f1: 0.8893 - val_loss: 0.2428 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3558/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8917 - val_loss: 0.2678 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3559/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8884 - val_loss: 0.2538 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3560/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3205 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2618 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3561/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2379 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3562/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2464 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3563/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3201 - acc: 0.8746 - f1: 0.8911 - val_loss: 0.2430 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 3564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2357 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 3565/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3219 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2342 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2340 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 3567/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3208 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 3568/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3245 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2509 - val_acc: 0.9700 - val_f1: 0.9703\n",
      "Epoch 3569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8766 - f1: 0.8924 - val_loss: 0.2394 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 3570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2376 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3571/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3223 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2258 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2482 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3573/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8733 - f1: 0.8902 - val_loss: 0.2459 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 3574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2393 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3575/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3187 - acc: 0.8762 - f1: 0.8917 - val_loss: 0.2547 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 3576/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8646 - f1: 0.8829 - val_loss: 0.2408 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 3577/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8895 - val_loss: 0.2532 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2456 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8737 - f1: 0.8896 - val_loss: 0.2499 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 3580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2320 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 3581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2232 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3582/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2642 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8615 - f1: 0.8804 - val_loss: 0.2291 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8715 - f1: 0.8879 - val_loss: 0.2274 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 3585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2355 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 3586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2673 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2344 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8890 - val_loss: 0.2432 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2632 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2389 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8696 - f1: 0.8875 - val_loss: 0.2289 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 3592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2302 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3593/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2411 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3594/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2668 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3595/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2430 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3596/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3279 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2497 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3597/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3302 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2703 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3598/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.2886 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 3599/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2482 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3600/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3185 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2691 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3601/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8724 - f1: 0.8898 - val_loss: 0.2781 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3602/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3297 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2430 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 3603/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2586 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8651 - f1: 0.8837 - val_loss: 0.2594 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2498 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 3606/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2768 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 3607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2708 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8741 - f1: 0.8898 - val_loss: 0.2689 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 3609/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2239 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3610/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2411 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 3611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8864 - val_loss: 0.2493 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 3612/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3352 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2557 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3613/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3321 - acc: 0.8678 - f1: 0.8859 - val_loss: 0.2434 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3614/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3214 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2530 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3615/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2392 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 3616/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2381 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2486 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2554 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 3619/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3195 - acc: 0.8741 - f1: 0.8911 - val_loss: 0.2585 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3620/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2521 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 3621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2666 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 3622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8746 - f1: 0.8912 - val_loss: 0.2700 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2800 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3624/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3370 - acc: 0.8655 - f1: 0.8844 - val_loss: 0.2475 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3625/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3360 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2508 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3626/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 3627/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2604 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2388 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8683 - f1: 0.8859 - val_loss: 0.2326 - val_acc: 0.9634 - val_f1: 0.9657\n",
      "Epoch 3631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8711 - f1: 0.8884 - val_loss: 0.2479 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 3632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2259 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2345 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2338 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2421 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2355 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 3638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2240 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 3639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8770 - f1: 0.8926 - val_loss: 0.2462 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 3640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3134 - acc: 0.8779 - f1: 0.8937 - val_loss: 0.2472 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 3641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8694 - f1: 0.8872 - val_loss: 0.2303 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2320 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 3644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8665 - f1: 0.8851 - val_loss: 0.2750 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 3645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2475 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 3646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3143 - acc: 0.8774 - f1: 0.8932 - val_loss: 0.2801 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2741 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 3648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8875 - val_loss: 0.2601 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2657 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2428 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8730 - f1: 0.8903 - val_loss: 0.2439 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2520 - val_acc: 0.9691 - val_f1: 0.9697\n",
      "Epoch 3653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2617 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2556 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2451 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8671 - f1: 0.8847 - val_loss: 0.2496 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2349 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2298 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3142 - acc: 0.8780 - f1: 0.8939 - val_loss: 0.2654 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 3661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2765 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8876 - val_loss: 0.2297 - val_acc: 0.9541 - val_f1: 0.9567\n",
      "Epoch 3663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2380 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 3664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8634 - f1: 0.8823 - val_loss: 0.2290 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 3665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2295 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2476 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2378 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2544 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 3669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2477 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8728 - f1: 0.8901 - val_loss: 0.2405 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2360 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2400 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2550 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3147 - acc: 0.8773 - f1: 0.8926 - val_loss: 0.2473 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2916 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2632 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 3677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2147 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 3678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2242 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8629 - f1: 0.8819 - val_loss: 0.2293 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 3680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2498 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 3681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2629 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8731 - f1: 0.8901 - val_loss: 0.2320 - val_acc: 0.9456 - val_f1: 0.9496\n",
      "Epoch 3683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2514 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3166 - acc: 0.8761 - f1: 0.8925 - val_loss: 0.2420 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 3686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2429 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2424 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2553 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2405 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2380 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 3691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2486 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8724 - f1: 0.8893 - val_loss: 0.2462 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2619 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3169 - acc: 0.8763 - f1: 0.8926 - val_loss: 0.2511 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 3695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2366 - val_acc: 0.9641 - val_f1: 0.9662\n",
      "Epoch 3696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2666 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 3697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2496 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8693 - f1: 0.8873 - val_loss: 0.3386 - val_acc: 0.9569 - val_f1: 0.9582\n",
      "Epoch 3699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2187 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 3700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2527 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2403 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 3702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2373 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3165 - acc: 0.8772 - f1: 0.8933 - val_loss: 0.2639 - val_acc: 0.9681 - val_f1: 0.9679\n",
      "Epoch 3704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2446 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2297 - val_acc: 0.9491 - val_f1: 0.9525\n",
      "Epoch 3706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8669 - f1: 0.8854 - val_loss: 0.2331 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2415 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2785 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2514 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2931 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2525 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2376 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2258 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 3714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2610 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2319 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8737 - f1: 0.8908 - val_loss: 0.2534 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2252 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 3719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2494 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 3720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3721/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2772 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2501 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 3723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2359 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2513 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3725/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3232 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2799 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 3726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2578 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3727/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2347 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 3728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2505 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2152 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 3730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2346 - val_acc: 0.9669 - val_f1: 0.9671\n",
      "Epoch 3731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2478 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2622 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2515 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 3734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2750 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 3735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8728 - f1: 0.8898 - val_loss: 0.2358 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 3736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2565 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8689 - f1: 0.8869 - val_loss: 0.2313 - val_acc: 0.9597 - val_f1: 0.9609\n",
      "Epoch 3738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2288 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 3739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2535 - val_acc: 0.9481 - val_f1: 0.9519\n",
      "Epoch 3740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2714 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2288 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2362 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8716 - f1: 0.8883 - val_loss: 0.2488 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3744/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2289 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2667 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3746/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2165 - val_acc: 0.9556 - val_f1: 0.9576\n",
      "Epoch 3747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2328 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2558 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8767 - f1: 0.8927 - val_loss: 0.2502 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3157 - acc: 0.8770 - f1: 0.8934 - val_loss: 0.2623 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2541 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2313 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8676 - f1: 0.8860 - val_loss: 0.2705 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2794 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2487 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8757 - f1: 0.8918 - val_loss: 0.2460 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2448 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2514 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 3759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2384 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2580 - val_acc: 0.9647 - val_f1: 0.9646\n",
      "Epoch 3761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8847 - val_loss: 0.2499 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2566 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2411 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2595 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2366 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 3766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2538 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2594 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8735 - f1: 0.8904 - val_loss: 0.2318 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2258 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2558 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2538 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8749 - f1: 0.8908 - val_loss: 0.2478 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2491 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2494 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8718 - f1: 0.8893 - val_loss: 0.2609 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.3224 - val_acc: 0.9591 - val_f1: 0.9595\n",
      "Epoch 3777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2405 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2639 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.3000 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3128 - acc: 0.8797 - f1: 0.8951 - val_loss: 0.2539 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2494 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3163 - acc: 0.8760 - f1: 0.8921 - val_loss: 0.2625 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8652 - f1: 0.8841 - val_loss: 0.2540 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 3784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2468 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 3785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8692 - f1: 0.8873 - val_loss: 0.2824 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2722 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2414 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8897 - val_loss: 0.2507 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2497 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2445 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2373 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 3792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2577 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8862 - val_loss: 0.2660 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8922 - val_loss: 0.2418 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2813 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8756 - f1: 0.8920 - val_loss: 0.2535 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8610 - f1: 0.8803 - val_loss: 0.2504 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 3799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2518 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8869 - val_loss: 0.2399 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2507 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2548 - val_acc: 0.9653 - val_f1: 0.9657\n",
      "Epoch 3803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2480 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2514 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2709 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 3807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2296 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2364 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8771 - f1: 0.8926 - val_loss: 0.2470 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 3810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2701 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2283 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2799 - val_acc: 0.9644 - val_f1: 0.9647\n",
      "Epoch 3813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2259 - val_acc: 0.9691 - val_f1: 0.9702\n",
      "Epoch 3814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2670 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3815/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2445 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 3816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2410 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8651 - f1: 0.8839 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2525 - val_acc: 0.9684 - val_f1: 0.9689\n",
      "Epoch 3819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2267 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 3820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2549 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8767 - f1: 0.8932 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 3822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2457 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2938 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8726 - f1: 0.8893 - val_loss: 0.2547 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2437 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2451 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2494 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 3828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2422 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 3829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3153 - acc: 0.8764 - f1: 0.8929 - val_loss: 0.2675 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8859 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 3832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2459 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3136 - acc: 0.8778 - f1: 0.8935 - val_loss: 0.2743 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2896 - val_acc: 0.9563 - val_f1: 0.9567\n",
      "Epoch 3835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2416 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 3836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2326 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 3837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2300 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2343 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 3839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2343 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2580 - val_acc: 0.9672 - val_f1: 0.9675\n",
      "Epoch 3841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2532 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 3842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3143 - acc: 0.8783 - f1: 0.8940 - val_loss: 0.2416 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8757 - f1: 0.8922 - val_loss: 0.2256 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 3844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8652 - f1: 0.8841 - val_loss: 0.2533 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8643 - f1: 0.8830 - val_loss: 0.2936 - val_acc: 0.9597 - val_f1: 0.9600\n",
      "Epoch 3846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2622 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8740 - f1: 0.8907 - val_loss: 0.2664 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2448 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2544 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 3850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2723 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2683 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 3852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8754 - f1: 0.8917 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2580 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2559 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2085 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 3856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8643 - f1: 0.8829 - val_loss: 0.2140 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 3857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8634 - f1: 0.8822 - val_loss: 0.2359 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2257 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8668 - f1: 0.8848 - val_loss: 0.2230 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2786 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8736 - f1: 0.8902 - val_loss: 0.2395 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2476 - val_acc: 0.9684 - val_f1: 0.9694\n",
      "Epoch 3864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2438 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3148 - acc: 0.8769 - f1: 0.8930 - val_loss: 0.2778 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2692 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2432 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2433 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2996 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 3870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2753 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2202 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 3873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2517 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8743 - f1: 0.8908 - val_loss: 0.2606 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3875/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2784 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 3876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2471 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2317 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8669 - f1: 0.8849 - val_loss: 0.2903 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8743 - f1: 0.8909 - val_loss: 0.2334 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2399 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 3882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2429 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8757 - f1: 0.8919 - val_loss: 0.2382 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 3884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2614 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 3885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8682 - f1: 0.8863 - val_loss: 0.2563 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8769 - f1: 0.8925 - val_loss: 0.2554 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2527 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2301 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2488 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8910 - val_loss: 0.2487 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2455 - val_acc: 0.9591 - val_f1: 0.9608\n",
      "Epoch 3892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8713 - f1: 0.8878 - val_loss: 0.2242 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2392 - val_acc: 0.9694 - val_f1: 0.9700\n",
      "Epoch 3894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2619 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2552 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8707 - f1: 0.8875 - val_loss: 0.2336 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2666 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8749 - f1: 0.8914 - val_loss: 0.2327 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8897 - val_loss: 0.2752 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2368 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 3901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2185 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 3902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8638 - f1: 0.8822 - val_loss: 0.2419 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9663\n",
      "Epoch 3904/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2629 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 3905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2385 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 3906/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3225 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3907/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3193 - acc: 0.8748 - f1: 0.8909 - val_loss: 0.2482 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3908/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2312 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 3909/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2416 - val_acc: 0.9666 - val_f1: 0.9669\n",
      "Epoch 3910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8765 - f1: 0.8927 - val_loss: 0.2517 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 3911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2431 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8654 - f1: 0.8842 - val_loss: 0.2246 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 3913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2315 - val_acc: 0.9569 - val_f1: 0.9593\n",
      "Epoch 3914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2411 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2436 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3144 - acc: 0.8774 - f1: 0.8935 - val_loss: 0.2411 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8853 - val_loss: 0.2716 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 3918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8651 - f1: 0.8837 - val_loss: 0.2634 - val_acc: 0.9603 - val_f1: 0.9610\n",
      "Epoch 3919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2310 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 3920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2443 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3121 - acc: 0.8791 - f1: 0.8947 - val_loss: 0.2731 - val_acc: 0.9647 - val_f1: 0.9650\n",
      "Epoch 3922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2192 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2900 - val_acc: 0.9638 - val_f1: 0.9639\n",
      "Epoch 3924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8748 - f1: 0.8908 - val_loss: 0.2396 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8879 - val_loss: 0.2280 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 3926/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2303 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 3927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2496 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2648 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8708 - f1: 0.8876 - val_loss: 0.2444 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8671 - f1: 0.8854 - val_loss: 0.2435 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2555 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 3932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2691 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2412 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 3934/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2642 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2484 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 3936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2403 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3937/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3237 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2354 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2673 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 3939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2483 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8621 - f1: 0.8815 - val_loss: 0.2700 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 3941/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2324 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3942/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8895 - val_loss: 0.2505 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3943/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2366 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3944/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3294 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2320 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 3945/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2534 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3946/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2708 - val_acc: 0.9694 - val_f1: 0.9708\n",
      "Epoch 3947/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.3023 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 3948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2404 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3949/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2400 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 3950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8682 - f1: 0.8854 - val_loss: 0.2486 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3951/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8873 - val_loss: 0.2477 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3952/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2795 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8726 - f1: 0.8898 - val_loss: 0.2312 - val_acc: 0.9625 - val_f1: 0.9649\n",
      "Epoch 3954/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2535 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 3955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2588 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2511 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8740 - f1: 0.8905 - val_loss: 0.2305 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 3958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2489 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2467 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8762 - f1: 0.8923 - val_loss: 0.2323 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 3962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2617 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 3963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2190 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 3964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2471 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8721 - f1: 0.8897 - val_loss: 0.2316 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2387 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2584 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2592 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2287 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2544 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 3971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2508 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2495 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2330 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2400 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2266 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2377 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2408 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8728 - f1: 0.8902 - val_loss: 0.2420 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2309 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2639 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8673 - f1: 0.8859 - val_loss: 0.2468 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2390 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2571 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2426 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 3985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8684 - f1: 0.8868 - val_loss: 0.2572 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 3986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8676 - f1: 0.8859 - val_loss: 0.2403 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2307 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8880 - val_loss: 0.2307 - val_acc: 0.9559 - val_f1: 0.9582\n",
      "Epoch 3989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2367 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 3990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2647 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2520 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 3992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8730 - f1: 0.8895 - val_loss: 0.2883 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 3993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2445 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 3994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2481 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8900 - val_loss: 0.2541 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8884 - val_loss: 0.2403 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8717 - f1: 0.8886 - val_loss: 0.2369 - val_acc: 0.9531 - val_f1: 0.9559\n",
      "Epoch 3998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2397 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2315 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 4000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2611 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2602 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2418 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4003/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8697 - f1: 0.8871 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2557 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4005/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2543 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8733 - f1: 0.8903 - val_loss: 0.2336 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 4007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2470 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4008/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2403 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2140 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 4010/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2367 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2492 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4012/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3194 - acc: 0.8748 - f1: 0.89 - 0s 16us/sample - loss: 0.3195 - acc: 0.8753 - f1: 0.8918 - val_loss: 0.2366 - val_acc: 0.9594 - val_f1: 0.9610\n",
      "Epoch 4013/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3212 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2568 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4014/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2662 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8709 - f1: 0.8876 - val_loss: 0.2254 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 4016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2481 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8725 - f1: 0.8889 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2432 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8744 - f1: 0.8908 - val_loss: 0.2406 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2600 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2367 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2814 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 4023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2320 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 4024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2454 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2700 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2548 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 4028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2390 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 4029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2658 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2604 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2480 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2245 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2449 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2311 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 4035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8737 - f1: 0.8899 - val_loss: 0.2860 - val_acc: 0.9634 - val_f1: 0.9638\n",
      "Epoch 4036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.2364 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8706 - f1: 0.8884 - val_loss: 0.2391 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2411 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2688 - val_acc: 0.9653 - val_f1: 0.9655\n",
      "Epoch 4040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2374 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 4041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2659 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8773 - f1: 0.8931 - val_loss: 0.2509 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8743 - f1: 0.8907 - val_loss: 0.2620 - val_acc: 0.9656 - val_f1: 0.9660\n",
      "Epoch 4045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2997 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 4046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2367 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 4047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2441 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 4048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2934 - val_acc: 0.9647 - val_f1: 0.9647\n",
      "Epoch 4049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2606 - val_acc: 0.9647 - val_f1: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2599 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8712 - f1: 0.8889 - val_loss: 0.2609 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8682 - f1: 0.8864 - val_loss: 0.2656 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8711 - f1: 0.8879 - val_loss: 0.2493 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 4054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2590 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 4055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2272 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8721 - f1: 0.8887 - val_loss: 0.2707 - val_acc: 0.9669 - val_f1: 0.9673\n",
      "Epoch 4057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2453 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2616 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8654 - f1: 0.8835 - val_loss: 0.2244 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2407 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 4062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2563 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2547 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4064/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3200 - acc: 0.8743 - f1: 0.8905 - val_loss: 0.2728 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2539 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2587 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 4067/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3166 - acc: 0.8763 - f1: 0.8923 - val_loss: 0.2686 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2637 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2492 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8704 - f1: 0.8872 - val_loss: 0.2495 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4071/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8744 - f1: 0.8913 - val_loss: 0.2689 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.3028 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4073/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3127 - acc: 0.8796 - f1: 0.8947 - val_loss: 0.2665 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 4074/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3258 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2459 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 4075/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8735 - f1: 0.8907 - val_loss: 0.2587 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4076/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3141 - acc: 0.8779 - f1: 0.8938 - val_loss: 0.2819 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4077/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2525 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 4078/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8704 - f1: 0.8881 - val_loss: 0.2817 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4079/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2510 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 4080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2629 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2557 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4082/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4083/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8736 - f1: 0.8900 - val_loss: 0.2478 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3128 - acc: 0.8780 - f1: 0.8936 - val_loss: 0.2410 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 4085/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3394 - acc: 0.8647 - f1: 0.8836 - val_loss: 0.2186 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4086/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2367 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4087/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3188 - acc: 0.8757 - f1: 0.8917 - val_loss: 0.2986 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4088/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3152 - acc: 0.8770 - f1: 0.8929 - val_loss: 0.2479 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4089/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2605 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8657 - f1: 0.8843 - val_loss: 0.2549 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2407 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4092/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2522 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3111 - acc: 0.8797 - f1: 0.8949 - val_loss: 0.2395 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8729 - f1: 0.8895 - val_loss: 0.2684 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4095/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3256 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2790 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2446 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4097/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2743 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8742 - f1: 0.8906 - val_loss: 0.2581 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8729 - f1: 0.8895 - val_loss: 0.2540 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2511 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2635 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2603 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2544 - val_acc: 0.9681 - val_f1: 0.9686\n",
      "Epoch 4104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2318 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2576 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2410 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 4107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2474 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2680 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 4109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8724 - f1: 0.8895 - val_loss: 0.2428 - val_acc: 0.9500 - val_f1: 0.9529\n",
      "Epoch 4110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.2669 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 4111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8667 - f1: 0.8852 - val_loss: 0.2564 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2565 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8766 - f1: 0.8930 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8753 - f1: 0.8916 - val_loss: 0.2628 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8753 - f1: 0.8914 - val_loss: 0.2622 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2425 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8679 - f1: 0.8860 - val_loss: 0.2452 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2667 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2753 - val_acc: 0.9606 - val_f1: 0.9616\n",
      "Epoch 4120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8708 - f1: 0.8876 - val_loss: 0.2555 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2364 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 4122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2775 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2371 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.3054 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2820 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8729 - f1: 0.8900 - val_loss: 0.2579 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2487 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 4128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2493 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2640 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8894 - val_loss: 0.2635 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8751 - f1: 0.8914 - val_loss: 0.2564 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2360 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2653 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 4134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2224 - val_acc: 0.9563 - val_f1: 0.9580\n",
      "Epoch 4135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8716 - f1: 0.8892 - val_loss: 0.2354 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 4136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2911 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2441 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2704 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2870 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2563 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8718 - f1: 0.8889 - val_loss: 0.2556 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2558 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 4143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2614 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 4144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8752 - f1: 0.8911 - val_loss: 0.2697 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2388 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 4147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2713 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8731 - f1: 0.8899 - val_loss: 0.2431 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8733 - f1: 0.8897 - val_loss: 0.2262 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 4150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2374 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 4151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2589 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8724 - f1: 0.8897 - val_loss: 0.2451 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2604 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8688 - f1: 0.8869 - val_loss: 0.2470 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2522 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 4156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2538 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2376 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 4158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2700 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8750 - f1: 0.8911 - val_loss: 0.2662 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8652 - f1: 0.8840 - val_loss: 0.2715 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8762 - f1: 0.8922 - val_loss: 0.2559 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 4162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2564 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 4163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8894 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2725 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8690 - f1: 0.8870 - val_loss: 0.2465 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8768 - f1: 0.8927 - val_loss: 0.2531 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8715 - f1: 0.8882 - val_loss: 0.2355 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2556 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2445 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 4170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.3111 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8649 - f1: 0.8838 - val_loss: 0.2660 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2476 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8785 - f1: 0.8940 - val_loss: 0.2512 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2580 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2393 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2415 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2459 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2748 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 4179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8706 - f1: 0.8882 - val_loss: 0.2466 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2296 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2280 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2554 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2558 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8738 - f1: 0.8908 - val_loss: 0.2356 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2426 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8855 - val_loss: 0.2504 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3150 - acc: 0.8770 - f1: 0.8927 - val_loss: 0.2413 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8728 - f1: 0.8895 - val_loss: 0.2581 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2663 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2443 - val_acc: 0.9622 - val_f1: 0.9644\n",
      "Epoch 4191/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8720 - f1: 0.8886 - val_loss: 0.2667 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2534 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2527 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2502 - val_acc: 0.9675 - val_f1: 0.9693\n",
      "Epoch 4195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2559 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8732 - f1: 0.8903 - val_loss: 0.2408 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2619 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2642 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2456 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2517 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8752 - f1: 0.8913 - val_loss: 0.2400 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 4202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2884 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2375 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8678 - f1: 0.8863 - val_loss: 0.2222 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2482 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 4206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8771 - f1: 0.8932 - val_loss: 0.2551 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8683 - f1: 0.8857 - val_loss: 0.2668 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2688 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8784 - f1: 0.8936 - val_loss: 0.2271 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2355 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2206 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3151 - acc: 0.8777 - f1: 0.8935 - val_loss: 0.2312 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 4213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8896 - val_loss: 0.2644 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 4214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2372 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2308 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 4216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2192 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2343 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2442 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2331 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2603 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 4221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2683 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2371 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4223/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2372 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2738 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2276 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4226/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3234 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2313 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.3094 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2329 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4229/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2444 - val_acc: 0.9694 - val_f1: 0.9697\n",
      "Epoch 4230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2610 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8751 - f1: 0.8918 - val_loss: 0.2588 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8661 - f1: 0.8838 - val_loss: 0.2495 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2620 - val_acc: 0.9688 - val_f1: 0.9698\n",
      "Epoch 4234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2295 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4235/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3203 - acc: 0.8748 - f1: 0.89 - 0s 16us/sample - loss: 0.3184 - acc: 0.8756 - f1: 0.8921 - val_loss: 0.2449 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2532 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4237/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3282 - acc: 0.8695 - f1: 0.88 - 0s 16us/sample - loss: 0.3299 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2526 - val_acc: 0.9647 - val_f1: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2488 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2877 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2735 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2385 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8768 - f1: 0.8929 - val_loss: 0.2438 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2427 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2282 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2672 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8649 - f1: 0.8835 - val_loss: 0.2355 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4247/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2475 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2445 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 4249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3121 - acc: 0.8783 - f1: 0.8940 - val_loss: 0.2655 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2569 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 4251/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2376 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 4252/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3290 - acc: 0.8703 - f1: 0.88 - 0s 16us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8889 - val_loss: 0.2951 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 4253/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8689 - f1: 0.8863 - val_loss: 0.2490 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 4254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2871 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2713 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 4256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8731 - f1: 0.8902 - val_loss: 0.2385 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4258/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2572 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4259/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2650 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2280 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 4261/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2581 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2598 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4263/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2695 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 4264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8750 - f1: 0.8918 - val_loss: 0.2444 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4265/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2532 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8701 - f1: 0.8877 - val_loss: 0.2615 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 4267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2673 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4268/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3340 - acc: 0.8683 - f1: 0.8857 - val_loss: 0.2505 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8722 - f1: 0.8895 - val_loss: 0.2936 - val_acc: 0.9638 - val_f1: 0.9634\n",
      "Epoch 4270/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2541 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4271/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8742 - f1: 0.8909 - val_loss: 0.2319 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8641 - f1: 0.8831 - val_loss: 0.2578 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 4273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2332 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 4274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2429 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2567 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2635 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8765 - f1: 0.8924 - val_loss: 0.2485 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 4279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2644 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4280/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2337 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2576 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4282/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3362 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2516 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2322 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2289 - val_acc: 0.9650 - val_f1: 0.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8669 - f1: 0.8851 - val_loss: 0.2455 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 4286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2415 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2334 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 4288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2854 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2651 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2565 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4291/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3227 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2470 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2440 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4293/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3208 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2414 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 4294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2330 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 4295/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3297 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2250 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2684 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 4297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2549 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2365 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 4299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 4300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8900 - val_loss: 0.2681 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2364 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 4302/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2626 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4303/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3231 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2704 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2592 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8910 - val_loss: 0.2512 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4306/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2711 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3159 - acc: 0.8767 - f1: 0.8931 - val_loss: 0.2369 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2403 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4309/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2520 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4310/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3182 - acc: 0.8758 - f1: 0.8920 - val_loss: 0.2578 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2393 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4312/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4313/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8713 - f1: 0.88 - 0s 16us/sample - loss: 0.3224 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2778 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8683 - f1: 0.8865 - val_loss: 0.2309 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8771 - f1: 0.8933 - val_loss: 0.2545 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2480 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 4317/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2322 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2607 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2534 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4320/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3342 - acc: 0.8665 - f1: 0.8848 - val_loss: 0.2499 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4321/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3387 - acc: 0.8643 - f1: 0.8833 - val_loss: 0.2716 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2375 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4323/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2586 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4324/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2440 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 4325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2364 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 4326/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2620 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2351 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 4328/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3334 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2307 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4329/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2360 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 4330/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3296 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2483 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 4331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8767 - f1: 0.8928 - val_loss: 0.2538 - val_acc: 0.9647 - val_f1: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4332/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3215 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9588 - val_f1: 0.9611\n",
      "Epoch 4333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2555 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2409 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2438 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 4336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8759 - f1: 0.8923 - val_loss: 0.2776 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2565 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 4338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2630 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2719 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 4340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2544 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2518 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2489 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2397 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 4344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2714 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 4346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2287 - val_acc: 0.9531 - val_f1: 0.9561\n",
      "Epoch 4347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8612 - f1: 0.8803 - val_loss: 0.2480 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2423 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8670 - f1: 0.8855 - val_loss: 0.2719 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2976 - val_acc: 0.9644 - val_f1: 0.9645\n",
      "Epoch 4351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2613 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4352/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2644 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4353/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8880 - val_loss: 0.2632 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4354/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2485 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2655 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2561 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4357/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2584 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2596 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4359/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3251 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2458 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4360/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2382 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 4361/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2638 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4362/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2707 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 4363/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2626 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 4364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2754 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4365/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3244 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2548 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 4367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2406 - val_acc: 0.9628 - val_f1: 0.9631\n",
      "Epoch 4368/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2618 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4369/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2534 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 4370/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3267 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2594 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 4371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.3016 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4372/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2535 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 4373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2541 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2530 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4375/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3255 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.3054 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4376/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2835 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4377/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2603 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8735 - f1: 0.8896 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4379/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2325 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 4380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2580 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2672 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8722 - f1: 0.8888 - val_loss: 0.2360 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2520 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2308 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 4385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2434 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4386/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3320 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2302 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 4387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8675 - f1: 0.8858 - val_loss: 0.2520 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8914 - val_loss: 0.2328 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2502 - val_acc: 0.9684 - val_f1: 0.9698\n",
      "Epoch 4390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2380 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 4391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2536 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4392/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2469 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2777 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4394/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3218 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2485 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4395/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3188 - acc: 0.8755 - f1: 0.8913 - val_loss: 0.2502 - val_acc: 0.9678 - val_f1: 0.9681\n",
      "Epoch 4396/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2346 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2499 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3110 - acc: 0.8795 - f1: 0.8949 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2517 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 4400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8742 - f1: 0.8905 - val_loss: 0.2638 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8868 - val_loss: 0.2637 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 4402/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8865 - val_loss: 0.2768 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 4403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8689 - f1: 0.8871 - val_loss: 0.2738 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2825 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 4405/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2433 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2562 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4407/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3165 - acc: 0.8765 - f1: 0.8928 - val_loss: 0.2463 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2390 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4409/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2536 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4411/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8729 - f1: 0.8900 - val_loss: 0.2601 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4412/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3134 - acc: 0.8785 - f1: 0.8945 - val_loss: 0.2684 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4413/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8719 - f1: 0.88 - 0s 16us/sample - loss: 0.3292 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2419 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 4414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2221 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4415/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2444 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2497 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4417/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8679 - f1: 0.8862 - val_loss: 0.2721 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4418/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2547 - val_acc: 0.9619 - val_f1: 0.9622\n",
      "Epoch 4419/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3230 - acc: 0.8736 - f1: 0.89 - 0s 16us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8887 - val_loss: 0.2462 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4420/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2500 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2413 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4422/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3302 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2792 - val_acc: 0.9606 - val_f1: 0.9617\n",
      "Epoch 4423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8886 - val_loss: 0.2518 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4424/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3242 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2233 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4425/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2249 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2826 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 4427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2544 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8739 - f1: 0.8906 - val_loss: 0.2467 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 4429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2285 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 4430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2770 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 4431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3166 - acc: 0.8758 - f1: 0.8923 - val_loss: 0.2742 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 4432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2360 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 4433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8876 - val_loss: 0.2383 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8873 - val_loss: 0.2534 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8902 - val_loss: 0.2645 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2376 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2479 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2827 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2727 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2367 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 4441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2547 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 4442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2402 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2538 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8691 - f1: 0.8872 - val_loss: 0.2435 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 4445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2505 - val_acc: 0.9684 - val_f1: 0.9691\n",
      "Epoch 4446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3172 - acc: 0.8761 - f1: 0.8925 - val_loss: 0.2510 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2763 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2789 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2650 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2487 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2535 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2582 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2577 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2782 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2425 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2281 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8862 - val_loss: 0.2411 - val_acc: 0.9697 - val_f1: 0.9706\n",
      "Epoch 4458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2553 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8642 - f1: 0.8830 - val_loss: 0.2291 - val_acc: 0.9575 - val_f1: 0.9592\n",
      "Epoch 4460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2676 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2444 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2540 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2445 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2392 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 4465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2506 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8755 - f1: 0.8922 - val_loss: 0.2704 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8670 - f1: 0.8856 - val_loss: 0.2456 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2466 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2459 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2293 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8765 - f1: 0.8925 - val_loss: 0.2755 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4472/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2344 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2494 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2421 - val_acc: 0.9553 - val_f1: 0.9572\n",
      "Epoch 4475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2465 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2746 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2385 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2422 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2591 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 4480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2386 - val_acc: 0.9581 - val_f1: 0.9605\n",
      "Epoch 4481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2351 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8777 - f1: 0.8936 - val_loss: 0.2633 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8747 - f1: 0.8914 - val_loss: 0.2482 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3138 - acc: 0.8782 - f1: 0.8938 - val_loss: 0.2247 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 4486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2658 - val_acc: 0.9681 - val_f1: 0.9685\n",
      "Epoch 4487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2458 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2387 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2291 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 4490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2316 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2399 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2244 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 4493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2121 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 4494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2259 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2207 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2324 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2365 - val_acc: 0.9556 - val_f1: 0.9582\n",
      "Epoch 4498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2593 - val_acc: 0.9594 - val_f1: 0.9601\n",
      "Epoch 4499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8627 - f1: 0.8820 - val_loss: 0.2469 - val_acc: 0.9653 - val_f1: 0.9656\n",
      "Epoch 4500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2363 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2364 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8708 - f1: 0.8883 - val_loss: 0.2542 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 4503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2581 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2608 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 4505/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8879 - val_loss: 0.2505 - val_acc: 0.9650 - val_f1: 0.9654\n",
      "Epoch 4506/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8732 - f1: 0.8904 - val_loss: 0.2528 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8717 - f1: 0.8887 - val_loss: 0.2525 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4508/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8860 - val_loss: 0.2484 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2477 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2449 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 4511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2490 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4512/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8713 - f1: 0.8880 - val_loss: 0.2582 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2732 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2397 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2359 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8691 - f1: 0.8860 - val_loss: 0.2448 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4517/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2470 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2408 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2528 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2833 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2677 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2455 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2711 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8669 - f1: 0.8857 - val_loss: 0.2624 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 4526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2416 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8749 - f1: 0.8908 - val_loss: 0.2486 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2461 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2611 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2311 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2340 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2305 - val_acc: 0.9694 - val_f1: 0.9701\n",
      "Epoch 4533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2410 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 4534/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2321 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2638 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 4537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8752 - f1: 0.8917 - val_loss: 0.2180 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 4538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2674 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8732 - f1: 0.8894 - val_loss: 0.2621 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2575 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2541 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2897 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.3624 - val_acc: 0.9597 - val_f1: 0.9599\n",
      "Epoch 4544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2398 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8701 - f1: 0.8879 - val_loss: 0.2297 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2504 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2468 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8762 - f1: 0.8924 - val_loss: 0.2559 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2234 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2442 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2434 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2382 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2547 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2498 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 4556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2491 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8873 - val_loss: 0.2458 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2706 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2576 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2392 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8747 - f1: 0.8916 - val_loss: 0.3016 - val_acc: 0.9634 - val_f1: 0.9640\n",
      "Epoch 4562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2495 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 4564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2648 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 4565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8764 - f1: 0.8927 - val_loss: 0.2420 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4566/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2442 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 4567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2421 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2428 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2293 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8718 - f1: 0.8894 - val_loss: 0.2268 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2455 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8881 - val_loss: 0.2492 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2462 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8759 - f1: 0.8925 - val_loss: 0.2571 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2767 - val_acc: 0.9675 - val_f1: 0.9679\n",
      "Epoch 4577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2455 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8897 - val_loss: 0.2392 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2412 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 4580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2362 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2386 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2539 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 4583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.3021 - val_acc: 0.9613 - val_f1: 0.9617\n",
      "Epoch 4584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2325 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8770 - f1: 0.8934 - val_loss: 0.2933 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2561 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2473 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2578 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2761 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8718 - f1: 0.8895 - val_loss: 0.2854 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8665 - f1: 0.8849 - val_loss: 0.2574 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2701 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 4593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2822 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 4594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8733 - f1: 0.8903 - val_loss: 0.2466 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2490 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2447 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8715 - f1: 0.8883 - val_loss: 0.2654 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 4598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2745 - val_acc: 0.9559 - val_f1: 0.9578\n",
      "Epoch 4599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2702 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8759 - f1: 0.8923 - val_loss: 0.2761 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2673 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8880 - val_loss: 0.2562 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2542 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2539 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2543 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8743 - f1: 0.8907 - val_loss: 0.2710 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2589 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8770 - f1: 0.8931 - val_loss: 0.2539 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8916 - val_loss: 0.2606 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3141 - acc: 0.8780 - f1: 0.8942 - val_loss: 0.2601 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2959 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 4612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8675 - f1: 0.8850 - val_loss: 0.2523 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8776 - f1: 0.8935 - val_loss: 0.2713 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 4614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2453 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2632 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8877 - val_loss: 0.2626 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2671 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2565 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 4619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2400 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 4620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2652 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 4622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8749 - f1: 0.8915 - val_loss: 0.2599 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8674 - f1: 0.8857 - val_loss: 0.2822 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2413 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2652 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 4626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8718 - f1: 0.8896 - val_loss: 0.2459 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 4627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8752 - f1: 0.8915 - val_loss: 0.2685 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2573 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2688 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 4631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8713 - f1: 0.8890 - val_loss: 0.2314 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2497 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 4633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2669 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2740 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2109 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2609 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 4637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2694 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8760 - f1: 0.8923 - val_loss: 0.2640 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 4639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2625 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2664 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8772 - f1: 0.8935 - val_loss: 0.2637 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.3037 - val_acc: 0.9638 - val_f1: 0.9640\n",
      "Epoch 4643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2721 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 4644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2904 - val_acc: 0.9669 - val_f1: 0.9670\n",
      "Epoch 4645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2740 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 4646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8725 - f1: 0.8892 - val_loss: 0.2704 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8742 - f1: 0.8910 - val_loss: 0.2760 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 4648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2670 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2391 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 4650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2423 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2645 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2581 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 4653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2678 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8768 - f1: 0.8929 - val_loss: 0.2461 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8758 - f1: 0.8919 - val_loss: 0.2644 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2323 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 4657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2297 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 4658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8620 - f1: 0.8815 - val_loss: 0.2635 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2780 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2491 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 4661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2335 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2571 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 4663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8704 - f1: 0.8874 - val_loss: 0.2327 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 4664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2702 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2417 - val_acc: 0.9684 - val_f1: 0.9687\n",
      "Epoch 4666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8871 - val_loss: 0.2475 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8731 - f1: 0.8906 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8766 - f1: 0.8929 - val_loss: 0.2650 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8725 - f1: 0.8893 - val_loss: 0.2728 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2550 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 4671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2359 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 4672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2542 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8753 - f1: 0.8918 - val_loss: 0.2485 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2516 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8678 - f1: 0.8863 - val_loss: 0.2483 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8732 - f1: 0.8900 - val_loss: 0.2864 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8759 - f1: 0.8919 - val_loss: 0.2641 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8678 - f1: 0.8856 - val_loss: 0.2421 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2573 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 4680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2836 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 4681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2384 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2432 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2260 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2529 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8722 - f1: 0.8890 - val_loss: 0.2966 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2678 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2519 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3099 - acc: 0.8804 - f1: 0.8959 - val_loss: 0.2465 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2811 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2709 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 4692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2424 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8853 - val_loss: 0.2378 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2698 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2683 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8733 - f1: 0.8902 - val_loss: 0.2461 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8872 - val_loss: 0.2912 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 4698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2293 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2494 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2253 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 4701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2522 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2430 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8717 - f1: 0.8892 - val_loss: 0.2489 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2389 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2548 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2300 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 4707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2366 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 4708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2607 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 4709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2574 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2550 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2554 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2865 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8711 - f1: 0.8888 - val_loss: 0.2449 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2368 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2412 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2382 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2439 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8731 - f1: 0.8902 - val_loss: 0.2640 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8888 - val_loss: 0.2404 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2544 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2575 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2716 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 4723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8754 - f1: 0.8915 - val_loss: 0.2494 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8663 - f1: 0.8850 - val_loss: 0.2428 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 4725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2507 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2465 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 4727/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2306 - val_acc: 0.9497 - val_f1: 0.9530\n",
      "Epoch 4728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2535 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2333 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 4731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2683 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8877 - val_loss: 0.2828 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 4733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8743 - f1: 0.8912 - val_loss: 0.2525 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4734/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3167 - acc: 0.8761 - f1: 0.8919 - val_loss: 0.2774 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2811 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2463 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2557 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 4738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2573 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2926 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2155 - val_acc: 0.9513 - val_f1: 0.9541\n",
      "Epoch 4741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2298 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 4742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2559 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2561 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4744/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2454 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2400 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 4746/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2454 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2619 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2871 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8857 - val_loss: 0.2726 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2893 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 4751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8681 - f1: 0.8857 - val_loss: 0.2442 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4752/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8735 - f1: 0.8906 - val_loss: 0.2711 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2519 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 4754/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2383 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2613 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2672 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2657 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2397 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2590 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8761 - f1: 0.8923 - val_loss: 0.2659 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2552 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2650 - val_acc: 0.9666 - val_f1: 0.9683\n",
      "Epoch 4763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2655 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2855 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2862 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2579 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2412 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2426 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2800 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 4770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2340 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 4771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2661 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 4772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8736 - f1: 0.8902 - val_loss: 0.2237 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2378 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 4774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2793 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2480 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8742 - f1: 0.8905 - val_loss: 0.2420 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 4777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2605 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2453 - val_acc: 0.9472 - val_f1: 0.9507\n",
      "Epoch 4779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2592 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 4780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2463 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2313 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2653 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2684 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8744 - f1: 0.8913 - val_loss: 0.2703 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2680 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8754 - f1: 0.8918 - val_loss: 0.2550 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 4787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2563 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 4788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2799 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2483 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2717 - val_acc: 0.9609 - val_f1: 0.9615\n",
      "Epoch 4791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8724 - f1: 0.8892 - val_loss: 0.2498 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3149 - acc: 0.8780 - f1: 0.8935 - val_loss: 0.2714 - val_acc: 0.9656 - val_f1: 0.9659\n",
      "Epoch 4793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2226 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2629 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2333 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2572 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8746 - f1: 0.8912 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2534 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 4800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2624 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2554 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 4802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3142 - acc: 0.8781 - f1: 0.8940 - val_loss: 0.2670 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 4803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2461 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 4804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8731 - f1: 0.8892 - val_loss: 0.2419 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2545 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2521 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 4807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2612 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2397 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2884 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2845 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 4811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2547 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 4812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3163 - acc: 0.8767 - f1: 0.8924 - val_loss: 0.2623 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2610 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8754 - f1: 0.8922 - val_loss: 0.2531 - val_acc: 0.9644 - val_f1: 0.9647\n",
      "Epoch 4815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2304 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8728 - f1: 0.8890 - val_loss: 0.2325 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2825 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2342 - val_acc: 0.9572 - val_f1: 0.9596\n",
      "Epoch 4820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8613 - f1: 0.8805 - val_loss: 0.2618 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2497 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2853 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8682 - f1: 0.8864 - val_loss: 0.2608 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8735 - f1: 0.8908 - val_loss: 0.2710 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2466 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2634 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8736 - f1: 0.8907 - val_loss: 0.2673 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2241 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 4829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2568 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2905 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 4831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2562 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8750 - f1: 0.8916 - val_loss: 0.2441 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 4833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2581 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2615 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2824 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 4836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2319 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2489 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2575 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 4839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2907 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2590 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2908 - val_acc: 0.9663 - val_f1: 0.9666\n",
      "Epoch 4842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2726 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2437 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 4844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2540 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 4845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8631 - f1: 0.8824 - val_loss: 0.2265 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2382 - val_acc: 0.9566 - val_f1: 0.9589\n",
      "Epoch 4847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8674 - f1: 0.8859 - val_loss: 0.2186 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 4848/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2451 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2600 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 4850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8885 - val_loss: 0.2563 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4851/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2253 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 4852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8703 - f1: 0.8882 - val_loss: 0.2700 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 4853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8731 - f1: 0.8899 - val_loss: 0.2564 - val_acc: 0.9681 - val_f1: 0.9683\n",
      "Epoch 4854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2416 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2458 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2485 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3147 - acc: 0.8780 - f1: 0.8938 - val_loss: 0.2523 - val_acc: 0.9541 - val_f1: 0.9559\n",
      "Epoch 4858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4859/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8716 - f1: 0.8894 - val_loss: 0.2616 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4860/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2691 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4861/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2309 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 4862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8771 - f1: 0.8926 - val_loss: 0.2593 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2661 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8764 - f1: 0.8930 - val_loss: 0.2591 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 4865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2764 - val_acc: 0.9650 - val_f1: 0.9654\n",
      "Epoch 4866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2339 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2550 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4868/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3222 - acc: 0.8735 - f1: 0.8905 - val_loss: 0.2695 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8718 - f1: 0.8886 - val_loss: 0.2561 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2523 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 4871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2502 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8761 - f1: 0.8919 - val_loss: 0.2278 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 4873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2621 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2356 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 4875/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3372 - acc: 0.8664 - f1: 0.88 - 0s 16us/sample - loss: 0.3359 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2478 - val_acc: 0.9575 - val_f1: 0.9597\n",
      "Epoch 4876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2499 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4877/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2733 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2446 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2533 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4880/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8893 - val_loss: 0.2570 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 4881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8709 - f1: 0.8877 - val_loss: 0.2647 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 4882/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2690 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3151 - acc: 0.8778 - f1: 0.8936 - val_loss: 0.2709 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 4884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2649 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4885/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2752 - val_acc: 0.9625 - val_f1: 0.9629\n",
      "Epoch 4886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2633 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8914 - val_loss: 0.2476 - val_acc: 0.9672 - val_f1: 0.9676\n",
      "Epoch 4888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2555 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 4889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2430 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2583 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2806 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8708 - f1: 0.8885 - val_loss: 0.2691 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 4893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8904 - val_loss: 0.2722 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4894/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3280 - acc: 0.8705 - f1: 0.88 - 0s 16us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2370 - val_acc: 0.9669 - val_f1: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2499 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 4896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2468 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2740 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2715 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 4899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2143 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 4900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8681 - f1: 0.8859 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2241 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 4902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2516 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 4903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2663 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 4904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8717 - f1: 0.8884 - val_loss: 0.2777 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8746 - f1: 0.8913 - val_loss: 0.2606 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2526 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3176 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2546 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8704 - f1: 0.8880 - val_loss: 0.2620 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8644 - f1: 0.8833 - val_loss: 0.2305 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 4910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2442 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8753 - f1: 0.8921 - val_loss: 0.2696 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2567 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8636 - f1: 0.8826 - val_loss: 0.2484 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2714 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 4915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2863 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2423 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8761 - f1: 0.8922 - val_loss: 0.2410 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2490 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 4919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 4920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2762 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 4921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2609 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2772 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8685 - f1: 0.8866 - val_loss: 0.2302 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2597 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2732 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 4926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2625 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 4927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2563 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8784 - f1: 0.8941 - val_loss: 0.2682 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8753 - f1: 0.8915 - val_loss: 0.2535 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2632 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2819 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2786 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2685 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8761 - f1: 0.8926 - val_loss: 0.2644 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2760 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2243 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 4938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2457 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2702 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8721 - f1: 0.8891 - val_loss: 0.2598 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2494 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4942/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2501 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 4943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2619 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8708 - f1: 0.8884 - val_loss: 0.2673 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8742 - f1: 0.8909 - val_loss: 0.2646 - val_acc: 0.9684 - val_f1: 0.9683\n",
      "Epoch 4946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8681 - f1: 0.8865 - val_loss: 0.2584 - val_acc: 0.9569 - val_f1: 0.9584\n",
      "Epoch 4948/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2384 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 4949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2568 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 4950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8868 - val_loss: 0.2880 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2492 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2240 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2352 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2272 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2481 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2474 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2676 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2319 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8878 - val_loss: 0.2255 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2507 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2711 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2818 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8766 - f1: 0.8928 - val_loss: 0.2527 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2536 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3173 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2530 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2714 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2610 - val_acc: 0.9659 - val_f1: 0.9660\n",
      "Epoch 4968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2883 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8764 - f1: 0.8917 - val_loss: 0.2192 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.3012 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2204 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2507 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4973/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2563 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2491 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2573 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 4976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2876 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 4977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2626 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2763 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2833 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 4980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2454 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4981/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8762 - f1: 0.8925 - val_loss: 0.2569 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4982/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3345 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2659 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2597 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4984/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3156 - acc: 0.8766 - f1: 0.8927 - val_loss: 0.2558 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8637 - f1: 0.8827 - val_loss: 0.2836 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4986/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2684 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 4987/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3348 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2270 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2570 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2618 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 4990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2490 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2635 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8759 - f1: 0.8924 - val_loss: 0.2647 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2687 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2361 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2621 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 4996/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3250 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2546 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2553 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 4998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2400 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2654 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 5000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8668 - f1: 0.8850 - val_loss: 0.2491 - val_acc: 0.9647 - val_f1: 0.9659\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "epochs_range = [30,60, 5000]                                                                                                                                            \n",
    "max_ep = max(epochs_range) \n",
    "\n",
    "# Suppression de la dernière étude d'hyperparamètre\n",
    "try:\n",
    "    tf.reset_default_graph()\n",
    "    shutil.rmtree('./logs')\n",
    "except:\n",
    "    print(\"nothing to delete\")\n",
    "    \n",
    "# Callbacks pour affichage des performances dans tensorflow : 1 callback pour chaque hyperparamètre\n",
    "tensorboard_callback = []\n",
    "for i in range(3):\n",
    "    tensorboard_callback.append(TensorBoard(log_dir=\"logs\\{}\".format(i)))\n",
    "# Par invité de commande : \n",
    "# tensorboard --logdir=\"./logs\" --port 6006\n",
    "cpt = 0\n",
    "for ep in epochs_range:                                                                                                                                                            \n",
    "    model = RN_model(layer_sizes, dropout, learning_rate)                                                                                                                          \n",
    "    #### Apprentissage                                                                                                                                                             \n",
    "    start = time.time()                                                                                                                                                            \n",
    "    #model.fit(X_train, Y_train, batch_size = 100, epochs = 60)                                                                                                                    \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = ep, validation_data=(X_test, Y_test), callbacks = [tensorboard_callback[cpt]])                                                                  \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    training_delay_RN.append(end - start)                                                                                                                                          \n",
    "\n",
    "    ho_tmp = list(hist_obj.history.values())                                                                                                                                       \n",
    "    ho_tmp = [i + [np.nan for _ in range(max_ep-ep)] for i in ho_tmp ]                                                                                                             \n",
    "    history_obj.append(ho_tmp)\n",
    "    #### Prédiction                                                                                                                                                                \n",
    "    start = time.time()                                                                                                                                                            \n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    predicting_delay_RN.append(end - start) \n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in epochs_range]                                                                                                                                                \n",
    "                                                                                                                                       \n",
    "titre = \"RN : HyperParam = number of epochs\"                                                                                                                                          \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Nous remarquons que les performances (accuracy et f1_score) tendent vers les mêmes taux qu'il y ait 30, 60 ou 5000 itérations. En revanche, nous remarquons qu'à partir de 1000 itérations, le val_loss augmente. Ceci illustre le surapprentissage. Le nombre optimal d'itérations se situe donc plus autour de 60."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Notons ici que les temps d'apprentissage et de prédiction croissent avec le nombre d'itérations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 5\n",
    "\n",
    "Finalement, concernant la classification MLP, nous voyons qu'il faut trouver le bon compromis entre le nombre de couches, le nombre de perceptrons et le learning rate.   \n",
    "\n",
    "\n",
    "| Hyperparamètre        | Nombre d'epochs |Couche Cachées          | Valeur Accuracy (val_acc) | Valeur f1_score (val_f1) | \n",
    "|-----------------------|-----------------|------------------------|-----------------|-----------------|\n",
    "| Nombre de perceptrons | 60              |[5,4,4]                 |0.9411           |0,9478           |\n",
    "| Nombre de perceptrons | 60              |[100,100,2]             |0.9550           |0.9571           |\n",
    "| Nombre de perceptrons | 60              |[500,500,500]           |0.9634           |0.9662           |\n",
    "|-----------------------|-----------------|------------------------|-----------------|-----------------|\n",
    "| Nombre de couches     | 60              |[100]                   |0.9634           |0.9631           |\n",
    "| Nombre de couches     | 60              |[100,100,2]             |0.9619           |0.9627           |\n",
    "| Nombre de couches     | 60              |[100,100,100,100,100,2] |0.9419           |0.9417           |\n",
    "|-----------------------|-----------------|------------------------|-----------------|-----------------|\n",
    "| Learning rate (1e-5)  | 60              |[100,100,2]             |0.8553           |0.8594           |\n",
    "| Learning rate (0.0005)| 60              |[100,100,2]             |0.9600           |0.9604           |\n",
    "| Learning rate (0.01)  | 60              |[100,100,2]             |0.5191           |0.6815           |\n",
    "|-----------------------|-----------------|------------------------|-----------------|-----------------|\n",
    "| Nombre d'epochs       | 30              |[100,100,2]             |0.9563           |0.9577           |\n",
    "| Nombre d'epochs       | 60              |[100,100,2]             |0.9559           |0.9558           |\n",
    "| Nombre d'epochs       | 5000            |[100,100,2]             |0.9647           |0.9659           |   \n",
    "\n",
    "\n",
    "- La meilleure solution pour le nombre de perceptrons par couche cachée est [500,500,500] en terme performance. Néanmoins il est préférable de choisir la solution [100,100,2] qui apporte de meilleures performance temporelles.  \n",
    "- Le nombre de couche cachée apportant le meilleur compromis est de 3 ([100,100,2]).   \n",
    "- Le learning rate apportant les meilleurs résultat est : 0.0005.\n",
    "- Ici nous voyons que 5000 itérations apporte les meilleurs performances, nénanmoins elle apporte du sur apprentissage. De plus, le temps de traitement et d'apprentissage est plus long. Le meilleur compromis est donc de 60 itérations.   \n",
    "\n",
    "En résumé, la meilleure solution pour le réseau MLP est :  \n",
    "couche [100,100,2],  \n",
    "learning rate de 0.0005,  \n",
    "60 epochs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "\n",
    "L'objectif de la méthode SVM est donc de déterminer des hyperplans séparant les classes avec une marge maximale lorsque les ensembles sont linéairement séparables.\n",
    "Le paramètre C est un facteur qui permet de pénaliser les points qui sont présents dans la marge. Si le point est présent dans la marge mais dont la prédiction est correcte, on peut affecter un poids entre 0 et 1. Dans notre cas, la meilleure performance est quand le paramètre C vaut 10. Cela veut dire que l'on pénalise très fortement les points dont la prédiction est mauvaise.\n",
    "Par ailleurs, le paramètre gamma permet de déterminer la taille du noyau lorsque les ensembles ne sont pas linéairement séparables. Il faut néanmoins évaluer ce paramètre avec minutie, car il peut être source de sur apprentissage (quand la valeur de gamma est faible) ou de sous apprentissage (gamma élevé).\n",
    "\n",
    "Pour l'étude de nos deux classificateurs, nous avons utilisé la même de machine dont les performances sont les suivantes :\n",
    "\n",
    "Memoire : 15.5GB  \n",
    "Processor : IntelCore i7-8700 CPU @ 3.2GHz x 12  \n",
    "Graphics : Titan Xp/PCle/SSE2  \n",
    "GNOME : 3.28.2  \n",
    "OS type : 64bit  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca commence\n",
      "best param\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "best score\n",
      "0.967375\n"
     ]
    }
   ],
   "source": [
    "X_grid,Y_grid = get_data_GridSearch()\n",
    "Grid=GridSearch_bestparam(X_grid,Y_grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En utilisant l'outil \"grid_search\" nous obtenons une combinaison des meilleurs paramètres ci-dessus. Nous obtenons dans ce cas une accuracy de plus de 96%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse Linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  app.launch_new_instance()\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:22: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:23: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('Analyse Linear')\n",
    "plot_Linear_acc(Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous remarquons que l'on obtient rapidement tes performances très satisfaisantes. Par ailleurs, notons que le temps de traitement décroit avec l'augmentation du paramètre C."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse RBF\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Analyse RBF')\n",
    "plot_RBF_acc(Grid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On peut également représenter les résultats sous la forme d'un tableau :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table de valeur\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>0.946063</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>0.947985</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>10.812186</td>\n",
       "      <td>0.912470</td>\n",
       "      <td>1.693979</td>\n",
       "      <td>0.159801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>0.941813</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>0.943939</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>12.676310</td>\n",
       "      <td>0.228588</td>\n",
       "      <td>2.336374</td>\n",
       "      <td>0.082925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>0.929168</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>20.398949</td>\n",
       "      <td>0.679764</td>\n",
       "      <td>4.614898</td>\n",
       "      <td>0.334103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15</td>\n",
       "      <td>0.823063</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>0.844318</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>56.841637</td>\n",
       "      <td>0.364709</td>\n",
       "      <td>12.590611</td>\n",
       "      <td>0.896276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.967375</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>0.968615</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>7.057173</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>1.381827</td>\n",
       "      <td>0.136445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.961375</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.962855</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>9.614222</td>\n",
       "      <td>0.311527</td>\n",
       "      <td>2.176467</td>\n",
       "      <td>0.149358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>0.957844</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>9.733783</td>\n",
       "      <td>0.502281</td>\n",
       "      <td>2.087624</td>\n",
       "      <td>0.116255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "      <td>0.952063</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>0.954683</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>20.209869</td>\n",
       "      <td>0.217480</td>\n",
       "      <td>4.897746</td>\n",
       "      <td>0.334222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>5</td>\n",
       "      <td>0.951875</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>0.954324</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>12.342011</td>\n",
       "      <td>1.218828</td>\n",
       "      <td>2.993964</td>\n",
       "      <td>0.296574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.947688</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>17.304033</td>\n",
       "      <td>0.560825</td>\n",
       "      <td>3.993368</td>\n",
       "      <td>0.169731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>8</td>\n",
       "      <td>0.945187</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>0.947112</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>16.423818</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>3.634397</td>\n",
       "      <td>0.116167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>0.911062</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>0.919397</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>26.250061</td>\n",
       "      <td>0.165005</td>\n",
       "      <td>7.314962</td>\n",
       "      <td>0.197853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.908438</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>0.911779</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>31.606892</td>\n",
       "      <td>0.954140</td>\n",
       "      <td>7.834986</td>\n",
       "      <td>0.449831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>13</td>\n",
       "      <td>0.896813</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>0.900781</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>30.477180</td>\n",
       "      <td>0.304203</td>\n",
       "      <td>8.052330</td>\n",
       "      <td>0.389286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>14</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>0.828766</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>53.377109</td>\n",
       "      <td>0.618891</td>\n",
       "      <td>14.409290</td>\n",
       "      <td>0.394985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>0.763563</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>60.407225</td>\n",
       "      <td>1.051235</td>\n",
       "      <td>16.301724</td>\n",
       "      <td>0.457529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>59.869992</td>\n",
       "      <td>1.209002</td>\n",
       "      <td>16.273317</td>\n",
       "      <td>0.472568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>17</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>60.479505</td>\n",
       "      <td>1.244972</td>\n",
       "      <td>16.378230</td>\n",
       "      <td>0.540361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>17</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>59.836619</td>\n",
       "      <td>0.353329</td>\n",
       "      <td>15.992407</td>\n",
       "      <td>0.603869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>17</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>59.874684</td>\n",
       "      <td>0.810027</td>\n",
       "      <td>15.545575</td>\n",
       "      <td>0.402114</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_kernel param_C param_gamma  rank_test_Accuracy  mean_test_Accuracy  \\\n",
       "3        linear      10         NaN                   7            0.946063   \n",
       "2        linear       1         NaN                   9            0.941813   \n",
       "1        linear     0.1         NaN                  10            0.926500   \n",
       "0        linear   0.001         NaN                  15            0.823063   \n",
       "18          rbf      10           1                   1            0.967375   \n",
       "14          rbf       1           1                   2            0.961375   \n",
       "17          rbf      10         0.1                   3            0.956250   \n",
       "15          rbf       1          10                   4            0.952063   \n",
       "19          rbf      10          10                   5            0.951875   \n",
       "10          rbf     0.1           1                   6            0.947688   \n",
       "13          rbf       1         0.1                   8            0.945187   \n",
       "11          rbf     0.1          10                  11            0.911062   \n",
       "9           rbf     0.1         0.1                  12            0.908438   \n",
       "16          rbf      10       0.001                  13            0.896813   \n",
       "12          rbf       1       0.001                  14            0.827000   \n",
       "6           rbf   0.001           1                  16            0.763563   \n",
       "4           rbf   0.001       0.001                  17            0.519188   \n",
       "5           rbf   0.001         0.1                  17            0.519188   \n",
       "7           rbf   0.001          10                  17            0.519188   \n",
       "8           rbf     0.1       0.001                  17            0.519188   \n",
       "\n",
       "    std_test_Accuracy  mean_test_F1  std_test_F1  mean_fit_time  std_fit_time  \\\n",
       "3            0.003021      0.947985     0.003004      10.812186      0.912470   \n",
       "2            0.003174      0.943939     0.003059      12.676310      0.228588   \n",
       "1            0.005323      0.929168     0.005085      20.398949      0.679764   \n",
       "0            0.006238      0.844318     0.005067      56.841637      0.364709   \n",
       "18           0.002112      0.968615     0.002072       7.057173      0.464026   \n",
       "14           0.001941      0.962855     0.001872       9.614222      0.311527   \n",
       "17           0.003422      0.957844     0.003256       9.733783      0.502281   \n",
       "15           0.002334      0.954683     0.002185      20.209869      0.217480   \n",
       "19           0.002351      0.954324     0.002220      12.342011      1.218828   \n",
       "10           0.004742      0.949900     0.004345      17.304033      0.560825   \n",
       "13           0.005501      0.947112     0.005200      16.423818      0.582909   \n",
       "11           0.005057      0.919397     0.004303      26.250061      0.165005   \n",
       "9            0.007772      0.911779     0.007275      31.606892      0.954140   \n",
       "16           0.005141      0.900781     0.004552      30.477180      0.304203   \n",
       "12           0.006142      0.828766     0.006334      53.377109      0.618891   \n",
       "6            0.001182      0.811331     0.000872      60.407225      1.051235   \n",
       "4            0.000063      0.683507     0.000054      59.869992      1.209002   \n",
       "5            0.000063      0.683507     0.000054      60.479505      1.244972   \n",
       "7            0.000063      0.683507     0.000054      59.836619      0.353329   \n",
       "8            0.000063      0.683507     0.000054      59.874684      0.810027   \n",
       "\n",
       "    mean_score_time  std_score_time  \n",
       "3          1.693979        0.159801  \n",
       "2          2.336374        0.082925  \n",
       "1          4.614898        0.334103  \n",
       "0         12.590611        0.896276  \n",
       "18         1.381827        0.136445  \n",
       "14         2.176467        0.149358  \n",
       "17         2.087624        0.116255  \n",
       "15         4.897746        0.334222  \n",
       "19         2.993964        0.296574  \n",
       "10         3.993368        0.169731  \n",
       "13         3.634397        0.116167  \n",
       "11         7.314962        0.197853  \n",
       "9          7.834986        0.449831  \n",
       "16         8.052330        0.389286  \n",
       "12        14.409290        0.394985  \n",
       "6         16.301724        0.457529  \n",
       "4         16.273317        0.472568  \n",
       "5         16.378230        0.540361  \n",
       "7         15.992407        0.603869  \n",
       "8         15.545575        0.402114  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Table de valeur')\n",
    "\n",
    "result = Grid.cv_results_\n",
    "df = pd.DataFrame(data=result)\n",
    "dfData=df[['param_kernel','param_C','param_gamma','rank_test_Accuracy','mean_test_Accuracy','std_test_Accuracy', 'mean_test_F1','std_test_F1','mean_fit_time', 'std_fit_time','mean_score_time', 'std_score_time']]\n",
    "dfData= dfData.sort_values(['param_kernel','rank_test_Accuracy','mean_test_F1'],ascending=[True,True,True])\n",
    "dfData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de linear avec hyperparametre\n",
      "[[1442   97]\n",
      " [  85 1576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1539\n",
      "           1       0.94      0.95      0.95      1661\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.94      0.94      0.94      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Résultat de linear avec hyperparametre')\n",
    "SVCLine(X_train, Y_train, X_test, Y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de rbf avec hyperparametre\n",
      "[[1486   53]\n",
      " [  40 1621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1539\n",
      "           1       0.97      0.98      0.97      1661\n",
      "\n",
      "    accuracy                           0.97      3200\n",
      "   macro avg       0.97      0.97      0.97      3200\n",
      "weighted avg       0.97      0.97      0.97      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Résultat de rbf avec hyperparametre')\n",
    "SVC_rbf(X_train, Y_train, X_test, Y_test,10,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "scrolled": true
   },
   "source": [
    "## Question 7\n",
    "\n",
    "Dans le cas du MLP, on remarque que pour 1600 images, le temps d'apprentissage se situe autour de 5 secondes. Pour 16000, le temps d'apprentissage est d'environ 32 secondes. Le temps d'apprentissage est donc bien réduit tandis que le temps de prédiction et les performances ne diminuent pas considérablement avec la taille du dataset d'entrainement.\n",
    "\n",
    "Dans le cas de SVM, nous avons étudié la double influence des paramètres gamma et C sur le temps d'apprentissage. On remarque alors que ce temps de traitement est le plus élevé dans le cas où les valeurs de C et gamma sont faibles. C'est à dire quand on ne pénalise pas trop les mauvais points et que la taille du noyau est faible, que l'on tend donc vers une situation de sur apprentissage. \n",
    "\n",
    "Globalement, les temps d'apprentissages et de prédiction sont du même ordre de grandeur bien que le temps d'apprentissage MLP soit plus faible que celui de SVM qui nécessite plus de calculs (noyau ou transformation non linéaire par exemple). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 8\n",
    "\n",
    "Du point de vue des performances, il semblerait que le SVM avec noyau rbf soit le plus adapté avec des performances avoisinant les 97%. En revanche, le temps de traitement est quant à lui beaucoup plus élevé. Dans le cas de classification des galaxies, il n'est pas gênant d'avoir un long temps de traitement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 9\n",
    "\n",
    "L'idéal serait de mener une étude plus précise des hyperparamètres pour trouver une solution optimale.\n",
    "Par ailleurs, il faudrait utiliser des méthodes de validation telle que 5-fold cross validation pour la méthode MLP par exemple. Ceci nous aurait permis d'avoir un meilleur support de comparaison de performance. Par ailleurs, nous avons utilisé l'optimisation Adam qui nous procurait de meilleurs résultats. On pourrait toutefois étudier plus en détail la méthode de descente de gradient à laquelle il faudrait coupler l'étude du pas de descente de gradient."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Conlusion\n",
    "\n",
    "Ce troisième laboratoire nous a permis de comprendre davantage le fonctionnement de deux nouvelles méthodes de classification : SVM et MLP. Dans les deux cas, les temps d'apprentissage sont bien plus longs que les premiers laboratoires.  \n",
    "Dans le cas de MLP nous obtenons des performances qui s'approchent de 95% avec un temps de traitement de l'ordre de la minute. SVM nous apporte de meilleures performances (96%) avec un temps de prédiction similaire, mais un temps d'apprentissage beaucoup plus long. \n",
    "Finalement, dans le cas de notre étude le classificateur le plus adapté est donc SVM avec les paramètres étudiés dans la recherche des meilleurs paramètres.\n",
    "Comme mentionné précédemment, il pourrait être intéressant de tester le modèle MLP avec une validation croisée pour pouvoir comparer au mieux les 2 modèles."
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
