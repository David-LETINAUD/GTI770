{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Laboratoire 3 : Machines à vecteur de support et réseaux neuronaux\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2019                                            |\n",
    "| Groupe                | 1                                                       |\n",
    "| Numéro du laboratoire | 3                                                       |\n",
    "| Professeur            | Prof. LOMBAERT                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 18/11/2019                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Au cours de ce troisième laboratoire nous allons étudier deux nouveaux algorithme de classification pour résoudre le problème de classification des galaxies : les réseaux neuronaux et les machines à vecteurs de support (SVM). \n",
    "Dans un premier temps, nous allons concevoir un modèle de réseaux neuronaux basé sur le Multi-Layer Perceptron. Nous entrainerons ce modèle afin qu'il puisse classer les galaxies en \"smooth\" ou \"spiral\" en utilisant l'ensemble des primitives. Nous utiliserons le module keras de Google tensorflow\n",
    "Le deuxième modèle d'apprentissage s'appuie sur un modèle d'optimisation convexe dans le cas du SVM. Dans ce cas, nous n'utiliserons qu'une partie des primitives proposées et seront couplées à nos primitives développées lors du premier laboratoire.\n",
    "Nous étudierons également l'influence des hyperparamètres de ces deux méthodes afin de proposer le modèle le plus optimal dans le cas de notre problème de classification de galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 1\n",
    "(grille de correction : Les approches de validations sont présentées et utilisées correctement.)\n",
    "\n",
    "Dans le cas des réseaux neuronaux, l'utilisation d'une méthode de validation croisée prendrait beaucoup de temps. En effet, il faudrait répéter plusieurs tests avec un nombre \"d'epochs\" conséquent : ceci serait très chronophage. Nous avons donc décider d'utiliser la méthode de validation hold-out avec 70% de donées d'entrainement et 30% de test.\n",
    "\n",
    "Concernant la méthode SVM, nous utilisons la méthode ......... (k-fold????)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 2\n",
    "(La méthode de normalisation des données est décrite et correcte.)\n",
    "\n",
    "Nous normalisons nos données grâce à la méthode \"normalize\" de la librairie preprocessing. La normalisation se fait par rapport à la valeur maximale. Nous avons décider de normaliser par rapport aux primitives (axis = 0). Par ailleurs, nous avons remarqué avec nos premier tests que les performances étaient meilleures si l'on normalisait par rapport à la valeur maximale (norm = 'max')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 3\n",
    "(Le modèle MLP est décrit (structure, nombre de couches). La fonction de coût choisie est mentionnée ainsi que les raisons pour lesquelles elle a été choisie.)\n",
    "\n",
    "La principale contrainte du modèle MLP est de trouver un compromis entre le temps d'apprentissage et l'accuracy. La première architecture proposée par l'énoncé est de trois couches : 100, 100, 2 (nombre de perceptrons). Nous avons étudié différents cas avec 60 epochs :  \n",
    "1 - l'influence du nombre de perceptrons avec un nombre de couche fixé.  \n",
    "2 - l'influence du nombre de couches avec le même nombre de perceptrons par couche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ens/AN03460/venv/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:65: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "# Initialisation\n",
    "# conda install -c conda-forge tensorflow \n",
    "from RN_model import *\n",
    "from SVC import *\n",
    "from functions import get_data , plot_perf, plot_delay, get_data_GridSearch,plot_Linear_acc,plot_RBF_acc,plot_analyse_grille\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import make_scorer\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV\n",
    "#import csv\n",
    "X_train, X_test, Y_train, Y_test = get_data()\n",
    "\n",
    "layer_sizes = [100, 100, 2]\n",
    "epochs = 60\n",
    "learning_rate = 0.0005\n",
    "batch_size = 100\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "# Pour affichage\n",
    "sub_title = ['loss','acc','f1','val_loss','val_acc', 'val_f1']\n",
    "x_lab = \"epochs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Voici donc nos résultats avec différentes structures de réseaux de neurones :\n",
    "\n",
    "1 - a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ens/AQ38840/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ens/AQ38840/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "WARNING:tensorflow:From /home/ens/AQ38840/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6932 - acc: 0.5165 - f1: 0.6763 - val_loss: 0.6927 - val_acc: 0.5191 - val_f1: 0.6827\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.6926 - acc: 0.5195 - f1: 0.6811 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6814\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.6925 - acc: 0.5176 - f1: 0.6802 - val_loss: 0.6922 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6823 - acc: 0.5073 - f1: 0.6697 - val_loss: 0.6564 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6512 - acc: 0.5150 - f1: 0.6784 - val_loss: 0.6042 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6282 - acc: 0.6591 - f1: 0.5898 - val_loss: 0.5667 - val_acc: 0.8234 - val_f1: 0.8493\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6090 - acc: 0.6877 - f1: 0.6199 - val_loss: 0.5537 - val_acc: 0.9016 - val_f1: 0.9052\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5896 - acc: 0.6986 - f1: 0.6317 - val_loss: 0.5057 - val_acc: 0.9103 - val_f1: 0.9139\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5634 - acc: 0.7194 - f1: 0.6606 - val_loss: 0.4591 - val_acc: 0.9153 - val_f1: 0.9190\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5544 - acc: 0.7252 - f1: 0.6672 - val_loss: 0.4322 - val_acc: 0.9212 - val_f1: 0.9234\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5347 - acc: 0.7509 - f1: 0.7031 - val_loss: 0.4083 - val_acc: 0.9228 - val_f1: 0.9244\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.5349 - acc: 0.7462 - f1: 0.6927 - val_loss: 0.4148 - val_acc: 0.9209 - val_f1: 0.9197\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5189 - acc: 0.7555 - f1: 0.7063 - val_loss: 0.3725 - val_acc: 0.9297 - val_f1: 0.9309\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5061 - acc: 0.7605 - f1: 0.7118 - val_loss: 0.3522 - val_acc: 0.9203 - val_f1: 0.9256\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5103 - acc: 0.7608 - f1: 0.7109 - val_loss: 0.3532 - val_acc: 0.9319 - val_f1: 0.9329\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4866 - acc: 0.7759 - f1: 0.7328 - val_loss: 0.3747 - val_acc: 0.9050 - val_f1: 0.9006\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4915 - acc: 0.7728 - f1: 0.7284 - val_loss: 0.3233 - val_acc: 0.9344 - val_f1: 0.9369\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4870 - acc: 0.7784 - f1: 0.7359 - val_loss: 0.3389 - val_acc: 0.9253 - val_f1: 0.9233\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4852 - acc: 0.7771 - f1: 0.7336 - val_loss: 0.3154 - val_acc: 0.9394 - val_f1: 0.9398\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4710 - acc: 0.7880 - f1: 0.7504 - val_loss: 0.3258 - val_acc: 0.9253 - val_f1: 0.9235\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4730 - acc: 0.7850 - f1: 0.7453 - val_loss: 0.3107 - val_acc: 0.9391 - val_f1: 0.9390\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4735 - acc: 0.7857 - f1: 0.7468 - val_loss: 0.3011 - val_acc: 0.9381 - val_f1: 0.9387\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4714 - acc: 0.7809 - f1: 0.7407 - val_loss: 0.3012 - val_acc: 0.9350 - val_f1: 0.9351\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4729 - acc: 0.7829 - f1: 0.7423 - val_loss: 0.2968 - val_acc: 0.9388 - val_f1: 0.9390\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4658 - acc: 0.7880 - f1: 0.7489 - val_loss: 0.2984 - val_acc: 0.9312 - val_f1: 0.9307\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4672 - acc: 0.7865 - f1: 0.7462 - val_loss: 0.3013 - val_acc: 0.9262 - val_f1: 0.9246\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4689 - acc: 0.7873 - f1: 0.7480 - val_loss: 0.2834 - val_acc: 0.9453 - val_f1: 0.9464\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4551 - acc: 0.7956 - f1: 0.7594 - val_loss: 0.2817 - val_acc: 0.9431 - val_f1: 0.9446\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4621 - acc: 0.7921 - f1: 0.7542 - val_loss: 0.2854 - val_acc: 0.9366 - val_f1: 0.9368\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4539 - acc: 0.7959 - f1: 0.7596 - val_loss: 0.2762 - val_acc: 0.9444 - val_f1: 0.9446\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4612 - acc: 0.7896 - f1: 0.7510 - val_loss: 0.2775 - val_acc: 0.9447 - val_f1: 0.9456\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4604 - acc: 0.7961 - f1: 0.7604 - val_loss: 0.2741 - val_acc: 0.9447 - val_f1: 0.9454\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4583 - acc: 0.7926 - f1: 0.7561 - val_loss: 0.2939 - val_acc: 0.9234 - val_f1: 0.9209\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4505 - acc: 0.7973 - f1: 0.7619 - val_loss: 0.2704 - val_acc: 0.9466 - val_f1: 0.9482\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4620 - acc: 0.7893 - f1: 0.7509 - val_loss: 0.2703 - val_acc: 0.9463 - val_f1: 0.9474\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4540 - acc: 0.7986 - f1: 0.7647 - val_loss: 0.2690 - val_acc: 0.9456 - val_f1: 0.9471\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4597 - acc: 0.7897 - f1: 0.7500 - val_loss: 0.2727 - val_acc: 0.9422 - val_f1: 0.9421\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4539 - acc: 0.7921 - f1: 0.7544 - val_loss: 0.2704 - val_acc: 0.9475 - val_f1: 0.9481\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4553 - acc: 0.7958 - f1: 0.7601 - val_loss: 0.2881 - val_acc: 0.9281 - val_f1: 0.9272\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4551 - acc: 0.7988 - f1: 0.7651 - val_loss: 0.2658 - val_acc: 0.9459 - val_f1: 0.9468\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4539 - acc: 0.7926 - f1: 0.7541 - val_loss: 0.2708 - val_acc: 0.9394 - val_f1: 0.9398\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4632 - acc: 0.7897 - f1: 0.7498 - val_loss: 0.2770 - val_acc: 0.9366 - val_f1: 0.9356\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4492 - acc: 0.7997 - f1: 0.7654 - val_loss: 0.2821 - val_acc: 0.9291 - val_f1: 0.9271\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4509 - acc: 0.7940 - f1: 0.7569 - val_loss: 0.2721 - val_acc: 0.9397 - val_f1: 0.9390\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4542 - acc: 0.7938 - f1: 0.7574 - val_loss: 0.2797 - val_acc: 0.9312 - val_f1: 0.9296\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4523 - acc: 0.8009 - f1: 0.7656 - val_loss: 0.2751 - val_acc: 0.9356 - val_f1: 0.9353\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4513 - acc: 0.7945 - f1: 0.7570 - val_loss: 0.2815 - val_acc: 0.9275 - val_f1: 0.9263\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4461 - acc: 0.7999 - f1: 0.7649 - val_loss: 0.2719 - val_acc: 0.9388 - val_f1: 0.9386\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4528 - acc: 0.7962 - f1: 0.7597 - val_loss: 0.2724 - val_acc: 0.9369 - val_f1: 0.9364\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4623 - acc: 0.7891 - f1: 0.7492 - val_loss: 0.2653 - val_acc: 0.9472 - val_f1: 0.9483\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4532 - acc: 0.7962 - f1: 0.7594 - val_loss: 0.2630 - val_acc: 0.9494 - val_f1: 0.9504\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4502 - acc: 0.7987 - f1: 0.7635 - val_loss: 0.2688 - val_acc: 0.9463 - val_f1: 0.9479\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4499 - acc: 0.7973 - f1: 0.7609 - val_loss: 0.2719 - val_acc: 0.9397 - val_f1: 0.9388\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4508 - acc: 0.7959 - f1: 0.7590 - val_loss: 0.2709 - val_acc: 0.9391 - val_f1: 0.9382\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4334 - acc: 0.8030 - f1: 0.7683 - val_loss: 0.2633 - val_acc: 0.9447 - val_f1: 0.9444\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4521 - acc: 0.7946 - f1: 0.7562 - val_loss: 0.2785 - val_acc: 0.9303 - val_f1: 0.9289\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4454 - acc: 0.8028 - f1: 0.7695 - val_loss: 0.2778 - val_acc: 0.9294 - val_f1: 0.9280\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4567 - acc: 0.7920 - f1: 0.7527 - val_loss: 0.2684 - val_acc: 0.9500 - val_f1: 0.9518\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4482 - acc: 0.7977 - f1: 0.7626 - val_loss: 0.2991 - val_acc: 0.9125 - val_f1: 0.9087\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4489 - acc: 0.7982 - f1: 0.7619 - val_loss: 0.2601 - val_acc: 0.9491 - val_f1: 0.9497\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 33us/sample - loss: 0.6947 - acc: 0.5028 - f1: 0.4201 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.6533 - acc: 0.5773 - f1: 0.6714 - val_loss: 0.5607 - val_acc: 0.8647 - val_f1: 0.8735\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5527 - acc: 0.7585 - f1: 0.7469 - val_loss: 0.4458 - val_acc: 0.9034 - val_f1: 0.9091\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.5071 - acc: 0.7957 - f1: 0.7765 - val_loss: 0.4005 - val_acc: 0.9059 - val_f1: 0.9146\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4878 - acc: 0.8010 - f1: 0.7790 - val_loss: 0.3870 - val_acc: 0.9322 - val_f1: 0.9325\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4645 - acc: 0.8141 - f1: 0.7938 - val_loss: 0.3599 - val_acc: 0.9366 - val_f1: 0.9389\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4592 - acc: 0.8141 - f1: 0.7912 - val_loss: 0.3600 - val_acc: 0.9278 - val_f1: 0.9270\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4493 - acc: 0.8145 - f1: 0.7908 - val_loss: 0.3289 - val_acc: 0.9409 - val_f1: 0.9422\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4360 - acc: 0.8234 - f1: 0.8032 - val_loss: 0.3501 - val_acc: 0.9197 - val_f1: 0.9169\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4332 - acc: 0.8175 - f1: 0.7949 - val_loss: 0.3275 - val_acc: 0.9303 - val_f1: 0.9299\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4324 - acc: 0.8185 - f1: 0.7959 - val_loss: 0.3130 - val_acc: 0.9384 - val_f1: 0.9386\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4263 - acc: 0.8242 - f1: 0.8027 - val_loss: 0.3077 - val_acc: 0.9397 - val_f1: 0.9396\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4225 - acc: 0.8244 - f1: 0.8023 - val_loss: 0.2881 - val_acc: 0.9447 - val_f1: 0.9460\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4151 - acc: 0.8283 - f1: 0.8071 - val_loss: 0.2833 - val_acc: 0.9466 - val_f1: 0.9482\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4177 - acc: 0.8235 - f1: 0.8016 - val_loss: 0.2825 - val_acc: 0.9444 - val_f1: 0.9441\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4142 - acc: 0.8261 - f1: 0.8040 - val_loss: 0.2803 - val_acc: 0.9466 - val_f1: 0.9473\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4075 - acc: 0.8305 - f1: 0.8106 - val_loss: 0.3081 - val_acc: 0.9203 - val_f1: 0.9166\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4215 - acc: 0.8180 - f1: 0.7935 - val_loss: 0.2711 - val_acc: 0.9472 - val_f1: 0.9477\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4139 - acc: 0.8206 - f1: 0.7973 - val_loss: 0.2621 - val_acc: 0.9488 - val_f1: 0.9479\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4068 - acc: 0.8282 - f1: 0.8068 - val_loss: 0.2535 - val_acc: 0.9491 - val_f1: 0.9514\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3966 - acc: 0.8339 - f1: 0.8143 - val_loss: 0.2723 - val_acc: 0.9359 - val_f1: 0.9353\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4033 - acc: 0.8314 - f1: 0.8115 - val_loss: 0.2625 - val_acc: 0.9419 - val_f1: 0.9416\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4008 - acc: 0.8275 - f1: 0.8057 - val_loss: 0.2568 - val_acc: 0.9478 - val_f1: 0.9482\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4035 - acc: 0.8289 - f1: 0.8079 - val_loss: 0.2410 - val_acc: 0.9534 - val_f1: 0.9551\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4056 - acc: 0.8257 - f1: 0.8037 - val_loss: 0.2541 - val_acc: 0.9466 - val_f1: 0.9461\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4047 - acc: 0.8255 - f1: 0.8028 - val_loss: 0.2396 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3917 - acc: 0.8342 - f1: 0.8146 - val_loss: 0.2682 - val_acc: 0.9328 - val_f1: 0.9309\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3971 - acc: 0.8320 - f1: 0.8120 - val_loss: 0.2356 - val_acc: 0.9519 - val_f1: 0.9538\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3935 - acc: 0.8328 - f1: 0.8130 - val_loss: 0.2370 - val_acc: 0.9531 - val_f1: 0.9541\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4023 - acc: 0.8287 - f1: 0.8072 - val_loss: 0.2310 - val_acc: 0.9506 - val_f1: 0.9524\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3973 - acc: 0.8302 - f1: 0.8104 - val_loss: 0.2369 - val_acc: 0.9488 - val_f1: 0.9496\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3958 - acc: 0.8298 - f1: 0.8085 - val_loss: 0.2326 - val_acc: 0.9519 - val_f1: 0.9520\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3863 - acc: 0.8363 - f1: 0.8171 - val_loss: 0.2253 - val_acc: 0.9575 - val_f1: 0.9591\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3911 - acc: 0.8333 - f1: 0.8127 - val_loss: 0.2284 - val_acc: 0.9519 - val_f1: 0.9524\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4060 - acc: 0.8235 - f1: 0.7996 - val_loss: 0.2559 - val_acc: 0.9350 - val_f1: 0.9336\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3938 - acc: 0.8312 - f1: 0.8104 - val_loss: 0.2437 - val_acc: 0.9453 - val_f1: 0.9446\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3922 - acc: 0.8320 - f1: 0.8121 - val_loss: 0.2252 - val_acc: 0.9553 - val_f1: 0.9560\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3901 - acc: 0.8356 - f1: 0.8151 - val_loss: 0.2312 - val_acc: 0.9509 - val_f1: 0.9510\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3878 - acc: 0.8332 - f1: 0.8125 - val_loss: 0.2429 - val_acc: 0.9419 - val_f1: 0.9411\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3859 - acc: 0.8375 - f1: 0.8179 - val_loss: 0.2498 - val_acc: 0.9381 - val_f1: 0.9377\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3998 - acc: 0.8284 - f1: 0.8064 - val_loss: 0.2207 - val_acc: 0.9572 - val_f1: 0.9572\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3911 - acc: 0.8338 - f1: 0.8133 - val_loss: 0.2423 - val_acc: 0.9406 - val_f1: 0.9442\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3914 - acc: 0.8315 - f1: 0.8107 - val_loss: 0.2324 - val_acc: 0.9478 - val_f1: 0.9471\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3860 - acc: 0.8359 - f1: 0.8154 - val_loss: 0.2213 - val_acc: 0.9550 - val_f1: 0.9559\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3924 - acc: 0.8303 - f1: 0.8096 - val_loss: 0.2167 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3897 - acc: 0.8341 - f1: 0.8143 - val_loss: 0.2246 - val_acc: 0.9534 - val_f1: 0.9543\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3798 - acc: 0.8371 - f1: 0.8174 - val_loss: 0.2221 - val_acc: 0.9528 - val_f1: 0.9537\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3897 - acc: 0.8334 - f1: 0.8132 - val_loss: 0.2362 - val_acc: 0.9419 - val_f1: 0.9407\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3868 - acc: 0.8366 - f1: 0.8168 - val_loss: 0.2153 - val_acc: 0.9563 - val_f1: 0.9574\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3871 - acc: 0.8361 - f1: 0.8163 - val_loss: 0.2213 - val_acc: 0.9550 - val_f1: 0.9561\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3850 - acc: 0.8367 - f1: 0.8170 - val_loss: 0.2145 - val_acc: 0.9578 - val_f1: 0.9595\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3853 - acc: 0.8354 - f1: 0.8156 - val_loss: 0.2190 - val_acc: 0.9566 - val_f1: 0.9573\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3902 - acc: 0.8341 - f1: 0.8132 - val_loss: 0.2212 - val_acc: 0.9531 - val_f1: 0.9534\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3845 - acc: 0.8384 - f1: 0.8205 - val_loss: 0.2296 - val_acc: 0.9509 - val_f1: 0.9507\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3817 - acc: 0.8391 - f1: 0.8195 - val_loss: 0.2170 - val_acc: 0.9566 - val_f1: 0.9573\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3958 - acc: 0.8276 - f1: 0.8041 - val_loss: 0.2152 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3843 - acc: 0.8345 - f1: 0.8145 - val_loss: 0.2158 - val_acc: 0.9578 - val_f1: 0.9584\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3853 - acc: 0.8364 - f1: 0.8160 - val_loss: 0.2196 - val_acc: 0.9550 - val_f1: 0.9562\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3779 - acc: 0.8404 - f1: 0.8226 - val_loss: 0.2142 - val_acc: 0.9566 - val_f1: 0.9583\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3732 - acc: 0.8428 - f1: 0.8252 - val_loss: 0.2110 - val_acc: 0.9563 - val_f1: 0.9575\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 77us/sample - loss: 0.5002 - acc: 0.7407 - f1: 0.7518 - val_loss: 0.2583 - val_acc: 0.8972 - val_f1: 0.9003\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.2443 - acc: 0.9042 - f1: 0.9071 - val_loss: 0.1887 - val_acc: 0.9291 - val_f1: 0.9335\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1938 - acc: 0.9241 - f1: 0.9265 - val_loss: 0.1520 - val_acc: 0.9444 - val_f1: 0.9467\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1656 - acc: 0.9370 - f1: 0.9386 - val_loss: 0.1541 - val_acc: 0.9444 - val_f1: 0.9475\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1650 - acc: 0.9377 - f1: 0.9396 - val_loss: 0.1340 - val_acc: 0.9478 - val_f1: 0.9491\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1539 - acc: 0.9413 - f1: 0.9432 - val_loss: 0.1327 - val_acc: 0.9491 - val_f1: 0.9517\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1434 - acc: 0.9466 - f1: 0.9483 - val_loss: 0.1279 - val_acc: 0.9534 - val_f1: 0.9546\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1410 - acc: 0.9472 - f1: 0.9488 - val_loss: 0.1819 - val_acc: 0.9309 - val_f1: 0.9364\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1360 - acc: 0.9506 - f1: 0.9524 - val_loss: 0.1286 - val_acc: 0.9516 - val_f1: 0.9536\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1323 - acc: 0.9507 - f1: 0.9520 - val_loss: 0.1142 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1291 - acc: 0.9528 - f1: 0.9540 - val_loss: 0.1413 - val_acc: 0.9459 - val_f1: 0.9491\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1220 - acc: 0.9546 - f1: 0.9559 - val_loss: 0.1153 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1255 - acc: 0.9556 - f1: 0.9573 - val_loss: 0.1123 - val_acc: 0.9594 - val_f1: 0.9607\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1233 - acc: 0.9549 - f1: 0.9562 - val_loss: 0.1261 - val_acc: 0.9531 - val_f1: 0.9538\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1166 - acc: 0.9584 - f1: 0.9595 - val_loss: 0.1094 - val_acc: 0.9581 - val_f1: 0.9592\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1199 - acc: 0.9549 - f1: 0.9562 - val_loss: 0.1090 - val_acc: 0.9563 - val_f1: 0.9572\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1166 - acc: 0.9553 - f1: 0.9567 - val_loss: 0.1159 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1114 - acc: 0.9589 - f1: 0.9601 - val_loss: 0.1034 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 19/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1138 - acc: 0.9580 - f1: 0.9591 - val_loss: 0.1055 - val_acc: 0.9609 - val_f1: 0.9631\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1114 - acc: 0.9595 - f1: 0.9608 - val_loss: 0.1020 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1098 - acc: 0.9577 - f1: 0.9587 - val_loss: 0.1039 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1100 - acc: 0.9591 - f1: 0.9606 - val_loss: 0.1045 - val_acc: 0.9597 - val_f1: 0.9608\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1100 - acc: 0.9582 - f1: 0.9594 - val_loss: 0.1122 - val_acc: 0.9566 - val_f1: 0.9568\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1077 - acc: 0.9598 - f1: 0.9610 - val_loss: 0.1414 - val_acc: 0.9469 - val_f1: 0.9498\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1113 - acc: 0.9581 - f1: 0.9594 - val_loss: 0.1061 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1021 - acc: 0.9636 - f1: 0.9649 - val_loss: 0.1075 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1012 - acc: 0.9617 - f1: 0.9627 - val_loss: 0.1136 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 65us/sample - loss: 0.1044 - acc: 0.9601 - f1: 0.9612 - val_loss: 0.1079 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1003 - acc: 0.9619 - f1: 0.9631 - val_loss: 0.1111 - val_acc: 0.9597 - val_f1: 0.9601\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1070 - acc: 0.9592 - f1: 0.9604 - val_loss: 0.1008 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.1049 - acc: 0.9616 - f1: 0.9628 - val_loss: 0.1019 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1012 - acc: 0.9638 - f1: 0.9647 - val_loss: 0.0966 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1007 - acc: 0.9623 - f1: 0.9632 - val_loss: 0.0955 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0965 - acc: 0.9641 - f1: 0.9653 - val_loss: 0.1013 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0964 - acc: 0.9637 - f1: 0.9651 - val_loss: 0.0952 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0964 - acc: 0.9643 - f1: 0.9655 - val_loss: 0.1124 - val_acc: 0.9559 - val_f1: 0.9556\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0941 - acc: 0.9662 - f1: 0.9671 - val_loss: 0.0979 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0956 - acc: 0.9643 - f1: 0.9654 - val_loss: 0.1008 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0943 - acc: 0.9663 - f1: 0.9673 - val_loss: 0.1130 - val_acc: 0.9606 - val_f1: 0.9611\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0965 - acc: 0.9634 - f1: 0.9645 - val_loss: 0.1071 - val_acc: 0.9609 - val_f1: 0.9618\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0945 - acc: 0.9655 - f1: 0.9662 - val_loss: 0.1001 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0911 - acc: 0.9659 - f1: 0.9669 - val_loss: 0.1043 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0937 - acc: 0.9662 - f1: 0.9673 - val_loss: 0.1075 - val_acc: 0.9609 - val_f1: 0.9613\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0940 - acc: 0.9668 - f1: 0.9676 - val_loss: 0.1083 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0907 - acc: 0.9663 - f1: 0.9675 - val_loss: 0.1107 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0900 - acc: 0.9660 - f1: 0.9670 - val_loss: 0.1078 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0897 - acc: 0.9675 - f1: 0.9685 - val_loss: 0.1202 - val_acc: 0.9581 - val_f1: 0.9589\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0857 - acc: 0.9696 - f1: 0.9706 - val_loss: 0.1044 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0877 - acc: 0.9666 - f1: 0.9675 - val_loss: 0.1051 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0847 - acc: 0.9694 - f1: 0.9703 - val_loss: 0.1093 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0820 - acc: 0.9705 - f1: 0.9718 - val_loss: 0.1021 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0865 - acc: 0.9677 - f1: 0.9685 - val_loss: 0.1060 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0852 - acc: 0.9691 - f1: 0.9700 - val_loss: 0.1013 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0829 - acc: 0.9701 - f1: 0.9709 - val_loss: 0.1032 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0863 - acc: 0.9687 - f1: 0.9695 - val_loss: 0.1020 - val_acc: 0.9669 - val_f1: 0.9670\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0935 - acc: 0.9667 - f1: 0.9679 - val_loss: 0.1126 - val_acc: 0.9591 - val_f1: 0.9602\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0841 - acc: 0.9698 - f1: 0.9708 - val_loss: 0.1078 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0819 - acc: 0.9696 - f1: 0.9705 - val_loss: 0.1186 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 65us/sample - loss: 0.0845 - acc: 0.9701 - f1: 0.9711 - val_loss: 0.1198 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.0809 - acc: 0.9711 - f1: 0.9718 - val_loss: 0.1057 - val_acc: 0.9634 - val_f1: 0.9642\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "nb_perceptrons_range = [[5, 4, 4],[100, 100, 2],[500, 500, 500]]                                                                                                                      \n",
    "\n",
    "for nb_perceptrons in nb_perceptrons_range:                                                                                                                                                  \n",
    "    model = RN_model(nb_perceptrons, dropout, learning_rate)                                                                                                                              \n",
    "    #### Apprentissage                                                                                                                                                             \n",
    "    start = time.time()                                                                                                                                                            \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test))                                                             \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    training_delay_RN.append(end - start)                                                                                                                                          \n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                \n",
    "    start = time.time()                                                                                                                                                            \n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    predicting_delay_RN.append(end - start)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in nb_perceptrons_range]                                                                                                                                          \n",
    "\n",
    "titre = \"RN : HyperParam = layer size\"   \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Nous remarquons qu'avec trois couches, les performances d'accuracy et de f1_score sont meilleurs dans le cas de [500,500,500] (dépassant les 95%). On remarque également que la perte (\"loss\") est, en quelque sorte, inversement proportionnelle aux f1_score et accuracy dans ce cas. C'est à dire que pour un f1_score et une accuracy plus faible (nombre de perceptrons inférieur) la valeur de perte sera plus importante que les architectures avec plus de perceptrons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "En revanche, ajouter un nombre de perceptrons par couche important influence grandement le temps d'entrainement et de prediction.\n",
    "\n",
    "\n",
    "1 - b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 49us/sample - loss: 0.6234 - acc: 0.6728 - f1: 0.7001 - val_loss: 0.4902 - val_acc: 0.8391 - val_f1: 0.8390\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4013 - acc: 0.8518 - f1: 0.8558 - val_loss: 0.3231 - val_acc: 0.8778 - val_f1: 0.8792\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3019 - acc: 0.8876 - f1: 0.8905 - val_loss: 0.2578 - val_acc: 0.9103 - val_f1: 0.9156\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.2532 - acc: 0.9087 - f1: 0.9110 - val_loss: 0.2169 - val_acc: 0.9237 - val_f1: 0.9281\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.2171 - acc: 0.9202 - f1: 0.9224 - val_loss: 0.1956 - val_acc: 0.9216 - val_f1: 0.9213\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1957 - acc: 0.9275 - f1: 0.9298 - val_loss: 0.1773 - val_acc: 0.9388 - val_f1: 0.9418\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1810 - acc: 0.9345 - f1: 0.9364 - val_loss: 0.1783 - val_acc: 0.9272 - val_f1: 0.9266\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1706 - acc: 0.9395 - f1: 0.9410 - val_loss: 0.1547 - val_acc: 0.9416 - val_f1: 0.9422\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1645 - acc: 0.9408 - f1: 0.9427 - val_loss: 0.1581 - val_acc: 0.9434 - val_f1: 0.9463\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1559 - acc: 0.9436 - f1: 0.9453 - val_loss: 0.1585 - val_acc: 0.9362 - val_f1: 0.9358\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1528 - acc: 0.9459 - f1: 0.9476 - val_loss: 0.1456 - val_acc: 0.9469 - val_f1: 0.9493\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1509 - acc: 0.9451 - f1: 0.9469 - val_loss: 0.1367 - val_acc: 0.9481 - val_f1: 0.9495\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1480 - acc: 0.9469 - f1: 0.9482 - val_loss: 0.1334 - val_acc: 0.9481 - val_f1: 0.9495\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.1481 - acc: 0.9454 - f1: 0.9472 - val_loss: 0.1313 - val_acc: 0.9491 - val_f1: 0.9512\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 25us/sample - loss: 0.1428 - acc: 0.9469 - f1: 0.9484 - val_loss: 0.1288 - val_acc: 0.9516 - val_f1: 0.9531\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1376 - acc: 0.9516 - f1: 0.9530 - val_loss: 0.1295 - val_acc: 0.9506 - val_f1: 0.9532\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1363 - acc: 0.9505 - f1: 0.9517 - val_loss: 0.1278 - val_acc: 0.9522 - val_f1: 0.9540\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1359 - acc: 0.9493 - f1: 0.9510 - val_loss: 0.1307 - val_acc: 0.9475 - val_f1: 0.9486\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1336 - acc: 0.9515 - f1: 0.9530 - val_loss: 0.1305 - val_acc: 0.9509 - val_f1: 0.9536\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.1319 - acc: 0.9515 - f1: 0.9525 - val_loss: 0.1223 - val_acc: 0.9522 - val_f1: 0.9525\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1310 - acc: 0.9516 - f1: 0.9531 - val_loss: 0.1375 - val_acc: 0.9513 - val_f1: 0.9542\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1297 - acc: 0.9539 - f1: 0.9555 - val_loss: 0.1260 - val_acc: 0.9531 - val_f1: 0.9555\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1335 - acc: 0.9495 - f1: 0.9506 - val_loss: 0.1233 - val_acc: 0.9547 - val_f1: 0.9569\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1295 - acc: 0.9539 - f1: 0.9551 - val_loss: 0.1223 - val_acc: 0.9538 - val_f1: 0.9545\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1276 - acc: 0.9527 - f1: 0.9538 - val_loss: 0.1170 - val_acc: 0.9569 - val_f1: 0.9575\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1264 - acc: 0.9541 - f1: 0.9553 - val_loss: 0.1200 - val_acc: 0.9559 - val_f1: 0.9572\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1255 - acc: 0.9560 - f1: 0.9575 - val_loss: 0.1151 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1202 - acc: 0.9562 - f1: 0.9576 - val_loss: 0.1196 - val_acc: 0.9559 - val_f1: 0.9576\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1238 - acc: 0.9557 - f1: 0.9568 - val_loss: 0.1156 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1200 - acc: 0.9572 - f1: 0.9588 - val_loss: 0.1179 - val_acc: 0.9566 - val_f1: 0.9572\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1213 - acc: 0.9566 - f1: 0.9578 - val_loss: 0.1132 - val_acc: 0.9566 - val_f1: 0.9577\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1241 - acc: 0.9556 - f1: 0.9568 - val_loss: 0.1120 - val_acc: 0.9578 - val_f1: 0.9597\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1180 - acc: 0.9590 - f1: 0.9601 - val_loss: 0.1279 - val_acc: 0.9525 - val_f1: 0.9533\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1235 - acc: 0.9530 - f1: 0.9544 - val_loss: 0.1330 - val_acc: 0.9506 - val_f1: 0.9511\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1189 - acc: 0.9563 - f1: 0.9575 - val_loss: 0.1106 - val_acc: 0.9581 - val_f1: 0.9588\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1183 - acc: 0.9584 - f1: 0.9595 - val_loss: 0.1215 - val_acc: 0.9547 - val_f1: 0.9572\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1163 - acc: 0.9573 - f1: 0.9586 - val_loss: 0.1123 - val_acc: 0.9544 - val_f1: 0.9557\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1134 - acc: 0.9609 - f1: 0.9620 - val_loss: 0.1103 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1196 - acc: 0.9584 - f1: 0.9596 - val_loss: 0.1255 - val_acc: 0.9547 - val_f1: 0.9563\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1139 - acc: 0.9605 - f1: 0.9617 - val_loss: 0.1067 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1134 - acc: 0.9583 - f1: 0.9599 - val_loss: 0.1143 - val_acc: 0.9594 - val_f1: 0.9596\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1177 - acc: 0.9584 - f1: 0.9594 - val_loss: 0.1065 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1114 - acc: 0.9594 - f1: 0.9607 - val_loss: 0.1097 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1135 - acc: 0.9589 - f1: 0.9603 - val_loss: 0.1110 - val_acc: 0.9597 - val_f1: 0.9610\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1124 - acc: 0.9577 - f1: 0.9588 - val_loss: 0.1184 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1154 - acc: 0.9588 - f1: 0.9597 - val_loss: 0.1300 - val_acc: 0.9544 - val_f1: 0.9574\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1132 - acc: 0.9591 - f1: 0.9604 - val_loss: 0.1093 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1101 - acc: 0.9605 - f1: 0.9616 - val_loss: 0.1112 - val_acc: 0.9603 - val_f1: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1091 - acc: 0.9613 - f1: 0.9624 - val_loss: 0.1123 - val_acc: 0.9544 - val_f1: 0.9546\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1133 - acc: 0.9581 - f1: 0.9597 - val_loss: 0.1062 - val_acc: 0.9591 - val_f1: 0.9603\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1111 - acc: 0.9606 - f1: 0.9618 - val_loss: 0.1046 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1069 - acc: 0.9612 - f1: 0.9626 - val_loss: 0.1056 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1068 - acc: 0.9614 - f1: 0.9627 - val_loss: 0.1040 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1098 - acc: 0.9605 - f1: 0.9616 - val_loss: 0.1028 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1049 - acc: 0.9613 - f1: 0.9621 - val_loss: 0.1063 - val_acc: 0.9588 - val_f1: 0.9598\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1039 - acc: 0.9614 - f1: 0.9625 - val_loss: 0.1081 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1071 - acc: 0.9618 - f1: 0.9632 - val_loss: 0.1028 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1044 - acc: 0.9617 - f1: 0.9624 - val_loss: 0.1087 - val_acc: 0.9578 - val_f1: 0.9588\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1067 - acc: 0.9606 - f1: 0.9618 - val_loss: 0.1027 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1053 - acc: 0.9626 - f1: 0.9639 - val_loss: 0.1039 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.6801 - acc: 0.5645 - f1: 0.5767 - val_loss: 0.6230 - val_acc: 0.7716 - val_f1: 0.7336\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.6025 - acc: 0.7311 - f1: 0.7464 - val_loss: 0.5195 - val_acc: 0.8697 - val_f1: 0.8713\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.5444 - acc: 0.7798 - f1: 0.8062 - val_loss: 0.4548 - val_acc: 0.9016 - val_f1: 0.9060\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 25us/sample - loss: 0.5091 - acc: 0.8049 - f1: 0.8299 - val_loss: 0.4139 - val_acc: 0.9112 - val_f1: 0.9126\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4869 - acc: 0.8131 - f1: 0.8392 - val_loss: 0.3903 - val_acc: 0.9234 - val_f1: 0.9265\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 24us/sample - loss: 0.4749 - acc: 0.8159 - f1: 0.8413 - val_loss: 0.3837 - val_acc: 0.9266 - val_f1: 0.9318\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 23us/sample - loss: 0.4667 - acc: 0.8217 - f1: 0.8463 - val_loss: 0.3526 - val_acc: 0.9334 - val_f1: 0.9365\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4616 - acc: 0.8180 - f1: 0.8436 - val_loss: 0.3472 - val_acc: 0.9356 - val_f1: 0.9396\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4536 - acc: 0.8226 - f1: 0.8479 - val_loss: 0.3377 - val_acc: 0.9300 - val_f1: 0.9309\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.4442 - acc: 0.8255 - f1: 0.8502 - val_loss: 0.3254 - val_acc: 0.9366 - val_f1: 0.9388\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4350 - acc: 0.8279 - f1: 0.8522 - val_loss: 0.3167 - val_acc: 0.9375 - val_f1: 0.9389\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 21us/sample - loss: 0.4381 - acc: 0.8241 - f1: 0.8495 - val_loss: 0.3120 - val_acc: 0.9388 - val_f1: 0.9423\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.4259 - acc: 0.8315 - f1: 0.8556 - val_loss: 0.2967 - val_acc: 0.9444 - val_f1: 0.9466\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.4224 - acc: 0.8289 - f1: 0.8534 - val_loss: 0.3143 - val_acc: 0.9316 - val_f1: 0.9368\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4162 - acc: 0.8330 - f1: 0.8569 - val_loss: 0.2900 - val_acc: 0.9419 - val_f1: 0.9454\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.4216 - acc: 0.8295 - f1: 0.8543 - val_loss: 0.2830 - val_acc: 0.9469 - val_f1: 0.9500\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 21us/sample - loss: 0.4098 - acc: 0.8355 - f1: 0.8583 - val_loss: 0.2831 - val_acc: 0.9428 - val_f1: 0.9462\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.4078 - acc: 0.8370 - f1: 0.8594 - val_loss: 0.2722 - val_acc: 0.9450 - val_f1: 0.9474\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3982 - acc: 0.8401 - f1: 0.8621 - val_loss: 0.2714 - val_acc: 0.9431 - val_f1: 0.9469\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.4080 - acc: 0.8335 - f1: 0.8569 - val_loss: 0.3117 - val_acc: 0.9228 - val_f1: 0.9293\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3958 - acc: 0.8415 - f1: 0.8629 - val_loss: 0.2535 - val_acc: 0.9488 - val_f1: 0.9509\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3858 - acc: 0.8458 - f1: 0.8665 - val_loss: 0.2677 - val_acc: 0.9378 - val_f1: 0.9417\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3888 - acc: 0.8443 - f1: 0.8655 - val_loss: 0.2516 - val_acc: 0.9500 - val_f1: 0.9523\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3944 - acc: 0.8398 - f1: 0.8617 - val_loss: 0.2618 - val_acc: 0.9425 - val_f1: 0.9428\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3952 - acc: 0.8377 - f1: 0.8599 - val_loss: 0.2476 - val_acc: 0.9441 - val_f1: 0.9447\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3888 - acc: 0.8413 - f1: 0.8631 - val_loss: 0.2349 - val_acc: 0.9538 - val_f1: 0.9556\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3965 - acc: 0.8373 - f1: 0.8596 - val_loss: 0.2330 - val_acc: 0.9525 - val_f1: 0.9533\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3915 - acc: 0.8400 - f1: 0.8622 - val_loss: 0.2321 - val_acc: 0.9519 - val_f1: 0.9544\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3874 - acc: 0.8416 - f1: 0.8633 - val_loss: 0.2295 - val_acc: 0.9519 - val_f1: 0.9539\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3945 - acc: 0.8377 - f1: 0.8610 - val_loss: 0.2557 - val_acc: 0.9428 - val_f1: 0.9472\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3776 - acc: 0.8489 - f1: 0.8689 - val_loss: 0.2238 - val_acc: 0.9534 - val_f1: 0.9550\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3847 - acc: 0.8454 - f1: 0.8664 - val_loss: 0.2259 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3895 - acc: 0.8402 - f1: 0.8624 - val_loss: 0.2205 - val_acc: 0.9547 - val_f1: 0.9564\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3820 - acc: 0.8459 - f1: 0.8669 - val_loss: 0.2347 - val_acc: 0.9497 - val_f1: 0.9520\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3834 - acc: 0.8430 - f1: 0.8647 - val_loss: 0.2222 - val_acc: 0.9519 - val_f1: 0.9542\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3833 - acc: 0.8428 - f1: 0.8642 - val_loss: 0.2527 - val_acc: 0.9381 - val_f1: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3859 - acc: 0.8422 - f1: 0.8645 - val_loss: 0.2379 - val_acc: 0.9447 - val_f1: 0.9482\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3869 - acc: 0.8382 - f1: 0.8610 - val_loss: 0.2206 - val_acc: 0.9522 - val_f1: 0.9544\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3839 - acc: 0.8444 - f1: 0.8659 - val_loss: 0.2275 - val_acc: 0.9513 - val_f1: 0.9524\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3855 - acc: 0.8418 - f1: 0.8640 - val_loss: 0.2237 - val_acc: 0.9519 - val_f1: 0.9525\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3874 - acc: 0.8393 - f1: 0.8621 - val_loss: 0.2166 - val_acc: 0.9578 - val_f1: 0.9590\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3864 - acc: 0.8430 - f1: 0.8650 - val_loss: 0.2208 - val_acc: 0.9528 - val_f1: 0.9552\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3811 - acc: 0.8460 - f1: 0.8679 - val_loss: 0.2227 - val_acc: 0.9531 - val_f1: 0.9536\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 23us/sample - loss: 0.3765 - acc: 0.8474 - f1: 0.8686 - val_loss: 0.2209 - val_acc: 0.9547 - val_f1: 0.9568\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 21us/sample - loss: 0.3735 - acc: 0.8479 - f1: 0.8683 - val_loss: 0.2162 - val_acc: 0.9541 - val_f1: 0.9564\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3795 - acc: 0.8465 - f1: 0.8677 - val_loss: 0.2231 - val_acc: 0.9538 - val_f1: 0.9562\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 23us/sample - loss: 0.3782 - acc: 0.8452 - f1: 0.8664 - val_loss: 0.2186 - val_acc: 0.9550 - val_f1: 0.9572\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3787 - acc: 0.8445 - f1: 0.8658 - val_loss: 0.2172 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3840 - acc: 0.8435 - f1: 0.8646 - val_loss: 0.2316 - val_acc: 0.9491 - val_f1: 0.9520\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3751 - acc: 0.8493 - f1: 0.8700 - val_loss: 0.2173 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3802 - acc: 0.8452 - f1: 0.8668 - val_loss: 0.2134 - val_acc: 0.9569 - val_f1: 0.9581\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3753 - acc: 0.8469 - f1: 0.8679 - val_loss: 0.2177 - val_acc: 0.9544 - val_f1: 0.9566\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3747 - acc: 0.8502 - f1: 0.8702 - val_loss: 0.2154 - val_acc: 0.9559 - val_f1: 0.9586\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3749 - acc: 0.8476 - f1: 0.8691 - val_loss: 0.2174 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3827 - acc: 0.8439 - f1: 0.8658 - val_loss: 0.2259 - val_acc: 0.9519 - val_f1: 0.9542\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3802 - acc: 0.8451 - f1: 0.8666 - val_loss: 0.2192 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3778 - acc: 0.8461 - f1: 0.8676 - val_loss: 0.2162 - val_acc: 0.9541 - val_f1: 0.9562\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3792 - acc: 0.8445 - f1: 0.8661 - val_loss: 0.2139 - val_acc: 0.9566 - val_f1: 0.9586\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3843 - acc: 0.8445 - f1: 0.8662 - val_loss: 0.2479 - val_acc: 0.9394 - val_f1: 0.9437\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3761 - acc: 0.8471 - f1: 0.8683 - val_loss: 0.2140 - val_acc: 0.9584 - val_f1: 0.9602\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.6961 - acc: 0.5202 - f1: 0.6512 - val_loss: 0.6928 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6929 - acc: 0.5204 - f1: 0.6772 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6927 - acc: 0.5202 - f1: 0.6792 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5197 - f1: 0.6808 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6923 - acc: 0.5202 - f1: 0.6810 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6818\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6920 - acc: 0.5223 - f1: 0.6774 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.6917 - acc: 0.5276 - f1: 0.6780 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.6526 - acc: 0.6195 - f1: 0.7059 - val_loss: 0.5656 - val_acc: 0.8644 - val_f1: 0.8783\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5973 - acc: 0.6858 - f1: 0.7527 - val_loss: 0.4498 - val_acc: 0.9053 - val_f1: 0.9084\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5744 - acc: 0.7038 - f1: 0.7688 - val_loss: 0.4466 - val_acc: 0.9125 - val_f1: 0.9198\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5622 - acc: 0.7113 - f1: 0.7743 - val_loss: 0.4367 - val_acc: 0.9209 - val_f1: 0.9271\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5568 - acc: 0.7101 - f1: 0.7745 - val_loss: 0.3757 - val_acc: 0.9222 - val_f1: 0.9245\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5432 - acc: 0.7222 - f1: 0.7820 - val_loss: 0.4654 - val_acc: 0.8719 - val_f1: 0.8889\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5436 - acc: 0.7184 - f1: 0.7803 - val_loss: 0.3672 - val_acc: 0.9347 - val_f1: 0.9379\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5423 - acc: 0.7169 - f1: 0.7799 - val_loss: 0.3754 - val_acc: 0.9284 - val_f1: 0.9329\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5388 - acc: 0.7247 - f1: 0.7843 - val_loss: 0.3733 - val_acc: 0.9316 - val_f1: 0.9357\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5358 - acc: 0.7231 - f1: 0.7841 - val_loss: 0.3820 - val_acc: 0.9284 - val_f1: 0.9332\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5310 - acc: 0.7242 - f1: 0.7846 - val_loss: 0.3489 - val_acc: 0.9388 - val_f1: 0.9411\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5364 - acc: 0.7214 - f1: 0.7826 - val_loss: 0.4229 - val_acc: 0.8988 - val_f1: 0.9102\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5332 - acc: 0.7250 - f1: 0.7848 - val_loss: 0.3517 - val_acc: 0.9375 - val_f1: 0.9410\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5332 - acc: 0.7227 - f1: 0.7839 - val_loss: 0.3972 - val_acc: 0.9062 - val_f1: 0.9160\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5318 - acc: 0.7241 - f1: 0.7853 - val_loss: 0.3486 - val_acc: 0.9362 - val_f1: 0.9398\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5279 - acc: 0.7265 - f1: 0.7861 - val_loss: 0.3342 - val_acc: 0.9409 - val_f1: 0.9443\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5307 - acc: 0.7259 - f1: 0.7854 - val_loss: 0.3438 - val_acc: 0.9375 - val_f1: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5287 - acc: 0.7259 - f1: 0.7857 - val_loss: 0.3444 - val_acc: 0.9372 - val_f1: 0.9408\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5243 - acc: 0.7303 - f1: 0.7884 - val_loss: 0.3826 - val_acc: 0.9259 - val_f1: 0.9325\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5258 - acc: 0.7291 - f1: 0.7882 - val_loss: 0.3278 - val_acc: 0.9425 - val_f1: 0.9454\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5251 - acc: 0.7270 - f1: 0.7870 - val_loss: 0.3137 - val_acc: 0.9438 - val_f1: 0.9465\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5326 - acc: 0.7207 - f1: 0.7824 - val_loss: 0.3718 - val_acc: 0.9281 - val_f1: 0.9347\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 26us/sample - loss: 0.5188 - acc: 0.7345 - f1: 0.7916 - val_loss: 0.3437 - val_acc: 0.9416 - val_f1: 0.9448\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5152 - acc: 0.7361 - f1: 0.7924 - val_loss: 0.3122 - val_acc: 0.9466 - val_f1: 0.9484\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5231 - acc: 0.7328 - f1: 0.7905 - val_loss: 0.3597 - val_acc: 0.9344 - val_f1: 0.9395\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5217 - acc: 0.7312 - f1: 0.7896 - val_loss: 0.3127 - val_acc: 0.9466 - val_f1: 0.9480\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5188 - acc: 0.7318 - f1: 0.7903 - val_loss: 0.3580 - val_acc: 0.9350 - val_f1: 0.9402\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5208 - acc: 0.7341 - f1: 0.7914 - val_loss: 0.3215 - val_acc: 0.9500 - val_f1: 0.9516\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5207 - acc: 0.7300 - f1: 0.7884 - val_loss: 0.3114 - val_acc: 0.9456 - val_f1: 0.9476\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5158 - acc: 0.7344 - f1: 0.7923 - val_loss: 0.3061 - val_acc: 0.9506 - val_f1: 0.9524\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5251 - acc: 0.7255 - f1: 0.7856 - val_loss: 0.3468 - val_acc: 0.9434 - val_f1: 0.9472\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5167 - acc: 0.7350 - f1: 0.7922 - val_loss: 0.3601 - val_acc: 0.9291 - val_f1: 0.9344\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 30us/sample - loss: 0.5178 - acc: 0.7329 - f1: 0.7911 - val_loss: 0.3414 - val_acc: 0.9444 - val_f1: 0.9481\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 31us/sample - loss: 0.5153 - acc: 0.7352 - f1: 0.7923 - val_loss: 0.3719 - val_acc: 0.9200 - val_f1: 0.9272\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5203 - acc: 0.7327 - f1: 0.7907 - val_loss: 0.3036 - val_acc: 0.9509 - val_f1: 0.9517\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 30us/sample - loss: 0.5226 - acc: 0.7305 - f1: 0.7884 - val_loss: 0.3444 - val_acc: 0.9447 - val_f1: 0.9487\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5194 - acc: 0.7323 - f1: 0.7900 - val_loss: 0.3271 - val_acc: 0.9488 - val_f1: 0.9503\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 31us/sample - loss: 0.5161 - acc: 0.7360 - f1: 0.7927 - val_loss: 0.3309 - val_acc: 0.9400 - val_f1: 0.9436\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 32us/sample - loss: 0.5098 - acc: 0.7410 - f1: 0.7957 - val_loss: 0.3329 - val_acc: 0.9472 - val_f1: 0.9505\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5182 - acc: 0.7362 - f1: 0.7928 - val_loss: 0.3071 - val_acc: 0.9522 - val_f1: 0.9539\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5236 - acc: 0.7279 - f1: 0.7874 - val_loss: 0.3856 - val_acc: 0.9275 - val_f1: 0.9336\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5135 - acc: 0.7355 - f1: 0.7919 - val_loss: 0.3201 - val_acc: 0.9509 - val_f1: 0.9533\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5246 - acc: 0.7248 - f1: 0.7861 - val_loss: 0.3415 - val_acc: 0.9431 - val_f1: 0.9471\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 34us/sample - loss: 0.5186 - acc: 0.7323 - f1: 0.7905 - val_loss: 0.4025 - val_acc: 0.9103 - val_f1: 0.9200\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 33us/sample - loss: 0.5182 - acc: 0.7334 - f1: 0.7911 - val_loss: 0.3630 - val_acc: 0.9447 - val_f1: 0.9486\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5163 - acc: 0.7343 - f1: 0.7916 - val_loss: 0.3052 - val_acc: 0.9209 - val_f1: 0.9186\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 37us/sample - loss: 0.5204 - acc: 0.7319 - f1: 0.7894 - val_loss: 0.3206 - val_acc: 0.9553 - val_f1: 0.9577\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 41us/sample - loss: 0.5172 - acc: 0.7340 - f1: 0.7913 - val_loss: 0.3283 - val_acc: 0.9509 - val_f1: 0.9524\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 48us/sample - loss: 0.5166 - acc: 0.7377 - f1: 0.7938 - val_loss: 0.3338 - val_acc: 0.9522 - val_f1: 0.9543\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 37us/sample - loss: 0.5169 - acc: 0.7345 - f1: 0.7914 - val_loss: 0.4471 - val_acc: 0.8959 - val_f1: 0.9084\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 33us/sample - loss: 0.5112 - acc: 0.7384 - f1: 0.7943 - val_loss: 0.3278 - val_acc: 0.9550 - val_f1: 0.9569\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5165 - acc: 0.7333 - f1: 0.7918 - val_loss: 0.3223 - val_acc: 0.9509 - val_f1: 0.9535\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 38us/sample - loss: 0.5164 - acc: 0.7330 - f1: 0.7903 - val_loss: 0.3055 - val_acc: 0.9500 - val_f1: 0.9500\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "layer_sizes_range = [[100],[100, 100, 2],[100, 100, 100, 100, 100, 2]]\n",
    "\n",
    "for layer_s in layer_sizes_range:\n",
    "    model = RN_model(layer_s, dropout, learning_rate)\n",
    "    #### Apprentissage                                                                                                                                                               \n",
    "    start = time.time()                                                                                                                   \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test))\n",
    "\n",
    "    end = time.time()\n",
    "    training_delay_RN.append(end - start)\n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                  \n",
    "    start = time.time()\n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)\n",
    "\n",
    "    end = time.time()\n",
    "    predicting_delay_RN.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_sizes_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f13cfc91e535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mleg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_sizes_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtitre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RN : HyperParam = number of layer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer_sizes_range' is not defined"
     ]
    }
   ],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in layer_sizes_range]                                                                                                                                              \n",
    "\n",
    "titre = \"RN : HyperParam = number of layer\"                                                                                                                                         \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dans notre problème de classification de galaxies, on note que le les valeurs des accuracy et des f1_scores tendent vers les mêmes performances sur les jeux de données de tests qu'il y ait une, trois ou six couches (nb de perceptrons constant par couche). On remarque également que la valeur de perte est moins importante dans le cas où il y le moins de couche. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ici, nous remarquons que : plus le nombre de couche est important plus le temps d'entrainement et de prediction sont élevés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "################################## Learning rate                                                                                                                                     \n",
    "\n",
    "#l_rate_range = [0.00001,0.0005,0.1]                                                                                                                                                          \n",
    "\n",
    "# for l_rate in l_rate_range:                                                                                                                                                        \n",
    "#     model = RN_model(layer_sizes, dropout, l_rate)                                                                                                                                 \n",
    "#     #### Apprentissage                                                                                                                                                             \n",
    "#     start = time.time()                                                                                                                                                            \n",
    "#     #model.fit(X_train, Y_train, batch_size = 100, epochs = 60)                                                                                                                    \n",
    "#     hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test))                                                             \n",
    "#                                                                                                                                                                                    \n",
    "#     end = time.time()                                                                                                                                                              \n",
    "#     training_delay_RN.append(end - start)                                                                                                                                          \n",
    "#                                                                                                                                                                                    \n",
    "#     history_obj.append( list(hist_obj.history.values()))                                                                                                                           \n",
    "#                                                                                                                                                                                    \n",
    "#     #### Prédiction                                                                                                                                                                \n",
    "#     start = time.time()                                                                                                                                                            \n",
    "#                                                                                                                                                                                    \n",
    "#     Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "#                                                                                                                                                                                    \n",
    "#     end = time.time()                                                                                                                                                              \n",
    "#     predicting_delay_RN.append(end - start)   \n",
    "# \n",
    "#   \n",
    "\n",
    "# Traitement pour affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "                                                                                                                                      \n",
    "leg = [str(i) for i in l_rate_range]                                                                                                                                                \n",
    "                                                                                                                                    \n",
    "titre = \"RN : HyperParam = learning rate\"                                                                                                                                           \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)\n",
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "La fonction de coût que nous avons choisie est \"Binary Cross-Entropy Loss\". En effet, nous avons choisi cette fonction car nos valeurs cibles sont 0 ou 1, soit \"smooth\" ou \"spiral\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 4\n",
    "(L’analyse est claire et l’équipe démontre une compréhension du phénomène de sur-apprentissage. Il le phénomène est correctement décrit et montré dans le graphique dans la mesure du possible.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/30\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.6914 - acc: 0.5196 - f1: 0.5394 - val_loss: 0.6674 - val_acc: 0.6288 - val_f1: 0.7314\n",
      "Epoch 2/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.6181 - acc: 0.6126 - f1: 0.6093 - val_loss: 0.4916 - val_acc: 0.8550 - val_f1: 0.8533\n",
      "Epoch 3/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.5316 - acc: 0.6757 - f1: 0.5877 - val_loss: 0.3570 - val_acc: 0.9041 - val_f1: 0.9079\n",
      "Epoch 4/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4955 - acc: 0.6856 - f1: 0.5981 - val_loss: 0.3395 - val_acc: 0.8966 - val_f1: 0.8922\n",
      "Epoch 5/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4658 - acc: 0.6995 - f1: 0.6151 - val_loss: 0.2713 - val_acc: 0.9325 - val_f1: 0.9354\n",
      "Epoch 6/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4485 - acc: 0.7016 - f1: 0.6162 - val_loss: 0.2564 - val_acc: 0.9266 - val_f1: 0.9251\n",
      "Epoch 7/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4474 - acc: 0.7170 - f1: 0.7582 - val_loss: 0.2378 - val_acc: 0.9413 - val_f1: 0.9441\n",
      "Epoch 8/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4422 - acc: 0.7257 - f1: 0.7818 - val_loss: 0.2394 - val_acc: 0.9359 - val_f1: 0.9359\n",
      "Epoch 9/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4318 - acc: 0.7313 - f1: 0.7868 - val_loss: 0.2380 - val_acc: 0.9362 - val_f1: 0.9368\n",
      "Epoch 10/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4315 - acc: 0.7325 - f1: 0.7877 - val_loss: 0.2053 - val_acc: 0.9469 - val_f1: 0.9481\n",
      "Epoch 11/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4235 - acc: 0.7335 - f1: 0.7886 - val_loss: 0.1909 - val_acc: 0.9478 - val_f1: 0.9506\n",
      "Epoch 12/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4229 - acc: 0.7327 - f1: 0.7888 - val_loss: 0.2138 - val_acc: 0.9375 - val_f1: 0.9373\n",
      "Epoch 13/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4310 - acc: 0.7237 - f1: 0.7824 - val_loss: 0.2130 - val_acc: 0.9434 - val_f1: 0.9474\n",
      "Epoch 14/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4252 - acc: 0.7325 - f1: 0.7886 - val_loss: 0.1942 - val_acc: 0.9481 - val_f1: 0.9508\n",
      "Epoch 15/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4227 - acc: 0.7320 - f1: 0.7884 - val_loss: 0.2159 - val_acc: 0.9463 - val_f1: 0.9464\n",
      "Epoch 16/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4234 - acc: 0.7300 - f1: 0.7874 - val_loss: 0.2117 - val_acc: 0.9278 - val_f1: 0.9254\n",
      "Epoch 17/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4217 - acc: 0.7298 - f1: 0.7870 - val_loss: 0.1834 - val_acc: 0.9516 - val_f1: 0.9533\n",
      "Epoch 18/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4222 - acc: 0.7270 - f1: 0.7854 - val_loss: 0.1798 - val_acc: 0.9528 - val_f1: 0.9548\n",
      "Epoch 19/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4129 - acc: 0.7391 - f1: 0.7928 - val_loss: 0.1804 - val_acc: 0.9522 - val_f1: 0.9528\n",
      "Epoch 20/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4176 - acc: 0.7307 - f1: 0.7880 - val_loss: 0.1632 - val_acc: 0.9553 - val_f1: 0.9569\n",
      "Epoch 21/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4153 - acc: 0.7330 - f1: 0.7896 - val_loss: 0.1730 - val_acc: 0.9494 - val_f1: 0.9520\n",
      "Epoch 22/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4155 - acc: 0.7350 - f1: 0.7906 - val_loss: 0.2071 - val_acc: 0.9337 - val_f1: 0.9322\n",
      "Epoch 23/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4193 - acc: 0.7335 - f1: 0.7892 - val_loss: 0.1755 - val_acc: 0.9506 - val_f1: 0.9525\n",
      "Epoch 24/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4141 - acc: 0.7368 - f1: 0.7927 - val_loss: 0.1682 - val_acc: 0.9503 - val_f1: 0.9510\n",
      "Epoch 25/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4122 - acc: 0.7355 - f1: 0.7905 - val_loss: 0.1561 - val_acc: 0.9525 - val_f1: 0.9542\n",
      "Epoch 26/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4137 - acc: 0.7309 - f1: 0.7885 - val_loss: 0.1567 - val_acc: 0.9569 - val_f1: 0.9580\n",
      "Epoch 27/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4147 - acc: 0.7339 - f1: 0.7911 - val_loss: 0.1680 - val_acc: 0.9544 - val_f1: 0.9551\n",
      "Epoch 28/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4083 - acc: 0.7375 - f1: 0.7932 - val_loss: 0.1620 - val_acc: 0.9544 - val_f1: 0.9562\n",
      "Epoch 29/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4111 - acc: 0.7351 - f1: 0.7915 - val_loss: 0.1648 - val_acc: 0.9566 - val_f1: 0.9580\n",
      "Epoch 30/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4148 - acc: 0.7369 - f1: 0.7924 - val_loss: 0.1572 - val_acc: 0.9563 - val_f1: 0.9577\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 36us/sample - loss: 0.6791 - acc: 0.5435 - f1: 0.5851 - val_loss: 0.6254 - val_acc: 0.8259 - val_f1: 0.8365\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5923 - acc: 0.7173 - f1: 0.7109 - val_loss: 0.5351 - val_acc: 0.8628 - val_f1: 0.8569\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5307 - acc: 0.7768 - f1: 0.7586 - val_loss: 0.4271 - val_acc: 0.9053 - val_f1: 0.9116\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4985 - acc: 0.7922 - f1: 0.7702 - val_loss: 0.3911 - val_acc: 0.9078 - val_f1: 0.9135\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4779 - acc: 0.8046 - f1: 0.7820 - val_loss: 0.3639 - val_acc: 0.9316 - val_f1: 0.9348\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4637 - acc: 0.8102 - f1: 0.7879 - val_loss: 0.3501 - val_acc: 0.9409 - val_f1: 0.9420\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4511 - acc: 0.8146 - f1: 0.7917 - val_loss: 0.3378 - val_acc: 0.9431 - val_f1: 0.9441\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4471 - acc: 0.8169 - f1: 0.7955 - val_loss: 0.3270 - val_acc: 0.9422 - val_f1: 0.9428\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4342 - acc: 0.8204 - f1: 0.7989 - val_loss: 0.3581 - val_acc: 0.9109 - val_f1: 0.9073\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4238 - acc: 0.8249 - f1: 0.8042 - val_loss: 0.3014 - val_acc: 0.9463 - val_f1: 0.9468\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4206 - acc: 0.8243 - f1: 0.8022 - val_loss: 0.3258 - val_acc: 0.9269 - val_f1: 0.9251\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4239 - acc: 0.8213 - f1: 0.7989 - val_loss: 0.2911 - val_acc: 0.9456 - val_f1: 0.9463\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4278 - acc: 0.8186 - f1: 0.7946 - val_loss: 0.2794 - val_acc: 0.9506 - val_f1: 0.9520\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4140 - acc: 0.8252 - f1: 0.8044 - val_loss: 0.2766 - val_acc: 0.9491 - val_f1: 0.9517\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4120 - acc: 0.8266 - f1: 0.8058 - val_loss: 0.3027 - val_acc: 0.9322 - val_f1: 0.9304\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4037 - acc: 0.8320 - f1: 0.8121 - val_loss: 0.2758 - val_acc: 0.9456 - val_f1: 0.9457\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4036 - acc: 0.8320 - f1: 0.8120 - val_loss: 0.2561 - val_acc: 0.9547 - val_f1: 0.9552\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4057 - acc: 0.8272 - f1: 0.8056 - val_loss: 0.2518 - val_acc: 0.9547 - val_f1: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3978 - acc: 0.8338 - f1: 0.8147 - val_loss: 0.2567 - val_acc: 0.9519 - val_f1: 0.9532\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4058 - acc: 0.8241 - f1: 0.8023 - val_loss: 0.2704 - val_acc: 0.9378 - val_f1: 0.9363\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3990 - acc: 0.8291 - f1: 0.8078 - val_loss: 0.2408 - val_acc: 0.9569 - val_f1: 0.9584\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4000 - acc: 0.8280 - f1: 0.8068 - val_loss: 0.2412 - val_acc: 0.9544 - val_f1: 0.9552\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3924 - acc: 0.8316 - f1: 0.8107 - val_loss: 0.2397 - val_acc: 0.9544 - val_f1: 0.9554\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4002 - acc: 0.8291 - f1: 0.8078 - val_loss: 0.2452 - val_acc: 0.9513 - val_f1: 0.9507\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3977 - acc: 0.8305 - f1: 0.8093 - val_loss: 0.2909 - val_acc: 0.9147 - val_f1: 0.9100\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3983 - acc: 0.8305 - f1: 0.8099 - val_loss: 0.2298 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3918 - acc: 0.8316 - f1: 0.8116 - val_loss: 0.2383 - val_acc: 0.9500 - val_f1: 0.9502\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4053 - acc: 0.8255 - f1: 0.8027 - val_loss: 0.2258 - val_acc: 0.9575 - val_f1: 0.9581\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3911 - acc: 0.8341 - f1: 0.8138 - val_loss: 0.2366 - val_acc: 0.9478 - val_f1: 0.9481\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4002 - acc: 0.8279 - f1: 0.8064 - val_loss: 0.2527 - val_acc: 0.9384 - val_f1: 0.9377\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3949 - acc: 0.8297 - f1: 0.8086 - val_loss: 0.2302 - val_acc: 0.9541 - val_f1: 0.9542\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3970 - acc: 0.8302 - f1: 0.8089 - val_loss: 0.2194 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4016 - acc: 0.8258 - f1: 0.8027 - val_loss: 0.2378 - val_acc: 0.9500 - val_f1: 0.9503\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3874 - acc: 0.8355 - f1: 0.8162 - val_loss: 0.2209 - val_acc: 0.9569 - val_f1: 0.9587\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3967 - acc: 0.8283 - f1: 0.8067 - val_loss: 0.2354 - val_acc: 0.9500 - val_f1: 0.9502\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3901 - acc: 0.8344 - f1: 0.8147 - val_loss: 0.2615 - val_acc: 0.9312 - val_f1: 0.9300\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3884 - acc: 0.8330 - f1: 0.8123 - val_loss: 0.2177 - val_acc: 0.9594 - val_f1: 0.9602\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3933 - acc: 0.8352 - f1: 0.8158 - val_loss: 0.2136 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3907 - acc: 0.8338 - f1: 0.8137 - val_loss: 0.2174 - val_acc: 0.9578 - val_f1: 0.9595\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3867 - acc: 0.8353 - f1: 0.8154 - val_loss: 0.2335 - val_acc: 0.9491 - val_f1: 0.9483\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3872 - acc: 0.8354 - f1: 0.8160 - val_loss: 0.2133 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3900 - acc: 0.8340 - f1: 0.8142 - val_loss: 0.2182 - val_acc: 0.9578 - val_f1: 0.9594\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3888 - acc: 0.8341 - f1: 0.8137 - val_loss: 0.2131 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3847 - acc: 0.8383 - f1: 0.8192 - val_loss: 0.2222 - val_acc: 0.9575 - val_f1: 0.9582\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3848 - acc: 0.8363 - f1: 0.8161 - val_loss: 0.2175 - val_acc: 0.9566 - val_f1: 0.9569\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3890 - acc: 0.8338 - f1: 0.8141 - val_loss: 0.2103 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3914 - acc: 0.8329 - f1: 0.8125 - val_loss: 0.2128 - val_acc: 0.9609 - val_f1: 0.9616\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3773 - acc: 0.8409 - f1: 0.8233 - val_loss: 0.2119 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3856 - acc: 0.8354 - f1: 0.8152 - val_loss: 0.2095 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3837 - acc: 0.8377 - f1: 0.8170 - val_loss: 0.2298 - val_acc: 0.9475 - val_f1: 0.9479\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3823 - acc: 0.8381 - f1: 0.8185 - val_loss: 0.2094 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3802 - acc: 0.8409 - f1: 0.8236 - val_loss: 0.2090 - val_acc: 0.9591 - val_f1: 0.9598\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3882 - acc: 0.8341 - f1: 0.8134 - val_loss: 0.2727 - val_acc: 0.9244 - val_f1: 0.9221\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3870 - acc: 0.8355 - f1: 0.8152 - val_loss: 0.2119 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3820 - acc: 0.8387 - f1: 0.8201 - val_loss: 0.2115 - val_acc: 0.9606 - val_f1: 0.9612\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3791 - acc: 0.8398 - f1: 0.8214 - val_loss: 0.2079 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3769 - acc: 0.8408 - f1: 0.8219 - val_loss: 0.2156 - val_acc: 0.9575 - val_f1: 0.9580\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3901 - acc: 0.8340 - f1: 0.8138 - val_loss: 0.2057 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3846 - acc: 0.8366 - f1: 0.8163 - val_loss: 0.2338 - val_acc: 0.9472 - val_f1: 0.9471\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3884 - acc: 0.8312 - f1: 0.8100 - val_loss: 0.2197 - val_acc: 0.9559 - val_f1: 0.9558\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/5000\n",
      "12800/12800 [==============================] - 0s 38us/sample - loss: 0.6835 - acc: 0.5594 - f1: 0.6350 - val_loss: 0.6208 - val_acc: 0.7309 - val_f1: 0.7025\n",
      "Epoch 2/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5963 - acc: 0.7306 - f1: 0.7546 - val_loss: 0.5075 - val_acc: 0.8872 - val_f1: 0.8950\n",
      "Epoch 3/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5336 - acc: 0.7848 - f1: 0.8129 - val_loss: 0.4412 - val_acc: 0.9041 - val_f1: 0.9100\n",
      "Epoch 4/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5098 - acc: 0.8003 - f1: 0.8279 - val_loss: 0.4109 - val_acc: 0.9131 - val_f1: 0.9173\n",
      "Epoch 5/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4841 - acc: 0.8131 - f1: 0.8399 - val_loss: 0.3830 - val_acc: 0.9241 - val_f1: 0.9286\n",
      "Epoch 6/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4714 - acc: 0.8163 - f1: 0.8430 - val_loss: 0.3656 - val_acc: 0.9225 - val_f1: 0.9233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4668 - acc: 0.8155 - f1: 0.8425 - val_loss: 0.3501 - val_acc: 0.9362 - val_f1: 0.9390\n",
      "Epoch 8/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4544 - acc: 0.8248 - f1: 0.8497 - val_loss: 0.3380 - val_acc: 0.9344 - val_f1: 0.9373\n",
      "Epoch 9/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4514 - acc: 0.8207 - f1: 0.8469 - val_loss: 0.3306 - val_acc: 0.9362 - val_f1: 0.9384\n",
      "Epoch 10/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4338 - acc: 0.8320 - f1: 0.8548 - val_loss: 0.3279 - val_acc: 0.9375 - val_f1: 0.9416\n",
      "Epoch 11/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4344 - acc: 0.8300 - f1: 0.8540 - val_loss: 0.3064 - val_acc: 0.9394 - val_f1: 0.9415\n",
      "Epoch 12/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4189 - acc: 0.8359 - f1: 0.8589 - val_loss: 0.3015 - val_acc: 0.9431 - val_f1: 0.9448\n",
      "Epoch 13/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4269 - acc: 0.8279 - f1: 0.8521 - val_loss: 0.3102 - val_acc: 0.9291 - val_f1: 0.9288\n",
      "Epoch 14/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4287 - acc: 0.8257 - f1: 0.8512 - val_loss: 0.2927 - val_acc: 0.9428 - val_f1: 0.9459\n",
      "Epoch 15/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4065 - acc: 0.8405 - f1: 0.8624 - val_loss: 0.2777 - val_acc: 0.9441 - val_f1: 0.9444\n",
      "Epoch 16/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4081 - acc: 0.8370 - f1: 0.8595 - val_loss: 0.2820 - val_acc: 0.9406 - val_f1: 0.9435\n",
      "Epoch 17/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4008 - acc: 0.8424 - f1: 0.8638 - val_loss: 0.2645 - val_acc: 0.9459 - val_f1: 0.9479\n",
      "Epoch 18/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4027 - acc: 0.8384 - f1: 0.8603 - val_loss: 0.2598 - val_acc: 0.9475 - val_f1: 0.9500\n",
      "Epoch 19/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4028 - acc: 0.8377 - f1: 0.8603 - val_loss: 0.2855 - val_acc: 0.9325 - val_f1: 0.9381\n",
      "Epoch 20/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3999 - acc: 0.8370 - f1: 0.8597 - val_loss: 0.2550 - val_acc: 0.9475 - val_f1: 0.9478\n",
      "Epoch 21/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4015 - acc: 0.8375 - f1: 0.8600 - val_loss: 0.2568 - val_acc: 0.9484 - val_f1: 0.9514\n",
      "Epoch 22/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3898 - acc: 0.8420 - f1: 0.8640 - val_loss: 0.2615 - val_acc: 0.9419 - val_f1: 0.9451\n",
      "Epoch 23/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3966 - acc: 0.8360 - f1: 0.8595 - val_loss: 0.2412 - val_acc: 0.9478 - val_f1: 0.9503\n",
      "Epoch 24/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4031 - acc: 0.8305 - f1: 0.8545 - val_loss: 0.2500 - val_acc: 0.9428 - val_f1: 0.9464\n",
      "Epoch 25/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4024 - acc: 0.8327 - f1: 0.8567 - val_loss: 0.2534 - val_acc: 0.9419 - val_f1: 0.9458\n",
      "Epoch 26/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3964 - acc: 0.8367 - f1: 0.8594 - val_loss: 0.2767 - val_acc: 0.9278 - val_f1: 0.9334\n",
      "Epoch 27/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3912 - acc: 0.8438 - f1: 0.8650 - val_loss: 0.2322 - val_acc: 0.9519 - val_f1: 0.9540\n",
      "Epoch 28/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3881 - acc: 0.8403 - f1: 0.8621 - val_loss: 0.2369 - val_acc: 0.9466 - val_f1: 0.9498\n",
      "Epoch 29/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3850 - acc: 0.8440 - f1: 0.8651 - val_loss: 0.2572 - val_acc: 0.9334 - val_f1: 0.9378\n",
      "Epoch 30/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3921 - acc: 0.8379 - f1: 0.8611 - val_loss: 0.2391 - val_acc: 0.9441 - val_f1: 0.9479\n",
      "Epoch 31/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3852 - acc: 0.8439 - f1: 0.8658 - val_loss: 0.2189 - val_acc: 0.9550 - val_f1: 0.9565\n",
      "Epoch 32/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3852 - acc: 0.8423 - f1: 0.8642 - val_loss: 0.2204 - val_acc: 0.9556 - val_f1: 0.9572\n",
      "Epoch 33/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3903 - acc: 0.8408 - f1: 0.8633 - val_loss: 0.2392 - val_acc: 0.9419 - val_f1: 0.9458\n",
      "Epoch 34/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3884 - acc: 0.8405 - f1: 0.8620 - val_loss: 0.2345 - val_acc: 0.9406 - val_f1: 0.9450\n",
      "Epoch 35/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3832 - acc: 0.8410 - f1: 0.8629 - val_loss: 0.2208 - val_acc: 0.9506 - val_f1: 0.9528\n",
      "Epoch 36/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3858 - acc: 0.8405 - f1: 0.8632 - val_loss: 0.2138 - val_acc: 0.9547 - val_f1: 0.9560\n",
      "Epoch 37/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3859 - acc: 0.8427 - f1: 0.8649 - val_loss: 0.2200 - val_acc: 0.9544 - val_f1: 0.9562\n",
      "Epoch 38/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3839 - acc: 0.8440 - f1: 0.8654 - val_loss: 0.2147 - val_acc: 0.9547 - val_f1: 0.9571\n",
      "Epoch 39/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3835 - acc: 0.8424 - f1: 0.8644 - val_loss: 0.2118 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 40/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8449 - f1: 0.8667 - val_loss: 0.2181 - val_acc: 0.9528 - val_f1: 0.9561\n",
      "Epoch 41/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3799 - acc: 0.8448 - f1: 0.8660 - val_loss: 0.2280 - val_acc: 0.9434 - val_f1: 0.9475\n",
      "Epoch 42/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3784 - acc: 0.8462 - f1: 0.8675 - val_loss: 0.2160 - val_acc: 0.9538 - val_f1: 0.9569\n",
      "Epoch 43/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3821 - acc: 0.8427 - f1: 0.8645 - val_loss: 0.2072 - val_acc: 0.9563 - val_f1: 0.9569\n",
      "Epoch 44/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3831 - acc: 0.8432 - f1: 0.8649 - val_loss: 0.2121 - val_acc: 0.9575 - val_f1: 0.9596\n",
      "Epoch 45/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8478 - f1: 0.8685 - val_loss: 0.2090 - val_acc: 0.9553 - val_f1: 0.9565\n",
      "Epoch 46/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3796 - acc: 0.8456 - f1: 0.8673 - val_loss: 0.2067 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 47/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3761 - acc: 0.8456 - f1: 0.8667 - val_loss: 0.2039 - val_acc: 0.9597 - val_f1: 0.9611\n",
      "Epoch 48/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3685 - acc: 0.8514 - f1: 0.8714 - val_loss: 0.2046 - val_acc: 0.9581 - val_f1: 0.9587\n",
      "Epoch 49/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8457 - f1: 0.8673 - val_loss: 0.2266 - val_acc: 0.9425 - val_f1: 0.9463\n",
      "Epoch 50/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3827 - acc: 0.8429 - f1: 0.8654 - val_loss: 0.2062 - val_acc: 0.9578 - val_f1: 0.9593\n",
      "Epoch 51/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3834 - acc: 0.8434 - f1: 0.8651 - val_loss: 0.2125 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 52/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3816 - acc: 0.8441 - f1: 0.8651 - val_loss: 0.2121 - val_acc: 0.9516 - val_f1: 0.9519\n",
      "Epoch 53/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3807 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2320 - val_acc: 0.9375 - val_f1: 0.9422\n",
      "Epoch 54/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8441 - f1: 0.8658 - val_loss: 0.2118 - val_acc: 0.9559 - val_f1: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3771 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2483 - val_acc: 0.9353 - val_f1: 0.9407\n",
      "Epoch 56/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3681 - acc: 0.8505 - f1: 0.8710 - val_loss: 0.2095 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 57/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3770 - acc: 0.8467 - f1: 0.8675 - val_loss: 0.2199 - val_acc: 0.9472 - val_f1: 0.9505\n",
      "Epoch 58/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3778 - acc: 0.8461 - f1: 0.8675 - val_loss: 0.2065 - val_acc: 0.9578 - val_f1: 0.9591\n",
      "Epoch 59/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3802 - acc: 0.8440 - f1: 0.8660 - val_loss: 0.2077 - val_acc: 0.9572 - val_f1: 0.9580\n",
      "Epoch 60/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3676 - acc: 0.8542 - f1: 0.8736 - val_loss: 0.2079 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 61/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3691 - acc: 0.8511 - f1: 0.8715 - val_loss: 0.2110 - val_acc: 0.9519 - val_f1: 0.9547\n",
      "Epoch 62/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3770 - acc: 0.8462 - f1: 0.8675 - val_loss: 0.1991 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 63/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3714 - acc: 0.8503 - f1: 0.8708 - val_loss: 0.2180 - val_acc: 0.9478 - val_f1: 0.9512\n",
      "Epoch 64/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3711 - acc: 0.8489 - f1: 0.8699 - val_loss: 0.2142 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 65/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3700 - acc: 0.8496 - f1: 0.8703 - val_loss: 0.2031 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 66/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3750 - acc: 0.8486 - f1: 0.8692 - val_loss: 0.2080 - val_acc: 0.9547 - val_f1: 0.9557\n",
      "Epoch 67/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3716 - acc: 0.8504 - f1: 0.8711 - val_loss: 0.2561 - val_acc: 0.9256 - val_f1: 0.9322\n",
      "Epoch 68/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3728 - acc: 0.8482 - f1: 0.8685 - val_loss: 0.1979 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 69/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3835 - acc: 0.8427 - f1: 0.8648 - val_loss: 0.2036 - val_acc: 0.9559 - val_f1: 0.9570\n",
      "Epoch 70/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8477 - f1: 0.8688 - val_loss: 0.2008 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 71/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3779 - acc: 0.8450 - f1: 0.8662 - val_loss: 0.2050 - val_acc: 0.9563 - val_f1: 0.9571\n",
      "Epoch 72/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3714 - acc: 0.8493 - f1: 0.8699 - val_loss: 0.2074 - val_acc: 0.9550 - val_f1: 0.9566\n",
      "Epoch 73/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3697 - acc: 0.8498 - f1: 0.8705 - val_loss: 0.2015 - val_acc: 0.9591 - val_f1: 0.9596\n",
      "Epoch 74/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3708 - acc: 0.8498 - f1: 0.8707 - val_loss: 0.2119 - val_acc: 0.9528 - val_f1: 0.9556\n",
      "Epoch 75/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3736 - acc: 0.8484 - f1: 0.8685 - val_loss: 0.2417 - val_acc: 0.9381 - val_f1: 0.9426\n",
      "Epoch 76/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3757 - acc: 0.8474 - f1: 0.8684 - val_loss: 0.2050 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 77/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8495 - f1: 0.8700 - val_loss: 0.2006 - val_acc: 0.9594 - val_f1: 0.9603\n",
      "Epoch 78/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3713 - acc: 0.8491 - f1: 0.8698 - val_loss: 0.2217 - val_acc: 0.9438 - val_f1: 0.9478\n",
      "Epoch 79/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8501 - f1: 0.8705 - val_loss: 0.2002 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 80/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3792 - acc: 0.8461 - f1: 0.8676 - val_loss: 0.1979 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 81/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2029 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 82/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3735 - acc: 0.8496 - f1: 0.8701 - val_loss: 0.1990 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 83/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3739 - acc: 0.8474 - f1: 0.8682 - val_loss: 0.1985 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 84/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3740 - acc: 0.8470 - f1: 0.8684 - val_loss: 0.2028 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 85/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3697 - acc: 0.8491 - f1: 0.8701 - val_loss: 0.2159 - val_acc: 0.9500 - val_f1: 0.9530\n",
      "Epoch 86/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3712 - acc: 0.8503 - f1: 0.8706 - val_loss: 0.1968 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 87/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8502 - f1: 0.8707 - val_loss: 0.2014 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 88/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8552 - f1: 0.8746 - val_loss: 0.2195 - val_acc: 0.9478 - val_f1: 0.9512\n",
      "Epoch 89/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3575 - acc: 0.8567 - f1: 0.8762 - val_loss: 0.2225 - val_acc: 0.9469 - val_f1: 0.9503\n",
      "Epoch 90/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8514 - f1: 0.8717 - val_loss: 0.1978 - val_acc: 0.9588 - val_f1: 0.9613\n",
      "Epoch 91/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3672 - acc: 0.8509 - f1: 0.8716 - val_loss: 0.2056 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 92/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8534 - f1: 0.8726 - val_loss: 0.1968 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 93/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3643 - acc: 0.8520 - f1: 0.8718 - val_loss: 0.2083 - val_acc: 0.9525 - val_f1: 0.9554\n",
      "Epoch 94/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3751 - acc: 0.8478 - f1: 0.8686 - val_loss: 0.1975 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 95/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3693 - acc: 0.8513 - f1: 0.8722 - val_loss: 0.2022 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 96/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8499 - f1: 0.8703 - val_loss: 0.2025 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 97/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8544 - f1: 0.8743 - val_loss: 0.2397 - val_acc: 0.9334 - val_f1: 0.9393\n",
      "Epoch 98/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8527 - f1: 0.8728 - val_loss: 0.1953 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 99/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3703 - acc: 0.8497 - f1: 0.8706 - val_loss: 0.1972 - val_acc: 0.9584 - val_f1: 0.9600\n",
      "Epoch 100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3619 - acc: 0.8563 - f1: 0.8756 - val_loss: 0.1963 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3673 - acc: 0.8509 - f1: 0.8714 - val_loss: 0.2137 - val_acc: 0.9503 - val_f1: 0.9534\n",
      "Epoch 102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3758 - acc: 0.8463 - f1: 0.8676 - val_loss: 0.1952 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8527 - f1: 0.8727 - val_loss: 0.1943 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3718 - acc: 0.8477 - f1: 0.8685 - val_loss: 0.2003 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3661 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.2049 - val_acc: 0.9538 - val_f1: 0.9570\n",
      "Epoch 106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3646 - acc: 0.8513 - f1: 0.8720 - val_loss: 0.1983 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3662 - acc: 0.8521 - f1: 0.8720 - val_loss: 0.2004 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3624 - acc: 0.8541 - f1: 0.8734 - val_loss: 0.1929 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3594 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.1985 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3639 - acc: 0.8538 - f1: 0.8742 - val_loss: 0.1937 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3641 - acc: 0.8545 - f1: 0.8744 - val_loss: 0.2114 - val_acc: 0.9500 - val_f1: 0.9531\n",
      "Epoch 112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3591 - acc: 0.8543 - f1: 0.8747 - val_loss: 0.2183 - val_acc: 0.9469 - val_f1: 0.9506\n",
      "Epoch 113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8542 - f1: 0.8740 - val_loss: 0.1992 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3621 - acc: 0.8542 - f1: 0.8745 - val_loss: 0.2116 - val_acc: 0.9488 - val_f1: 0.9522\n",
      "Epoch 115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8505 - f1: 0.8710 - val_loss: 0.2225 - val_acc: 0.9453 - val_f1: 0.9491\n",
      "Epoch 116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3693 - acc: 0.8490 - f1: 0.8706 - val_loss: 0.1971 - val_acc: 0.9597 - val_f1: 0.9604\n",
      "Epoch 117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3667 - acc: 0.8507 - f1: 0.8712 - val_loss: 0.1958 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.1960 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8535 - f1: 0.8730 - val_loss: 0.2118 - val_acc: 0.9559 - val_f1: 0.9569\n",
      "Epoch 120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3745 - acc: 0.8462 - f1: 0.8678 - val_loss: 0.1980 - val_acc: 0.9563 - val_f1: 0.9589\n",
      "Epoch 121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3638 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.1983 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3672 - acc: 0.8495 - f1: 0.8705 - val_loss: 0.1966 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3622 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.1973 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3648 - acc: 0.8512 - f1: 0.8716 - val_loss: 0.1955 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3628 - acc: 0.8532 - f1: 0.8735 - val_loss: 0.1951 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8547 - f1: 0.8744 - val_loss: 0.1976 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3611 - acc: 0.8525 - f1: 0.8726 - val_loss: 0.1935 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3570 - acc: 0.8546 - f1: 0.8744 - val_loss: 0.1922 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8552 - f1: 0.8754 - val_loss: 0.1982 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3558 - acc: 0.8555 - f1: 0.8753 - val_loss: 0.1979 - val_acc: 0.9594 - val_f1: 0.9604\n",
      "Epoch 131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3642 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.1940 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3665 - acc: 0.8494 - f1: 0.8697 - val_loss: 0.2251 - val_acc: 0.9409 - val_f1: 0.9444\n",
      "Epoch 133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3652 - acc: 0.8540 - f1: 0.8743 - val_loss: 0.1999 - val_acc: 0.9603 - val_f1: 0.9613\n",
      "Epoch 134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3640 - acc: 0.8530 - f1: 0.8734 - val_loss: 0.1994 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8530 - f1: 0.8734 - val_loss: 0.1930 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3702 - acc: 0.8469 - f1: 0.8680 - val_loss: 0.1974 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3505 - acc: 0.8609 - f1: 0.8794 - val_loss: 0.1999 - val_acc: 0.9569 - val_f1: 0.9587\n",
      "Epoch 138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3649 - acc: 0.8527 - f1: 0.8730 - val_loss: 0.2098 - val_acc: 0.9550 - val_f1: 0.9569\n",
      "Epoch 139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8498 - f1: 0.8712 - val_loss: 0.2051 - val_acc: 0.9538 - val_f1: 0.9562\n",
      "Epoch 140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3569 - acc: 0.8550 - f1: 0.8744 - val_loss: 0.1949 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8502 - f1: 0.8710 - val_loss: 0.1959 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3707 - acc: 0.8484 - f1: 0.8699 - val_loss: 0.2571 - val_acc: 0.9272 - val_f1: 0.9333\n",
      "Epoch 143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3682 - acc: 0.8493 - f1: 0.8701 - val_loss: 0.1935 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8538 - f1: 0.8737 - val_loss: 0.1959 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8579 - f1: 0.8764 - val_loss: 0.1991 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8541 - f1: 0.8743 - val_loss: 0.2022 - val_acc: 0.9606 - val_f1: 0.9614\n",
      "Epoch 147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.2013 - val_acc: 0.9597 - val_f1: 0.9608\n",
      "Epoch 148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3720 - acc: 0.8488 - f1: 0.8699 - val_loss: 0.1927 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 149/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3609 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.2022 - val_acc: 0.9547 - val_f1: 0.9576\n",
      "Epoch 150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3676 - acc: 0.8499 - f1: 0.8709 - val_loss: 0.2003 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3573 - acc: 0.8559 - f1: 0.8760 - val_loss: 0.2017 - val_acc: 0.9547 - val_f1: 0.9566\n",
      "Epoch 152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8558 - f1: 0.8748 - val_loss: 0.1992 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.1945 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8530 - f1: 0.8730 - val_loss: 0.1915 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8590 - f1: 0.8779 - val_loss: 0.1992 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3662 - acc: 0.8524 - f1: 0.8729 - val_loss: 0.1997 - val_acc: 0.9566 - val_f1: 0.9592\n",
      "Epoch 157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3621 - acc: 0.8545 - f1: 0.8742 - val_loss: 0.1962 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3625 - acc: 0.8527 - f1: 0.8726 - val_loss: 0.2021 - val_acc: 0.9553 - val_f1: 0.9574\n",
      "Epoch 159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3644 - acc: 0.8524 - f1: 0.8728 - val_loss: 0.1991 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3553 - acc: 0.8591 - f1: 0.8778 - val_loss: 0.1984 - val_acc: 0.9606 - val_f1: 0.9632\n",
      "Epoch 161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3595 - acc: 0.8549 - f1: 0.8751 - val_loss: 0.2330 - val_acc: 0.9397 - val_f1: 0.9442\n",
      "Epoch 162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8496 - f1: 0.8709 - val_loss: 0.2145 - val_acc: 0.9494 - val_f1: 0.9528\n",
      "Epoch 163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8555 - f1: 0.8752 - val_loss: 0.2330 - val_acc: 0.9384 - val_f1: 0.9432\n",
      "Epoch 164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8578 - f1: 0.8761 - val_loss: 0.1979 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8580 - f1: 0.8769 - val_loss: 0.2038 - val_acc: 0.9547 - val_f1: 0.9574\n",
      "Epoch 166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8517 - f1: 0.8722 - val_loss: 0.1938 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3630 - acc: 0.8534 - f1: 0.8740 - val_loss: 0.1958 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8621 - f1: 0.8807 - val_loss: 0.1950 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8571 - f1: 0.8763 - val_loss: 0.1922 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3544 - acc: 0.8575 - f1: 0.8771 - val_loss: 0.2037 - val_acc: 0.9553 - val_f1: 0.9582\n",
      "Epoch 171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8520 - f1: 0.8725 - val_loss: 0.2044 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8516 - f1: 0.8724 - val_loss: 0.2051 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3626 - acc: 0.8536 - f1: 0.8737 - val_loss: 0.1951 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3596 - acc: 0.8548 - f1: 0.8745 - val_loss: 0.1927 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3607 - acc: 0.8545 - f1: 0.8742 - val_loss: 0.2081 - val_acc: 0.9538 - val_f1: 0.9567\n",
      "Epoch 176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3625 - acc: 0.8538 - f1: 0.8739 - val_loss: 0.2036 - val_acc: 0.9556 - val_f1: 0.9583\n",
      "Epoch 177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8578 - f1: 0.8769 - val_loss: 0.1955 - val_acc: 0.9603 - val_f1: 0.9628\n",
      "Epoch 178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3503 - acc: 0.8606 - f1: 0.8793 - val_loss: 0.1928 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.2012 - val_acc: 0.9559 - val_f1: 0.9586\n",
      "Epoch 180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8573 - f1: 0.8766 - val_loss: 0.1942 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8590 - f1: 0.8778 - val_loss: 0.1939 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8553 - f1: 0.8754 - val_loss: 0.1939 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3623 - acc: 0.8529 - f1: 0.8732 - val_loss: 0.1945 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3602 - acc: 0.8534 - f1: 0.8737 - val_loss: 0.2036 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3577 - acc: 0.8554 - f1: 0.8746 - val_loss: 0.2154 - val_acc: 0.9491 - val_f1: 0.9526\n",
      "Epoch 186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3609 - acc: 0.8516 - f1: 0.8725 - val_loss: 0.2007 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8601 - f1: 0.8790 - val_loss: 0.1953 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3605 - acc: 0.8537 - f1: 0.8738 - val_loss: 0.1936 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8535 - f1: 0.8735 - val_loss: 0.2287 - val_acc: 0.9422 - val_f1: 0.9462\n",
      "Epoch 190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3623 - acc: 0.8521 - f1: 0.8727 - val_loss: 0.2022 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3554 - acc: 0.8567 - f1: 0.8760 - val_loss: 0.1915 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3604 - acc: 0.8534 - f1: 0.8734 - val_loss: 0.1974 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8527 - f1: 0.8727 - val_loss: 0.1956 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3618 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.1956 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3535 - acc: 0.8591 - f1: 0.8782 - val_loss: 0.2101 - val_acc: 0.9575 - val_f1: 0.9589\n",
      "Epoch 196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8582 - f1: 0.8775 - val_loss: 0.1949 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3539 - acc: 0.8577 - f1: 0.8771 - val_loss: 0.1946 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8539 - f1: 0.8741 - val_loss: 0.1964 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.1910 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8600 - f1: 0.8791 - val_loss: 0.2062 - val_acc: 0.9522 - val_f1: 0.9548\n",
      "Epoch 201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3563 - acc: 0.8564 - f1: 0.8757 - val_loss: 0.1924 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3602 - acc: 0.8542 - f1: 0.8746 - val_loss: 0.2406 - val_acc: 0.9325 - val_f1: 0.9383\n",
      "Epoch 203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3603 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.1977 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3654 - acc: 0.8520 - f1: 0.8723 - val_loss: 0.1998 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8550 - f1: 0.8751 - val_loss: 0.1920 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3627 - acc: 0.8525 - f1: 0.8733 - val_loss: 0.1943 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3510 - acc: 0.8585 - f1: 0.8777 - val_loss: 0.2053 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3605 - acc: 0.8559 - f1: 0.8757 - val_loss: 0.1954 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3618 - acc: 0.8539 - f1: 0.8739 - val_loss: 0.1951 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8596 - f1: 0.8787 - val_loss: 0.2144 - val_acc: 0.9491 - val_f1: 0.9521\n",
      "Epoch 211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8549 - f1: 0.8750 - val_loss: 0.2054 - val_acc: 0.9547 - val_f1: 0.9575\n",
      "Epoch 212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3584 - acc: 0.8552 - f1: 0.8751 - val_loss: 0.1978 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3548 - acc: 0.8568 - f1: 0.8767 - val_loss: 0.1965 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8562 - f1: 0.8757 - val_loss: 0.1974 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.1924 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8567 - f1: 0.8764 - val_loss: 0.2011 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3707 - acc: 0.8487 - f1: 0.8703 - val_loss: 0.1957 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8585 - f1: 0.8778 - val_loss: 0.1933 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8570 - f1: 0.8764 - val_loss: 0.1959 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3514 - acc: 0.8596 - f1: 0.8785 - val_loss: 0.1953 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8516 - f1: 0.8724 - val_loss: 0.1948 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3528 - acc: 0.8600 - f1: 0.8788 - val_loss: 0.1910 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8520 - f1: 0.8729 - val_loss: 0.1951 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8564 - f1: 0.8762 - val_loss: 0.2045 - val_acc: 0.9566 - val_f1: 0.9591\n",
      "Epoch 225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8567 - f1: 0.8764 - val_loss: 0.2000 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3668 - acc: 0.8510 - f1: 0.8716 - val_loss: 0.2015 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3545 - acc: 0.8573 - f1: 0.8768 - val_loss: 0.2254 - val_acc: 0.9478 - val_f1: 0.9518\n",
      "Epoch 228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8581 - f1: 0.8777 - val_loss: 0.2003 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3573 - acc: 0.8545 - f1: 0.8750 - val_loss: 0.2016 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8585 - f1: 0.8773 - val_loss: 0.1982 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8577 - f1: 0.8770 - val_loss: 0.1937 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8542 - f1: 0.8748 - val_loss: 0.2024 - val_acc: 0.9581 - val_f1: 0.9596\n",
      "Epoch 233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3546 - acc: 0.8566 - f1: 0.8764 - val_loss: 0.2035 - val_acc: 0.9588 - val_f1: 0.9611\n",
      "Epoch 234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3689 - acc: 0.8502 - f1: 0.8715 - val_loss: 0.2398 - val_acc: 0.9316 - val_f1: 0.9373\n",
      "Epoch 235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3633 - acc: 0.8537 - f1: 0.8737 - val_loss: 0.2044 - val_acc: 0.9550 - val_f1: 0.9574\n",
      "Epoch 236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3525 - acc: 0.8573 - f1: 0.8768 - val_loss: 0.1930 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.2093 - val_acc: 0.9531 - val_f1: 0.9564\n",
      "Epoch 238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8616 - f1: 0.8797 - val_loss: 0.2008 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8517 - f1: 0.8725 - val_loss: 0.1983 - val_acc: 0.9591 - val_f1: 0.9609\n",
      "Epoch 240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3574 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.1966 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8563 - f1: 0.8762 - val_loss: 0.2380 - val_acc: 0.9350 - val_f1: 0.9406\n",
      "Epoch 242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8591 - f1: 0.8780 - val_loss: 0.2096 - val_acc: 0.9522 - val_f1: 0.9550\n",
      "Epoch 243/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3627 - acc: 0.8514 - f1: 0.8723 - val_loss: 0.2042 - val_acc: 0.9563 - val_f1: 0.9589\n",
      "Epoch 244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1992 - val_acc: 0.9613 - val_f1: 0.9639\n",
      "Epoch 245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2264 - val_acc: 0.9422 - val_f1: 0.9460\n",
      "Epoch 246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8594 - f1: 0.8785 - val_loss: 0.1938 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3482 - acc: 0.8616 - f1: 0.8795 - val_loss: 0.1965 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3535 - acc: 0.8582 - f1: 0.8774 - val_loss: 0.2144 - val_acc: 0.9450 - val_f1: 0.9491\n",
      "Epoch 249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8568 - f1: 0.8766 - val_loss: 0.1967 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3599 - acc: 0.8545 - f1: 0.8749 - val_loss: 0.2032 - val_acc: 0.9594 - val_f1: 0.9592\n",
      "Epoch 251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8609 - f1: 0.8795 - val_loss: 0.1893 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8608 - f1: 0.8795 - val_loss: 0.1913 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3559 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.1871 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.1932 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8571 - f1: 0.8766 - val_loss: 0.2118 - val_acc: 0.9506 - val_f1: 0.9543\n",
      "Epoch 256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8514 - f1: 0.8722 - val_loss: 0.1922 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8586 - f1: 0.8780 - val_loss: 0.1966 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8547 - f1: 0.8745 - val_loss: 0.2010 - val_acc: 0.9597 - val_f1: 0.9604\n",
      "Epoch 259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8601 - f1: 0.8786 - val_loss: 0.2023 - val_acc: 0.9550 - val_f1: 0.9580\n",
      "Epoch 260/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3583 - acc: 0.8548 - f1: 0.8748 - val_loss: 0.1953 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8562 - f1: 0.8756 - val_loss: 0.1912 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3574 - acc: 0.8546 - f1: 0.8746 - val_loss: 0.2043 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3561 - acc: 0.8571 - f1: 0.8769 - val_loss: 0.1948 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8560 - f1: 0.8755 - val_loss: 0.1990 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 265/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3541 - acc: 0.8577 - f1: 0.8768 - val_loss: 0.2037 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8535 - f1: 0.8744 - val_loss: 0.2014 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3590 - acc: 0.8553 - f1: 0.8753 - val_loss: 0.1965 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3606 - acc: 0.8530 - f1: 0.8729 - val_loss: 0.1957 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8557 - f1: 0.8758 - val_loss: 0.2070 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8602 - f1: 0.8788 - val_loss: 0.1975 - val_acc: 0.9638 - val_f1: 0.9661\n",
      "Epoch 271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8574 - f1: 0.8768 - val_loss: 0.2003 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8584 - f1: 0.8773 - val_loss: 0.1966 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8562 - f1: 0.8764 - val_loss: 0.2154 - val_acc: 0.9584 - val_f1: 0.9597\n",
      "Epoch 274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8531 - f1: 0.8733 - val_loss: 0.2032 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8518 - f1: 0.8724 - val_loss: 0.1956 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 276/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3578 - acc: 0.8552 - f1: 0.8755 - val_loss: 0.1942 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 277/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3485 - acc: 0.8608 - f1: 0.8794 - val_loss: 0.2089 - val_acc: 0.9528 - val_f1: 0.9559\n",
      "Epoch 278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8573 - f1: 0.8766 - val_loss: 0.1949 - val_acc: 0.9653 - val_f1: 0.9675\n",
      "Epoch 279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.1919 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 280/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3513 - acc: 0.8593 - f1: 0.8784 - val_loss: 0.1941 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8570 - f1: 0.8769 - val_loss: 0.2006 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 282/5000\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3470 - acc: 0.8625 - f1: 0.8807 - val_loss: 0.1956 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8582 - f1: 0.8768 - val_loss: 0.1939 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3612 - acc: 0.8527 - f1: 0.8737 - val_loss: 0.1926 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3590 - acc: 0.8537 - f1: 0.8740 - val_loss: 0.2080 - val_acc: 0.9519 - val_f1: 0.9554\n",
      "Epoch 286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8570 - f1: 0.8764 - val_loss: 0.1975 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8573 - f1: 0.8764 - val_loss: 0.1975 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8573 - f1: 0.8765 - val_loss: 0.2046 - val_acc: 0.9588 - val_f1: 0.9617\n",
      "Epoch 289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8600 - f1: 0.8792 - val_loss: 0.1953 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.1988 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8602 - f1: 0.8789 - val_loss: 0.1943 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3570 - acc: 0.8546 - f1: 0.8742 - val_loss: 0.2023 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8517 - f1: 0.8725 - val_loss: 0.1973 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8577 - f1: 0.8774 - val_loss: 0.2019 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8615 - f1: 0.8802 - val_loss: 0.1970 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8620 - f1: 0.8803 - val_loss: 0.1956 - val_acc: 0.9666 - val_f1: 0.9683\n",
      "Epoch 297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.2058 - val_acc: 0.9522 - val_f1: 0.9548\n",
      "Epoch 298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3568 - acc: 0.8562 - f1: 0.8761 - val_loss: 0.1998 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8615 - f1: 0.8801 - val_loss: 0.1975 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.2118 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2068 - val_acc: 0.9606 - val_f1: 0.9610\n",
      "Epoch 302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1991 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3553 - acc: 0.8582 - f1: 0.8780 - val_loss: 0.1916 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3557 - acc: 0.8569 - f1: 0.8761 - val_loss: 0.1981 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8556 - f1: 0.8757 - val_loss: 0.2030 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8594 - f1: 0.8789 - val_loss: 0.1954 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8610 - f1: 0.8797 - val_loss: 0.1979 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8614 - f1: 0.8800 - val_loss: 0.2108 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8589 - f1: 0.8780 - val_loss: 0.1973 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8586 - f1: 0.8778 - val_loss: 0.1992 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8609 - f1: 0.8796 - val_loss: 0.2013 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8599 - f1: 0.8790 - val_loss: 0.2078 - val_acc: 0.9541 - val_f1: 0.9572\n",
      "Epoch 313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3481 - acc: 0.8615 - f1: 0.8802 - val_loss: 0.1964 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8555 - f1: 0.8754 - val_loss: 0.2027 - val_acc: 0.9603 - val_f1: 0.9611\n",
      "Epoch 315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8559 - f1: 0.8751 - val_loss: 0.2140 - val_acc: 0.9497 - val_f1: 0.9532\n",
      "Epoch 316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3582 - acc: 0.8545 - f1: 0.8749 - val_loss: 0.2001 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3586 - acc: 0.8572 - f1: 0.8765 - val_loss: 0.1966 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3582 - acc: 0.8562 - f1: 0.8760 - val_loss: 0.1962 - val_acc: 0.9691 - val_f1: 0.9704\n",
      "Epoch 319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8585 - f1: 0.8782 - val_loss: 0.2013 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8646 - f1: 0.8823 - val_loss: 0.2010 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8572 - f1: 0.8766 - val_loss: 0.1982 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8582 - f1: 0.8782 - val_loss: 0.2072 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8581 - f1: 0.8773 - val_loss: 0.2186 - val_acc: 0.9469 - val_f1: 0.9504\n",
      "Epoch 324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.2011 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8596 - f1: 0.8779 - val_loss: 0.1957 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8570 - f1: 0.8769 - val_loss: 0.2155 - val_acc: 0.9531 - val_f1: 0.9563\n",
      "Epoch 327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8641 - f1: 0.8817 - val_loss: 0.1979 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8592 - f1: 0.8787 - val_loss: 0.1989 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8588 - f1: 0.8781 - val_loss: 0.2039 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3529 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2010 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8550 - f1: 0.8749 - val_loss: 0.2158 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8575 - f1: 0.8767 - val_loss: 0.2015 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8575 - f1: 0.8765 - val_loss: 0.2078 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.1983 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3544 - acc: 0.8562 - f1: 0.8764 - val_loss: 0.2037 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8602 - f1: 0.8791 - val_loss: 0.2017 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 337/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3594 - acc: 0.8540 - f1: 0.8741 - val_loss: 0.2015 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.1952 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8598 - f1: 0.8787 - val_loss: 0.2082 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3452 - acc: 0.8619 - f1: 0.8802 - val_loss: 0.2034 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8548 - f1: 0.8751 - val_loss: 0.2038 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8651 - f1: 0.8831 - val_loss: 0.1966 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3599 - acc: 0.8550 - f1: 0.8752 - val_loss: 0.2008 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8570 - f1: 0.8765 - val_loss: 0.2052 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 345/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3505 - acc: 0.8579 - f1: 0.8773 - val_loss: 0.2027 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3539 - acc: 0.8570 - f1: 0.8771 - val_loss: 0.2008 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3485 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.1981 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8612 - f1: 0.8798 - val_loss: 0.1965 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3559 - acc: 0.8551 - f1: 0.8751 - val_loss: 0.2153 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3528 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2009 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3514 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.2195 - val_acc: 0.9453 - val_f1: 0.9499\n",
      "Epoch 352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8560 - f1: 0.8760 - val_loss: 0.2395 - val_acc: 0.9362 - val_f1: 0.9416\n",
      "Epoch 353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3529 - acc: 0.8586 - f1: 0.8783 - val_loss: 0.2024 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8589 - f1: 0.8774 - val_loss: 0.1994 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8608 - f1: 0.8795 - val_loss: 0.1975 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8634 - f1: 0.8817 - val_loss: 0.1958 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3541 - acc: 0.8572 - f1: 0.8767 - val_loss: 0.1986 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8623 - f1: 0.8810 - val_loss: 0.2013 - val_acc: 0.9622 - val_f1: 0.9626\n",
      "Epoch 359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8581 - f1: 0.8775 - val_loss: 0.1959 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8569 - f1: 0.8766 - val_loss: 0.1932 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8572 - f1: 0.8772 - val_loss: 0.2014 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8561 - f1: 0.8756 - val_loss: 0.2026 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3556 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1954 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.1986 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3451 - acc: 0.8601 - f1: 0.8788 - val_loss: 0.1977 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8589 - f1: 0.8784 - val_loss: 0.2021 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3562 - acc: 0.8564 - f1: 0.8762 - val_loss: 0.2154 - val_acc: 0.9513 - val_f1: 0.9545\n",
      "Epoch 368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3604 - acc: 0.8555 - f1: 0.8756 - val_loss: 0.2056 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3538 - acc: 0.8572 - f1: 0.8769 - val_loss: 0.2010 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8609 - f1: 0.8795 - val_loss: 0.1954 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8591 - f1: 0.8783 - val_loss: 0.2113 - val_acc: 0.9538 - val_f1: 0.9563\n",
      "Epoch 372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8667 - f1: 0.8841 - val_loss: 0.2029 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3578 - acc: 0.8552 - f1: 0.8756 - val_loss: 0.2061 - val_acc: 0.9519 - val_f1: 0.9545\n",
      "Epoch 374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8620 - f1: 0.8803 - val_loss: 0.2025 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8564 - f1: 0.8763 - val_loss: 0.1999 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8606 - f1: 0.8791 - val_loss: 0.2240 - val_acc: 0.9453 - val_f1: 0.9489\n",
      "Epoch 377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8620 - f1: 0.8804 - val_loss: 0.2032 - val_acc: 0.9581 - val_f1: 0.9607\n",
      "Epoch 378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.1953 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8583 - f1: 0.8775 - val_loss: 0.1953 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8637 - f1: 0.8818 - val_loss: 0.2075 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8578 - f1: 0.8778 - val_loss: 0.1932 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3496 - acc: 0.8591 - f1: 0.8781 - val_loss: 0.2084 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.1971 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8611 - f1: 0.8802 - val_loss: 0.1998 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8657 - f1: 0.8838 - val_loss: 0.2070 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.1938 - val_acc: 0.9659 - val_f1: 0.9681\n",
      "Epoch 387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8610 - f1: 0.8796 - val_loss: 0.2109 - val_acc: 0.9572 - val_f1: 0.9592\n",
      "Epoch 388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8575 - f1: 0.8773 - val_loss: 0.2180 - val_acc: 0.9513 - val_f1: 0.9546\n",
      "Epoch 389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8533 - f1: 0.8739 - val_loss: 0.1977 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8614 - f1: 0.8801 - val_loss: 0.1976 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8559 - f1: 0.8757 - val_loss: 0.1984 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8662 - f1: 0.8837 - val_loss: 0.1989 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8584 - f1: 0.8772 - val_loss: 0.2089 - val_acc: 0.9575 - val_f1: 0.9602\n",
      "Epoch 394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8574 - f1: 0.8765 - val_loss: 0.1981 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2036 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3659 - acc: 0.8505 - f1: 0.8712 - val_loss: 0.2004 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8559 - f1: 0.8754 - val_loss: 0.1972 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8579 - f1: 0.8772 - val_loss: 0.1956 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8641 - f1: 0.8822 - val_loss: 0.1955 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8611 - f1: 0.8800 - val_loss: 0.1964 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2079 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8628 - f1: 0.8811 - val_loss: 0.1996 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8604 - f1: 0.8794 - val_loss: 0.1952 - val_acc: 0.9691 - val_f1: 0.9705\n",
      "Epoch 404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8590 - f1: 0.8780 - val_loss: 0.1966 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8594 - f1: 0.8777 - val_loss: 0.2066 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8636 - f1: 0.8818 - val_loss: 0.1997 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8595 - f1: 0.8788 - val_loss: 0.2028 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8583 - f1: 0.8775 - val_loss: 0.1998 - val_acc: 0.9609 - val_f1: 0.9631\n",
      "Epoch 409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8557 - f1: 0.8756 - val_loss: 0.2010 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8579 - f1: 0.8779 - val_loss: 0.2112 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.2031 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8591 - f1: 0.8780 - val_loss: 0.2012 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2008 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8572 - f1: 0.8770 - val_loss: 0.1989 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8612 - f1: 0.8794 - val_loss: 0.1989 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8574 - f1: 0.8769 - val_loss: 0.2002 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8614 - f1: 0.8799 - val_loss: 0.2083 - val_acc: 0.9575 - val_f1: 0.9594\n",
      "Epoch 418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.1999 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8596 - f1: 0.8791 - val_loss: 0.1941 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8614 - f1: 0.8799 - val_loss: 0.1986 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2185 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8623 - f1: 0.8807 - val_loss: 0.1989 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8555 - f1: 0.8759 - val_loss: 0.2022 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8590 - f1: 0.8786 - val_loss: 0.2065 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8577 - f1: 0.8775 - val_loss: 0.1992 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2036 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8802 - val_loss: 0.1969 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8593 - f1: 0.8788 - val_loss: 0.1946 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2006 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8616 - f1: 0.8805 - val_loss: 0.2026 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 431/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8589 - f1: 0.8786 - val_loss: 0.1964 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8805 - val_loss: 0.2115 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8579 - f1: 0.8771 - val_loss: 0.2042 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8627 - f1: 0.8808 - val_loss: 0.2059 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8587 - f1: 0.8776 - val_loss: 0.2047 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8580 - f1: 0.8772 - val_loss: 0.2024 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8646 - f1: 0.8824 - val_loss: 0.2053 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2126 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2084 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8612 - f1: 0.8792 - val_loss: 0.2349 - val_acc: 0.9403 - val_f1: 0.9451\n",
      "Epoch 441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8616 - f1: 0.8805 - val_loss: 0.2032 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8595 - f1: 0.8786 - val_loss: 0.2012 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8607 - f1: 0.8794 - val_loss: 0.1998 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8643 - f1: 0.8824 - val_loss: 0.2110 - val_acc: 0.9566 - val_f1: 0.9585\n",
      "Epoch 445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2083 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8611 - f1: 0.8795 - val_loss: 0.1992 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8588 - f1: 0.8779 - val_loss: 0.1966 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8623 - f1: 0.8806 - val_loss: 0.2007 - val_acc: 0.9606 - val_f1: 0.9635\n",
      "Epoch 449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8576 - f1: 0.8770 - val_loss: 0.1946 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8586 - f1: 0.8778 - val_loss: 0.1935 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.1989 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8587 - f1: 0.8784 - val_loss: 0.2059 - val_acc: 0.9588 - val_f1: 0.9614\n",
      "Epoch 453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3545 - acc: 0.8571 - f1: 0.8769 - val_loss: 0.2146 - val_acc: 0.9522 - val_f1: 0.9547\n",
      "Epoch 454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.1980 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8624 - f1: 0.8807 - val_loss: 0.1935 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8580 - f1: 0.8776 - val_loss: 0.2096 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3478 - acc: 0.8599 - f1: 0.8788 - val_loss: 0.2154 - val_acc: 0.9613 - val_f1: 0.9621\n",
      "Epoch 458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2109 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8570 - f1: 0.8766 - val_loss: 0.2008 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8650 - f1: 0.8828 - val_loss: 0.2016 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8542 - f1: 0.8745 - val_loss: 0.2080 - val_acc: 0.9569 - val_f1: 0.9596\n",
      "Epoch 462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8616 - f1: 0.8803 - val_loss: 0.2076 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2031 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2049 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8617 - f1: 0.8808 - val_loss: 0.2013 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8613 - f1: 0.8800 - val_loss: 0.2052 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8796 - val_loss: 0.2074 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8613 - f1: 0.8801 - val_loss: 0.2172 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8611 - f1: 0.8799 - val_loss: 0.2010 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8608 - f1: 0.8792 - val_loss: 0.2047 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8549 - f1: 0.8750 - val_loss: 0.2018 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8593 - f1: 0.8784 - val_loss: 0.2042 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8658 - f1: 0.8832 - val_loss: 0.1973 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8576 - f1: 0.8771 - val_loss: 0.2175 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8602 - f1: 0.8788 - val_loss: 0.2049 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.1957 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8600 - f1: 0.8789 - val_loss: 0.2041 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8633 - f1: 0.8809 - val_loss: 0.2113 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8602 - f1: 0.8795 - val_loss: 0.1948 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2118 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.2016 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8641 - f1: 0.8819 - val_loss: 0.2008 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8678 - f1: 0.8854 - val_loss: 0.2019 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8620 - f1: 0.8812 - val_loss: 0.2003 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.2038 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2101 - val_acc: 0.9578 - val_f1: 0.9600\n",
      "Epoch 487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2001 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8612 - f1: 0.8802 - val_loss: 0.2075 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2051 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8614 - f1: 0.8803 - val_loss: 0.2002 - val_acc: 0.9669 - val_f1: 0.9688\n",
      "Epoch 491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8612 - f1: 0.8798 - val_loss: 0.2093 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8580 - f1: 0.8772 - val_loss: 0.2113 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8554 - f1: 0.8753 - val_loss: 0.2056 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8588 - f1: 0.8786 - val_loss: 0.2068 - val_acc: 0.9631 - val_f1: 0.9651\n",
      "Epoch 495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2139 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.2068 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2216 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 498/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3452 - acc: 0.8617 - f1: 0.8804 - val_loss: 0.2105 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8632 - f1: 0.8812 - val_loss: 0.2116 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 500/5000\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3439 - acc: 0.8609 - f1: 0.8801 - val_loss: 0.2090 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 501/5000\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3478 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.2111 - val_acc: 0.9556 - val_f1: 0.9583\n",
      "Epoch 502/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3544 - acc: 0.8565 - f1: 0.8759 - val_loss: 0.2189 - val_acc: 0.9503 - val_f1: 0.9537\n",
      "Epoch 503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2060 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8660 - f1: 0.8833 - val_loss: 0.2015 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8608 - f1: 0.8797 - val_loss: 0.2121 - val_acc: 0.9591 - val_f1: 0.9608\n",
      "Epoch 506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2090 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8607 - f1: 0.8794 - val_loss: 0.2160 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8798 - val_loss: 0.2045 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8590 - f1: 0.8785 - val_loss: 0.2040 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 510/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2040 - val_acc: 0.9600 - val_f1: 0.9623\n",
      "Epoch 511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2031 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8644 - f1: 0.8826 - val_loss: 0.2039 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8598 - f1: 0.8792 - val_loss: 0.2109 - val_acc: 0.9553 - val_f1: 0.9578\n",
      "Epoch 514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8596 - f1: 0.8786 - val_loss: 0.2077 - val_acc: 0.9591 - val_f1: 0.9616\n",
      "Epoch 515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8597 - f1: 0.8788 - val_loss: 0.2026 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8659 - f1: 0.8832 - val_loss: 0.2062 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3518 - acc: 0.8566 - f1: 0.8761 - val_loss: 0.2031 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2143 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 519/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3435 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2132 - val_acc: 0.9531 - val_f1: 0.9557\n",
      "Epoch 520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8610 - f1: 0.8802 - val_loss: 0.2189 - val_acc: 0.9550 - val_f1: 0.9568\n",
      "Epoch 521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8651 - f1: 0.8826 - val_loss: 0.2039 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 522/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8627 - f1: 0.8807 - val_loss: 0.2058 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8572 - f1: 0.8772 - val_loss: 0.2015 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8615 - f1: 0.8801 - val_loss: 0.2177 - val_acc: 0.9541 - val_f1: 0.9563\n",
      "Epoch 525/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3492 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2025 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8547 - f1: 0.8747 - val_loss: 0.2074 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 527/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8622 - f1: 0.8811 - val_loss: 0.2019 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2049 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8624 - f1: 0.8813 - val_loss: 0.2188 - val_acc: 0.9506 - val_f1: 0.9535\n",
      "Epoch 530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2052 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8571 - f1: 0.8770 - val_loss: 0.1971 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8647 - f1: 0.8827 - val_loss: 0.2015 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8646 - f1: 0.8830 - val_loss: 0.2027 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2199 - val_acc: 0.9491 - val_f1: 0.9526\n",
      "Epoch 535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8603 - f1: 0.8795 - val_loss: 0.1990 - val_acc: 0.9631 - val_f1: 0.9654\n",
      "Epoch 536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8606 - f1: 0.8798 - val_loss: 0.2063 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3494 - acc: 0.8592 - f1: 0.8788 - val_loss: 0.2045 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2063 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3452 - acc: 0.8600 - f1: 0.8789 - val_loss: 0.2049 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 540/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3405 - acc: 0.8645 - f1: 0.8825 - val_loss: 0.2201 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 541/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3426 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2110 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 542/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3461 - acc: 0.8618 - f1: 0.8804 - val_loss: 0.2094 - val_acc: 0.9578 - val_f1: 0.9600\n",
      "Epoch 543/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8650 - f1: 0.8827 - val_loss: 0.2057 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8575 - f1: 0.8772 - val_loss: 0.2201 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3577 - acc: 0.8556 - f1: 0.8755 - val_loss: 0.2020 - val_acc: 0.9644 - val_f1: 0.9665\n",
      "Epoch 546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8571 - f1: 0.8768 - val_loss: 0.2058 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2086 - val_acc: 0.9559 - val_f1: 0.9581\n",
      "Epoch 548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8618 - f1: 0.8806 - val_loss: 0.2069 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2031 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8633 - f1: 0.8819 - val_loss: 0.2202 - val_acc: 0.9534 - val_f1: 0.9569\n",
      "Epoch 551/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3542 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2009 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8607 - f1: 0.8799 - val_loss: 0.2132 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8628 - f1: 0.8815 - val_loss: 0.2056 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8584 - f1: 0.8781 - val_loss: 0.2008 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8611 - f1: 0.8803 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8631 - f1: 0.8816 - val_loss: 0.2142 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2049 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8578 - f1: 0.8769 - val_loss: 0.2080 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8612 - f1: 0.8797 - val_loss: 0.2189 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8659 - f1: 0.8835 - val_loss: 0.2036 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8609 - f1: 0.8796 - val_loss: 0.2057 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8581 - f1: 0.8771 - val_loss: 0.2082 - val_acc: 0.9681 - val_f1: 0.9699\n",
      "Epoch 563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8625 - f1: 0.8808 - val_loss: 0.2112 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8607 - f1: 0.8792 - val_loss: 0.2103 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8588 - f1: 0.8788 - val_loss: 0.2126 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3541 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.2026 - val_acc: 0.9691 - val_f1: 0.9709\n",
      "Epoch 567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.2154 - val_acc: 0.9544 - val_f1: 0.9572\n",
      "Epoch 568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3450 - acc: 0.8601 - f1: 0.8796 - val_loss: 0.2026 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8613 - f1: 0.8803 - val_loss: 0.2060 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8664 - f1: 0.8841 - val_loss: 0.2095 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8573 - f1: 0.8769 - val_loss: 0.2081 - val_acc: 0.9609 - val_f1: 0.9632\n",
      "Epoch 572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2088 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8645 - f1: 0.8826 - val_loss: 0.2153 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8609 - f1: 0.8801 - val_loss: 0.2102 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3543 - acc: 0.8557 - f1: 0.8760 - val_loss: 0.1987 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2018 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2080 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.2098 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2064 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8811 - val_loss: 0.1959 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2075 - val_acc: 0.9566 - val_f1: 0.9589\n",
      "Epoch 582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8609 - f1: 0.8798 - val_loss: 0.2078 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8672 - f1: 0.8847 - val_loss: 0.2204 - val_acc: 0.9603 - val_f1: 0.9618\n",
      "Epoch 584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8572 - f1: 0.8771 - val_loss: 0.2025 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2077 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2150 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8581 - f1: 0.8777 - val_loss: 0.2049 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8583 - f1: 0.8779 - val_loss: 0.2027 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8608 - f1: 0.8800 - val_loss: 0.2020 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8597 - f1: 0.8785 - val_loss: 0.2018 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2160 - val_acc: 0.9500 - val_f1: 0.9527\n",
      "Epoch 592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8575 - f1: 0.8774 - val_loss: 0.2175 - val_acc: 0.9544 - val_f1: 0.9571\n",
      "Epoch 593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8826 - val_loss: 0.2176 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3482 - acc: 0.8588 - f1: 0.8782 - val_loss: 0.2063 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8595 - f1: 0.8793 - val_loss: 0.2049 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.2066 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3509 - acc: 0.8563 - f1: 0.8763 - val_loss: 0.2093 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2128 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2201 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8611 - f1: 0.8796 - val_loss: 0.2020 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8627 - f1: 0.8812 - val_loss: 0.2145 - val_acc: 0.9559 - val_f1: 0.9581\n",
      "Epoch 603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2090 - val_acc: 0.9622 - val_f1: 0.9646\n",
      "Epoch 604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2032 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8643 - f1: 0.8823 - val_loss: 0.2001 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2128 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3556 - acc: 0.8575 - f1: 0.8772 - val_loss: 0.2096 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8585 - f1: 0.8779 - val_loss: 0.2016 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8674 - f1: 0.8849 - val_loss: 0.1988 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8654 - f1: 0.8834 - val_loss: 0.2065 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8673 - f1: 0.8845 - val_loss: 0.2080 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3439 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2001 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2049 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8673 - f1: 0.8841 - val_loss: 0.2108 - val_acc: 0.9525 - val_f1: 0.9554\n",
      "Epoch 615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.1988 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8642 - f1: 0.8825 - val_loss: 0.2109 - val_acc: 0.9541 - val_f1: 0.9574\n",
      "Epoch 617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8610 - f1: 0.8802 - val_loss: 0.2082 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8650 - f1: 0.8829 - val_loss: 0.2112 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8636 - f1: 0.8821 - val_loss: 0.2054 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8599 - f1: 0.8795 - val_loss: 0.2136 - val_acc: 0.9581 - val_f1: 0.9607\n",
      "Epoch 621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8612 - f1: 0.8800 - val_loss: 0.2098 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8650 - f1: 0.8830 - val_loss: 0.2060 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8598 - f1: 0.8791 - val_loss: 0.2014 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8655 - f1: 0.8835 - val_loss: 0.2140 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2090 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8827 - val_loss: 0.2127 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8560 - f1: 0.8760 - val_loss: 0.2078 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8628 - f1: 0.8818 - val_loss: 0.2063 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8613 - f1: 0.8805 - val_loss: 0.2118 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2108 - val_acc: 0.9581 - val_f1: 0.9597\n",
      "Epoch 631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2102 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8644 - f1: 0.8827 - val_loss: 0.2183 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8569 - f1: 0.8767 - val_loss: 0.2106 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2122 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8583 - f1: 0.8777 - val_loss: 0.2080 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8610 - f1: 0.8797 - val_loss: 0.2053 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8661 - f1: 0.8837 - val_loss: 0.2012 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8664 - f1: 0.8839 - val_loss: 0.2056 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2093 - val_acc: 0.9597 - val_f1: 0.9621\n",
      "Epoch 640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8637 - f1: 0.8819 - val_loss: 0.2113 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8611 - f1: 0.8800 - val_loss: 0.2075 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8609 - f1: 0.8798 - val_loss: 0.2157 - val_acc: 0.9556 - val_f1: 0.9579\n",
      "Epoch 643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2103 - val_acc: 0.9569 - val_f1: 0.9595\n",
      "Epoch 644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8605 - f1: 0.8800 - val_loss: 0.2059 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2052 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8631 - f1: 0.8817 - val_loss: 0.2182 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8595 - f1: 0.8788 - val_loss: 0.2089 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2093 - val_acc: 0.9566 - val_f1: 0.9594\n",
      "Epoch 649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8634 - f1: 0.8809 - val_loss: 0.2094 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2016 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3505 - acc: 0.8571 - f1: 0.8770 - val_loss: 0.2094 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 652/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2180 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2090 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3465 - acc: 0.8595 - f1: 0.8784 - val_loss: 0.2023 - val_acc: 0.9684 - val_f1: 0.9696\n",
      "Epoch 655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3465 - acc: 0.8618 - f1: 0.8802 - val_loss: 0.2176 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 656/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.2065 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2076 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 658/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2153 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3509 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2004 - val_acc: 0.9691 - val_f1: 0.9705\n",
      "Epoch 660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2033 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 661/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3436 - acc: 0.8617 - f1: 0.8804 - val_loss: 0.2092 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 662/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3502 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2066 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8634 - f1: 0.8815 - val_loss: 0.2229 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8679 - f1: 0.8852 - val_loss: 0.2098 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8613 - f1: 0.8807 - val_loss: 0.2049 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 666/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3454 - acc: 0.8637 - f1: 0.8820 - val_loss: 0.2056 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 667/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.2041 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2101 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2064 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 670/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2063 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8607 - f1: 0.8795 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 672/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8620 - f1: 0.8802 - val_loss: 0.2204 - val_acc: 0.9547 - val_f1: 0.9575\n",
      "Epoch 673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8575 - f1: 0.8769 - val_loss: 0.2173 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8576 - f1: 0.8772 - val_loss: 0.2086 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8600 - f1: 0.8795 - val_loss: 0.2181 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 676/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3476 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2124 - val_acc: 0.9563 - val_f1: 0.9584\n",
      "Epoch 677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8642 - f1: 0.8823 - val_loss: 0.2179 - val_acc: 0.9528 - val_f1: 0.9553\n",
      "Epoch 678/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3570 - acc: 0.8548 - f1: 0.8750 - val_loss: 0.2123 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8660 - f1: 0.8838 - val_loss: 0.2081 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.2117 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 681/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3349 - acc: 0.8668 - f1: 0.8844 - val_loss: 0.2094 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 682/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8689 - f1: 0.8858 - val_loss: 0.2081 - val_acc: 0.9575 - val_f1: 0.9597\n",
      "Epoch 683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3578 - acc: 0.8533 - f1: 0.8747 - val_loss: 0.2173 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8594 - f1: 0.8791 - val_loss: 0.2300 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8614 - f1: 0.8805 - val_loss: 0.2108 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2322 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2027 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8605 - f1: 0.8798 - val_loss: 0.2026 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2111 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2281 - val_acc: 0.9606 - val_f1: 0.9611\n",
      "Epoch 691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2058 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2043 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8593 - f1: 0.8779 - val_loss: 0.2106 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8611 - f1: 0.8798 - val_loss: 0.2048 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8642 - f1: 0.8823 - val_loss: 0.2227 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 696/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3451 - acc: 0.8612 - f1: 0.8806 - val_loss: 0.2143 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 697/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2110 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8580 - f1: 0.8779 - val_loss: 0.2070 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8658 - f1: 0.8835 - val_loss: 0.2074 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8619 - f1: 0.8811 - val_loss: 0.2116 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8657 - f1: 0.8838 - val_loss: 0.2120 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8606 - f1: 0.8802 - val_loss: 0.2116 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 703/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2088 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8564 - f1: 0.8765 - val_loss: 0.2055 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 705/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3441 - acc: 0.8609 - f1: 0.8806 - val_loss: 0.2096 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8808 - val_loss: 0.2129 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 707/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2059 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2105 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 709/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3380 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2103 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2087 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8635 - f1: 0.8818 - val_loss: 0.2162 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8591 - f1: 0.8783 - val_loss: 0.2061 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 713/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8632 - f1: 0.8812 - val_loss: 0.2132 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2092 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8612 - f1: 0.8800 - val_loss: 0.2099 - val_acc: 0.9578 - val_f1: 0.9607\n",
      "Epoch 716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8598 - f1: 0.8794 - val_loss: 0.2114 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 717/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3441 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2126 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8594 - f1: 0.8787 - val_loss: 0.2161 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2010 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2086 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2229 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8631 - f1: 0.8818 - val_loss: 0.2143 - val_acc: 0.9609 - val_f1: 0.9634\n",
      "Epoch 723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8567 - f1: 0.8771 - val_loss: 0.2132 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8595 - f1: 0.8783 - val_loss: 0.2040 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2056 - val_acc: 0.9656 - val_f1: 0.9677\n",
      "Epoch 726/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3358 - acc: 0.8646 - f1: 0.88 - 0s 16us/sample - loss: 0.3361 - acc: 0.8646 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3379 - acc: 0.8649 - f1: 0.8828 - val_loss: 0.2113 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 728/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3466 - acc: 0.8602 - f1: 0.8791 - val_loss: 0.2064 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 729/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3473 - acc: 0.8599 - f1: 0.88 - 0s 16us/sample - loss: 0.3463 - acc: 0.8598 - f1: 0.8795 - val_loss: 0.2076 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2140 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2138 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8650 - f1: 0.8829 - val_loss: 0.2074 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8629 - f1: 0.8817 - val_loss: 0.2089 - val_acc: 0.9553 - val_f1: 0.9575\n",
      "Epoch 734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2130 - val_acc: 0.9663 - val_f1: 0.9664\n",
      "Epoch 735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8608 - f1: 0.8797 - val_loss: 0.2120 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2150 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 737/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3505 - acc: 0.8591 - f1: 0.8785 - val_loss: 0.2220 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 738/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8628 - f1: 0.8814 - val_loss: 0.2072 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8613 - f1: 0.8801 - val_loss: 0.2090 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 740/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3383 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2016 - val_acc: 0.9606 - val_f1: 0.9632\n",
      "Epoch 741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8630 - f1: 0.8813 - val_loss: 0.2057 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8570 - f1: 0.8772 - val_loss: 0.2088 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8577 - f1: 0.8772 - val_loss: 0.2099 - val_acc: 0.9638 - val_f1: 0.9660\n",
      "Epoch 744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8810 - val_loss: 0.2114 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8645 - f1: 0.8825 - val_loss: 0.2222 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3398 - acc: 0.8653 - f1: 0.8829 - val_loss: 0.2226 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2126 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2273 - val_acc: 0.9447 - val_f1: 0.9485\n",
      "Epoch 749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8652 - f1: 0.8826 - val_loss: 0.2140 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8607 - f1: 0.8797 - val_loss: 0.2130 - val_acc: 0.9634 - val_f1: 0.9640\n",
      "Epoch 751/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8641 - f1: 0.8822 - val_loss: 0.2094 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 752/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2082 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2090 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 754/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3368 - acc: 0.8649 - f1: 0.8830 - val_loss: 0.2142 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2098 - val_acc: 0.9688 - val_f1: 0.9706\n",
      "Epoch 756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8660 - f1: 0.8836 - val_loss: 0.2222 - val_acc: 0.9531 - val_f1: 0.9560\n",
      "Epoch 757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.2150 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 758/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3536 - acc: 0.8563 - f1: 0.8762 - val_loss: 0.2097 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2199 - val_acc: 0.9522 - val_f1: 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8642 - f1: 0.8824 - val_loss: 0.2088 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 761/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3380 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2097 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 762/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3370 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2050 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2122 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 764/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2053 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 765/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2059 - val_acc: 0.9584 - val_f1: 0.9600\n",
      "Epoch 766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8611 - f1: 0.8801 - val_loss: 0.2278 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8638 - f1: 0.8819 - val_loss: 0.2096 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8593 - f1: 0.8791 - val_loss: 0.2141 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8639 - f1: 0.8815 - val_loss: 0.2209 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8669 - f1: 0.8850 - val_loss: 0.2400 - val_acc: 0.9606 - val_f1: 0.9614\n",
      "Epoch 773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8692 - f1: 0.8862 - val_loss: 0.2163 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2201 - val_acc: 0.9553 - val_f1: 0.9577\n",
      "Epoch 775/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3411 - acc: 0.8639 - f1: 0.8821 - val_loss: 0.2156 - val_acc: 0.9522 - val_f1: 0.9550\n",
      "Epoch 776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8615 - f1: 0.8803 - val_loss: 0.2063 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8602 - f1: 0.8794 - val_loss: 0.2038 - val_acc: 0.9669 - val_f1: 0.9688\n",
      "Epoch 778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.2095 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2147 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8607 - f1: 0.8798 - val_loss: 0.2081 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8625 - f1: 0.8812 - val_loss: 0.2057 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2053 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8647 - f1: 0.8828 - val_loss: 0.2080 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2075 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8628 - f1: 0.8817 - val_loss: 0.2137 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2162 - val_acc: 0.9556 - val_f1: 0.9576\n",
      "Epoch 787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8603 - f1: 0.8797 - val_loss: 0.2202 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2110 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2072 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3503 - acc: 0.8570 - f1: 0.8772 - val_loss: 0.2230 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8612 - f1: 0.8802 - val_loss: 0.2142 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8618 - f1: 0.8809 - val_loss: 0.2155 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3530 - acc: 0.8580 - f1: 0.8771 - val_loss: 0.2197 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2045 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2081 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 796/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3406 - acc: 0.8624 - f1: 0.88 - 0s 16us/sample - loss: 0.3411 - acc: 0.8625 - f1: 0.8815 - val_loss: 0.2230 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 797/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8642 - f1: 0.8821 - val_loss: 0.2250 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 798/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3457 - acc: 0.8612 - f1: 0.8806 - val_loss: 0.2124 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 799/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3485 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.2104 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 800/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3477 - acc: 0.8592 - f1: 0.8787 - val_loss: 0.2077 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8618 - f1: 0.8802 - val_loss: 0.2086 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8654 - f1: 0.8827 - val_loss: 0.2181 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2177 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8622 - f1: 0.8815 - val_loss: 0.2085 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2235 - val_acc: 0.9484 - val_f1: 0.9518\n",
      "Epoch 806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2035 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 807/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3477 - acc: 0.8590 - f1: 0.8788 - val_loss: 0.2070 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2040 - val_acc: 0.9672 - val_f1: 0.9691\n",
      "Epoch 809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2304 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2091 - val_acc: 0.9609 - val_f1: 0.9625\n",
      "Epoch 811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8640 - f1: 0.8822 - val_loss: 0.2075 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8655 - f1: 0.8831 - val_loss: 0.2062 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2082 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8597 - f1: 0.8790 - val_loss: 0.2084 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2139 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8703 - f1: 0.8874 - val_loss: 0.2156 - val_acc: 0.9522 - val_f1: 0.9553\n",
      "Epoch 817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2122 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8832 - val_loss: 0.2247 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8624 - f1: 0.8812 - val_loss: 0.2135 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2096 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8562 - f1: 0.8766 - val_loss: 0.2279 - val_acc: 0.9631 - val_f1: 0.9637\n",
      "Epoch 822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2076 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2027 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8675 - f1: 0.8851 - val_loss: 0.2136 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8665 - f1: 0.8843 - val_loss: 0.2218 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2100 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2113 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2112 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8610 - f1: 0.8801 - val_loss: 0.2111 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2076 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8637 - f1: 0.8821 - val_loss: 0.2091 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8580 - f1: 0.8776 - val_loss: 0.2191 - val_acc: 0.9491 - val_f1: 0.9523\n",
      "Epoch 833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3511 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.2082 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2126 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8595 - f1: 0.8784 - val_loss: 0.2131 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2081 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2064 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8658 - f1: 0.8835 - val_loss: 0.2091 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8660 - f1: 0.8839 - val_loss: 0.2087 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2195 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2085 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2164 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8653 - f1: 0.8832 - val_loss: 0.2078 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8696 - f1: 0.8865 - val_loss: 0.2097 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2131 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 846/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3324 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2106 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8636 - f1: 0.8823 - val_loss: 0.2289 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8641 - f1: 0.8832 - val_loss: 0.2114 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2048 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2151 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8624 - f1: 0.8814 - val_loss: 0.2127 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2320 - val_acc: 0.9416 - val_f1: 0.9453\n",
      "Epoch 853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8622 - f1: 0.8808 - val_loss: 0.2040 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2001 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2069 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2059 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 857/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3299 - acc: 0.8702 - f1: 0.8868 - val_loss: 0.2129 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2077 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2136 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3587 - acc: 0.8528 - f1: 0.8736 - val_loss: 0.2071 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8636 - f1: 0.8818 - val_loss: 0.2133 - val_acc: 0.9547 - val_f1: 0.9572\n",
      "Epoch 862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8637 - f1: 0.8821 - val_loss: 0.2138 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 863/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3385 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2092 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8651 - f1: 0.8830 - val_loss: 0.2166 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 865/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2090 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8576 - f1: 0.8776 - val_loss: 0.2155 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3450 - acc: 0.8610 - f1: 0.8803 - val_loss: 0.2127 - val_acc: 0.9566 - val_f1: 0.9592\n",
      "Epoch 868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2094 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2103 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2135 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8621 - f1: 0.8810 - val_loss: 0.2117 - val_acc: 0.9550 - val_f1: 0.9572\n",
      "Epoch 872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8824 - val_loss: 0.2041 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 874/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2158 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 875/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2085 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8598 - f1: 0.8792 - val_loss: 0.2175 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2076 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8657 - f1: 0.8835 - val_loss: 0.2035 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2065 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2132 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8630 - f1: 0.8816 - val_loss: 0.2087 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2134 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8625 - f1: 0.8809 - val_loss: 0.2155 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2148 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2128 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8677 - f1: 0.8850 - val_loss: 0.2080 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 887/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3317 - acc: 0.8692 - f1: 0.8859 - val_loss: 0.2132 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 888/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3427 - acc: 0.8616 - f1: 0.8801 - val_loss: 0.2244 - val_acc: 0.9497 - val_f1: 0.9526\n",
      "Epoch 889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8629 - f1: 0.8816 - val_loss: 0.2104 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 890/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3345 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2160 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 891/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2162 - val_acc: 0.9531 - val_f1: 0.9563\n",
      "Epoch 892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2247 - val_acc: 0.9541 - val_f1: 0.9567\n",
      "Epoch 893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8612 - f1: 0.8804 - val_loss: 0.2075 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8661 - f1: 0.8842 - val_loss: 0.2240 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 895/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3366 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2052 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2110 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2119 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 898/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3402 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 899/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3426 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2352 - val_acc: 0.9447 - val_f1: 0.9486\n",
      "Epoch 900/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3357 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2103 - val_acc: 0.9566 - val_f1: 0.9593\n",
      "Epoch 901/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8607 - f1: 0.8799 - val_loss: 0.2154 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2099 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2529 - val_acc: 0.9613 - val_f1: 0.9617\n",
      "Epoch 904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8667 - f1: 0.8842 - val_loss: 0.2133 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8637 - f1: 0.8818 - val_loss: 0.2169 - val_acc: 0.9650 - val_f1: 0.9652\n",
      "Epoch 906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2198 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2204 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 908/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3452 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2270 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2188 - val_acc: 0.9572 - val_f1: 0.9595\n",
      "Epoch 910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8614 - f1: 0.8800 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 911/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3376 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2088 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8631 - f1: 0.8822 - val_loss: 0.2185 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2064 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2128 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2093 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 916/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3344 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2122 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 917/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3375 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2089 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 918/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8835 - val_loss: 0.1988 - val_acc: 0.9659 - val_f1: 0.9682\n",
      "Epoch 919/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8672 - f1: 0.8848 - val_loss: 0.2133 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8615 - f1: 0.8805 - val_loss: 0.2094 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8639 - f1: 0.8829 - val_loss: 0.2173 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 922/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2189 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 923/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2109 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 924/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3421 - acc: 0.8624 - f1: 0.8813 - val_loss: 0.2227 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8661 - f1: 0.8843 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 926/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8643 - f1: 0.8829 - val_loss: 0.2102 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8638 - f1: 0.8815 - val_loss: 0.2134 - val_acc: 0.9625 - val_f1: 0.9647\n",
      "Epoch 928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2140 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2123 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8698 - f1: 0.8865 - val_loss: 0.2170 - val_acc: 0.9594 - val_f1: 0.9619\n",
      "Epoch 931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2073 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8584 - f1: 0.8781 - val_loss: 0.2229 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2261 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2149 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8638 - f1: 0.8827 - val_loss: 0.2068 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 936/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3396 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2207 - val_acc: 0.9600 - val_f1: 0.9609\n",
      "Epoch 937/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3526 - acc: 0.8566 - f1: 0.8772 - val_loss: 0.2285 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2183 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 939/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3472 - acc: 0.8588 - f1: 0.8778 - val_loss: 0.2154 - val_acc: 0.9575 - val_f1: 0.9600\n",
      "Epoch 940/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2146 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 941/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3385 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2240 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 942/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2185 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 943/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2053 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 944/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3427 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2391 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8648 - f1: 0.8839 - val_loss: 0.2041 - val_acc: 0.9647 - val_f1: 0.9666\n",
      "Epoch 946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2098 - val_acc: 0.9650 - val_f1: 0.9670\n",
      "Epoch 947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8624 - f1: 0.8812 - val_loss: 0.2168 - val_acc: 0.9556 - val_f1: 0.9577\n",
      "Epoch 948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8639 - f1: 0.8824 - val_loss: 0.2062 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8631 - f1: 0.8817 - val_loss: 0.2055 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8630 - f1: 0.8814 - val_loss: 0.2101 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 951/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3389 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2218 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2168 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3511 - acc: 0.8569 - f1: 0.8773 - val_loss: 0.2132 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2253 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2144 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 956/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3431 - acc: 0.8630 - f1: 0.8815 - val_loss: 0.2186 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 957/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3378 - acc: 0.8658 - f1: 0.8839 - val_loss: 0.2118 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8667 - f1: 0.8842 - val_loss: 0.2139 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8652 - f1: 0.8830 - val_loss: 0.2045 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2232 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8625 - f1: 0.8813 - val_loss: 0.2221 - val_acc: 0.9522 - val_f1: 0.9555\n",
      "Epoch 962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8630 - f1: 0.8816 - val_loss: 0.2143 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2073 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2114 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8635 - f1: 0.8821 - val_loss: 0.2103 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8602 - f1: 0.8794 - val_loss: 0.2117 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2071 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2049 - val_acc: 0.9669 - val_f1: 0.9689\n",
      "Epoch 969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2130 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 970/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3407 - acc: 0.8640 - f1: 0.8823 - val_loss: 0.2119 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 971/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2119 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 972/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3333 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2065 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 973/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3371 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2113 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 974/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2157 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8689 - f1: 0.8858 - val_loss: 0.2111 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8648 - f1: 0.8827 - val_loss: 0.2075 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8651 - f1: 0.8832 - val_loss: 0.2176 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 978/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2102 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 979/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8700 - f1: 0.8871 - val_loss: 0.2106 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2030 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 981/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3411 - acc: 0.8625 - f1: 0.88 - 0s 16us/sample - loss: 0.3374 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2078 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8806 - val_loss: 0.2087 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8571 - f1: 0.8775 - val_loss: 0.2237 - val_acc: 0.9438 - val_f1: 0.9476\n",
      "Epoch 984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2006 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8677 - f1: 0.8847 - val_loss: 0.2067 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2196 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2164 - val_acc: 0.9550 - val_f1: 0.9575\n",
      "Epoch 988/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3366 - acc: 0.8650 - f1: 0.8833 - val_loss: 0.2244 - val_acc: 0.9606 - val_f1: 0.9616\n",
      "Epoch 989/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2208 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 990/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2069 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2128 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2167 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8625 - f1: 0.8813 - val_loss: 0.2276 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 994/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3361 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2132 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 995/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8645 - f1: 0.8834 - val_loss: 0.2136 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8616 - f1: 0.8808 - val_loss: 0.2107 - val_acc: 0.9659 - val_f1: 0.9679\n",
      "Epoch 997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8673 - f1: 0.8848 - val_loss: 0.2336 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2525 - val_acc: 0.9522 - val_f1: 0.9533\n",
      "Epoch 999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8580 - f1: 0.8781 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2112 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2316 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8857 - val_loss: 0.2244 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2152 - val_acc: 0.9566 - val_f1: 0.9585\n",
      "Epoch 1004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8631 - f1: 0.8818 - val_loss: 0.2248 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 1005/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3364 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2246 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2173 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 1007/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3514 - acc: 0.8582 - f1: 0.8775 - val_loss: 0.2212 - val_acc: 0.9663 - val_f1: 0.9666\n",
      "Epoch 1008/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2345 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1009/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8686 - f1: 0.8859 - val_loss: 0.2108 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1010/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2110 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8643 - f1: 0.8830 - val_loss: 0.2078 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2063 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 1013/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3368 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2287 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2173 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2051 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2076 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Epoch 1017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8809 - val_loss: 0.2058 - val_acc: 0.9659 - val_f1: 0.9681\n",
      "Epoch 1018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2252 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8603 - f1: 0.8796 - val_loss: 0.2113 - val_acc: 0.9566 - val_f1: 0.9590\n",
      "Epoch 1020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8584 - f1: 0.8782 - val_loss: 0.2300 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8696 - f1: 0.8867 - val_loss: 0.2123 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 1022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2098 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 1023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2130 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8659 - f1: 0.8836 - val_loss: 0.2065 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8665 - f1: 0.8850 - val_loss: 0.2196 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8654 - f1: 0.8833 - val_loss: 0.2175 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1027/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3542 - acc: 0.8573 - f1: 0.8767 - val_loss: 0.2257 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 1028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2124 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 1029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2115 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 1030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8615 - f1: 0.8805 - val_loss: 0.2561 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 1031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2212 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2313 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 1033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8655 - f1: 0.8833 - val_loss: 0.2161 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2187 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 1035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8684 - f1: 0.8858 - val_loss: 0.2098 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 1036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2107 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2041 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8593 - f1: 0.8791 - val_loss: 0.2216 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8607 - f1: 0.8800 - val_loss: 0.2201 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 1040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8632 - f1: 0.8813 - val_loss: 0.2124 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2094 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2144 - val_acc: 0.9703 - val_f1: 0.9719\n",
      "Epoch 1043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2378 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2077 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8668 - f1: 0.8843 - val_loss: 0.2251 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8640 - f1: 0.8826 - val_loss: 0.2181 - val_acc: 0.9634 - val_f1: 0.9659\n",
      "Epoch 1047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8579 - f1: 0.8778 - val_loss: 0.2189 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8678 - f1: 0.8854 - val_loss: 0.2064 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 1049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8848 - val_loss: 0.2027 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 1050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2092 - val_acc: 0.9625 - val_f1: 0.9645\n",
      "Epoch 1051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2124 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 1052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2210 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 1053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2125 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8613 - f1: 0.8803 - val_loss: 0.2142 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2062 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 1056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8668 - f1: 0.8843 - val_loss: 0.2061 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2128 - val_acc: 0.9547 - val_f1: 0.9573\n",
      "Epoch 1058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3525 - acc: 0.8567 - f1: 0.8766 - val_loss: 0.2255 - val_acc: 0.9556 - val_f1: 0.9567\n",
      "Epoch 1059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2240 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2108 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 1062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8620 - f1: 0.8808 - val_loss: 0.2197 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8665 - f1: 0.8839 - val_loss: 0.2186 - val_acc: 0.9566 - val_f1: 0.9582\n",
      "Epoch 1064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8635 - f1: 0.8824 - val_loss: 0.2088 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2177 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2234 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 1067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8616 - f1: 0.8811 - val_loss: 0.2157 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 1068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2170 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3451 - acc: 0.8610 - f1: 0.8804 - val_loss: 0.2105 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 1070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8629 - f1: 0.8812 - val_loss: 0.2056 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 1071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8698 - f1: 0.8864 - val_loss: 0.2192 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 1072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2097 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8708 - f1: 0.8875 - val_loss: 0.2136 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1074/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8636 - f1: 0.8823 - val_loss: 0.2186 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 1075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8851 - val_loss: 0.2213 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2127 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1077/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2265 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2066 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8669 - f1: 0.8847 - val_loss: 0.2190 - val_acc: 0.9550 - val_f1: 0.9570\n",
      "Epoch 1080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2061 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2148 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8648 - f1: 0.8829 - val_loss: 0.2395 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8675 - f1: 0.8849 - val_loss: 0.2078 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 1084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2106 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1085/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8602 - f1: 0.8799 - val_loss: 0.2149 - val_acc: 0.9609 - val_f1: 0.9625\n",
      "Epoch 1086/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2120 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1087/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2184 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1088/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2068 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1089/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8632 - f1: 0.8819 - val_loss: 0.2302 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2252 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 1091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8646 - f1: 0.8833 - val_loss: 0.2329 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 1092/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8599 - f1: 0.8794 - val_loss: 0.2165 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 1093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8634 - f1: 0.8819 - val_loss: 0.2128 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 1094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2141 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 1095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2159 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2221 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1097/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8646 - f1: 0.8832 - val_loss: 0.2232 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8676 - f1: 0.8851 - val_loss: 0.2191 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2176 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8865 - val_loss: 0.2100 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2266 - val_acc: 0.9566 - val_f1: 0.9579\n",
      "Epoch 1102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2236 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8653 - f1: 0.8833 - val_loss: 0.2189 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8696 - f1: 0.8867 - val_loss: 0.2198 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 1105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2140 - val_acc: 0.9666 - val_f1: 0.9684\n",
      "Epoch 1106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8646 - f1: 0.8829 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8845 - val_loss: 0.2137 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2221 - val_acc: 0.9553 - val_f1: 0.9580\n",
      "Epoch 1109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8630 - f1: 0.8815 - val_loss: 0.2187 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 1111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2247 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2221 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2175 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2201 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2196 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8645 - f1: 0.8828 - val_loss: 0.2395 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 1118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8648 - f1: 0.8834 - val_loss: 0.2308 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2294 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2118 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8632 - f1: 0.8819 - val_loss: 0.2179 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 1122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2288 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2326 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8640 - f1: 0.8826 - val_loss: 0.2198 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2159 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8599 - f1: 0.8793 - val_loss: 0.2210 - val_acc: 0.9519 - val_f1: 0.9545\n",
      "Epoch 1127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8640 - f1: 0.8820 - val_loss: 0.2124 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8640 - f1: 0.8822 - val_loss: 0.2153 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8629 - f1: 0.8816 - val_loss: 0.2129 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8656 - f1: 0.8834 - val_loss: 0.2102 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 1131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2168 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 1132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8665 - f1: 0.8843 - val_loss: 0.2119 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 1133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8603 - f1: 0.8800 - val_loss: 0.2174 - val_acc: 0.9575 - val_f1: 0.9594\n",
      "Epoch 1134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8843 - val_loss: 0.2221 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2392 - val_acc: 0.9616 - val_f1: 0.9623\n",
      "Epoch 1136/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2197 - val_acc: 0.9534 - val_f1: 0.9563\n",
      "Epoch 1137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2073 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 1138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8623 - f1: 0.8814 - val_loss: 0.2210 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8737 - f1: 0.8898 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8643 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8610 - f1: 0.8800 - val_loss: 0.2251 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1142/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3346 - acc: 0.8685 - f1: 0.8858 - val_loss: 0.2358 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1143/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2309 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 1144/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8627 - f1: 0.8815 - val_loss: 0.2147 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2114 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8720 - f1: 0.8886 - val_loss: 0.2137 - val_acc: 0.9597 - val_f1: 0.9619\n",
      "Epoch 1147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8674 - f1: 0.8849 - val_loss: 0.2125 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 1148/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2288 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 1149/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8851 - val_loss: 0.2166 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1150/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2220 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 1151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2019 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2125 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1153/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3471 - acc: 0.8595 - f1: 0.8793 - val_loss: 0.2061 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1154/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3435 - acc: 0.8602 - f1: 0.8797 - val_loss: 0.2257 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8642 - f1: 0.8820 - val_loss: 0.2190 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1156/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8851 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9670\n",
      "Epoch 1157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8647 - f1: 0.8828 - val_loss: 0.2174 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1158/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8816 - val_loss: 0.2212 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1159/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3443 - acc: 0.8606 - f1: 0.8800 - val_loss: 0.2117 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 1160/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8644 - f1: 0.8825 - val_loss: 0.2312 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2164 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1162/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8650 - f1: 0.8830 - val_loss: 0.2250 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8704 - f1: 0.8873 - val_loss: 0.2145 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 1164/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8638 - f1: 0.8824 - val_loss: 0.2189 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 1165/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2427 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 1166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2156 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8651 - f1: 0.8830 - val_loss: 0.2142 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1168/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3360 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2251 - val_acc: 0.9588 - val_f1: 0.9612\n",
      "Epoch 1169/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3431 - acc: 0.8622 - f1: 0.8815 - val_loss: 0.2178 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 1170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2186 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1171/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3301 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2127 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 1172/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2163 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1173/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3419 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2104 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1174/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3447 - acc: 0.8605 - f1: 0.8807 - val_loss: 0.2120 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2488 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 1176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2242 - val_acc: 0.9669 - val_f1: 0.9672\n",
      "Epoch 1177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2262 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 1178/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2293 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1179/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2405 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 1180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8627 - f1: 0.8817 - val_loss: 0.2534 - val_acc: 0.9606 - val_f1: 0.9615\n",
      "Epoch 1181/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3391 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2076 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 1182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2142 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 1183/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2178 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1185/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8728 - f1: 0.8893 - val_loss: 0.2366 - val_acc: 0.9394 - val_f1: 0.9437\n",
      "Epoch 1186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3496 - acc: 0.8601 - f1: 0.8791 - val_loss: 0.2057 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2121 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 1188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2154 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 1189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8672 - f1: 0.8850 - val_loss: 0.2305 - val_acc: 0.9531 - val_f1: 0.9551\n",
      "Epoch 1190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2334 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 1191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2286 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8657 - f1: 0.8834 - val_loss: 0.2281 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 1193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2073 - val_acc: 0.9572 - val_f1: 0.9594\n",
      "Epoch 1194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8618 - f1: 0.8808 - val_loss: 0.2194 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2226 - val_acc: 0.9578 - val_f1: 0.9593\n",
      "Epoch 1196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8624 - f1: 0.8814 - val_loss: 0.2193 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2159 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 1198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8593 - f1: 0.8793 - val_loss: 0.2155 - val_acc: 0.9522 - val_f1: 0.9557\n",
      "Epoch 1199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2199 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8671 - f1: 0.8854 - val_loss: 0.2160 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2199 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8654 - f1: 0.8834 - val_loss: 0.2221 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2282 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2287 - val_acc: 0.9550 - val_f1: 0.9579\n",
      "Epoch 1205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2341 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 1206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2214 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 1207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2193 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2279 - val_acc: 0.9678 - val_f1: 0.9683\n",
      "Epoch 1209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.2169 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 1210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2225 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2111 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 1212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2109 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2703 - val_acc: 0.9581 - val_f1: 0.9582\n",
      "Epoch 1214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8600 - f1: 0.8794 - val_loss: 0.2094 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2225 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2213 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 1217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2226 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8642 - f1: 0.8822 - val_loss: 0.2210 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2406 - val_acc: 0.9609 - val_f1: 0.9618\n",
      "Epoch 1220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2134 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8652 - f1: 0.8837 - val_loss: 0.2159 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8655 - f1: 0.8833 - val_loss: 0.2170 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 1224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2321 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2106 - val_acc: 0.9656 - val_f1: 0.9677\n",
      "Epoch 1226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2276 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 1227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8646 - f1: 0.8827 - val_loss: 0.2147 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8849 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9658\n",
      "Epoch 1229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2216 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8689 - f1: 0.8861 - val_loss: 0.2229 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2182 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2390 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 1234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2164 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1235/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3395 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2357 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 1236/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3381 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2247 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8672 - f1: 0.8843 - val_loss: 0.2493 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 1238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2185 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 1239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2233 - val_acc: 0.9563 - val_f1: 0.9587\n",
      "Epoch 1240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2233 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2392 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 1242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2101 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 1243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2529 - val_acc: 0.9563 - val_f1: 0.9568\n",
      "Epoch 1244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8640 - f1: 0.8821 - val_loss: 0.2147 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8704 - f1: 0.8873 - val_loss: 0.2240 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2144 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 1247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2223 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 1248/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3422 - acc: 0.8620 - f1: 0.8806 - val_loss: 0.2153 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 1249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2300 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 1250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2095 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2089 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2121 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2135 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2207 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2377 - val_acc: 0.9397 - val_f1: 0.9442\n",
      "Epoch 1256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8577 - f1: 0.8775 - val_loss: 0.2194 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1257/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8640 - f1: 0.8830 - val_loss: 0.2110 - val_acc: 0.9591 - val_f1: 0.9617\n",
      "Epoch 1258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2319 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 1259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2099 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 1260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2118 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 1261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8704 - f1: 0.8868 - val_loss: 0.2180 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 1262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8636 - f1: 0.8825 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1264/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2240 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8627 - f1: 0.8809 - val_loss: 0.2127 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2069 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 1267/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3429 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2109 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2128 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1269/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2286 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2286 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2396 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2121 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1273/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3444 - acc: 0.8602 - f1: 0.8797 - val_loss: 0.2106 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 1274/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3357 - acc: 0.8651 - f1: 0.8834 - val_loss: 0.2204 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1275/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3369 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2423 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 1276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8561 - f1: 0.8762 - val_loss: 0.2129 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1277/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2158 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8639 - f1: 0.8824 - val_loss: 0.2336 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 1279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8820 - val_loss: 0.2163 - val_acc: 0.9581 - val_f1: 0.9608\n",
      "Epoch 1280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8694 - f1: 0.8863 - val_loss: 0.2039 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2183 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 1282/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8635 - f1: 0.8825 - val_loss: 0.2298 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2129 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2467 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2172 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8696 - f1: 0.8868 - val_loss: 0.2132 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2235 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2117 - val_acc: 0.9613 - val_f1: 0.9636\n",
      "Epoch 1289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2321 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2234 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 1291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2353 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2118 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2224 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 1294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2081 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 1295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2105 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 1296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2066 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 1297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8639 - f1: 0.8827 - val_loss: 0.2216 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2334 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 1299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2101 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2152 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 1302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2069 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2116 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 1304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8681 - f1: 0.8855 - val_loss: 0.2288 - val_acc: 0.9494 - val_f1: 0.9530\n",
      "Epoch 1305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2117 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2208 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8716 - f1: 0.8881 - val_loss: 0.2210 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2177 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 1309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2188 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2282 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2225 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2398 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2090 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 1314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2489 - val_acc: 0.9319 - val_f1: 0.9371\n",
      "Epoch 1315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3564 - acc: 0.8551 - f1: 0.8752 - val_loss: 0.2128 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2324 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 1317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2302 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 1318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2228 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8650 - f1: 0.8828 - val_loss: 0.2155 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2133 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2259 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8638 - f1: 0.8824 - val_loss: 0.2269 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2105 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 1324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2173 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2259 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 1327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2199 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8622 - f1: 0.8814 - val_loss: 0.2213 - val_acc: 0.9578 - val_f1: 0.9605\n",
      "Epoch 1329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8810 - val_loss: 0.2132 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2233 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2108 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2224 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2202 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 1334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2136 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8693 - f1: 0.8865 - val_loss: 0.2256 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8611 - f1: 0.8803 - val_loss: 0.2350 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 1337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2177 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2076 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 1339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2403 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 1340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2291 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2237 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2368 - val_acc: 0.9475 - val_f1: 0.9504\n",
      "Epoch 1343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8558 - f1: 0.8769 - val_loss: 0.2143 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2156 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2115 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8705 - f1: 0.8872 - val_loss: 0.2303 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8874 - val_loss: 0.2134 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8693 - f1: 0.8863 - val_loss: 0.2177 - val_acc: 0.9534 - val_f1: 0.9560\n",
      "Epoch 1349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2147 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 1350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2106 - val_acc: 0.9625 - val_f1: 0.9648\n",
      "Epoch 1351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8665 - f1: 0.8842 - val_loss: 0.2227 - val_acc: 0.9553 - val_f1: 0.9584\n",
      "Epoch 1352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2178 - val_acc: 0.9519 - val_f1: 0.9544\n",
      "Epoch 1353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2158 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2435 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8649 - f1: 0.8830 - val_loss: 0.2434 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8624 - f1: 0.8809 - val_loss: 0.2112 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2215 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 1358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8633 - f1: 0.8824 - val_loss: 0.2139 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2336 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 1361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2181 - val_acc: 0.9675 - val_f1: 0.9693\n",
      "Epoch 1362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8714 - f1: 0.8880 - val_loss: 0.2357 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 1363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2111 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2137 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2438 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 1366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2292 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 1367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2189 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8845 - val_loss: 0.2269 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8660 - f1: 0.8840 - val_loss: 0.2255 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2358 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1371/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2209 - val_acc: 0.9572 - val_f1: 0.9589\n",
      "Epoch 1372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2198 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2141 - val_acc: 0.9594 - val_f1: 0.9619\n",
      "Epoch 1374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8670 - f1: 0.8854 - val_loss: 0.2241 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8656 - f1: 0.8842 - val_loss: 0.2109 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 1376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2282 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8668 - f1: 0.8845 - val_loss: 0.2249 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8656 - f1: 0.8836 - val_loss: 0.2137 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 1379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8635 - f1: 0.8824 - val_loss: 0.2323 - val_acc: 0.9431 - val_f1: 0.9475\n",
      "Epoch 1380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8632 - f1: 0.8818 - val_loss: 0.2120 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2156 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2422 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8627 - f1: 0.8817 - val_loss: 0.2187 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 1384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8646 - f1: 0.8826 - val_loss: 0.2221 - val_acc: 0.9588 - val_f1: 0.9614\n",
      "Epoch 1385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2163 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 1387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8615 - f1: 0.8804 - val_loss: 0.2265 - val_acc: 0.9478 - val_f1: 0.9513\n",
      "Epoch 1388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2388 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 1389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2274 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2256 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 1391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2201 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 1392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2183 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8675 - f1: 0.8849 - val_loss: 0.2152 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 1394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8672 - f1: 0.8848 - val_loss: 0.2128 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 1395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2736 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 1396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8627 - f1: 0.8815 - val_loss: 0.2214 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2192 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 1398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2270 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8649 - f1: 0.8838 - val_loss: 0.2127 - val_acc: 0.9597 - val_f1: 0.9620\n",
      "Epoch 1400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2325 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2311 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 1402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8644 - f1: 0.8833 - val_loss: 0.2056 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 1403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8674 - f1: 0.8848 - val_loss: 0.2149 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2462 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2281 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 1406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2229 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2073 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2213 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2213 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8653 - f1: 0.8839 - val_loss: 0.2257 - val_acc: 0.9578 - val_f1: 0.9594\n",
      "Epoch 1411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2125 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 1412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8755 - f1: 0.8916 - val_loss: 0.2099 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2129 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8633 - f1: 0.8818 - val_loss: 0.2094 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2146 - val_acc: 0.9644 - val_f1: 0.9665\n",
      "Epoch 1416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8652 - f1: 0.8836 - val_loss: 0.2290 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2232 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8640 - f1: 0.8827 - val_loss: 0.2134 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 1419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8633 - f1: 0.8824 - val_loss: 0.2203 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 1420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2193 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8629 - f1: 0.8822 - val_loss: 0.2087 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2298 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8671 - f1: 0.8858 - val_loss: 0.2125 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 1424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8721 - f1: 0.8888 - val_loss: 0.2129 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 1425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8622 - f1: 0.8813 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2184 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 1427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8604 - f1: 0.8798 - val_loss: 0.2410 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2160 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 1429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8679 - f1: 0.8856 - val_loss: 0.2327 - val_acc: 0.9569 - val_f1: 0.9586\n",
      "Epoch 1430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8623 - f1: 0.8813 - val_loss: 0.2231 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2214 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 1432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8667 - f1: 0.8848 - val_loss: 0.2385 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1433/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2181 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 1434/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3394 - acc: 0.8643 - f1: 0.8828 - val_loss: 0.2336 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1435/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2161 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1436/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2195 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 1437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8674 - f1: 0.8858 - val_loss: 0.2270 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1438/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8711 - f1: 0.8876 - val_loss: 0.2447 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8634 - f1: 0.8824 - val_loss: 0.2582 - val_acc: 0.9616 - val_f1: 0.9619\n",
      "Epoch 1440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8653 - f1: 0.8838 - val_loss: 0.2498 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 1441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8687 - f1: 0.8857 - val_loss: 0.2177 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2191 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 1443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2263 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 1444/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3469 - acc: 0.8604 - f1: 0.8800 - val_loss: 0.2338 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8659 - f1: 0.8834 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2188 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2316 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 1448/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3280 - acc: 0.8706 - f1: 0.8876 - val_loss: 0.2256 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2478 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8606 - f1: 0.8799 - val_loss: 0.2159 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8640 - f1: 0.8825 - val_loss: 0.2134 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2145 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1453/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3279 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2283 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1454/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2304 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2420 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 1456/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3255 - acc: 0.8721 - f1: 0.8886 - val_loss: 0.2293 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 1457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2244 - val_acc: 0.9513 - val_f1: 0.9545\n",
      "Epoch 1458/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8612 - f1: 0.8803 - val_loss: 0.2116 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8710 - f1: 0.8877 - val_loss: 0.2216 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 1460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2245 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1461/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2336 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 1462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2238 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 1463/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8694 - f1: 0.8866 - val_loss: 0.2096 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 1465/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8849 - val_loss: 0.2183 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8655 - f1: 0.8834 - val_loss: 0.2232 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8641 - f1: 0.8831 - val_loss: 0.2172 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 1468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8648 - f1: 0.8835 - val_loss: 0.2143 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2248 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2277 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 1472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2175 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 1473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8851 - val_loss: 0.2258 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2165 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 1475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2136 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 1476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2150 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 1477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2213 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2293 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2255 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2332 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8637 - f1: 0.8826 - val_loss: 0.2273 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8748 - f1: 0.8904 - val_loss: 0.2274 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2413 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 1484/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3391 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2300 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 1485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2214 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 1486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2234 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 1487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2191 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 1488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2213 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2144 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2285 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2110 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2112 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 1493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2233 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 1494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2159 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2135 - val_acc: 0.9581 - val_f1: 0.9608\n",
      "Epoch 1496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2331 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 1497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8676 - f1: 0.8851 - val_loss: 0.2158 - val_acc: 0.9594 - val_f1: 0.9607\n",
      "Epoch 1498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8637 - f1: 0.8830 - val_loss: 0.2268 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8632 - f1: 0.8818 - val_loss: 0.2176 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 1500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2268 - val_acc: 0.9591 - val_f1: 0.9605\n",
      "Epoch 1501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8640 - f1: 0.8831 - val_loss: 0.2369 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8688 - f1: 0.8860 - val_loss: 0.2293 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2396 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2296 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2248 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8622 - f1: 0.8812 - val_loss: 0.2265 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 1507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2359 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2106 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 1509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2207 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 1510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2149 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2243 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2232 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2208 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 1514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8708 - f1: 0.8874 - val_loss: 0.2259 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 1515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2354 - val_acc: 0.9456 - val_f1: 0.9494\n",
      "Epoch 1516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8614 - f1: 0.8805 - val_loss: 0.2125 - val_acc: 0.9597 - val_f1: 0.9620\n",
      "Epoch 1517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2218 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2248 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 1519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8672 - f1: 0.8855 - val_loss: 0.2471 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2162 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8653 - f1: 0.8835 - val_loss: 0.2199 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8633 - f1: 0.8823 - val_loss: 0.2209 - val_acc: 0.9544 - val_f1: 0.9572\n",
      "Epoch 1523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2365 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2134 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2265 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 1526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2294 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2256 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 1528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2342 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2238 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 1531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2547 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 1532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2130 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8761 - f1: 0.8916 - val_loss: 0.2177 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2055 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 1535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2100 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 1537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8754 - f1: 0.8917 - val_loss: 0.2399 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8689 - f1: 0.8868 - val_loss: 0.2245 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 1539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2497 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2255 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 1541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8628 - f1: 0.8817 - val_loss: 0.2183 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2216 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2273 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 1544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8656 - f1: 0.8843 - val_loss: 0.2229 - val_acc: 0.9559 - val_f1: 0.9580\n",
      "Epoch 1545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2383 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 1546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2363 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 1547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2193 - val_acc: 0.9556 - val_f1: 0.9580\n",
      "Epoch 1549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8651 - f1: 0.8841 - val_loss: 0.2337 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2195 - val_acc: 0.9603 - val_f1: 0.9630\n",
      "Epoch 1551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2195 - val_acc: 0.9578 - val_f1: 0.9606\n",
      "Epoch 1552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8672 - f1: 0.8851 - val_loss: 0.2331 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 1553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2481 - val_acc: 0.9381 - val_f1: 0.9425\n",
      "Epoch 1554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2060 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8617 - f1: 0.8807 - val_loss: 0.2180 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 1556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8619 - f1: 0.8809 - val_loss: 0.2264 - val_acc: 0.9691 - val_f1: 0.9697\n",
      "Epoch 1557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2302 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 1558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2138 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1559/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2175 - val_acc: 0.9594 - val_f1: 0.9615\n",
      "Epoch 1560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8585 - f1: 0.8783 - val_loss: 0.2077 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 1561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2395 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8864 - val_loss: 0.2416 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 1563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8677 - f1: 0.8860 - val_loss: 0.2112 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2387 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2179 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2321 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2371 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2416 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2158 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 1570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8652 - f1: 0.8830 - val_loss: 0.2166 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2165 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2273 - val_acc: 0.9647 - val_f1: 0.9668\n",
      "Epoch 1573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8676 - f1: 0.8857 - val_loss: 0.2180 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2318 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2128 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2323 - val_acc: 0.9703 - val_f1: 0.9714\n",
      "Epoch 1577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2269 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2331 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8644 - f1: 0.8830 - val_loss: 0.2332 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2124 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2222 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2211 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8813 - val_loss: 0.2419 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 1584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2124 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 1586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2299 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 1587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2191 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 1588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8631 - f1: 0.8816 - val_loss: 0.2300 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2100 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2321 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 1591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2214 - val_acc: 0.9538 - val_f1: 0.9566\n",
      "Epoch 1592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2165 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2255 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2152 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2185 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2085 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2209 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2530 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 1599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2384 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2184 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2232 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2334 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2392 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2238 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 1605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2390 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2275 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 1607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8836 - val_loss: 0.2356 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2136 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8640 - f1: 0.8825 - val_loss: 0.2092 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2366 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2272 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2150 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2209 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 1614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2223 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 1615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2365 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 1616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2206 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2106 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2333 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 1619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2288 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2243 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8739 - f1: 0.8903 - val_loss: 0.2204 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2417 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 1623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8654 - f1: 0.8839 - val_loss: 0.2328 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 1624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2386 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2206 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2220 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2116 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8606 - f1: 0.8801 - val_loss: 0.2360 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2126 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8743 - f1: 0.8908 - val_loss: 0.2186 - val_acc: 0.9703 - val_f1: 0.9715\n",
      "Epoch 1631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2175 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2372 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8668 - f1: 0.8851 - val_loss: 0.2409 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 1634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2163 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2260 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 1636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2193 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 1637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2325 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 1638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2287 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 1639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2247 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 1640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2195 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2247 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2213 - val_acc: 0.9531 - val_f1: 0.9556\n",
      "Epoch 1643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2325 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8696 - f1: 0.8873 - val_loss: 0.2197 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8602 - f1: 0.8793 - val_loss: 0.2196 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 1646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2202 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 1647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8752 - f1: 0.8912 - val_loss: 0.2375 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2198 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2562 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8655 - f1: 0.8834 - val_loss: 0.2223 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2368 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 1652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2247 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1653/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2224 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8613 - f1: 0.8807 - val_loss: 0.2118 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2268 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 1656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8631 - f1: 0.8820 - val_loss: 0.2256 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2236 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 1658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8662 - f1: 0.8848 - val_loss: 0.2204 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 1659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2157 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 1660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2246 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8671 - f1: 0.8845 - val_loss: 0.2069 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8662 - f1: 0.8849 - val_loss: 0.2339 - val_acc: 0.9688 - val_f1: 0.9692\n",
      "Epoch 1663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2142 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2892 - val_acc: 0.9603 - val_f1: 0.9612\n",
      "Epoch 1665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8552 - f1: 0.8757 - val_loss: 0.2222 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2119 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 1667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2097 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2165 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 1669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2250 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2226 - val_acc: 0.9616 - val_f1: 0.9642\n",
      "Epoch 1671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2412 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2246 - val_acc: 0.9628 - val_f1: 0.9650\n",
      "Epoch 1673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2255 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1674/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8627 - f1: 0.8818 - val_loss: 0.2273 - val_acc: 0.9631 - val_f1: 0.9636\n",
      "Epoch 1675/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2338 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 1676/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2170 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2221 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8745 - f1: 0.8904 - val_loss: 0.2453 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 1679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2189 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 1680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2090 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8585 - f1: 0.8783 - val_loss: 0.2215 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 1682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2490 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 1683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2389 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8753 - f1: 0.8911 - val_loss: 0.2358 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2243 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2357 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2477 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 1689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2394 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8631 - f1: 0.8821 - val_loss: 0.2216 - val_acc: 0.9575 - val_f1: 0.9593\n",
      "Epoch 1691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8634 - f1: 0.8816 - val_loss: 0.2293 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 1692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2250 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8618 - f1: 0.8812 - val_loss: 0.2183 - val_acc: 0.9534 - val_f1: 0.9564\n",
      "Epoch 1694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8629 - f1: 0.8820 - val_loss: 0.2289 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 1695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8706 - f1: 0.8882 - val_loss: 0.2308 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8657 - f1: 0.8836 - val_loss: 0.2339 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2291 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 1699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2288 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2267 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1701/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3294 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2173 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 1702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8589 - f1: 0.8793 - val_loss: 0.2277 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8675 - f1: 0.8850 - val_loss: 0.2327 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2338 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2487 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 1706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2239 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 1707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2456 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2422 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1709/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3352 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2287 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1710/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3363 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2416 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1711/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2177 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 1712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2177 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 1713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2262 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8594 - f1: 0.8785 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8653 - f1: 0.8840 - val_loss: 0.2189 - val_acc: 0.9681 - val_f1: 0.9684\n",
      "Epoch 1716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2269 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2187 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2258 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2168 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8698 - f1: 0.8877 - val_loss: 0.2367 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 1721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2162 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 1722/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2156 - val_acc: 0.9672 - val_f1: 0.9690\n",
      "Epoch 1723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8705 - f1: 0.8871 - val_loss: 0.2068 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 1724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8650 - f1: 0.8835 - val_loss: 0.2196 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2294 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2200 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 1727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2099 - val_acc: 0.9606 - val_f1: 0.9629\n",
      "Epoch 1728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8700 - f1: 0.8869 - val_loss: 0.2249 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8669 - f1: 0.8845 - val_loss: 0.2323 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 1730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2274 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2378 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2556 - val_acc: 0.9572 - val_f1: 0.9585\n",
      "Epoch 1733/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2125 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8663 - f1: 0.8840 - val_loss: 0.2191 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2147 - val_acc: 0.9625 - val_f1: 0.9645\n",
      "Epoch 1736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2478 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 1737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2251 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2281 - val_acc: 0.9591 - val_f1: 0.9606\n",
      "Epoch 1739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8707 - f1: 0.8876 - val_loss: 0.2308 - val_acc: 0.9547 - val_f1: 0.9571\n",
      "Epoch 1740/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8629 - f1: 0.8814 - val_loss: 0.2273 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1741/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3356 - acc: 0.8657 - f1: 0.8842 - val_loss: 0.2245 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1742/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3247 - acc: 0.8728 - f1: 0.88 - 0s 16us/sample - loss: 0.3268 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2193 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2257 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 1744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2493 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1745/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8618 - f1: 0.8812 - val_loss: 0.2256 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3213 - acc: 0.8738 - f1: 0.8898 - val_loss: 0.2323 - val_acc: 0.9663 - val_f1: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8640 - f1: 0.8827 - val_loss: 0.2190 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2366 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 1749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2214 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 1750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8631 - f1: 0.8824 - val_loss: 0.2145 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 1751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8627 - f1: 0.8814 - val_loss: 0.2580 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2121 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 1753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2260 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2169 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2275 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 1756/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2125 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1758/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8655 - f1: 0.8840 - val_loss: 0.2201 - val_acc: 0.9619 - val_f1: 0.9642\n",
      "Epoch 1759/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3296 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2196 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 1760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2189 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 1761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2192 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1762/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2358 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2238 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1764/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2351 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1765/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2459 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1766/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2299 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1767/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3277 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2417 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1768/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2342 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1769/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8634 - f1: 0.8827 - val_loss: 0.2302 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 1770/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3353 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2266 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 1771/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2349 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 1772/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2241 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1773/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2490 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 1774/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3334 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2234 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 1775/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2215 - val_acc: 0.9594 - val_f1: 0.9609\n",
      "Epoch 1776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2149 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1777/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2226 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2238 - val_acc: 0.9550 - val_f1: 0.9574\n",
      "Epoch 1779/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2233 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 1780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8703 - f1: 0.8868 - val_loss: 0.2537 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1781/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8634 - f1: 0.8824 - val_loss: 0.2176 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1782/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8620 - f1: 0.8808 - val_loss: 0.2168 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 1783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2245 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2226 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 1785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2387 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 1786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2241 - val_acc: 0.9509 - val_f1: 0.9538\n",
      "Epoch 1787/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8871 - val_loss: 0.2407 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 1788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2483 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2213 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2249 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1791/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2342 - val_acc: 0.9684 - val_f1: 0.9692\n",
      "Epoch 1792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2567 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 1793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2210 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1794/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8679 - f1: 0.8853 - val_loss: 0.2136 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2301 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2234 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 1797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2291 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 1798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2192 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2364 - val_acc: 0.9675 - val_f1: 0.9692\n",
      "Epoch 1801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8718 - f1: 0.8883 - val_loss: 0.2186 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 1802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8637 - f1: 0.8827 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8640 - f1: 0.8828 - val_loss: 0.2135 - val_acc: 0.9659 - val_f1: 0.9663\n",
      "Epoch 1804/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2186 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1805/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2217 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1806/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3285 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2200 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1807/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2300 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2283 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8679 - f1: 0.8858 - val_loss: 0.2290 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1810/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2144 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1811/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2299 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2196 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 1813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3478 - acc: 0.8595 - f1: 0.8790 - val_loss: 0.2155 - val_acc: 0.9603 - val_f1: 0.9618\n",
      "Epoch 1814/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2331 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 1815/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2216 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1816/5000\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2329 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1817/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3369 - acc: 0.8661 - f1: 0.8842 - val_loss: 0.2213 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1818/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2250 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2213 - val_acc: 0.9453 - val_f1: 0.9491\n",
      "Epoch 1821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2273 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 1822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2203 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2351 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 1824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2249 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1825/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3354 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2346 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1826/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2285 - val_acc: 0.9581 - val_f1: 0.9596\n",
      "Epoch 1827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2128 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 1828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2270 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2198 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1830/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2181 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2540 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2375 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 1833/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2231 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2206 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2346 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 1836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8619 - f1: 0.8814 - val_loss: 0.2199 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2379 - val_acc: 0.9681 - val_f1: 0.9687\n",
      "Epoch 1838/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3301 - acc: 0.8681 - f1: 0.8854 - val_loss: 0.2363 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 1839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2192 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2295 - val_acc: 0.9478 - val_f1: 0.9515\n",
      "Epoch 1841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2138 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2224 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1843/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3225 - acc: 0.8746 - f1: 0.8906 - val_loss: 0.2281 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1844/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2265 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2263 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1846/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2300 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2148 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 1848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2142 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8674 - f1: 0.8850 - val_loss: 0.2174 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 1850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8659 - f1: 0.8847 - val_loss: 0.2388 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1851/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2424 - val_acc: 0.9666 - val_f1: 0.9667\n",
      "Epoch 1852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2264 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 1853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2393 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2300 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 1855/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3344 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2272 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 1856/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8613 - f1: 0.8806 - val_loss: 0.2274 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 1857/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3276 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2311 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1858/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3258 - acc: 0.8710 - f1: 0.8878 - val_loss: 0.2286 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1859/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8694 - f1: 0.8866 - val_loss: 0.2144 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 1860/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3270 - acc: 0.8706 - f1: 0.88 - 0s 15us/sample - loss: 0.3287 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2375 - val_acc: 0.9688 - val_f1: 0.9703\n",
      "Epoch 1861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2388 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2536 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 1863/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2269 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1864/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2290 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 1865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2181 - val_acc: 0.9650 - val_f1: 0.9673\n",
      "Epoch 1866/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3361 - acc: 0.8665 - f1: 0.8845 - val_loss: 0.2134 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1867/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2345 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1868/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3356 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2138 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 1869/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2459 - val_acc: 0.9669 - val_f1: 0.9686\n",
      "Epoch 1870/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3305 - acc: 0.8686 - f1: 0.8866 - val_loss: 0.2208 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1871/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8845 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 1872/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2123 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2264 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8641 - f1: 0.8823 - val_loss: 0.2191 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 1875/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2167 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 1876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2158 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2272 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 1878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2256 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2296 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 1880/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3388 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2124 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2301 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2444 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2349 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 1885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2336 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 1886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2204 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2462 - val_acc: 0.9663 - val_f1: 0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2498 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 1889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2320 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2290 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2467 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1892/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2222 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 1893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8635 - f1: 0.8823 - val_loss: 0.2166 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2300 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1896/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2272 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1897/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2258 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 1898/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8645 - f1: 0.8834 - val_loss: 0.2238 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1899/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3341 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2347 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2235 - val_acc: 0.9625 - val_f1: 0.9627\n",
      "Epoch 1901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2072 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2328 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1903/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2314 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 1904/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2276 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 1905/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8881 - val_loss: 0.2271 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 1906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2183 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8876 - val_loss: 0.2348 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2236 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 1909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2656 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2340 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1911/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2314 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1912/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8693 - f1: 0.8863 - val_loss: 0.2347 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 1913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8650 - f1: 0.8838 - val_loss: 0.2283 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 1914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2400 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2278 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 1916/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2156 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 1917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2257 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2324 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2245 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2269 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2429 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2401 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2304 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2743 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 1925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8658 - f1: 0.8843 - val_loss: 0.2212 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2235 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2378 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8658 - f1: 0.8836 - val_loss: 0.2560 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2368 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 1930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2258 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 1931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2260 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 1932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2173 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2236 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 1934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2390 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1935/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2241 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2220 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2213 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2243 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2199 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2167 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 1941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2550 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1942/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8610 - f1: 0.8800 - val_loss: 0.2135 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2182 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8697 - f1: 0.8871 - val_loss: 0.2526 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 1945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2176 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2378 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 1947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2292 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1948/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8738 - f1: 0.8901 - val_loss: 0.2562 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2273 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2253 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 1951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2157 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 1952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8711 - f1: 0.8876 - val_loss: 0.2234 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2242 - val_acc: 0.9653 - val_f1: 0.9674\n",
      "Epoch 1954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2319 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2322 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2217 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 1957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8600 - f1: 0.8787 - val_loss: 0.2094 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 1958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8651 - f1: 0.8832 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2305 - val_acc: 0.9697 - val_f1: 0.9710\n",
      "Epoch 1960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2727 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 1961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8642 - f1: 0.8826 - val_loss: 0.2464 - val_acc: 0.9600 - val_f1: 0.9611\n",
      "Epoch 1962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2319 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2215 - val_acc: 0.9550 - val_f1: 0.9573\n",
      "Epoch 1965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8598 - f1: 0.8798 - val_loss: 0.2575 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8750 - f1: 0.8914 - val_loss: 0.2296 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2484 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2346 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2318 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2321 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1972/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2147 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2341 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2250 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2509 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2221 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2098 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2474 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1980/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3420 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2141 - val_acc: 0.9575 - val_f1: 0.9602\n",
      "Epoch 1981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2267 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 1982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2060 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 1983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2195 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2563 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 1985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8739 - f1: 0.8906 - val_loss: 0.2317 - val_acc: 0.9488 - val_f1: 0.9519\n",
      "Epoch 1986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8667 - f1: 0.8844 - val_loss: 0.2335 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2323 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 1988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2297 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2333 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2213 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 1991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 1992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2173 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 1993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8661 - f1: 0.8845 - val_loss: 0.2433 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 1994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2107 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2651 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2279 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 1997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2408 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2340 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2315 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2241 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8719 - f1: 0.8885 - val_loss: 0.2183 - val_acc: 0.9634 - val_f1: 0.9657\n",
      "Epoch 2002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2428 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2181 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2239 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2005/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2360 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 2006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2365 - val_acc: 0.9681 - val_f1: 0.9687\n",
      "Epoch 2007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2437 - val_acc: 0.9566 - val_f1: 0.9588\n",
      "Epoch 2008/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2316 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2325 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 2010/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8669 - f1: 0.8851 - val_loss: 0.2097 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2363 - val_acc: 0.9691 - val_f1: 0.9707\n",
      "Epoch 2012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2331 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 2013/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2139 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 2014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2276 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2324 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2276 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2137 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 2018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2245 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2290 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2470 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 2021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2259 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2230 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 2023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2323 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8672 - f1: 0.8846 - val_loss: 0.2383 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8700 - f1: 0.8870 - val_loss: 0.2201 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8690 - f1: 0.8871 - val_loss: 0.2320 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2521 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2463 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2029/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8647 - f1: 0.8835 - val_loss: 0.2374 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8647 - f1: 0.8834 - val_loss: 0.2297 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2173 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8746 - f1: 0.8910 - val_loss: 0.2166 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8887 - val_loss: 0.2293 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8775 - f1: 0.8932 - val_loss: 0.2545 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2389 - val_acc: 0.9638 - val_f1: 0.9641\n",
      "Epoch 2036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2295 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2256 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2514 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2253 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 2040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9672\n",
      "Epoch 2041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2302 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2873 - val_acc: 0.9625 - val_f1: 0.9631\n",
      "Epoch 2043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8670 - f1: 0.8855 - val_loss: 0.2308 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 2044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2151 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2242 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2284 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2216 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2343 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8722 - f1: 0.8890 - val_loss: 0.2239 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2484 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 2051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2214 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2373 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2400 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2376 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2385 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8746 - f1: 0.8908 - val_loss: 0.2319 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 2057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2173 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8707 - f1: 0.8875 - val_loss: 0.2111 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 2059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2274 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2258 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8748 - f1: 0.8905 - val_loss: 0.2210 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 2062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8671 - f1: 0.8850 - val_loss: 0.2434 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 2063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2608 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 2064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8832 - val_loss: 0.2549 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2065/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3225 - acc: 0.8735 - f1: 0.89 - 0s 16us/sample - loss: 0.3211 - acc: 0.8736 - f1: 0.8898 - val_loss: 0.2286 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 2066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2267 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2665 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2260 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8740 - f1: 0.8907 - val_loss: 0.2352 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2169 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 2071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2519 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8654 - f1: 0.8840 - val_loss: 0.2240 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 2073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2182 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2074/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2405 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8683 - f1: 0.8863 - val_loss: 0.2267 - val_acc: 0.9616 - val_f1: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8715 - f1: 0.8880 - val_loss: 0.2219 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2077/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2246 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2230 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2268 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 2080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2286 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2133 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2871 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 2083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2338 - val_acc: 0.9681 - val_f1: 0.9686\n",
      "Epoch 2084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2131 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 2085/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2332 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2086/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2188 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2087/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2369 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 2088/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8684 - f1: 0.8852 - val_loss: 0.2194 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2089/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2428 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2169 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2354 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 2092/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3348 - acc: 0.8657 - f1: 0.8844 - val_loss: 0.2246 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 2093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2393 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2276 - val_acc: 0.9556 - val_f1: 0.9586\n",
      "Epoch 2095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2333 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2096/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8740 - f1: 0.8906 - val_loss: 0.2591 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2097/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2080 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 2098/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3269 - acc: 0.8708 - f1: 0.88 - 0s 16us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2090 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2099/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2242 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8740 - f1: 0.8910 - val_loss: 0.2655 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8677 - f1: 0.8850 - val_loss: 0.2380 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 2103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8697 - f1: 0.8876 - val_loss: 0.2317 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8857 - val_loss: 0.2352 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2429 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2340 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2107/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3189 - acc: 0.8755 - f1: 0.8919 - val_loss: 0.2388 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2108/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3319 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2368 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 2109/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2701 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 2110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8728 - f1: 0.8893 - val_loss: 0.2221 - val_acc: 0.9597 - val_f1: 0.9622\n",
      "Epoch 2111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8732 - f1: 0.8895 - val_loss: 0.2361 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2112/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2167 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2139 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2227 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 2116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2287 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2268 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2252 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 2119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2336 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2377 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 2121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8619 - f1: 0.8810 - val_loss: 0.2310 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2190 - val_acc: 0.9619 - val_f1: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2575 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2187 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2218 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2306 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2328 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 2128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2193 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 2129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2244 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2130/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8717 - f1: 0.8886 - val_loss: 0.2435 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 2131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8844 - val_loss: 0.2207 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 2132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2421 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2325 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8855 - val_loss: 0.2909 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 2135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2256 - val_acc: 0.9550 - val_f1: 0.9570\n",
      "Epoch 2136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2366 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 2137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8752 - f1: 0.8913 - val_loss: 0.2339 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 2138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2186 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2270 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2140/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2495 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2695 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 2142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2453 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8707 - f1: 0.8876 - val_loss: 0.2621 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8607 - f1: 0.8802 - val_loss: 0.2322 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 2145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2510 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8632 - f1: 0.8823 - val_loss: 0.2264 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 2147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2261 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2148/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3324 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2267 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2123 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2255 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2305 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8873 - val_loss: 0.2483 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 2153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2276 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 2154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2582 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8670 - f1: 0.8854 - val_loss: 0.2435 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2305 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2157/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3223 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2653 - val_acc: 0.9609 - val_f1: 0.9616\n",
      "Epoch 2158/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3319 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2388 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2159/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3312 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2464 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2160/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2491 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2161/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2233 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 2162/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2248 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2163/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3144 - acc: 0.8781 - f1: 0.89 - 0s 16us/sample - loss: 0.3156 - acc: 0.8775 - f1: 0.8931 - val_loss: 0.2299 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 2164/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2398 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 2165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2213 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8608 - f1: 0.8800 - val_loss: 0.2232 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2396 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 2168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2240 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2181 - val_acc: 0.9603 - val_f1: 0.9621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2279 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 2171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3165 - acc: 0.8767 - f1: 0.8927 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2320 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2173/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2422 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 2174/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3273 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2309 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 2175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2301 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2328 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 2177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2319 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2189 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2146 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2479 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8843 - val_loss: 0.2146 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2409 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 2184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8721 - f1: 0.8887 - val_loss: 0.2446 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 2185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2244 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8725 - f1: 0.8892 - val_loss: 0.2379 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8654 - f1: 0.8839 - val_loss: 0.2360 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2236 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8657 - f1: 0.8841 - val_loss: 0.2255 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8848 - val_loss: 0.2281 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 2191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2321 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2192/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2269 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2193/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8846 - val_loss: 0.2254 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2194/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3508 - acc: 0.8584 - f1: 0.8786 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 2195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2335 - val_acc: 0.9688 - val_f1: 0.9694\n",
      "Epoch 2196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2305 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2297 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2330 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 2199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2351 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8691 - f1: 0.8860 - val_loss: 0.2128 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8680 - f1: 0.8854 - val_loss: 0.2249 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 2202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8711 - f1: 0.8880 - val_loss: 0.2351 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2258 - val_acc: 0.9684 - val_f1: 0.9698\n",
      "Epoch 2204/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2299 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2205/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2270 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2206/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2346 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2372 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 2208/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2484 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 2209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2554 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 2210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2262 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2413 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2212/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2198 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 2213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2373 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2214/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2325 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8623 - f1: 0.8816 - val_loss: 0.2209 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2343 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2217/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2239 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2530 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2181 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8640 - f1: 0.8828 - val_loss: 0.2182 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2200 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2232 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2290 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2401 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2230 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8869 - val_loss: 0.2389 - val_acc: 0.9678 - val_f1: 0.9683\n",
      "Epoch 2228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2409 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8640 - f1: 0.8824 - val_loss: 0.2326 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8721 - f1: 0.8888 - val_loss: 0.2351 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 2231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2505 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 2232/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2366 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 2233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2330 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2744 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 2235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2282 - val_acc: 0.9509 - val_f1: 0.9542\n",
      "Epoch 2236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2512 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2226 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2238/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2800 - val_acc: 0.9609 - val_f1: 0.9615\n",
      "Epoch 2239/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3283 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2471 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2353 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2314 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2700 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2243/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8711 - f1: 0.8878 - val_loss: 0.2410 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2668 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2529 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2246/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3326 - acc: 0.8674 - f1: 0.8851 - val_loss: 0.2719 - val_acc: 0.9200 - val_f1: 0.9278\n",
      "Epoch 2247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8612 - f1: 0.8807 - val_loss: 0.2218 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2248/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2359 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2273 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2289 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2684 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 2252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8708 - f1: 0.8873 - val_loss: 0.2557 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 2253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2220 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 2254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2308 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 2255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2329 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 2256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8672 - f1: 0.8853 - val_loss: 0.2211 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 2257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8637 - f1: 0.8825 - val_loss: 0.2238 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2105 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2251 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2504 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 2261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8754 - f1: 0.8915 - val_loss: 0.2451 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2394 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 2263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2384 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 2264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2353 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2492 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 2266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2329 - val_acc: 0.9672 - val_f1: 0.9675\n",
      "Epoch 2267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8621 - f1: 0.8809 - val_loss: 0.2540 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 2268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2305 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 2269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2388 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2121 - val_acc: 0.9603 - val_f1: 0.9631\n",
      "Epoch 2271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8632 - f1: 0.8820 - val_loss: 0.2644 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8650 - f1: 0.8837 - val_loss: 0.2301 - val_acc: 0.9675 - val_f1: 0.9692\n",
      "Epoch 2273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2150 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2508 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8747 - f1: 0.8909 - val_loss: 0.2351 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2274 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2310 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2095 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8696 - f1: 0.8866 - val_loss: 0.2201 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 2280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8681 - f1: 0.8863 - val_loss: 0.2458 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2568 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2282/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2419 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2490 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2161 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8892 - val_loss: 0.2664 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8645 - f1: 0.8828 - val_loss: 0.2367 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 2287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2531 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2135 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 2289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8687 - f1: 0.8860 - val_loss: 0.2222 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2145 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 2291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8634 - f1: 0.8819 - val_loss: 0.2259 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2235 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8879 - val_loss: 0.2386 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8691 - f1: 0.8861 - val_loss: 0.2394 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2282 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2499 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2163 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 2298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8655 - f1: 0.8841 - val_loss: 0.2469 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 2299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2226 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 2300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2221 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2487 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8667 - f1: 0.8844 - val_loss: 0.2663 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 2303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2237 - val_acc: 0.9534 - val_f1: 0.9558\n",
      "Epoch 2304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2114 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 2305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8666 - f1: 0.8844 - val_loss: 0.2800 - val_acc: 0.9616 - val_f1: 0.9620\n",
      "Epoch 2306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2427 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 2307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2532 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8651 - f1: 0.8840 - val_loss: 0.2445 - val_acc: 0.9341 - val_f1: 0.9394\n",
      "Epoch 2309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2204 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8746 - f1: 0.8905 - val_loss: 0.2366 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 2311/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8630 - f1: 0.8819 - val_loss: 0.2150 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2598 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2259 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2287 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2204 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8844 - val_loss: 0.2365 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2327 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 2318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8889 - val_loss: 0.2445 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 2319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2364 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 2320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8854 - val_loss: 0.2420 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 2321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8766 - f1: 0.8925 - val_loss: 0.2212 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8858 - val_loss: 0.2321 - val_acc: 0.9547 - val_f1: 0.9570\n",
      "Epoch 2323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2265 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8758 - f1: 0.8921 - val_loss: 0.2561 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8701 - f1: 0.8868 - val_loss: 0.2156 - val_acc: 0.9553 - val_f1: 0.9579\n",
      "Epoch 2326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8696 - f1: 0.8868 - val_loss: 0.2121 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2347 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 2328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2334 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 2329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2550 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2242 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8637 - f1: 0.8828 - val_loss: 0.2309 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2326 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 2333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2478 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2288 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8718 - f1: 0.8884 - val_loss: 0.2451 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2472 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2350 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2373 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8616 - f1: 0.8809 - val_loss: 0.2437 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 2340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8711 - f1: 0.8877 - val_loss: 0.2346 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 2341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2548 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2242 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2383 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 2344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2400 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2414 - val_acc: 0.9684 - val_f1: 0.9691\n",
      "Epoch 2346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2381 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 2347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2158 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 2348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2240 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2508 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2281 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2371 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 2352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2490 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.2478 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2262 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2179 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 2356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2292 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 2357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2198 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 2358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2477 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 2359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2486 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8882 - val_loss: 0.2447 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2412 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 2363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2917 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 2364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2494 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2417 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8708 - f1: 0.8871 - val_loss: 0.2151 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2353 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8662 - f1: 0.8844 - val_loss: 0.2591 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 2369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2311 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2196 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2302 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2215 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8607 - f1: 0.8811 - val_loss: 0.2167 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2374/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8862 - val_loss: 0.2368 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 2375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2332 - val_acc: 0.9619 - val_f1: 0.9622\n",
      "Epoch 2376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2343 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2271 - val_acc: 0.9528 - val_f1: 0.9554\n",
      "Epoch 2378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2350 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2200 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8636 - f1: 0.8830 - val_loss: 0.2968 - val_acc: 0.9597 - val_f1: 0.9606\n",
      "Epoch 2381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8638 - f1: 0.8825 - val_loss: 0.2285 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 2382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2338 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8752 - f1: 0.8915 - val_loss: 0.2346 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 2384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2361 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 2385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2162 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2480 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 2388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2422 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8884 - val_loss: 0.2400 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 2390/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2204 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2151 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8648 - f1: 0.8835 - val_loss: 0.2252 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8657 - f1: 0.8842 - val_loss: 0.2240 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 2394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8667 - f1: 0.8843 - val_loss: 0.2157 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 2395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2365 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 2396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8626 - f1: 0.8821 - val_loss: 0.2099 - val_acc: 0.9603 - val_f1: 0.9626\n",
      "Epoch 2397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8636 - f1: 0.8824 - val_loss: 0.2124 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2212 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2512 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 2400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2447 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.2428 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 2402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2579 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2334 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2616 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 2405/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8901 - val_loss: 0.2259 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2300 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 2407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2496 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2459 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2270 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8642 - f1: 0.8833 - val_loss: 0.2317 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8646 - f1: 0.8828 - val_loss: 0.2323 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 2413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8678 - f1: 0.8856 - val_loss: 0.2605 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8743 - f1: 0.8909 - val_loss: 0.2479 - val_acc: 0.9644 - val_f1: 0.9646\n",
      "Epoch 2415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2183 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2323 - val_acc: 0.9488 - val_f1: 0.9519\n",
      "Epoch 2417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8591 - f1: 0.8790 - val_loss: 0.2261 - val_acc: 0.9544 - val_f1: 0.9569\n",
      "Epoch 2418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2318 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2419 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2716 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 2421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2521 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2205 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2509 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2704 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 2425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2607 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 2426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2360 - val_acc: 0.9663 - val_f1: 0.9679\n",
      "Epoch 2427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2378 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8648 - f1: 0.8834 - val_loss: 0.2534 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 2429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8563 - f1: 0.8768 - val_loss: 0.2392 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 2430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2332 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 2431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2380 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2232 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8676 - f1: 0.8850 - val_loss: 0.2160 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2351 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 2435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2418 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2676 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 2437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2373 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 2438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2188 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3096 - acc: 0.8813 - f1: 0.8962 - val_loss: 0.2372 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2185 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 2441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2297 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2448 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 2443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2604 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 2444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2291 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 2446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2414 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2300 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8595 - f1: 0.8791 - val_loss: 0.2288 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8672 - f1: 0.8851 - val_loss: 0.2337 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 2450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8639 - f1: 0.8830 - val_loss: 0.2286 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8681 - f1: 0.8855 - val_loss: 0.2447 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2825 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 2453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2189 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 2454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2438 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2420 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2442 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 2458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8850 - val_loss: 0.2293 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 2459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2443 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2164 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 2461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2098 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8855 - val_loss: 0.2464 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8675 - f1: 0.8848 - val_loss: 0.2221 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8689 - f1: 0.8869 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8895 - val_loss: 0.2477 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8696 - f1: 0.8871 - val_loss: 0.2272 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3135 - acc: 0.8789 - f1: 0.8941 - val_loss: 0.2600 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2342 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 2470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2197 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2236 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2232 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2243 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 2474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2289 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2377 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8606 - f1: 0.8799 - val_loss: 0.2384 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 2478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8822 - val_loss: 0.2614 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2462 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 2480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2331 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2349 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8739 - f1: 0.8901 - val_loss: 0.2194 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8600 - f1: 0.8793 - val_loss: 0.2188 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2327 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2404 - val_acc: 0.9669 - val_f1: 0.9672\n",
      "Epoch 2486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2264 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8761 - f1: 0.8922 - val_loss: 0.2507 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 2488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2405 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 2489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2242 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8860 - val_loss: 0.2310 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 2491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2366 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2295 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2459 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2366 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 2495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2622 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8651 - f1: 0.8838 - val_loss: 0.2379 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2455 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2789 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 2499/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8665 - f1: 0.8848 - val_loss: 0.2169 - val_acc: 0.9619 - val_f1: 0.9642\n",
      "Epoch 2500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8680 - f1: 0.8863 - val_loss: 0.2415 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2130 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8642 - f1: 0.8829 - val_loss: 0.2279 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2503/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2311 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2351 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2300 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 2506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2172 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2483 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8717 - f1: 0.8887 - val_loss: 0.2367 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2887 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 2510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3124 - acc: 0.8786 - f1: 0.8941 - val_loss: 0.2596 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2264 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2184 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 2513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2367 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2502 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 2515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2357 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 2516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 2517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8668 - f1: 0.8849 - val_loss: 0.2430 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 2518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2228 - val_acc: 0.9563 - val_f1: 0.9590\n",
      "Epoch 2519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2197 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2469 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2337 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2458 - val_acc: 0.9684 - val_f1: 0.9694\n",
      "Epoch 2524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2339 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 2525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2348 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2263 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2504 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2276 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2315 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 2530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2495 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 2531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2391 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2472 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 2533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2324 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 2534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2348 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2387 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2352 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2624 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 2538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2361 - val_acc: 0.9663 - val_f1: 0.9679\n",
      "Epoch 2539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2384 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2488 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 2541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8646 - f1: 0.8834 - val_loss: 0.2261 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8901 - val_loss: 0.2374 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8762 - f1: 0.8917 - val_loss: 0.2388 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 2544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2303 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 2545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2184 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2238 - val_acc: 0.9538 - val_f1: 0.9567\n",
      "Epoch 2547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2373 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2342 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 2549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2481 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2178 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2667 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2350 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2450 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2435 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8854 - val_loss: 0.2437 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2338 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2261 - val_acc: 0.9569 - val_f1: 0.9592\n",
      "Epoch 2559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2314 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 2560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2264 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2421 - val_acc: 0.9688 - val_f1: 0.9703\n",
      "Epoch 2562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8738 - f1: 0.8900 - val_loss: 0.2299 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2369 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2341 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2571 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2185 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2125 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2301 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2344 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8755 - f1: 0.8916 - val_loss: 0.2139 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 2571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2182 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8709 - f1: 0.8877 - val_loss: 0.2507 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2341 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 2574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2333 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 2575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2160 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2290 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2386 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2947 - val_acc: 0.9616 - val_f1: 0.9617\n",
      "Epoch 2579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2264 - val_acc: 0.9538 - val_f1: 0.9565\n",
      "Epoch 2580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2281 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2968 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2262 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 2583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2234 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 2584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2592 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2080 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 2586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 2587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2241 - val_acc: 0.9594 - val_f1: 0.9610\n",
      "Epoch 2588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2188 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2379 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8884 - val_loss: 0.2306 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8764 - f1: 0.8921 - val_loss: 0.2408 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8643 - f1: 0.8831 - val_loss: 0.2298 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2593/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8723 - f1: 0.8886 - val_loss: 0.2276 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2243 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2378 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2260 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 2597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2398 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8752 - f1: 0.8918 - val_loss: 0.2572 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2337 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2387 - val_acc: 0.9594 - val_f1: 0.9609\n",
      "Epoch 2601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2708 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 2602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2622 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 2603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2252 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 2604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2490 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8724 - f1: 0.8897 - val_loss: 0.2393 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8757 - f1: 0.8911 - val_loss: 0.2363 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2392 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8718 - f1: 0.8884 - val_loss: 0.2381 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 2609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2506 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2374 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2484 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2312 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8729 - f1: 0.8893 - val_loss: 0.2357 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 2614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2480 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2621 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 2616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2496 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 2617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2294 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8602 - f1: 0.8796 - val_loss: 0.2352 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 2619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2230 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8633 - f1: 0.8825 - val_loss: 0.2511 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2772 - val_acc: 0.9591 - val_f1: 0.9603\n",
      "Epoch 2622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2517 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 2623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2290 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2248 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 2625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2276 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 2626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2382 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2552 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 2628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2332 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2482 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 2630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8751 - f1: 0.8916 - val_loss: 0.2232 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8657 - f1: 0.8841 - val_loss: 0.2466 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2375 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8899 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8668 - f1: 0.8850 - val_loss: 0.2519 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2182 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2365 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 2637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2202 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2329 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2505 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2273 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8744 - f1: 0.8911 - val_loss: 0.2448 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2845 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 2644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2348 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 2645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2344 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2326 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 2647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2279 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2625 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 2649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8674 - f1: 0.8857 - val_loss: 0.2200 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 2650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8634 - f1: 0.8822 - val_loss: 0.2270 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2313 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8646 - f1: 0.8830 - val_loss: 0.2439 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2337 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 2654/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2306 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8674 - f1: 0.8851 - val_loss: 0.2415 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2486 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2343 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2360 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2631 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8716 - f1: 0.8883 - val_loss: 0.2362 - val_acc: 0.9694 - val_f1: 0.9710\n",
      "Epoch 2661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8747 - f1: 0.8917 - val_loss: 0.2805 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 2662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2131 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 2663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8706 - f1: 0.8874 - val_loss: 0.2291 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2396 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8652 - f1: 0.8836 - val_loss: 0.2195 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 2666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2466 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2375 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2298 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 2669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8753 - f1: 0.8916 - val_loss: 0.2317 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 2670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2875 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2236 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8651 - f1: 0.8833 - val_loss: 0.2510 - val_acc: 0.9597 - val_f1: 0.9612\n",
      "Epoch 2673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2494 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2615 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 2675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2348 - val_acc: 0.9553 - val_f1: 0.9574\n",
      "Epoch 2676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8685 - f1: 0.8857 - val_loss: 0.2395 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2411 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2307 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2355 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 2680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2596 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.3258 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 2682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2284 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8650 - f1: 0.8840 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2527 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2212 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2313 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2687/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8689 - f1: 0.8863 - val_loss: 0.2531 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 2688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2293 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2184 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 2690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.2368 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2384 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2394 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2384 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8748 - f1: 0.8913 - val_loss: 0.2364 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 2695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2239 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8723 - f1: 0.8887 - val_loss: 0.2361 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2421 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 2701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2364 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2197 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2227 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 2704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2225 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8693 - f1: 0.8865 - val_loss: 0.2520 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8711 - f1: 0.8884 - val_loss: 0.2350 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2333 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2396 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8738 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2546 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2184 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2712/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2357 - val_acc: 0.9594 - val_f1: 0.9601\n",
      "Epoch 2713/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2283 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2714/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2395 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2715/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3335 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2313 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2287 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 2717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2498 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2718/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2350 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2719/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2397 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2720/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3357 - acc: 0.8673 - f1: 0.88 - 0s 16us/sample - loss: 0.3327 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2350 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2188 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2592 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 2723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2589 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 2724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2484 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2293 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 2726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8732 - f1: 0.8903 - val_loss: 0.2396 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 2727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2402 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 2728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8651 - f1: 0.8840 - val_loss: 0.2796 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8844 - val_loss: 0.2424 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2730/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3179 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2329 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2211 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 2732/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3242 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2240 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2486 - val_acc: 0.9678 - val_f1: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8766 - f1: 0.8923 - val_loss: 0.2609 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2309 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 2736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8886 - val_loss: 0.2255 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2193 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2478 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 2739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2524 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2485 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 2741/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2307 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8701 - f1: 0.8877 - val_loss: 0.2374 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2254 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 2744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3392 - acc: 0.8643 - f1: 0.8828 - val_loss: 0.2487 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2432 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 2746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2480 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 2747/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3322 - acc: 0.8686 - f1: 0.8858 - val_loss: 0.2224 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 2748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2749/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3236 - acc: 0.8719 - f1: 0.8894 - val_loss: 0.2335 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2155 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 2751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2130 - val_acc: 0.9597 - val_f1: 0.9619\n",
      "Epoch 2752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2260 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 2753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2470 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2837 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2202 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 2756/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3289 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2215 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8711 - f1: 0.8879 - val_loss: 0.2252 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 2758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2410 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2759/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.3001 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 2760/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2465 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2532 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 2762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2242 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 2763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2670 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 2765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2309 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2766/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2328 - val_acc: 0.9609 - val_f1: 0.9633\n",
      "Epoch 2767/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3310 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2219 - val_acc: 0.9553 - val_f1: 0.9578\n",
      "Epoch 2768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2215 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2105 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 2770/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8865 - val_loss: 0.2296 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2771/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2727 - val_acc: 0.9647 - val_f1: 0.9650\n",
      "Epoch 2772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2203 - val_acc: 0.9631 - val_f1: 0.9651\n",
      "Epoch 2773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2504 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2774/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2460 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 2775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2345 - val_acc: 0.9666 - val_f1: 0.9684\n",
      "Epoch 2776/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2773 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 2777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2397 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2778/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2301 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 2779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2171 - val_acc: 0.9603 - val_f1: 0.9617\n",
      "Epoch 2780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2119 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 2781/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8673 - f1: 0.8847 - val_loss: 0.2284 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2271 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 2783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2650 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2611 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 2785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2269 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Epoch 2786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2258 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 2787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8735 - f1: 0.8905 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 2788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2282 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2267 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2416 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 2791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2521 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2618 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8730 - f1: 0.8894 - val_loss: 0.2503 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8879 - val_loss: 0.2264 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 2795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8709 - f1: 0.8878 - val_loss: 0.2562 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2358 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 2797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2254 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8814 - val_loss: 0.2255 - val_acc: 0.9684 - val_f1: 0.9692\n",
      "Epoch 2799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8639 - f1: 0.8826 - val_loss: 0.2176 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 2800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2307 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2376 - val_acc: 0.9678 - val_f1: 0.9695\n",
      "Epoch 2802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8728 - f1: 0.8898 - val_loss: 0.2323 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2271 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 2804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2458 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2255 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 2806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8684 - f1: 0.8858 - val_loss: 0.2200 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8686 - f1: 0.8859 - val_loss: 0.2240 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 2808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2378 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 2809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2304 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2122 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2198 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2229 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2958 - val_acc: 0.9647 - val_f1: 0.9647\n",
      "Epoch 2815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2297 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8667 - f1: 0.8852 - val_loss: 0.2530 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 2817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2354 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 2818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8760 - f1: 0.8920 - val_loss: 0.2212 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2202 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 2820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2433 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 2821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2444 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8764 - f1: 0.8923 - val_loss: 0.2264 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 2823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2293 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 2824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8896 - val_loss: 0.2310 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2347 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8731 - f1: 0.8895 - val_loss: 0.2458 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2484 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8723 - f1: 0.8887 - val_loss: 0.2579 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2336 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8736 - f1: 0.8899 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8635 - f1: 0.8826 - val_loss: 0.2506 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2472 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.3032 - val_acc: 0.9603 - val_f1: 0.9611\n",
      "Epoch 2836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8649 - f1: 0.8835 - val_loss: 0.2563 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2284 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2188 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 2839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2409 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8666 - f1: 0.8857 - val_loss: 0.2273 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2514 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2190 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2273 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2435 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8615 - f1: 0.8811 - val_loss: 0.2375 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2647 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 2848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8758 - f1: 0.8921 - val_loss: 0.2299 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 2849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2318 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2325 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2499 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8699 - f1: 0.8879 - val_loss: 0.2583 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2446 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2371 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2251 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 2856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2461 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 2857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2405 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2656 - val_acc: 0.9544 - val_f1: 0.9560\n",
      "Epoch 2859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8661 - f1: 0.8840 - val_loss: 0.2322 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2216 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 2861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2293 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2447 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2505 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2382 - val_acc: 0.9688 - val_f1: 0.9695\n",
      "Epoch 2865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2473 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3119 - acc: 0.8793 - f1: 0.8946 - val_loss: 0.2499 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2628 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 2868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2377 - val_acc: 0.9656 - val_f1: 0.9658\n",
      "Epoch 2869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2563 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2436 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 2871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2508 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2404 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8725 - f1: 0.8893 - val_loss: 0.2371 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 2874/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3342 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2364 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2875/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2261 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2485 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8618 - f1: 0.8808 - val_loss: 0.2188 - val_acc: 0.9569 - val_f1: 0.9590\n",
      "Epoch 2879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8692 - f1: 0.8872 - val_loss: 0.2458 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8706 - f1: 0.8883 - val_loss: 0.2534 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2477 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 2882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2266 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2366 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8703 - f1: 0.8874 - val_loss: 0.2462 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 2885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2815 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2469 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 2887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8758 - f1: 0.8919 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8722 - f1: 0.8889 - val_loss: 0.2454 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 2889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2509 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2517 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2312 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2825 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2357 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 2894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2744 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 2895/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8850 - val_loss: 0.2454 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2386 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2337 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2307 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2583 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 2900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2731 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 2901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2655 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2365 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2903/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2441 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2317 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 2905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8742 - f1: 0.8908 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2488 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8699 - f1: 0.8877 - val_loss: 0.2472 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 2908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8644 - f1: 0.8827 - val_loss: 0.2310 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 2909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2299 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2210 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 2911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2395 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8685 - f1: 0.8869 - val_loss: 0.2310 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 2913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 2914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2465 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 2915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2283 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2591 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2464 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2281 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2686 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 2920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2388 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2450 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2303 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 2923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2558 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2366 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 2925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2345 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2367 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2263 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2442 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2794 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 2930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8679 - f1: 0.8861 - val_loss: 0.2317 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2294 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 2932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2526 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8922 - val_loss: 0.2494 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8751 - f1: 0.8918 - val_loss: 0.2266 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2174 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 2936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8766 - f1: 0.8924 - val_loss: 0.2399 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 2937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2609 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2415 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2477 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 2940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2320 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 2941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2869 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2942/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2367 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2302 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 2944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2276 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2838 - val_acc: 0.9634 - val_f1: 0.9637\n",
      "Epoch 2946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2597 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2469 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2518 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 2949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2487 - val_acc: 0.9366 - val_f1: 0.9407\n",
      "Epoch 2950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8621 - f1: 0.8813 - val_loss: 0.2293 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 2951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8863 - val_loss: 0.2511 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 2952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2380 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 2953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2724 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2571 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 2955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2286 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 2956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2247 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2281 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 2958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2282 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 2959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2278 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2498 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 2961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2490 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2471 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2437 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2607 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2539 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 2967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2542 - val_acc: 0.9681 - val_f1: 0.9696\n",
      "Epoch 2968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2566 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 2969/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2427 - val_acc: 0.9531 - val_f1: 0.9555\n",
      "Epoch 2970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2331 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2598 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2481 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 2973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2511 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2635 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2400 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2558 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2577 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8873 - val_loss: 0.2363 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2443 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2462 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2397 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 2982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2346 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 2983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8648 - f1: 0.8837 - val_loss: 0.2388 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8679 - f1: 0.8852 - val_loss: 0.2458 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2420 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2986/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3277 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2169 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 2987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2179 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2320 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 2989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8739 - f1: 0.8902 - val_loss: 0.2808 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2199 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 2991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2513 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2129 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 2993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2320 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 2994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8718 - f1: 0.8885 - val_loss: 0.2654 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2439 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2381 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 2997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2265 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2663 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 2999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2264 - val_acc: 0.9591 - val_f1: 0.9609\n",
      "Epoch 3000/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2377 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 3001/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3182 - acc: 0.8753 - f1: 0.8910 - val_loss: 0.2490 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3002/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2706 - val_acc: 0.9631 - val_f1: 0.9637\n",
      "Epoch 3003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2269 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 3004/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3486 - acc: 0.8616 - f1: 0.8811 - val_loss: 0.2519 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3005/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2752 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2296 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8742 - f1: 0.8908 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3008/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3168 - acc: 0.8760 - f1: 0.8921 - val_loss: 0.2376 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 3009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2502 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3010/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2213 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 3011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2358 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 3012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2317 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3013/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2304 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2487 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 3015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2464 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2454 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 3017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2449 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2408 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8873 - val_loss: 0.2276 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2673 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 3021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2330 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2391 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.3286 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 3024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2289 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2264 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2474 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2287 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2296 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2693 - val_acc: 0.9541 - val_f1: 0.9561\n",
      "Epoch 3030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2468 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3031/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2461 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2401 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2625 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 3034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2207 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3035/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3036/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8912 - val_loss: 0.2166 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3037/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2451 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3038/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2596 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2609 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2340 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2122 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 3042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8637 - f1: 0.8826 - val_loss: 0.2328 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2829 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 3044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2791 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 3045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2379 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3046/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3304 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2330 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 3047/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8899 - val_loss: 0.2304 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3048/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3183 - acc: 0.8754 - f1: 0.8919 - val_loss: 0.2376 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 3049/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2476 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3050/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3257 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2261 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3051/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2218 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 3052/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2439 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 3053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2710 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2669 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3055/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2334 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3056/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8675 - f1: 0.8860 - val_loss: 0.2276 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3057/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2407 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8724 - f1: 0.8893 - val_loss: 0.2467 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2318 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8678 - f1: 0.8862 - val_loss: 0.2423 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8711 - f1: 0.8878 - val_loss: 0.2220 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 3063/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2439 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3173 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2410 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2338 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2386 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2417 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2412 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3069/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8743 - f1: 0.8905 - val_loss: 0.2485 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2506 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2582 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2502 - val_acc: 0.9588 - val_f1: 0.9600\n",
      "Epoch 3073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2504 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3074/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8635 - f1: 0.8823 - val_loss: 0.2749 - val_acc: 0.9663 - val_f1: 0.9664\n",
      "Epoch 3075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2290 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2297 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 3077/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2413 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2840 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 3079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2904 - val_acc: 0.9600 - val_f1: 0.9609\n",
      "Epoch 3080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8624 - f1: 0.8816 - val_loss: 0.2917 - val_acc: 0.9603 - val_f1: 0.9602\n",
      "Epoch 3081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2404 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2486 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8772 - f1: 0.8930 - val_loss: 0.2539 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2652 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3085/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2306 - val_acc: 0.9694 - val_f1: 0.9701\n",
      "Epoch 3086/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2301 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3087/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2647 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3088/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3273 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2386 - val_acc: 0.9709 - val_f1: 0.9722\n",
      "Epoch 3089/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2466 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2709 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 3091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8714 - f1: 0.8880 - val_loss: 0.2239 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 3092/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2485 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2537 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2374 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2270 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 3096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2231 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3097/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2820 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 3098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8868 - val_loss: 0.2486 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2212 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2221 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 3101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8657 - f1: 0.8837 - val_loss: 0.2645 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2340 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8735 - f1: 0.8901 - val_loss: 0.2288 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2464 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8669 - f1: 0.8853 - val_loss: 0.2321 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2366 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2351 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2317 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8858 - val_loss: 0.2453 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 3110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2339 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8725 - f1: 0.8889 - val_loss: 0.2361 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 3112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2175 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 3113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2289 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2458 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 3115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2267 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 3116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2506 - val_acc: 0.9625 - val_f1: 0.9628\n",
      "Epoch 3117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2561 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2358 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 3119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2344 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2363 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8672 - f1: 0.8853 - val_loss: 0.2366 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 3122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8632 - f1: 0.8820 - val_loss: 0.2363 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 3123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2589 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2527 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2501 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 3127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2426 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2302 - val_acc: 0.9578 - val_f1: 0.9602\n",
      "Epoch 3129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2257 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 3130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2429 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8656 - f1: 0.8845 - val_loss: 0.2691 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2570 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8709 - f1: 0.8878 - val_loss: 0.2218 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2452 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 3135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8764 - f1: 0.8928 - val_loss: 0.2474 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2253 - val_acc: 0.9572 - val_f1: 0.9590\n",
      "Epoch 3137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2274 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 3138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2374 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8693 - f1: 0.8866 - val_loss: 0.2279 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2241 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8852 - val_loss: 0.2268 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 3142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2316 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2655 - val_acc: 0.9631 - val_f1: 0.9635\n",
      "Epoch 3146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8704 - f1: 0.8880 - val_loss: 0.2292 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 3147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2171 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2187 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 3149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2392 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 3150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2510 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2424 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 3152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2129 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 3153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8667 - f1: 0.8848 - val_loss: 0.2398 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8754 - f1: 0.8919 - val_loss: 0.2745 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2413 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2255 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3157/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2291 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2573 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8740 - f1: 0.8910 - val_loss: 0.2742 - val_acc: 0.9613 - val_f1: 0.9622\n",
      "Epoch 3160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2449 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2393 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2656 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2504 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2468 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8678 - f1: 0.8862 - val_loss: 0.2509 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2654 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 3167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2659 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8692 - f1: 0.8870 - val_loss: 0.2284 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2637 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2267 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2281 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2707 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2472 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.2506 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2533 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8627 - f1: 0.8821 - val_loss: 0.2392 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 3178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2526 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2507 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3149 - acc: 0.8786 - f1: 0.8944 - val_loss: 0.2459 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8636 - f1: 0.8825 - val_loss: 0.2292 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2348 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2348 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 3184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2444 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2713 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 3186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2767 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2417 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 3188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8731 - f1: 0.8894 - val_loss: 0.2418 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8664 - f1: 0.8848 - val_loss: 0.2606 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 3190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8732 - f1: 0.8896 - val_loss: 0.2490 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2272 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8773 - f1: 0.8927 - val_loss: 0.2336 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2456 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2427 - val_acc: 0.9697 - val_f1: 0.9703\n",
      "Epoch 3195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2495 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 3196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2421 - val_acc: 0.9694 - val_f1: 0.9710\n",
      "Epoch 3197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2122 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2372 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8749 - f1: 0.8909 - val_loss: 0.2665 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2565 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8688 - f1: 0.8867 - val_loss: 0.2423 - val_acc: 0.9656 - val_f1: 0.9660\n",
      "Epoch 3202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2524 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2500 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2643 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2425 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 3206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2498 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 3207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2397 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2247 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8763 - f1: 0.8928 - val_loss: 0.2463 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2293 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2589 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2529 - val_acc: 0.9666 - val_f1: 0.9669\n",
      "Epoch 3213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8691 - f1: 0.8873 - val_loss: 0.2311 - val_acc: 0.9541 - val_f1: 0.9571\n",
      "Epoch 3214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.2193 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 3215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2542 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2392 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2424 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2569 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2338 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2266 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2445 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3222/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3289 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2561 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2354 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 3224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2558 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 3225/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3164 - acc: 0.8765 - f1: 0.8928 - val_loss: 0.2526 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3226/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2211 - val_acc: 0.9616 - val_f1: 0.9640\n",
      "Epoch 3227/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2265 - val_acc: 0.9575 - val_f1: 0.9596\n",
      "Epoch 3228/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2349 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8740 - f1: 0.8906 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3230/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2355 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3231/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2850 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8678 - f1: 0.8851 - val_loss: 0.2251 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2291 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2439 - val_acc: 0.9669 - val_f1: 0.9673\n",
      "Epoch 3235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8868 - val_loss: 0.2200 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2361 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2444 - val_acc: 0.9638 - val_f1: 0.9640\n",
      "Epoch 3238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2223 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3239/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2227 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3240/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3205 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2359 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 3241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2415 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8706 - f1: 0.8881 - val_loss: 0.2312 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 3243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2198 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2379 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8858 - val_loss: 0.2165 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2627 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2278 - val_acc: 0.9547 - val_f1: 0.9570\n",
      "Epoch 3248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2307 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 3249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2453 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2205 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3251/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8871 - val_loss: 0.2364 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 3252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8685 - f1: 0.8857 - val_loss: 0.2288 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2406 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2401 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2280 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 3256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8715 - f1: 0.8883 - val_loss: 0.2755 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2367 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8725 - f1: 0.8899 - val_loss: 0.2589 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2285 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2340 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2386 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 3262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2491 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8882 - val_loss: 0.3088 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2616 - val_acc: 0.9653 - val_f1: 0.9657\n",
      "Epoch 3265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8867 - val_loss: 0.2501 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2607 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3267/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2408 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2218 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 3269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8625 - f1: 0.8815 - val_loss: 0.2655 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3270/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2388 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3271/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3428 - acc: 0.8616 - f1: 0.8812 - val_loss: 0.2577 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 3272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8762 - f1: 0.8918 - val_loss: 0.2508 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 3273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8692 - f1: 0.8872 - val_loss: 0.2175 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2652 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 3276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8702 - f1: 0.8871 - val_loss: 0.2464 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2673 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3278/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2408 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2301 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 3280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2469 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2183 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 3282/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2333 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 3283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2529 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2370 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 3285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8816 - val_loss: 0.2311 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 3286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2546 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 3287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2743 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3288/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2717 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3146 - acc: 0.8781 - f1: 0.8937 - val_loss: 0.2486 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2517 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 3291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2490 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3292/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2805 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3293/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2564 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 3294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8682 - f1: 0.8857 - val_loss: 0.2501 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2389 - val_acc: 0.9663 - val_f1: 0.9685\n",
      "Epoch 3296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2600 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2268 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 3298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2456 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2396 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2496 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2276 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2476 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2444 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8746 - f1: 0.8908 - val_loss: 0.2713 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2694 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 3306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2367 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 3307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2563 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2388 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8656 - f1: 0.8842 - val_loss: 0.2205 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 3310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2505 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2439 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8617 - f1: 0.8803 - val_loss: 0.2239 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2361 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2351 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2108 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2474 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2553 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2688 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 3319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2451 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2595 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2606 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 3323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8718 - f1: 0.8885 - val_loss: 0.2507 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2524 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 3325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2656 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2272 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2314 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2493 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8890 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2411 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2380 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2534 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 3333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2708 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9669\n",
      "Epoch 3335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2606 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2574 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2578 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2335 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2362 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2697 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2716 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2301 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2701 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8750 - f1: 0.8915 - val_loss: 0.2517 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3345/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2356 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 3346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8749 - f1: 0.8910 - val_loss: 0.2380 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8876 - val_loss: 0.2371 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8747 - f1: 0.8915 - val_loss: 0.2381 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8747 - f1: 0.8914 - val_loss: 0.2493 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 3350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2371 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2558 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8821 - val_loss: 0.2407 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2536 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2516 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2309 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2549 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 3357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8673 - f1: 0.8859 - val_loss: 0.2616 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8750 - f1: 0.8913 - val_loss: 0.2437 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 3359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2228 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 3360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2602 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2602 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8750 - f1: 0.8917 - val_loss: 0.2476 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2452 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2601 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2606 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8758 - f1: 0.8920 - val_loss: 0.2824 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 3367/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3280 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2424 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3368/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2579 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2404 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2475 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2432 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2308 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2330 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8839 - val_loss: 0.2618 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 3375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2198 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8651 - f1: 0.8833 - val_loss: 0.2312 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2352 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8748 - f1: 0.8913 - val_loss: 0.2327 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8899 - val_loss: 0.2446 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2276 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2266 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2888 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2360 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 3384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2624 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2574 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 3386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8672 - f1: 0.8850 - val_loss: 0.2953 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 3387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2424 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8769 - f1: 0.8931 - val_loss: 0.2793 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8755 - f1: 0.8915 - val_loss: 0.2370 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2447 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 3391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2248 - val_acc: 0.9584 - val_f1: 0.9602\n",
      "Epoch 3392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2460 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2445 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 3394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2544 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8673 - f1: 0.8857 - val_loss: 0.2483 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2477 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2353 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2386 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 3399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2351 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2401 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2592 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2281 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 3403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8683 - f1: 0.8863 - val_loss: 0.2568 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8909 - val_loss: 0.2331 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2521 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8886 - val_loss: 0.2396 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 3407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2273 - val_acc: 0.9581 - val_f1: 0.9605\n",
      "Epoch 3408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2359 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2526 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2908 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 3411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2391 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8858 - val_loss: 0.2372 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8688 - f1: 0.8866 - val_loss: 0.2603 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2627 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3134 - acc: 0.8794 - f1: 0.8952 - val_loss: 0.2343 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2365 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2392 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2313 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 3419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2524 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2930 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2457 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8646 - f1: 0.8832 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8644 - f1: 0.8835 - val_loss: 0.2722 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2226 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2458 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 3427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8702 - f1: 0.8881 - val_loss: 0.2351 - val_acc: 0.9603 - val_f1: 0.9614\n",
      "Epoch 3428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2490 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 3429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8732 - f1: 0.8896 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2837 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 3431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2554 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2313 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2200 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 3434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2514 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2284 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8761 - f1: 0.8926 - val_loss: 0.2395 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2218 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 3439/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2391 - val_acc: 0.9678 - val_f1: 0.9680\n",
      "Epoch 3440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2671 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 3441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2397 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 3442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8709 - f1: 0.8888 - val_loss: 0.2370 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2593 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8696 - f1: 0.8865 - val_loss: 0.2300 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2461 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2703 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2383 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 3448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2556 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2570 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2503 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8677 - f1: 0.8860 - val_loss: 0.2248 - val_acc: 0.9691 - val_f1: 0.9702\n",
      "Epoch 3452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2549 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8644 - f1: 0.8834 - val_loss: 0.2244 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2452 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 3455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2309 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2305 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 3457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2209 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.3002 - val_acc: 0.9622 - val_f1: 0.9625\n",
      "Epoch 3459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2299 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2479 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2529 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2443 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2640 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2202 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2397 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2714 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2454 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8746 - f1: 0.8910 - val_loss: 0.2255 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8749 - f1: 0.8915 - val_loss: 0.2425 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8756 - f1: 0.8917 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8768 - f1: 0.8927 - val_loss: 0.2661 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2265 - val_acc: 0.9578 - val_f1: 0.9598\n",
      "Epoch 3473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8668 - f1: 0.8842 - val_loss: 0.2375 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 3474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8685 - f1: 0.8869 - val_loss: 0.2553 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2439 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8749 - f1: 0.8914 - val_loss: 0.2517 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2669 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2406 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 3479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2464 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 3480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2377 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 3481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2362 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2423 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 3483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2399 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8872 - val_loss: 0.2134 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 3485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8701 - f1: 0.8878 - val_loss: 0.2753 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2487 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2343 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2297 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 3489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2455 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 3490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8692 - f1: 0.8870 - val_loss: 0.2378 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2440 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 3492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2523 - val_acc: 0.9644 - val_f1: 0.9663\n",
      "Epoch 3493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8668 - f1: 0.8849 - val_loss: 0.2427 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2377 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 3495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2463 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2329 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8685 - f1: 0.8861 - val_loss: 0.2417 - val_acc: 0.9494 - val_f1: 0.9521\n",
      "Epoch 3499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2322 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 3500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2524 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2361 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2699 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2359 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8671 - f1: 0.8850 - val_loss: 0.2565 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2578 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2362 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 3507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2318 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8868 - val_loss: 0.2609 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 3509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8737 - f1: 0.8899 - val_loss: 0.2397 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8693 - f1: 0.8864 - val_loss: 0.2703 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2654 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 3512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8725 - f1: 0.8897 - val_loss: 0.2627 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2894 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 3514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2883 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8729 - f1: 0.8901 - val_loss: 0.2851 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 3516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2787 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 3517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8746 - f1: 0.8913 - val_loss: 0.2900 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 3518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8640 - f1: 0.8830 - val_loss: 0.2870 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8762 - f1: 0.8924 - val_loss: 0.2264 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2341 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 3521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2497 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2407 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2457 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8710 - f1: 0.8888 - val_loss: 0.2239 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 3525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2339 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2376 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 3528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2115 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2438 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8704 - f1: 0.8872 - val_loss: 0.2292 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2711 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3532/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3201 - acc: 0.8741 - f1: 0.8902 - val_loss: 0.2615 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8763 - f1: 0.8920 - val_loss: 0.2612 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3534/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2521 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2406 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 3536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3132 - acc: 0.8782 - f1: 0.8941 - val_loss: 0.2580 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2581 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8882 - val_loss: 0.2382 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 3539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8660 - f1: 0.8843 - val_loss: 0.2589 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2757 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2517 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2838 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 3543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2321 - val_acc: 0.9581 - val_f1: 0.9597\n",
      "Epoch 3544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2498 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2483 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8690 - f1: 0.8870 - val_loss: 0.2662 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8690 - f1: 0.8871 - val_loss: 0.2474 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 3548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8862 - val_loss: 0.2314 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 3549/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3451 - acc: 0.8625 - f1: 0.8812 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3550/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2727 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2297 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 3552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2465 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3553/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8836 - val_loss: 0.2427 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 3554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8757 - f1: 0.8920 - val_loss: 0.2724 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3555/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2468 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 3556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8739 - f1: 0.8903 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3557/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8729 - f1: 0.8893 - val_loss: 0.2428 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3558/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8917 - val_loss: 0.2678 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3559/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8884 - val_loss: 0.2538 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3560/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3205 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2618 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3561/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2379 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3562/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2464 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3563/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3201 - acc: 0.8746 - f1: 0.8911 - val_loss: 0.2430 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 3564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2357 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 3565/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3219 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2342 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2340 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 3567/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3208 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 3568/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3245 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2509 - val_acc: 0.9700 - val_f1: 0.9703\n",
      "Epoch 3569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8766 - f1: 0.8924 - val_loss: 0.2394 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 3570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2376 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3571/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3223 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2258 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2482 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3573/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8733 - f1: 0.8902 - val_loss: 0.2459 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 3574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2393 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3575/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3187 - acc: 0.8762 - f1: 0.8917 - val_loss: 0.2547 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 3576/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8646 - f1: 0.8829 - val_loss: 0.2408 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 3577/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8895 - val_loss: 0.2532 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2456 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8737 - f1: 0.8896 - val_loss: 0.2499 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 3580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2320 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 3581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2232 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3582/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2642 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8615 - f1: 0.8804 - val_loss: 0.2291 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8715 - f1: 0.8879 - val_loss: 0.2274 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 3585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2355 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 3586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2673 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2344 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8890 - val_loss: 0.2432 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2632 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2389 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8696 - f1: 0.8875 - val_loss: 0.2289 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 3592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2302 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3593/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2411 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3594/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2668 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3595/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2430 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3596/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3279 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2497 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3597/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3302 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2703 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3598/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.2886 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 3599/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2482 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3600/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3185 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2691 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3601/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8724 - f1: 0.8898 - val_loss: 0.2781 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3602/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3297 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2430 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 3603/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2586 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8651 - f1: 0.8837 - val_loss: 0.2594 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2498 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 3606/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2768 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 3607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2708 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8741 - f1: 0.8898 - val_loss: 0.2689 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 3609/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2239 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3610/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2411 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 3611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8864 - val_loss: 0.2493 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 3612/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3352 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2557 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3613/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3321 - acc: 0.8678 - f1: 0.8859 - val_loss: 0.2434 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3614/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3214 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2530 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3615/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2392 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 3616/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2381 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2486 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2554 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 3619/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3195 - acc: 0.8741 - f1: 0.8911 - val_loss: 0.2585 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3620/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2521 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 3621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2666 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 3622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8746 - f1: 0.8912 - val_loss: 0.2700 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2800 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3624/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3370 - acc: 0.8655 - f1: 0.8844 - val_loss: 0.2475 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3625/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3360 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2508 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3626/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 3627/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2604 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2388 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8683 - f1: 0.8859 - val_loss: 0.2326 - val_acc: 0.9634 - val_f1: 0.9657\n",
      "Epoch 3631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8711 - f1: 0.8884 - val_loss: 0.2479 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 3632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2259 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2345 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2338 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2421 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2355 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 3638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2240 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 3639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8770 - f1: 0.8926 - val_loss: 0.2462 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 3640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3134 - acc: 0.8779 - f1: 0.8937 - val_loss: 0.2472 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 3641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8694 - f1: 0.8872 - val_loss: 0.2303 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2320 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 3644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8665 - f1: 0.8851 - val_loss: 0.2750 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 3645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2475 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 3646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3143 - acc: 0.8774 - f1: 0.8932 - val_loss: 0.2801 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2741 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 3648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8875 - val_loss: 0.2601 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2657 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2428 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8730 - f1: 0.8903 - val_loss: 0.2439 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2520 - val_acc: 0.9691 - val_f1: 0.9697\n",
      "Epoch 3653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2617 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2556 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2451 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8671 - f1: 0.8847 - val_loss: 0.2496 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2349 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2298 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3142 - acc: 0.8780 - f1: 0.8939 - val_loss: 0.2654 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 3661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2765 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8876 - val_loss: 0.2297 - val_acc: 0.9541 - val_f1: 0.9567\n",
      "Epoch 3663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2380 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 3664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8634 - f1: 0.8823 - val_loss: 0.2290 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 3665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2295 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2476 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2378 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2544 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 3669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2477 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8728 - f1: 0.8901 - val_loss: 0.2405 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2360 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2400 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2550 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3147 - acc: 0.8773 - f1: 0.8926 - val_loss: 0.2473 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2916 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2632 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 3677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2147 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 3678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2242 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8629 - f1: 0.8819 - val_loss: 0.2293 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 3680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2498 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 3681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2629 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8731 - f1: 0.8901 - val_loss: 0.2320 - val_acc: 0.9456 - val_f1: 0.9496\n",
      "Epoch 3683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2514 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3166 - acc: 0.8761 - f1: 0.8925 - val_loss: 0.2420 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 3686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2429 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2424 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2553 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2405 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2380 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 3691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2486 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8724 - f1: 0.8893 - val_loss: 0.2462 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2619 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3169 - acc: 0.8763 - f1: 0.8926 - val_loss: 0.2511 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 3695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2366 - val_acc: 0.9641 - val_f1: 0.9662\n",
      "Epoch 3696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2666 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 3697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2496 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8693 - f1: 0.8873 - val_loss: 0.3386 - val_acc: 0.9569 - val_f1: 0.9582\n",
      "Epoch 3699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2187 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 3700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2527 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2403 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 3702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2373 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3165 - acc: 0.8772 - f1: 0.8933 - val_loss: 0.2639 - val_acc: 0.9681 - val_f1: 0.9679\n",
      "Epoch 3704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2446 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2297 - val_acc: 0.9491 - val_f1: 0.9525\n",
      "Epoch 3706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8669 - f1: 0.8854 - val_loss: 0.2331 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2415 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2785 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2514 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2931 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2525 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2376 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2258 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 3714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2610 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2319 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8737 - f1: 0.8908 - val_loss: 0.2534 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2252 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 3719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2494 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 3720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3721/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2772 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2501 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 3723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2359 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2513 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3725/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3232 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2799 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 3726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2578 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3727/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2347 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 3728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2505 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2152 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 3730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2346 - val_acc: 0.9669 - val_f1: 0.9671\n",
      "Epoch 3731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2478 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2622 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2515 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 3734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2750 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 3735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8728 - f1: 0.8898 - val_loss: 0.2358 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 3736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2565 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8689 - f1: 0.8869 - val_loss: 0.2313 - val_acc: 0.9597 - val_f1: 0.9609\n",
      "Epoch 3738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2288 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 3739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2535 - val_acc: 0.9481 - val_f1: 0.9519\n",
      "Epoch 3740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2714 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2288 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2362 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8716 - f1: 0.8883 - val_loss: 0.2488 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3744/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2289 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2667 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3746/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2165 - val_acc: 0.9556 - val_f1: 0.9576\n",
      "Epoch 3747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2328 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2558 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8767 - f1: 0.8927 - val_loss: 0.2502 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3157 - acc: 0.8770 - f1: 0.8934 - val_loss: 0.2623 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2541 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2313 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8676 - f1: 0.8860 - val_loss: 0.2705 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2794 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2487 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8757 - f1: 0.8918 - val_loss: 0.2460 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2448 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2514 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 3759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2384 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2580 - val_acc: 0.9647 - val_f1: 0.9646\n",
      "Epoch 3761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8847 - val_loss: 0.2499 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2566 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2411 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2595 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2366 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 3766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2538 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2594 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8735 - f1: 0.8904 - val_loss: 0.2318 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2258 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2558 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2538 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8749 - f1: 0.8908 - val_loss: 0.2478 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2491 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2494 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8718 - f1: 0.8893 - val_loss: 0.2609 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.3224 - val_acc: 0.9591 - val_f1: 0.9595\n",
      "Epoch 3777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2405 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2639 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.3000 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3128 - acc: 0.8797 - f1: 0.8951 - val_loss: 0.2539 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2494 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3163 - acc: 0.8760 - f1: 0.8921 - val_loss: 0.2625 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8652 - f1: 0.8841 - val_loss: 0.2540 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 3784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2468 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 3785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8692 - f1: 0.8873 - val_loss: 0.2824 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2722 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2414 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8897 - val_loss: 0.2507 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2497 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2445 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2373 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 3792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2577 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8862 - val_loss: 0.2660 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8922 - val_loss: 0.2418 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2813 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8756 - f1: 0.8920 - val_loss: 0.2535 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8610 - f1: 0.8803 - val_loss: 0.2504 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 3799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2518 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8869 - val_loss: 0.2399 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2507 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2548 - val_acc: 0.9653 - val_f1: 0.9657\n",
      "Epoch 3803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2480 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2514 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2709 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 3807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2296 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2364 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8771 - f1: 0.8926 - val_loss: 0.2470 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 3810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2701 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2283 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2799 - val_acc: 0.9644 - val_f1: 0.9647\n",
      "Epoch 3813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2259 - val_acc: 0.9691 - val_f1: 0.9702\n",
      "Epoch 3814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2670 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3815/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2445 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 3816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2410 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8651 - f1: 0.8839 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2525 - val_acc: 0.9684 - val_f1: 0.9689\n",
      "Epoch 3819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2267 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 3820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2549 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8767 - f1: 0.8932 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 3822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2457 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2938 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8726 - f1: 0.8893 - val_loss: 0.2547 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2437 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2451 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2494 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 3828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2422 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 3829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3153 - acc: 0.8764 - f1: 0.8929 - val_loss: 0.2675 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8859 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 3832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2459 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3136 - acc: 0.8778 - f1: 0.8935 - val_loss: 0.2743 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2896 - val_acc: 0.9563 - val_f1: 0.9567\n",
      "Epoch 3835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2416 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 3836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2326 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 3837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2300 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2343 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 3839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2343 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2580 - val_acc: 0.9672 - val_f1: 0.9675\n",
      "Epoch 3841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2532 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 3842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3143 - acc: 0.8783 - f1: 0.8940 - val_loss: 0.2416 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8757 - f1: 0.8922 - val_loss: 0.2256 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 3844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8652 - f1: 0.8841 - val_loss: 0.2533 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8643 - f1: 0.8830 - val_loss: 0.2936 - val_acc: 0.9597 - val_f1: 0.9600\n",
      "Epoch 3846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2622 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8740 - f1: 0.8907 - val_loss: 0.2664 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2448 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2544 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 3850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2723 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2683 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 3852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8754 - f1: 0.8917 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2580 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2559 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2085 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 3856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8643 - f1: 0.8829 - val_loss: 0.2140 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 3857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8634 - f1: 0.8822 - val_loss: 0.2359 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2257 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8668 - f1: 0.8848 - val_loss: 0.2230 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2786 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8736 - f1: 0.8902 - val_loss: 0.2395 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2476 - val_acc: 0.9684 - val_f1: 0.9694\n",
      "Epoch 3864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2438 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3148 - acc: 0.8769 - f1: 0.8930 - val_loss: 0.2778 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2692 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2432 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2433 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2996 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 3870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2753 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2202 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 3873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2517 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8743 - f1: 0.8908 - val_loss: 0.2606 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3875/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2784 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 3876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2471 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2317 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8669 - f1: 0.8849 - val_loss: 0.2903 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8743 - f1: 0.8909 - val_loss: 0.2334 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2399 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 3882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2429 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8757 - f1: 0.8919 - val_loss: 0.2382 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 3884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2614 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 3885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8682 - f1: 0.8863 - val_loss: 0.2563 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8769 - f1: 0.8925 - val_loss: 0.2554 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2527 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2301 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2488 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8910 - val_loss: 0.2487 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2455 - val_acc: 0.9591 - val_f1: 0.9608\n",
      "Epoch 3892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8713 - f1: 0.8878 - val_loss: 0.2242 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2392 - val_acc: 0.9694 - val_f1: 0.9700\n",
      "Epoch 3894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2619 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2552 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8707 - f1: 0.8875 - val_loss: 0.2336 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2666 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8749 - f1: 0.8914 - val_loss: 0.2327 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8897 - val_loss: 0.2752 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2368 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 3901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2185 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 3902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8638 - f1: 0.8822 - val_loss: 0.2419 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9663\n",
      "Epoch 3904/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2629 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 3905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2385 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 3906/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3225 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3907/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3193 - acc: 0.8748 - f1: 0.8909 - val_loss: 0.2482 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3908/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2312 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 3909/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2416 - val_acc: 0.9666 - val_f1: 0.9669\n",
      "Epoch 3910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8765 - f1: 0.8927 - val_loss: 0.2517 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 3911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2431 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8654 - f1: 0.8842 - val_loss: 0.2246 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 3913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2315 - val_acc: 0.9569 - val_f1: 0.9593\n",
      "Epoch 3914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2411 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2436 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3144 - acc: 0.8774 - f1: 0.8935 - val_loss: 0.2411 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8853 - val_loss: 0.2716 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 3918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8651 - f1: 0.8837 - val_loss: 0.2634 - val_acc: 0.9603 - val_f1: 0.9610\n",
      "Epoch 3919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2310 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 3920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2443 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3121 - acc: 0.8791 - f1: 0.8947 - val_loss: 0.2731 - val_acc: 0.9647 - val_f1: 0.9650\n",
      "Epoch 3922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2192 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2900 - val_acc: 0.9638 - val_f1: 0.9639\n",
      "Epoch 3924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8748 - f1: 0.8908 - val_loss: 0.2396 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8879 - val_loss: 0.2280 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 3926/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2303 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 3927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2496 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2648 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8708 - f1: 0.8876 - val_loss: 0.2444 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8671 - f1: 0.8854 - val_loss: 0.2435 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2555 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 3932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2691 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2412 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 3934/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2642 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2484 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 3936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2403 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3937/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3237 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2354 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2673 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 3939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2483 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8621 - f1: 0.8815 - val_loss: 0.2700 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 3941/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2324 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3942/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8895 - val_loss: 0.2505 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3943/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2366 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3944/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3294 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2320 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 3945/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2534 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3946/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2708 - val_acc: 0.9694 - val_f1: 0.9708\n",
      "Epoch 3947/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.3023 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 3948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2404 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3949/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2400 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 3950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8682 - f1: 0.8854 - val_loss: 0.2486 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3951/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8873 - val_loss: 0.2477 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3952/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2795 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8726 - f1: 0.8898 - val_loss: 0.2312 - val_acc: 0.9625 - val_f1: 0.9649\n",
      "Epoch 3954/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2535 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 3955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2588 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2511 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8740 - f1: 0.8905 - val_loss: 0.2305 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 3958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2489 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2467 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8762 - f1: 0.8923 - val_loss: 0.2323 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 3962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2617 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 3963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2190 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 3964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2471 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8721 - f1: 0.8897 - val_loss: 0.2316 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2387 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2584 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2592 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2287 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2544 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 3971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2508 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2495 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2330 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2400 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2266 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2377 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2408 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8728 - f1: 0.8902 - val_loss: 0.2420 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2309 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2639 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8673 - f1: 0.8859 - val_loss: 0.2468 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2390 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2571 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2426 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 3985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8684 - f1: 0.8868 - val_loss: 0.2572 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 3986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8676 - f1: 0.8859 - val_loss: 0.2403 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2307 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8880 - val_loss: 0.2307 - val_acc: 0.9559 - val_f1: 0.9582\n",
      "Epoch 3989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2367 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 3990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2647 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2520 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 3992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8730 - f1: 0.8895 - val_loss: 0.2883 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 3993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2445 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 3994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2481 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8900 - val_loss: 0.2541 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8884 - val_loss: 0.2403 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8717 - f1: 0.8886 - val_loss: 0.2369 - val_acc: 0.9531 - val_f1: 0.9559\n",
      "Epoch 3998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2397 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2315 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 4000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2611 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2602 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2418 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4003/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8697 - f1: 0.8871 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2557 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4005/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2543 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8733 - f1: 0.8903 - val_loss: 0.2336 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 4007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2470 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4008/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2403 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2140 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 4010/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2367 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2492 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4012/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3194 - acc: 0.8748 - f1: 0.89 - 0s 16us/sample - loss: 0.3195 - acc: 0.8753 - f1: 0.8918 - val_loss: 0.2366 - val_acc: 0.9594 - val_f1: 0.9610\n",
      "Epoch 4013/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3212 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2568 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4014/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2662 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8709 - f1: 0.8876 - val_loss: 0.2254 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 4016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2481 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8725 - f1: 0.8889 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2432 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8744 - f1: 0.8908 - val_loss: 0.2406 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2600 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2367 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2814 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 4023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2320 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 4024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2454 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2700 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2548 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 4028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2390 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 4029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2658 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2604 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2480 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2245 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2449 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2311 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 4035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8737 - f1: 0.8899 - val_loss: 0.2860 - val_acc: 0.9634 - val_f1: 0.9638\n",
      "Epoch 4036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.2364 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8706 - f1: 0.8884 - val_loss: 0.2391 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2411 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2688 - val_acc: 0.9653 - val_f1: 0.9655\n",
      "Epoch 4040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2374 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 4041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2659 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8773 - f1: 0.8931 - val_loss: 0.2509 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8743 - f1: 0.8907 - val_loss: 0.2620 - val_acc: 0.9656 - val_f1: 0.9660\n",
      "Epoch 4045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2997 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 4046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2367 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 4047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2441 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 4048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2934 - val_acc: 0.9647 - val_f1: 0.9647\n",
      "Epoch 4049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2606 - val_acc: 0.9647 - val_f1: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2599 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8712 - f1: 0.8889 - val_loss: 0.2609 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8682 - f1: 0.8864 - val_loss: 0.2656 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8711 - f1: 0.8879 - val_loss: 0.2493 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 4054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2590 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 4055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2272 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8721 - f1: 0.8887 - val_loss: 0.2707 - val_acc: 0.9669 - val_f1: 0.9673\n",
      "Epoch 4057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2453 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2616 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8654 - f1: 0.8835 - val_loss: 0.2244 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2407 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 4062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2563 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2547 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4064/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3200 - acc: 0.8743 - f1: 0.8905 - val_loss: 0.2728 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2539 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2587 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 4067/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3166 - acc: 0.8763 - f1: 0.8923 - val_loss: 0.2686 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2637 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2492 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8704 - f1: 0.8872 - val_loss: 0.2495 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4071/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8744 - f1: 0.8913 - val_loss: 0.2689 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.3028 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4073/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3127 - acc: 0.8796 - f1: 0.8947 - val_loss: 0.2665 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 4074/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3258 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2459 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 4075/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8735 - f1: 0.8907 - val_loss: 0.2587 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4076/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3141 - acc: 0.8779 - f1: 0.8938 - val_loss: 0.2819 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4077/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2525 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 4078/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8704 - f1: 0.8881 - val_loss: 0.2817 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4079/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2510 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 4080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2629 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2557 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4082/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4083/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8736 - f1: 0.8900 - val_loss: 0.2478 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3128 - acc: 0.8780 - f1: 0.8936 - val_loss: 0.2410 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 4085/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3394 - acc: 0.8647 - f1: 0.8836 - val_loss: 0.2186 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4086/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2367 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4087/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3188 - acc: 0.8757 - f1: 0.8917 - val_loss: 0.2986 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4088/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3152 - acc: 0.8770 - f1: 0.8929 - val_loss: 0.2479 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4089/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2605 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8657 - f1: 0.8843 - val_loss: 0.2549 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2407 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4092/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2522 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3111 - acc: 0.8797 - f1: 0.8949 - val_loss: 0.2395 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8729 - f1: 0.8895 - val_loss: 0.2684 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4095/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3256 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2790 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2446 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4097/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2743 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8742 - f1: 0.8906 - val_loss: 0.2581 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8729 - f1: 0.8895 - val_loss: 0.2540 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2511 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2635 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2603 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2544 - val_acc: 0.9681 - val_f1: 0.9686\n",
      "Epoch 4104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2318 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2576 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2410 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 4107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2474 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2680 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 4109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8724 - f1: 0.8895 - val_loss: 0.2428 - val_acc: 0.9500 - val_f1: 0.9529\n",
      "Epoch 4110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.2669 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 4111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8667 - f1: 0.8852 - val_loss: 0.2564 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2565 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8766 - f1: 0.8930 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8753 - f1: 0.8916 - val_loss: 0.2628 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8753 - f1: 0.8914 - val_loss: 0.2622 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2425 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8679 - f1: 0.8860 - val_loss: 0.2452 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2667 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2753 - val_acc: 0.9606 - val_f1: 0.9616\n",
      "Epoch 4120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8708 - f1: 0.8876 - val_loss: 0.2555 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2364 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 4122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2775 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2371 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.3054 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2820 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8729 - f1: 0.8900 - val_loss: 0.2579 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2487 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 4128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2493 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2640 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8894 - val_loss: 0.2635 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8751 - f1: 0.8914 - val_loss: 0.2564 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2360 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2653 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 4134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2224 - val_acc: 0.9563 - val_f1: 0.9580\n",
      "Epoch 4135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8716 - f1: 0.8892 - val_loss: 0.2354 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 4136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2911 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2441 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2704 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2870 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2563 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8718 - f1: 0.8889 - val_loss: 0.2556 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2558 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 4143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2614 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 4144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8752 - f1: 0.8911 - val_loss: 0.2697 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2388 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 4147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2713 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8731 - f1: 0.8899 - val_loss: 0.2431 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8733 - f1: 0.8897 - val_loss: 0.2262 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 4150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2374 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 4151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2589 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8724 - f1: 0.8897 - val_loss: 0.2451 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2604 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8688 - f1: 0.8869 - val_loss: 0.2470 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2522 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 4156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2538 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2376 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 4158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2700 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8750 - f1: 0.8911 - val_loss: 0.2662 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8652 - f1: 0.8840 - val_loss: 0.2715 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8762 - f1: 0.8922 - val_loss: 0.2559 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 4162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2564 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 4163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8894 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2725 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8690 - f1: 0.8870 - val_loss: 0.2465 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8768 - f1: 0.8927 - val_loss: 0.2531 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8715 - f1: 0.8882 - val_loss: 0.2355 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2556 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2445 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 4170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.3111 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8649 - f1: 0.8838 - val_loss: 0.2660 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2476 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8785 - f1: 0.8940 - val_loss: 0.2512 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2580 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2393 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2415 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2459 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2748 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 4179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8706 - f1: 0.8882 - val_loss: 0.2466 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2296 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2280 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2554 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2558 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8738 - f1: 0.8908 - val_loss: 0.2356 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2426 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8855 - val_loss: 0.2504 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3150 - acc: 0.8770 - f1: 0.8927 - val_loss: 0.2413 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8728 - f1: 0.8895 - val_loss: 0.2581 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2663 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2443 - val_acc: 0.9622 - val_f1: 0.9644\n",
      "Epoch 4191/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8720 - f1: 0.8886 - val_loss: 0.2667 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2534 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2527 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2502 - val_acc: 0.9675 - val_f1: 0.9693\n",
      "Epoch 4195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2559 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8732 - f1: 0.8903 - val_loss: 0.2408 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2619 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2642 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2456 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2517 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8752 - f1: 0.8913 - val_loss: 0.2400 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 4202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2884 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2375 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8678 - f1: 0.8863 - val_loss: 0.2222 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2482 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 4206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8771 - f1: 0.8932 - val_loss: 0.2551 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8683 - f1: 0.8857 - val_loss: 0.2668 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2688 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8784 - f1: 0.8936 - val_loss: 0.2271 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2355 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2206 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3151 - acc: 0.8777 - f1: 0.8935 - val_loss: 0.2312 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 4213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8896 - val_loss: 0.2644 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 4214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2372 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2308 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 4216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2192 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2343 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2442 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2331 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2603 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 4221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2683 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2371 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4223/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2372 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2738 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2276 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4226/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3234 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2313 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.3094 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2329 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4229/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2444 - val_acc: 0.9694 - val_f1: 0.9697\n",
      "Epoch 4230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2610 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8751 - f1: 0.8918 - val_loss: 0.2588 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8661 - f1: 0.8838 - val_loss: 0.2495 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2620 - val_acc: 0.9688 - val_f1: 0.9698\n",
      "Epoch 4234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2295 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4235/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3203 - acc: 0.8748 - f1: 0.89 - 0s 16us/sample - loss: 0.3184 - acc: 0.8756 - f1: 0.8921 - val_loss: 0.2449 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2532 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4237/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3282 - acc: 0.8695 - f1: 0.88 - 0s 16us/sample - loss: 0.3299 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2526 - val_acc: 0.9647 - val_f1: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2488 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2877 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2735 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2385 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8768 - f1: 0.8929 - val_loss: 0.2438 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2427 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2282 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2672 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8649 - f1: 0.8835 - val_loss: 0.2355 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4247/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2475 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2445 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 4249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3121 - acc: 0.8783 - f1: 0.8940 - val_loss: 0.2655 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2569 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 4251/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2376 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 4252/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3290 - acc: 0.8703 - f1: 0.88 - 0s 16us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8889 - val_loss: 0.2951 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 4253/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8689 - f1: 0.8863 - val_loss: 0.2490 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 4254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2871 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2713 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 4256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8731 - f1: 0.8902 - val_loss: 0.2385 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4258/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2572 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4259/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2650 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2280 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 4261/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2581 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2598 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4263/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2695 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 4264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8750 - f1: 0.8918 - val_loss: 0.2444 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4265/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2532 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8701 - f1: 0.8877 - val_loss: 0.2615 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 4267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2673 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4268/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3340 - acc: 0.8683 - f1: 0.8857 - val_loss: 0.2505 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8722 - f1: 0.8895 - val_loss: 0.2936 - val_acc: 0.9638 - val_f1: 0.9634\n",
      "Epoch 4270/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2541 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4271/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8742 - f1: 0.8909 - val_loss: 0.2319 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8641 - f1: 0.8831 - val_loss: 0.2578 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 4273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2332 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 4274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2429 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2567 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2635 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8765 - f1: 0.8924 - val_loss: 0.2485 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 4279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2644 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4280/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2337 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2576 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4282/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3362 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2516 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2322 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2289 - val_acc: 0.9650 - val_f1: 0.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8669 - f1: 0.8851 - val_loss: 0.2455 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 4286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2415 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2334 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 4288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2854 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2651 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2565 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4291/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3227 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2470 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2440 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4293/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3208 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2414 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 4294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2330 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 4295/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3297 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2250 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2684 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 4297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2549 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2365 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 4299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 4300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8900 - val_loss: 0.2681 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2364 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 4302/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2626 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4303/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3231 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2704 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2592 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8910 - val_loss: 0.2512 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4306/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2711 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3159 - acc: 0.8767 - f1: 0.8931 - val_loss: 0.2369 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2403 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4309/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2520 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4310/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3182 - acc: 0.8758 - f1: 0.8920 - val_loss: 0.2578 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2393 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4312/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4313/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8713 - f1: 0.88 - 0s 16us/sample - loss: 0.3224 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2778 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8683 - f1: 0.8865 - val_loss: 0.2309 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8771 - f1: 0.8933 - val_loss: 0.2545 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2480 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 4317/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2322 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2607 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2534 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4320/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3342 - acc: 0.8665 - f1: 0.8848 - val_loss: 0.2499 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4321/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3387 - acc: 0.8643 - f1: 0.8833 - val_loss: 0.2716 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2375 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4323/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2586 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4324/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2440 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 4325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2364 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 4326/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2620 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2351 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 4328/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3334 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2307 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4329/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2360 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 4330/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3296 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2483 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 4331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8767 - f1: 0.8928 - val_loss: 0.2538 - val_acc: 0.9647 - val_f1: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4332/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3215 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9588 - val_f1: 0.9611\n",
      "Epoch 4333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2555 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2409 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2438 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 4336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8759 - f1: 0.8923 - val_loss: 0.2776 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2565 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 4338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2630 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2719 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 4340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2544 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2518 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2489 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2397 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 4344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2714 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 4346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2287 - val_acc: 0.9531 - val_f1: 0.9561\n",
      "Epoch 4347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8612 - f1: 0.8803 - val_loss: 0.2480 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2423 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8670 - f1: 0.8855 - val_loss: 0.2719 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2976 - val_acc: 0.9644 - val_f1: 0.9645\n",
      "Epoch 4351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2613 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4352/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2644 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4353/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8880 - val_loss: 0.2632 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4354/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2485 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2655 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2561 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4357/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2584 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2596 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4359/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3251 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2458 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4360/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2382 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 4361/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2638 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4362/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2707 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 4363/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2626 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 4364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2754 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4365/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3244 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2548 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 4367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2406 - val_acc: 0.9628 - val_f1: 0.9631\n",
      "Epoch 4368/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2618 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4369/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2534 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 4370/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3267 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2594 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 4371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.3016 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4372/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2535 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 4373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2541 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2530 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4375/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3255 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.3054 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4376/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2835 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4377/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2603 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8735 - f1: 0.8896 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4379/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2325 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 4380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2580 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2672 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8722 - f1: 0.8888 - val_loss: 0.2360 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2520 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2308 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 4385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2434 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4386/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3320 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2302 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 4387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8675 - f1: 0.8858 - val_loss: 0.2520 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8914 - val_loss: 0.2328 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2502 - val_acc: 0.9684 - val_f1: 0.9698\n",
      "Epoch 4390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2380 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 4391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2536 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4392/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2469 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2777 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4394/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3218 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2485 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4395/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3188 - acc: 0.8755 - f1: 0.8913 - val_loss: 0.2502 - val_acc: 0.9678 - val_f1: 0.9681\n",
      "Epoch 4396/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2346 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2499 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3110 - acc: 0.8795 - f1: 0.8949 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2517 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 4400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8742 - f1: 0.8905 - val_loss: 0.2638 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8868 - val_loss: 0.2637 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 4402/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8865 - val_loss: 0.2768 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 4403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8689 - f1: 0.8871 - val_loss: 0.2738 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2825 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 4405/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2433 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2562 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4407/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3165 - acc: 0.8765 - f1: 0.8928 - val_loss: 0.2463 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2390 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4409/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2536 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4411/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8729 - f1: 0.8900 - val_loss: 0.2601 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4412/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3134 - acc: 0.8785 - f1: 0.8945 - val_loss: 0.2684 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4413/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8719 - f1: 0.88 - 0s 16us/sample - loss: 0.3292 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2419 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 4414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2221 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4415/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2444 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2497 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4417/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8679 - f1: 0.8862 - val_loss: 0.2721 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4418/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2547 - val_acc: 0.9619 - val_f1: 0.9622\n",
      "Epoch 4419/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3230 - acc: 0.8736 - f1: 0.89 - 0s 16us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8887 - val_loss: 0.2462 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4420/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2500 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2413 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4422/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3302 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2792 - val_acc: 0.9606 - val_f1: 0.9617\n",
      "Epoch 4423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8886 - val_loss: 0.2518 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4424/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3242 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2233 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4425/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2249 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2826 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 4427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2544 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8739 - f1: 0.8906 - val_loss: 0.2467 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 4429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2285 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 4430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2770 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 4431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3166 - acc: 0.8758 - f1: 0.8923 - val_loss: 0.2742 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 4432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2360 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 4433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8876 - val_loss: 0.2383 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8873 - val_loss: 0.2534 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8902 - val_loss: 0.2645 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2376 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2479 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2827 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2727 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2367 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 4441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2547 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 4442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2402 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2538 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8691 - f1: 0.8872 - val_loss: 0.2435 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 4445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2505 - val_acc: 0.9684 - val_f1: 0.9691\n",
      "Epoch 4446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3172 - acc: 0.8761 - f1: 0.8925 - val_loss: 0.2510 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2763 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2789 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2650 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2487 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2535 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2582 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2577 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2782 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2425 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2281 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8862 - val_loss: 0.2411 - val_acc: 0.9697 - val_f1: 0.9706\n",
      "Epoch 4458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2553 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8642 - f1: 0.8830 - val_loss: 0.2291 - val_acc: 0.9575 - val_f1: 0.9592\n",
      "Epoch 4460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2676 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2444 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2540 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2445 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2392 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 4465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2506 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8755 - f1: 0.8922 - val_loss: 0.2704 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8670 - f1: 0.8856 - val_loss: 0.2456 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2466 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2459 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2293 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8765 - f1: 0.8925 - val_loss: 0.2755 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4472/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2344 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2494 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2421 - val_acc: 0.9553 - val_f1: 0.9572\n",
      "Epoch 4475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2465 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2746 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2385 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2422 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2591 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 4480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2386 - val_acc: 0.9581 - val_f1: 0.9605\n",
      "Epoch 4481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2351 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8777 - f1: 0.8936 - val_loss: 0.2633 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8747 - f1: 0.8914 - val_loss: 0.2482 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3138 - acc: 0.8782 - f1: 0.8938 - val_loss: 0.2247 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 4486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2658 - val_acc: 0.9681 - val_f1: 0.9685\n",
      "Epoch 4487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2458 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2387 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2291 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 4490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2316 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2399 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2244 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 4493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2121 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 4494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2259 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2207 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2324 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2365 - val_acc: 0.9556 - val_f1: 0.9582\n",
      "Epoch 4498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2593 - val_acc: 0.9594 - val_f1: 0.9601\n",
      "Epoch 4499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8627 - f1: 0.8820 - val_loss: 0.2469 - val_acc: 0.9653 - val_f1: 0.9656\n",
      "Epoch 4500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2363 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2364 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8708 - f1: 0.8883 - val_loss: 0.2542 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 4503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2581 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2608 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 4505/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8879 - val_loss: 0.2505 - val_acc: 0.9650 - val_f1: 0.9654\n",
      "Epoch 4506/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8732 - f1: 0.8904 - val_loss: 0.2528 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8717 - f1: 0.8887 - val_loss: 0.2525 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4508/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8860 - val_loss: 0.2484 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2477 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2449 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 4511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2490 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4512/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8713 - f1: 0.8880 - val_loss: 0.2582 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2732 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2397 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2359 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8691 - f1: 0.8860 - val_loss: 0.2448 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4517/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2470 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2408 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2528 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2833 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2677 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2455 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2711 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8669 - f1: 0.8857 - val_loss: 0.2624 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 4526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2416 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8749 - f1: 0.8908 - val_loss: 0.2486 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2461 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2611 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2311 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2340 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2305 - val_acc: 0.9694 - val_f1: 0.9701\n",
      "Epoch 4533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2410 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 4534/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2321 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2638 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 4537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8752 - f1: 0.8917 - val_loss: 0.2180 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 4538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2674 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8732 - f1: 0.8894 - val_loss: 0.2621 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2575 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2541 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2897 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.3624 - val_acc: 0.9597 - val_f1: 0.9599\n",
      "Epoch 4544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2398 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8701 - f1: 0.8879 - val_loss: 0.2297 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2504 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2468 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8762 - f1: 0.8924 - val_loss: 0.2559 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2234 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2442 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2434 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2382 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2547 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2498 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 4556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2491 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8873 - val_loss: 0.2458 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2706 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2576 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2392 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8747 - f1: 0.8916 - val_loss: 0.3016 - val_acc: 0.9634 - val_f1: 0.9640\n",
      "Epoch 4562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2495 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 4564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2648 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 4565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8764 - f1: 0.8927 - val_loss: 0.2420 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4566/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2442 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 4567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2421 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2428 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2293 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8718 - f1: 0.8894 - val_loss: 0.2268 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2455 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8881 - val_loss: 0.2492 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2462 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8759 - f1: 0.8925 - val_loss: 0.2571 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2767 - val_acc: 0.9675 - val_f1: 0.9679\n",
      "Epoch 4577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2455 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8897 - val_loss: 0.2392 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2412 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 4580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2362 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2386 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2539 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 4583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.3021 - val_acc: 0.9613 - val_f1: 0.9617\n",
      "Epoch 4584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2325 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8770 - f1: 0.8934 - val_loss: 0.2933 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2561 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2473 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2578 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2761 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8718 - f1: 0.8895 - val_loss: 0.2854 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8665 - f1: 0.8849 - val_loss: 0.2574 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2701 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 4593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2822 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 4594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8733 - f1: 0.8903 - val_loss: 0.2466 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2490 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2447 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8715 - f1: 0.8883 - val_loss: 0.2654 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 4598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2745 - val_acc: 0.9559 - val_f1: 0.9578\n",
      "Epoch 4599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2702 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8759 - f1: 0.8923 - val_loss: 0.2761 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2673 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8880 - val_loss: 0.2562 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2542 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2539 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2543 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8743 - f1: 0.8907 - val_loss: 0.2710 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2589 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8770 - f1: 0.8931 - val_loss: 0.2539 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8916 - val_loss: 0.2606 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3141 - acc: 0.8780 - f1: 0.8942 - val_loss: 0.2601 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2959 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 4612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8675 - f1: 0.8850 - val_loss: 0.2523 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8776 - f1: 0.8935 - val_loss: 0.2713 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 4614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2453 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2632 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8877 - val_loss: 0.2626 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2671 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2565 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 4619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2400 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 4620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2652 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 4622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8749 - f1: 0.8915 - val_loss: 0.2599 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8674 - f1: 0.8857 - val_loss: 0.2822 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2413 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2652 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 4626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8718 - f1: 0.8896 - val_loss: 0.2459 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 4627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8752 - f1: 0.8915 - val_loss: 0.2685 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2573 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2688 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 4631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8713 - f1: 0.8890 - val_loss: 0.2314 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2497 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 4633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2669 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2740 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2109 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2609 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 4637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2694 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8760 - f1: 0.8923 - val_loss: 0.2640 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 4639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2625 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2664 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8772 - f1: 0.8935 - val_loss: 0.2637 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.3037 - val_acc: 0.9638 - val_f1: 0.9640\n",
      "Epoch 4643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2721 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 4644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2904 - val_acc: 0.9669 - val_f1: 0.9670\n",
      "Epoch 4645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2740 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 4646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8725 - f1: 0.8892 - val_loss: 0.2704 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8742 - f1: 0.8910 - val_loss: 0.2760 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 4648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2670 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2391 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 4650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2423 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2645 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2581 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 4653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2678 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8768 - f1: 0.8929 - val_loss: 0.2461 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8758 - f1: 0.8919 - val_loss: 0.2644 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2323 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 4657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2297 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 4658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8620 - f1: 0.8815 - val_loss: 0.2635 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2780 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2491 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 4661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2335 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2571 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 4663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8704 - f1: 0.8874 - val_loss: 0.2327 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 4664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2702 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2417 - val_acc: 0.9684 - val_f1: 0.9687\n",
      "Epoch 4666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8871 - val_loss: 0.2475 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8731 - f1: 0.8906 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8766 - f1: 0.8929 - val_loss: 0.2650 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8725 - f1: 0.8893 - val_loss: 0.2728 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2550 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 4671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2359 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 4672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2542 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8753 - f1: 0.8918 - val_loss: 0.2485 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2516 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8678 - f1: 0.8863 - val_loss: 0.2483 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8732 - f1: 0.8900 - val_loss: 0.2864 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8759 - f1: 0.8919 - val_loss: 0.2641 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8678 - f1: 0.8856 - val_loss: 0.2421 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2573 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 4680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2836 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 4681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2384 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2432 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2260 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2529 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8722 - f1: 0.8890 - val_loss: 0.2966 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2678 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2519 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3099 - acc: 0.8804 - f1: 0.8959 - val_loss: 0.2465 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2811 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2709 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 4692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2424 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8853 - val_loss: 0.2378 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2698 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2683 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8733 - f1: 0.8902 - val_loss: 0.2461 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8872 - val_loss: 0.2912 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 4698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2293 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2494 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2253 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 4701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2522 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2430 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8717 - f1: 0.8892 - val_loss: 0.2489 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2389 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2548 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2300 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 4707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2366 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 4708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2607 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 4709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2574 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2550 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2554 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2865 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8711 - f1: 0.8888 - val_loss: 0.2449 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2368 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2412 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2382 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2439 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8731 - f1: 0.8902 - val_loss: 0.2640 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8888 - val_loss: 0.2404 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2544 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2575 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2716 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 4723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8754 - f1: 0.8915 - val_loss: 0.2494 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8663 - f1: 0.8850 - val_loss: 0.2428 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 4725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2507 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2465 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 4727/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2306 - val_acc: 0.9497 - val_f1: 0.9530\n",
      "Epoch 4728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2535 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2333 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 4731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2683 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8877 - val_loss: 0.2828 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 4733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8743 - f1: 0.8912 - val_loss: 0.2525 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4734/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3167 - acc: 0.8761 - f1: 0.8919 - val_loss: 0.2774 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2811 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2463 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2557 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 4738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2573 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2926 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2155 - val_acc: 0.9513 - val_f1: 0.9541\n",
      "Epoch 4741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2298 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 4742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2559 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2561 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4744/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2454 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2400 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 4746/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2454 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2619 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2871 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8857 - val_loss: 0.2726 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2893 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 4751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8681 - f1: 0.8857 - val_loss: 0.2442 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4752/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8735 - f1: 0.8906 - val_loss: 0.2711 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2519 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 4754/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2383 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2613 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2672 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2657 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2397 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2590 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8761 - f1: 0.8923 - val_loss: 0.2659 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2552 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2650 - val_acc: 0.9666 - val_f1: 0.9683\n",
      "Epoch 4763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2655 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2855 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2862 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2579 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2412 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2426 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2800 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 4770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2340 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 4771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2661 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 4772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8736 - f1: 0.8902 - val_loss: 0.2237 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2378 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 4774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2793 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2480 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8742 - f1: 0.8905 - val_loss: 0.2420 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 4777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2605 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2453 - val_acc: 0.9472 - val_f1: 0.9507\n",
      "Epoch 4779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2592 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 4780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2463 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2313 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2653 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2684 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8744 - f1: 0.8913 - val_loss: 0.2703 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2680 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8754 - f1: 0.8918 - val_loss: 0.2550 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 4787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2563 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 4788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2799 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2483 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2717 - val_acc: 0.9609 - val_f1: 0.9615\n",
      "Epoch 4791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8724 - f1: 0.8892 - val_loss: 0.2498 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3149 - acc: 0.8780 - f1: 0.8935 - val_loss: 0.2714 - val_acc: 0.9656 - val_f1: 0.9659\n",
      "Epoch 4793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2226 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2629 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2333 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2572 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8746 - f1: 0.8912 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2534 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 4800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2624 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2554 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 4802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3142 - acc: 0.8781 - f1: 0.8940 - val_loss: 0.2670 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 4803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2461 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 4804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8731 - f1: 0.8892 - val_loss: 0.2419 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2545 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2521 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 4807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2612 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2397 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2884 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2845 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 4811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2547 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 4812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3163 - acc: 0.8767 - f1: 0.8924 - val_loss: 0.2623 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2610 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8754 - f1: 0.8922 - val_loss: 0.2531 - val_acc: 0.9644 - val_f1: 0.9647\n",
      "Epoch 4815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2304 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8728 - f1: 0.8890 - val_loss: 0.2325 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2825 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2342 - val_acc: 0.9572 - val_f1: 0.9596\n",
      "Epoch 4820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8613 - f1: 0.8805 - val_loss: 0.2618 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2497 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2853 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8682 - f1: 0.8864 - val_loss: 0.2608 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8735 - f1: 0.8908 - val_loss: 0.2710 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2466 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2634 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8736 - f1: 0.8907 - val_loss: 0.2673 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2241 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 4829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2568 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2905 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 4831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2562 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8750 - f1: 0.8916 - val_loss: 0.2441 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 4833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2581 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2615 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2824 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 4836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2319 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2489 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2575 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 4839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2907 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2590 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2908 - val_acc: 0.9663 - val_f1: 0.9666\n",
      "Epoch 4842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2726 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2437 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 4844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2540 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 4845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8631 - f1: 0.8824 - val_loss: 0.2265 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2382 - val_acc: 0.9566 - val_f1: 0.9589\n",
      "Epoch 4847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8674 - f1: 0.8859 - val_loss: 0.2186 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 4848/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2451 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2600 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 4850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8885 - val_loss: 0.2563 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4851/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2253 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 4852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8703 - f1: 0.8882 - val_loss: 0.2700 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 4853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8731 - f1: 0.8899 - val_loss: 0.2564 - val_acc: 0.9681 - val_f1: 0.9683\n",
      "Epoch 4854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2416 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2458 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2485 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3147 - acc: 0.8780 - f1: 0.8938 - val_loss: 0.2523 - val_acc: 0.9541 - val_f1: 0.9559\n",
      "Epoch 4858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4859/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8716 - f1: 0.8894 - val_loss: 0.2616 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4860/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2691 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4861/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2309 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 4862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8771 - f1: 0.8926 - val_loss: 0.2593 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2661 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8764 - f1: 0.8930 - val_loss: 0.2591 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 4865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2764 - val_acc: 0.9650 - val_f1: 0.9654\n",
      "Epoch 4866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2339 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2550 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4868/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3222 - acc: 0.8735 - f1: 0.8905 - val_loss: 0.2695 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8718 - f1: 0.8886 - val_loss: 0.2561 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2523 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 4871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2502 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8761 - f1: 0.8919 - val_loss: 0.2278 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 4873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2621 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2356 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 4875/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3372 - acc: 0.8664 - f1: 0.88 - 0s 16us/sample - loss: 0.3359 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2478 - val_acc: 0.9575 - val_f1: 0.9597\n",
      "Epoch 4876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2499 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4877/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2733 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2446 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2533 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4880/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8893 - val_loss: 0.2570 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 4881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8709 - f1: 0.8877 - val_loss: 0.2647 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 4882/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2690 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3151 - acc: 0.8778 - f1: 0.8936 - val_loss: 0.2709 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 4884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2649 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4885/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2752 - val_acc: 0.9625 - val_f1: 0.9629\n",
      "Epoch 4886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2633 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8914 - val_loss: 0.2476 - val_acc: 0.9672 - val_f1: 0.9676\n",
      "Epoch 4888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2555 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 4889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2430 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2583 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2806 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8708 - f1: 0.8885 - val_loss: 0.2691 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 4893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8904 - val_loss: 0.2722 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4894/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3280 - acc: 0.8705 - f1: 0.88 - 0s 16us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2370 - val_acc: 0.9669 - val_f1: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2499 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 4896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2468 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2740 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2715 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 4899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2143 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 4900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8681 - f1: 0.8859 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2241 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 4902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2516 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 4903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2663 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 4904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8717 - f1: 0.8884 - val_loss: 0.2777 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8746 - f1: 0.8913 - val_loss: 0.2606 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2526 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3176 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2546 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8704 - f1: 0.8880 - val_loss: 0.2620 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8644 - f1: 0.8833 - val_loss: 0.2305 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 4910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2442 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8753 - f1: 0.8921 - val_loss: 0.2696 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2567 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8636 - f1: 0.8826 - val_loss: 0.2484 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2714 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 4915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2863 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2423 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8761 - f1: 0.8922 - val_loss: 0.2410 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2490 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 4919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 4920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2762 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 4921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2609 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2772 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8685 - f1: 0.8866 - val_loss: 0.2302 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2597 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2732 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 4926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2625 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 4927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2563 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8784 - f1: 0.8941 - val_loss: 0.2682 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8753 - f1: 0.8915 - val_loss: 0.2535 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2632 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2819 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2786 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2685 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8761 - f1: 0.8926 - val_loss: 0.2644 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2760 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2243 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 4938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2457 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2702 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8721 - f1: 0.8891 - val_loss: 0.2598 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2494 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4942/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2501 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 4943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2619 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8708 - f1: 0.8884 - val_loss: 0.2673 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8742 - f1: 0.8909 - val_loss: 0.2646 - val_acc: 0.9684 - val_f1: 0.9683\n",
      "Epoch 4946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8681 - f1: 0.8865 - val_loss: 0.2584 - val_acc: 0.9569 - val_f1: 0.9584\n",
      "Epoch 4948/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2384 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 4949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2568 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 4950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8868 - val_loss: 0.2880 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2492 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2240 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2352 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2272 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2481 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2474 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2676 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2319 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8878 - val_loss: 0.2255 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2507 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2711 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2818 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8766 - f1: 0.8928 - val_loss: 0.2527 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2536 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3173 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2530 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2714 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2610 - val_acc: 0.9659 - val_f1: 0.9660\n",
      "Epoch 4968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2883 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8764 - f1: 0.8917 - val_loss: 0.2192 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.3012 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2204 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2507 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4973/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2563 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2491 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2573 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 4976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2876 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 4977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2626 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2763 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2833 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 4980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2454 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4981/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8762 - f1: 0.8925 - val_loss: 0.2569 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4982/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3345 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2659 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2597 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4984/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3156 - acc: 0.8766 - f1: 0.8927 - val_loss: 0.2558 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8637 - f1: 0.8827 - val_loss: 0.2836 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4986/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2684 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 4987/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3348 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2270 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2570 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2618 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 4990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2490 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2635 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8759 - f1: 0.8924 - val_loss: 0.2647 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2687 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2361 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2621 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 4996/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3250 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2546 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2553 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 4998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2400 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2654 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 5000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8668 - f1: 0.8850 - val_loss: 0.2491 - val_acc: 0.9647 - val_f1: 0.9659\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "epochs_range = [30,60, 5000]                                                                                                                                            \n",
    "max_ep = max(epochs_range)                                                                                                                                                         \n",
    "\n",
    "for ep in epochs_range:                                                                                                                                                            \n",
    "    model = RN_model(layer_sizes, dropout, learning_rate)                                                                                                                          \n",
    "    #### Apprentissage                                                                                                                                                             \n",
    "    start = time.time()                                                                                                                                                            \n",
    "    #model.fit(X_train, Y_train, batch_size = 100, epochs = 60)                                                                                                                    \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = ep, validation_data=(X_test, Y_test))                                                                 \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    training_delay_RN.append(end - start)                                                                                                                                          \n",
    "\n",
    "    ho_tmp = list(hist_obj.history.values())                                                                                                                                       \n",
    "    ho_tmp = [i + [np.nan for _ in range(max_ep-ep)] for i in ho_tmp ]                                                                                                             \n",
    "    history_obj.append(ho_tmp)\n",
    "    #### Prédiction                                                                                                                                                                \n",
    "    start = time.time()                                                                                                                                                            \n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    predicting_delay_RN.append(end - start) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in epochs_range]                                                                                                                                                \n",
    "                                                                                                                                       \n",
    "titre = \"RN : HyperParam = number of epochs\"                                                                                                                                          \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "EXPLICATION A REVOIR CAR JE NE VOIS PAS DE SURAPPRENTISSAGE : \n",
    "Nous remarquons que les performances (accuracy et f1_score) tendent vers les mêmes taux qu'il y ait 30, 60 ou 120 itérations. \n",
    "\n",
    "(graphe time - itérations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Notons ici que le temps d'apprentissage et de prédiction croissent avec le nombre d'itération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 5\n",
    "(1 - La démarche de comparaison des hyperparamètres est sérieuse. Les résultats sont présentés de façon correcte et concise dans un tableau et un graphique.\n",
    "2 - Les explications montrant les différences sont claires, concises et plausibles.\n",
    "3 - La configuration matérielle sur laquelle les expérimentations est présenteainsi que le temps d’exécution requis pour compléter les expérimentations)\n",
    "\n",
    "1&2 : (alterner graphe et explication (cf q3) ou mettre tous les graphes (en q3) puis explication ici en q5.\n",
    "\n",
    "3 : regarder les specs du PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca commence\n",
      "best param\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "best score\n",
      "0.967375\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_grid,Y_grid = get_data_GridSearch()\n",
    "Grid=GridSearch_bestparam(X_grid,Y_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse Linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  app.launch_new_instance()\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:20: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:21: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print ('Analyse Linear')\n",
    "\n",
    "plot_Linear_acc(Grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse RBF\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print('Analyse RBF')\n",
    "plot_RBF_acc(Grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table de valeur\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.947985</td>\n",
       "      <td>0.003004</td>\n",
       "      <td>0.946063</td>\n",
       "      <td>0.003021</td>\n",
       "      <td>7</td>\n",
       "      <td>10.812186</td>\n",
       "      <td>0.912470</td>\n",
       "      <td>1.693979</td>\n",
       "      <td>0.159801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.943939</td>\n",
       "      <td>0.003059</td>\n",
       "      <td>0.941813</td>\n",
       "      <td>0.003174</td>\n",
       "      <td>9</td>\n",
       "      <td>12.676310</td>\n",
       "      <td>0.228588</td>\n",
       "      <td>2.336374</td>\n",
       "      <td>0.082925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.929168</td>\n",
       "      <td>0.005085</td>\n",
       "      <td>0.926500</td>\n",
       "      <td>0.005323</td>\n",
       "      <td>10</td>\n",
       "      <td>20.398949</td>\n",
       "      <td>0.679764</td>\n",
       "      <td>4.614898</td>\n",
       "      <td>0.334103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844318</td>\n",
       "      <td>0.005067</td>\n",
       "      <td>0.823063</td>\n",
       "      <td>0.006238</td>\n",
       "      <td>15</td>\n",
       "      <td>56.841637</td>\n",
       "      <td>0.364709</td>\n",
       "      <td>12.590611</td>\n",
       "      <td>0.896276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.954324</td>\n",
       "      <td>0.002220</td>\n",
       "      <td>0.951875</td>\n",
       "      <td>0.002351</td>\n",
       "      <td>5</td>\n",
       "      <td>12.342011</td>\n",
       "      <td>1.218828</td>\n",
       "      <td>2.993964</td>\n",
       "      <td>0.296574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>0.968615</td>\n",
       "      <td>0.002072</td>\n",
       "      <td>0.967375</td>\n",
       "      <td>0.002112</td>\n",
       "      <td>1</td>\n",
       "      <td>7.057173</td>\n",
       "      <td>0.464026</td>\n",
       "      <td>1.381827</td>\n",
       "      <td>0.136445</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.957844</td>\n",
       "      <td>0.003256</td>\n",
       "      <td>0.956250</td>\n",
       "      <td>0.003422</td>\n",
       "      <td>3</td>\n",
       "      <td>9.733783</td>\n",
       "      <td>0.502281</td>\n",
       "      <td>2.087624</td>\n",
       "      <td>0.116255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.900781</td>\n",
       "      <td>0.004552</td>\n",
       "      <td>0.896813</td>\n",
       "      <td>0.005141</td>\n",
       "      <td>13</td>\n",
       "      <td>30.477180</td>\n",
       "      <td>0.304203</td>\n",
       "      <td>8.052330</td>\n",
       "      <td>0.389286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.954683</td>\n",
       "      <td>0.002185</td>\n",
       "      <td>0.952063</td>\n",
       "      <td>0.002334</td>\n",
       "      <td>4</td>\n",
       "      <td>20.209869</td>\n",
       "      <td>0.217480</td>\n",
       "      <td>4.897746</td>\n",
       "      <td>0.334222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.962855</td>\n",
       "      <td>0.001872</td>\n",
       "      <td>0.961375</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>2</td>\n",
       "      <td>9.614222</td>\n",
       "      <td>0.311527</td>\n",
       "      <td>2.176467</td>\n",
       "      <td>0.149358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.947112</td>\n",
       "      <td>0.005200</td>\n",
       "      <td>0.945187</td>\n",
       "      <td>0.005501</td>\n",
       "      <td>8</td>\n",
       "      <td>16.423818</td>\n",
       "      <td>0.582909</td>\n",
       "      <td>3.634397</td>\n",
       "      <td>0.116167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.828766</td>\n",
       "      <td>0.006334</td>\n",
       "      <td>0.827000</td>\n",
       "      <td>0.006142</td>\n",
       "      <td>14</td>\n",
       "      <td>53.377109</td>\n",
       "      <td>0.618891</td>\n",
       "      <td>14.409290</td>\n",
       "      <td>0.394985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.919397</td>\n",
       "      <td>0.004303</td>\n",
       "      <td>0.911062</td>\n",
       "      <td>0.005057</td>\n",
       "      <td>11</td>\n",
       "      <td>26.250061</td>\n",
       "      <td>0.165005</td>\n",
       "      <td>7.314962</td>\n",
       "      <td>0.197853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.949900</td>\n",
       "      <td>0.004345</td>\n",
       "      <td>0.947688</td>\n",
       "      <td>0.004742</td>\n",
       "      <td>6</td>\n",
       "      <td>17.304033</td>\n",
       "      <td>0.560825</td>\n",
       "      <td>3.993368</td>\n",
       "      <td>0.169731</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.911779</td>\n",
       "      <td>0.007275</td>\n",
       "      <td>0.908438</td>\n",
       "      <td>0.007772</td>\n",
       "      <td>12</td>\n",
       "      <td>31.606892</td>\n",
       "      <td>0.954140</td>\n",
       "      <td>7.834986</td>\n",
       "      <td>0.449831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>17</td>\n",
       "      <td>59.874684</td>\n",
       "      <td>0.810027</td>\n",
       "      <td>15.545575</td>\n",
       "      <td>0.402114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>17</td>\n",
       "      <td>59.836619</td>\n",
       "      <td>0.353329</td>\n",
       "      <td>15.992407</td>\n",
       "      <td>0.603869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>0.811331</td>\n",
       "      <td>0.000872</td>\n",
       "      <td>0.763563</td>\n",
       "      <td>0.001182</td>\n",
       "      <td>16</td>\n",
       "      <td>60.407225</td>\n",
       "      <td>1.051235</td>\n",
       "      <td>16.301724</td>\n",
       "      <td>0.457529</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>17</td>\n",
       "      <td>60.479505</td>\n",
       "      <td>1.244972</td>\n",
       "      <td>16.378230</td>\n",
       "      <td>0.540361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.683507</td>\n",
       "      <td>0.000054</td>\n",
       "      <td>0.519188</td>\n",
       "      <td>0.000063</td>\n",
       "      <td>17</td>\n",
       "      <td>59.869992</td>\n",
       "      <td>1.209002</td>\n",
       "      <td>16.273317</td>\n",
       "      <td>0.472568</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_kernel param_C param_gamma  mean_test_F1  std_test_F1  \\\n",
       "3        linear      10         NaN      0.947985     0.003004   \n",
       "2        linear       1         NaN      0.943939     0.003059   \n",
       "1        linear     0.1         NaN      0.929168     0.005085   \n",
       "0        linear   0.001         NaN      0.844318     0.005067   \n",
       "19          rbf      10          10      0.954324     0.002220   \n",
       "18          rbf      10           1      0.968615     0.002072   \n",
       "17          rbf      10         0.1      0.957844     0.003256   \n",
       "16          rbf      10       0.001      0.900781     0.004552   \n",
       "15          rbf       1          10      0.954683     0.002185   \n",
       "14          rbf       1           1      0.962855     0.001872   \n",
       "13          rbf       1         0.1      0.947112     0.005200   \n",
       "12          rbf       1       0.001      0.828766     0.006334   \n",
       "11          rbf     0.1          10      0.919397     0.004303   \n",
       "10          rbf     0.1           1      0.949900     0.004345   \n",
       "9           rbf     0.1         0.1      0.911779     0.007275   \n",
       "8           rbf     0.1       0.001      0.683507     0.000054   \n",
       "7           rbf   0.001          10      0.683507     0.000054   \n",
       "6           rbf   0.001           1      0.811331     0.000872   \n",
       "5           rbf   0.001         0.1      0.683507     0.000054   \n",
       "4           rbf   0.001       0.001      0.683507     0.000054   \n",
       "\n",
       "    mean_test_Accuracy  std_test_Accuracy  rank_test_Accuracy  mean_fit_time  \\\n",
       "3             0.946063           0.003021                   7      10.812186   \n",
       "2             0.941813           0.003174                   9      12.676310   \n",
       "1             0.926500           0.005323                  10      20.398949   \n",
       "0             0.823063           0.006238                  15      56.841637   \n",
       "19            0.951875           0.002351                   5      12.342011   \n",
       "18            0.967375           0.002112                   1       7.057173   \n",
       "17            0.956250           0.003422                   3       9.733783   \n",
       "16            0.896813           0.005141                  13      30.477180   \n",
       "15            0.952063           0.002334                   4      20.209869   \n",
       "14            0.961375           0.001941                   2       9.614222   \n",
       "13            0.945187           0.005501                   8      16.423818   \n",
       "12            0.827000           0.006142                  14      53.377109   \n",
       "11            0.911062           0.005057                  11      26.250061   \n",
       "10            0.947688           0.004742                   6      17.304033   \n",
       "9             0.908438           0.007772                  12      31.606892   \n",
       "8             0.519188           0.000063                  17      59.874684   \n",
       "7             0.519188           0.000063                  17      59.836619   \n",
       "6             0.763563           0.001182                  16      60.407225   \n",
       "5             0.519188           0.000063                  17      60.479505   \n",
       "4             0.519188           0.000063                  17      59.869992   \n",
       "\n",
       "    std_fit_time  mean_score_time  std_score_time  \n",
       "3       0.912470         1.693979        0.159801  \n",
       "2       0.228588         2.336374        0.082925  \n",
       "1       0.679764         4.614898        0.334103  \n",
       "0       0.364709        12.590611        0.896276  \n",
       "19      1.218828         2.993964        0.296574  \n",
       "18      0.464026         1.381827        0.136445  \n",
       "17      0.502281         2.087624        0.116255  \n",
       "16      0.304203         8.052330        0.389286  \n",
       "15      0.217480         4.897746        0.334222  \n",
       "14      0.311527         2.176467        0.149358  \n",
       "13      0.582909         3.634397        0.116167  \n",
       "12      0.618891        14.409290        0.394985  \n",
       "11      0.165005         7.314962        0.197853  \n",
       "10      0.560825         3.993368        0.169731  \n",
       "9       0.954140         7.834986        0.449831  \n",
       "8       0.810027        15.545575        0.402114  \n",
       "7       0.353329        15.992407        0.603869  \n",
       "6       1.051235        16.301724        0.457529  \n",
       "5       1.244972        16.378230        0.540361  \n",
       "4       1.209002        16.273317        0.472568  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Table de valeur')\n",
    "\n",
    "result = Grid.cv_results_\n",
    "df = pd.DataFrame(data=result)\n",
    "dfData=df[['param_kernel','param_C','param_gamma','mean_test_F1','std_test_F1','mean_test_Accuracy','std_test_Accuracy','rank_test_Accuracy','mean_fit_time', 'std_fit_time', 'mean_score_time', 'std_score_time']]\n",
    "dfData= dfData.sort_values(['param_kernel','param_C','param_gamma'],ascending=[True,False,False])\n",
    "dfData\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de linear avec hyperparametre\n",
      "[[1442   97]\n",
      " [  85 1576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1539\n",
      "           1       0.94      0.95      0.95      1661\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.94      0.94      0.94      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Résultat de linear avec hyperparametre')\n",
    "SVCLine(X_train, Y_train, X_test, Y_test,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Résultat de rbf avec hyperparametre\n",
      "[[1486   53]\n",
      " [  40 1621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1539\n",
      "           1       0.97      0.98      0.97      1661\n",
      "\n",
      "    accuracy                           0.97      3200\n",
      "   macro avg       0.97      0.97      0.97      3200\n",
      "weighted avg       0.97      0.97      0.97      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Résultat de rbf avec hyperparametre')\n",
    "SVC_rbf(X_train, Y_train, X_test, Y_test,10,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 6\n",
    "(1 - La méthode est décrite et un lien avec l’implémentation est fait afin d’expliquer comment l’équipe a trouvé le meilleur modèle SVM. \n",
    "2- Les résultats sont présentés de façon correcte et concise dans un TABLEAU ET un GRAPHIQUE. \n",
    "3 - La configuration matérielle sur laquelle les expérimentations est présente ainsi que le temps d’exécution requis pour compléter les expérimentations.)\n",
    "\n",
    "1 - explication implémentation SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "scrolled": true
   },
   "source": [
    "## Question 7\n",
    "(L’impact de la taille de l’ensemble d’apprentissage sur les performances est présent et décrit convenablement.)\n",
    "\n",
    "Dans le cas du MLP, on remarque que pour 1600 images, le temps d'apprentissage se situe autour de 5 secondes. Pour 16000, le temps d'apprentissage est d'environ 32 secondes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 8\n",
    "(Un classificateur est recommandé en se basant sur l’expérimentation précédemment effectuée.)\n",
    "\n",
    "SVM ou MLP en fonction des résultats (perf + time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 9\n",
    "(Des pistes d’amélioration sont proposées.)\n",
    "\n",
    "Bonne question : investiguer davantages les études d'hyperparamètres pour trouver une solution optimale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Conlusion\n",
    "\n",
    "(1 - Un court résumé du problème est présent.\n",
    "2 - Un rappel des résultats est présent.\n",
    "3 - Des pistes pour de possibles améliorations sont présentes.)\n",
    "\n",
    "Ce troisième laboratoire nous a permis de comprendre davantage le fonctionnment de deux nouvelles méthodes de classification : SVM et MLP. Dans les deux cas, les temps d'apprentissage sont bien plus long que les premiers laboratoires. \n",
    "Avantages et incovénients entre les deux méthodes:\n",
    "MLP : nb de sorties non limitée != svm => MLP plus évolutif si plus de deux catégories. \n",
    "\n",
    "Les résultats sont meilleurs dans le cas de ..... (MLP,SVM ?).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
