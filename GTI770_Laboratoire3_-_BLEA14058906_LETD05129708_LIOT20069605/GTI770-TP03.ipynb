{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "# Laboratoire 3 : Machines à vecteur de support et réseaux neuronaux\n#### Département du génie logiciel et des technologies de l’information\n\n| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n|-----------------------|---------------------------------------------------------|\n| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n| Session               | Automne 2019                                            |\n| Groupe                | 1                                                       |\n| Numéro du laboratoire | 3                                                       |\n| Professeur            | Prof. LOMBAERT                                          |\n| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n| Date                  | 18/11/2019                                              |"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Au cours de ce troisième laboratoire nous allons étudier deux nouveaux algorithme de classification pour résoudre le problème de classification des galaxies : les réseaux neuronaux et les machines à vecteurs de support (SVM). \n",
        "Dans un premier temps, nous allons concevoir un modèle de réseaux neuronaux basé sur le Multi-Layer Perceptron. Nous entrainerons ce modèle afin qu\u0027il puisse classer les galaxies en \"smooth\" ou \"spiral\" en utilisant l\u0027ensemble des primitives. Nous utiliserons le module keras de Google tensorflow\n",
        "Le deuxième modèle d\u0027apprentissage s\u0027appuie sur un modèle d\u0027optimisation convexe dans le cas du SVM. Dans ce cas, nous n\u0027utiliserons qu\u0027une partie des primitives proposées et seront couplées à nos primitives développées lors du premier laboratoire.\n",
        "Nous étudierons également l\u0027influence des hyperparamètres de ces deux méthodes afin de proposer le modèle le plus optimal dans le cas de notre problème de classification de galaxies."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 1\n",
        "(grille de correction : Les approches de validations sont présentées et utilisées correctement.)\n",
        "\n",
        "Dans le cas des réseaux neuronaux, l\u0027utilisation d\u0027une méthode de validation croisée prendrait beaucoup de temps. En effet, il faudrait répéter plusieurs tests avec un nombre \"d\u0027epochs\" conséquent : ceci serait très chronophage. Nous avons donc décider d\u0027utiliser la méthode de validation hold-out avec 70% de donées d\u0027entrainement et 30% de test.\n",
        "\n",
        "Concernant la méthode SVM, nous utilisons la méthode ......... (k-fold????)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 2\n",
        "(La méthode de normalisation des données est décrite et correcte.)\n",
        "\n",
        "Nous normalisons nos données grâce à la méthode \"normalize\" de la librairie preprocessing. La normalisation se fait par rapport à la valeur maximale. Nous avons décider de normaliser par rapport aux primitives (axis \u003d 0). Par ailleurs, nous avons remarqué avec nos premier tests que les performances étaient meilleures si l\u0027on normalisait par rapport à la valeur maximale (norm \u003d \u0027max\u0027)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": "## Question 3\n(Le modèle MLP est décrit (structure, nombre de couches). La fonction de coût choisie est mentionnée ainsi que les raisons pour lesquelles elle a été choisie.)\n\nLa principale contrainte du modèle MLP est de trouver un compromis entre le temps d\u0027apprentissage et l\u0027accuracy. La première architecture proposée par l\u0027énoncé est de trois couches : 100, 100, 2 (nombre de perceptrons). Nous avons étudié différents cas avec 60 epochs :  \n1 - l\u0027influence du nombre de perceptrons avec un nombre de couche fixé.  \n2 - l\u0027influence du nombre de couches avec le même nombre de perceptrons par couche.\n\nVoici donc nos résultats avec différentes structures de réseaux de neurones :\n\n1 - a:\n(Graphes nombre de perceptrons)\n\nNous remarquons qu\u0027avec trois couches, les performances d\u0027accuracy et de f1_score sont meilleurs dans le cas de [500,500,500] (dépassant les 95%). On remarque également que la perte (\"loss\") est, en quelque sorte, inversement proportionnelle aux f1_score et accuracy dans ce cas. C\u0027est à dire que pour un f1_score et une accuracy plus faible (nombre de perceptrons inférieur) la valeur de perte sera plus importante que les architectures avec plus de perceptrons.\n\n(graphe time nb perceptrons)\n\nEn revanche, ajouter un nombre de perceptrons par couche important influence grandement le temps d\u0027entrainement et de prediction.\n\n\n1 - b:\n(graphe nombre de couches)\n\nDans notre problème de classification de galaxies, on note que le les valeurs des accuracy et des f1_scores tendent vers les mêmes performances sur les jeux de données de tests qu\u0027il y ait une, trois ou six couches (nb de perceptrons constant par couche). On remarque également que la valeur de perte est moins importante dans le cas où il y le moins de couche. \n\n(graphe time nb couche)\nIci, nous remarquons que : plus le nombre de couche est important plus le temps d\u0027entrainement et de prediction sont élevés.\n"
    },
    {
      "cell_type": "raw",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "La fonction de coût que nous avons choisie est \"Binary Cross-Entropy Loss\". En effet, nous avons choisi cette fonction car nos valeurs cibles sont 0 ou 1, soit \"smooth\" ou \"spiral\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 4\n",
        "(L’analyse est claire et l’équipe démontre une compréhension du phénomène de sur-apprentissage. Il le phénomène est correctement décrit et montré dans le graphique dans la mesure du possible.)\n",
        "\n",
        "(graphe nb d\u0027epoch/perf)\n",
        "\n",
        "EXPLICATION A REVOIR CAR JE NE VOIS PAS DE SURAPPRENTISSAGE : \n",
        "Nous remarquons que les performances (accuracy et f1_score) tendent vers les mêmes taux qu\u0027il y ait 30, 60 ou 120 itérations. \n",
        "\n",
        "(graphe time - itérations)\n",
        "\n",
        "Notons ici que le temps d\u0027apprentissage et de prédiction croissent avec le nombre d\u0027itération."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 5\n",
        "(1 - La démarche de comparaison des hyperparamètres est sérieuse. Les résultats sont présentés de façon correcte et concise dans un tableau et un graphique.\n",
        "2 - Les explications montrant les différences sont claires, concises et plausibles.\n",
        "3 - La configuration matérielle sur laquelle les expérimentations est présenteainsi que le temps d’exécution requis pour compléter les expérimentations)\n",
        "\n",
        "1\u00262 : (alterner graphe et explication (cf q3) ou mettre tous les graphes (en q3) puis explication ici en q5.\n",
        "\n",
        "3 : regarder les specs du PC."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 6\n",
        "(1 - La méthode est décrite et un lien avec l’implémentation est fait afin d’expliquer comment l’équipe a trouvé le meilleur modèle SVM. \n",
        "2- Les résultats sont présentés de façon correcte et concise dans un TABLEAU ET un GRAPHIQUE. \n",
        "3 - La configuration matérielle sur laquelle les expérimentations est présente ainsi que le temps d’exécution requis pour compléter les expérimentations.)\n",
        "\n",
        "1 - explication implémentation SVM"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {},
        "scrolled": true
      },
      "source": [
        "## Question 7\n",
        "(L’impact de la taille de l’ensemble d’apprentissage sur les performances est présent et décrit convenablement.)\n",
        "\n",
        "Dans le cas du MLP, on remarque que pour 1600 images, le temps d\u0027apprentissage se situe autour de 5 secondes. Pour 16000, le temps d\u0027apprentissage est d\u0027environ 32 secondes. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 8\n",
        "(Un classificateur est recommandé en se basant sur l’expérimentation précédemment effectuée.)\n",
        "\n",
        "SVM ou MLP en fonction des résultats (perf + time)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Question 9\n",
        "(Des pistes d’amélioration sont proposées.)\n",
        "\n",
        "Bonne question : investiguer davantages les études d\u0027hyperparamètres pour trouver une solution optimale ?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "pycharm": {}
      },
      "source": [
        "## Conlusion\n",
        "\n",
        "(1 - Un court résumé du problème est présent.\n",
        "2 - Un rappel des résultats est présent.\n",
        "3 - Des pistes pour de possibles améliorations sont présentes.)\n",
        "\n",
        "Ce troisième laboratoire nous a permis de comprendre davantage le fonctionnment de deux nouvelles méthodes de classification : SVM et MLP. Dans les deux cas, les temps d\u0027apprentissage sont bien plus long que les premiers laboratoires. \n",
        "Avantages et incovénients entre les deux méthodes:\n",
        "MLP : nb de sorties non limitée !\u003d svm \u003d\u003e MLP plus évolutif si plus de deux catégories. \n",
        "\n",
        "Les résultats sont meilleurs dans le cas de ..... (MLP,SVM ?).\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "file_extension": ".py",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "mimetype": "text/x-python",
    "name": "python",
    "npconvert_exporter": "python",
    "pygments_lexer": "ipython3",
    "version": 3
  },
  "nbformat": 4,
  "nbformat_minor": 2
}