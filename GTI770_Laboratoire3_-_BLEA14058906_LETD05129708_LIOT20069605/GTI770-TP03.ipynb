{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "# Laboratoire 3 : Machines à vecteur de support et réseaux neuronaux\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2019                                            |\n",
    "| Groupe                | 1                                                       |\n",
    "| Numéro du laboratoire | 3                                                       |\n",
    "| Professeur            | Prof. LOMBAERT                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 18/11/2019                                              |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Introduction\n",
    "\n",
    "Au cours de ce troisième laboratoire nous allons étudier deux nouveaux algorithme de classification pour résoudre le problème de classification des galaxies : les réseaux neuronaux et les machines à vecteurs de support (SVM). \n",
    "Dans un premier temps, nous allons concevoir un modèle de réseaux neuronaux basé sur le Multi-Layer Perceptron. Nous entrainerons ce modèle afin qu'il puisse classer les galaxies en \"smooth\" ou \"spiral\" en utilisant l'ensemble des primitives. Nous utiliserons le module keras de Google tensorflow\n",
    "Le deuxième modèle d'apprentissage s'appuie sur un modèle d'optimisation convexe dans le cas du SVM. Dans ce cas, nous n'utiliserons qu'une partie des primitives proposées et seront couplées à nos primitives développées lors du premier laboratoire.\n",
    "Nous étudierons également l'influence des hyperparamètres de ces deux méthodes afin de proposer le modèle le plus optimal dans le cas de notre problème de classification de galaxies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 1\n",
    "(grille de correction : Les approches de validations sont présentées et utilisées correctement.)\n",
    "\n",
    "Dans le cas des réseaux neuronaux, l'utilisation d'une méthode de validation croisée prendrait beaucoup de temps. En effet, il faudrait répéter plusieurs tests avec un nombre \"d'epochs\" conséquent : ceci serait très chronophage. Nous avons donc décider d'utiliser la méthode de validation hold-out avec 70% de donées d'entrainement et 30% de test.\n",
    "\n",
    "Concernant la méthode SVM, nous utilisons la méthode ......... (k-fold????)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 2\n",
    "(La méthode de normalisation des données est décrite et correcte.)\n",
    "\n",
    "Nous normalisons nos données grâce à la méthode \"normalize\" de la librairie preprocessing. La normalisation se fait par rapport à la valeur maximale. Nous avons décider de normaliser par rapport aux primitives (axis = 0). Par ailleurs, nous avons remarqué avec nos premier tests que les performances étaient meilleures si l'on normalisait par rapport à la valeur maximale (norm = 'max')."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 3\n",
    "(Le modèle MLP est décrit (structure, nombre de couches). La fonction de coût choisie est mentionnée ainsi que les raisons pour lesquelles elle a été choisie.)\n",
    "\n",
    "La principale contrainte du modèle MLP est de trouver un compromis entre le temps d'apprentissage et l'accuracy. La première architecture proposée par l'énoncé est de trois couches : 100, 100, 2 (nombre de perceptrons). Nous avons étudié différents cas avec 60 epochs :  \n",
    "1 - l'influence du nombre de perceptrons avec un nombre de couche fixé.  \n",
    "2 - l'influence du nombre de couches avec le même nombre de perceptrons par couche.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Initialisation\n",
    "# conda install -c conda-forge tensorflow \n",
    "from RN_model import *\n",
    "from SVC import *\n",
    "from functions import get_data , plot_perf, plot_delay, get_data_GridSearch,plot_Linear_acc,plot_RBF_acc,plot_analyse\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn.metrics import make_scorer\n",
    "#from sklearn.metrics import accuracy_score\n",
    "#from sklearn.model_selection import StratifiedShuffleSplit,GridSearchCV\n",
    "#import csv\n",
    "X_train, X_test, Y_train, Y_test = get_data()\n",
    "\n",
    "layer_sizes = [100, 100, 2]\n",
    "epochs = 60\n",
    "learning_rate = 0.0005\n",
    "batch_size = 100\n",
    "\n",
    "dropout = 0.5\n",
    "\n",
    "# Pour affichage\n",
    "sub_title = ['loss','acc','f1','val_loss','val_acc', 'val_f1']\n",
    "x_lab = \"epochs\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Voici donc nos résultats avec différentes structures de réseaux de neurones :\n",
    "\n",
    "1 - a:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/ens/AQ38840/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /home/ens/AQ38840/anaconda3/lib/python3.7/site-packages/tensorflow/python/keras/layers/core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "WARNING:tensorflow:From /home/ens/AQ38840/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6932 - acc: 0.5165 - f1: 0.6763 - val_loss: 0.6927 - val_acc: 0.5191 - val_f1: 0.6827\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.6926 - acc: 0.5195 - f1: 0.6811 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6814\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.6925 - acc: 0.5176 - f1: 0.6802 - val_loss: 0.6922 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6823 - acc: 0.5073 - f1: 0.6697 - val_loss: 0.6564 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6512 - acc: 0.5150 - f1: 0.6784 - val_loss: 0.6042 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6282 - acc: 0.6591 - f1: 0.5898 - val_loss: 0.5667 - val_acc: 0.8234 - val_f1: 0.8493\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.6090 - acc: 0.6877 - f1: 0.6199 - val_loss: 0.5537 - val_acc: 0.9016 - val_f1: 0.9052\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5896 - acc: 0.6986 - f1: 0.6317 - val_loss: 0.5057 - val_acc: 0.9103 - val_f1: 0.9139\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5634 - acc: 0.7194 - f1: 0.6606 - val_loss: 0.4591 - val_acc: 0.9153 - val_f1: 0.9190\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5544 - acc: 0.7252 - f1: 0.6672 - val_loss: 0.4322 - val_acc: 0.9212 - val_f1: 0.9234\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5347 - acc: 0.7509 - f1: 0.7031 - val_loss: 0.4083 - val_acc: 0.9228 - val_f1: 0.9244\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.5349 - acc: 0.7462 - f1: 0.6927 - val_loss: 0.4148 - val_acc: 0.9209 - val_f1: 0.9197\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5189 - acc: 0.7555 - f1: 0.7063 - val_loss: 0.3725 - val_acc: 0.9297 - val_f1: 0.9309\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5061 - acc: 0.7605 - f1: 0.7118 - val_loss: 0.3522 - val_acc: 0.9203 - val_f1: 0.9256\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.5103 - acc: 0.7608 - f1: 0.7109 - val_loss: 0.3532 - val_acc: 0.9319 - val_f1: 0.9329\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4866 - acc: 0.7759 - f1: 0.7328 - val_loss: 0.3747 - val_acc: 0.9050 - val_f1: 0.9006\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4915 - acc: 0.7728 - f1: 0.7284 - val_loss: 0.3233 - val_acc: 0.9344 - val_f1: 0.9369\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4870 - acc: 0.7784 - f1: 0.7359 - val_loss: 0.3389 - val_acc: 0.9253 - val_f1: 0.9233\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4852 - acc: 0.7771 - f1: 0.7336 - val_loss: 0.3154 - val_acc: 0.9394 - val_f1: 0.9398\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4710 - acc: 0.7880 - f1: 0.7504 - val_loss: 0.3258 - val_acc: 0.9253 - val_f1: 0.9235\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4730 - acc: 0.7850 - f1: 0.7453 - val_loss: 0.3107 - val_acc: 0.9391 - val_f1: 0.9390\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4735 - acc: 0.7857 - f1: 0.7468 - val_loss: 0.3011 - val_acc: 0.9381 - val_f1: 0.9387\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4714 - acc: 0.7809 - f1: 0.7407 - val_loss: 0.3012 - val_acc: 0.9350 - val_f1: 0.9351\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4729 - acc: 0.7829 - f1: 0.7423 - val_loss: 0.2968 - val_acc: 0.9388 - val_f1: 0.9390\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4658 - acc: 0.7880 - f1: 0.7489 - val_loss: 0.2984 - val_acc: 0.9312 - val_f1: 0.9307\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4672 - acc: 0.7865 - f1: 0.7462 - val_loss: 0.3013 - val_acc: 0.9262 - val_f1: 0.9246\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4689 - acc: 0.7873 - f1: 0.7480 - val_loss: 0.2834 - val_acc: 0.9453 - val_f1: 0.9464\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4551 - acc: 0.7956 - f1: 0.7594 - val_loss: 0.2817 - val_acc: 0.9431 - val_f1: 0.9446\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4621 - acc: 0.7921 - f1: 0.7542 - val_loss: 0.2854 - val_acc: 0.9366 - val_f1: 0.9368\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4539 - acc: 0.7959 - f1: 0.7596 - val_loss: 0.2762 - val_acc: 0.9444 - val_f1: 0.9446\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4612 - acc: 0.7896 - f1: 0.7510 - val_loss: 0.2775 - val_acc: 0.9447 - val_f1: 0.9456\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4604 - acc: 0.7961 - f1: 0.7604 - val_loss: 0.2741 - val_acc: 0.9447 - val_f1: 0.9454\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4583 - acc: 0.7926 - f1: 0.7561 - val_loss: 0.2939 - val_acc: 0.9234 - val_f1: 0.9209\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4505 - acc: 0.7973 - f1: 0.7619 - val_loss: 0.2704 - val_acc: 0.9466 - val_f1: 0.9482\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4620 - acc: 0.7893 - f1: 0.7509 - val_loss: 0.2703 - val_acc: 0.9463 - val_f1: 0.9474\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4540 - acc: 0.7986 - f1: 0.7647 - val_loss: 0.2690 - val_acc: 0.9456 - val_f1: 0.9471\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4597 - acc: 0.7897 - f1: 0.7500 - val_loss: 0.2727 - val_acc: 0.9422 - val_f1: 0.9421\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4539 - acc: 0.7921 - f1: 0.7544 - val_loss: 0.2704 - val_acc: 0.9475 - val_f1: 0.9481\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4553 - acc: 0.7958 - f1: 0.7601 - val_loss: 0.2881 - val_acc: 0.9281 - val_f1: 0.9272\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4551 - acc: 0.7988 - f1: 0.7651 - val_loss: 0.2658 - val_acc: 0.9459 - val_f1: 0.9468\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4539 - acc: 0.7926 - f1: 0.7541 - val_loss: 0.2708 - val_acc: 0.9394 - val_f1: 0.9398\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4632 - acc: 0.7897 - f1: 0.7498 - val_loss: 0.2770 - val_acc: 0.9366 - val_f1: 0.9356\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4492 - acc: 0.7997 - f1: 0.7654 - val_loss: 0.2821 - val_acc: 0.9291 - val_f1: 0.9271\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4509 - acc: 0.7940 - f1: 0.7569 - val_loss: 0.2721 - val_acc: 0.9397 - val_f1: 0.9390\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4542 - acc: 0.7938 - f1: 0.7574 - val_loss: 0.2797 - val_acc: 0.9312 - val_f1: 0.9296\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4523 - acc: 0.8009 - f1: 0.7656 - val_loss: 0.2751 - val_acc: 0.9356 - val_f1: 0.9353\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4513 - acc: 0.7945 - f1: 0.7570 - val_loss: 0.2815 - val_acc: 0.9275 - val_f1: 0.9263\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4461 - acc: 0.7999 - f1: 0.7649 - val_loss: 0.2719 - val_acc: 0.9388 - val_f1: 0.9386\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4528 - acc: 0.7962 - f1: 0.7597 - val_loss: 0.2724 - val_acc: 0.9369 - val_f1: 0.9364\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 11us/sample - loss: 0.4623 - acc: 0.7891 - f1: 0.7492 - val_loss: 0.2653 - val_acc: 0.9472 - val_f1: 0.9483\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4532 - acc: 0.7962 - f1: 0.7594 - val_loss: 0.2630 - val_acc: 0.9494 - val_f1: 0.9504\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4502 - acc: 0.7987 - f1: 0.7635 - val_loss: 0.2688 - val_acc: 0.9463 - val_f1: 0.9479\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4499 - acc: 0.7973 - f1: 0.7609 - val_loss: 0.2719 - val_acc: 0.9397 - val_f1: 0.9388\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4508 - acc: 0.7959 - f1: 0.7590 - val_loss: 0.2709 - val_acc: 0.9391 - val_f1: 0.9382\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4334 - acc: 0.8030 - f1: 0.7683 - val_loss: 0.2633 - val_acc: 0.9447 - val_f1: 0.9444\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4521 - acc: 0.7946 - f1: 0.7562 - val_loss: 0.2785 - val_acc: 0.9303 - val_f1: 0.9289\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4454 - acc: 0.8028 - f1: 0.7695 - val_loss: 0.2778 - val_acc: 0.9294 - val_f1: 0.9280\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4567 - acc: 0.7920 - f1: 0.7527 - val_loss: 0.2684 - val_acc: 0.9500 - val_f1: 0.9518\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4482 - acc: 0.7977 - f1: 0.7626 - val_loss: 0.2991 - val_acc: 0.9125 - val_f1: 0.9087\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 10us/sample - loss: 0.4489 - acc: 0.7982 - f1: 0.7619 - val_loss: 0.2601 - val_acc: 0.9491 - val_f1: 0.9497\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 33us/sample - loss: 0.6947 - acc: 0.5028 - f1: 0.4201 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.6533 - acc: 0.5773 - f1: 0.6714 - val_loss: 0.5607 - val_acc: 0.8647 - val_f1: 0.8735\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5527 - acc: 0.7585 - f1: 0.7469 - val_loss: 0.4458 - val_acc: 0.9034 - val_f1: 0.9091\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.5071 - acc: 0.7957 - f1: 0.7765 - val_loss: 0.4005 - val_acc: 0.9059 - val_f1: 0.9146\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4878 - acc: 0.8010 - f1: 0.7790 - val_loss: 0.3870 - val_acc: 0.9322 - val_f1: 0.9325\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4645 - acc: 0.8141 - f1: 0.7938 - val_loss: 0.3599 - val_acc: 0.9366 - val_f1: 0.9389\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4592 - acc: 0.8141 - f1: 0.7912 - val_loss: 0.3600 - val_acc: 0.9278 - val_f1: 0.9270\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4493 - acc: 0.8145 - f1: 0.7908 - val_loss: 0.3289 - val_acc: 0.9409 - val_f1: 0.9422\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4360 - acc: 0.8234 - f1: 0.8032 - val_loss: 0.3501 - val_acc: 0.9197 - val_f1: 0.9169\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4332 - acc: 0.8175 - f1: 0.7949 - val_loss: 0.3275 - val_acc: 0.9303 - val_f1: 0.9299\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4324 - acc: 0.8185 - f1: 0.7959 - val_loss: 0.3130 - val_acc: 0.9384 - val_f1: 0.9386\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4263 - acc: 0.8242 - f1: 0.8027 - val_loss: 0.3077 - val_acc: 0.9397 - val_f1: 0.9396\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4225 - acc: 0.8244 - f1: 0.8023 - val_loss: 0.2881 - val_acc: 0.9447 - val_f1: 0.9460\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4151 - acc: 0.8283 - f1: 0.8071 - val_loss: 0.2833 - val_acc: 0.9466 - val_f1: 0.9482\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4177 - acc: 0.8235 - f1: 0.8016 - val_loss: 0.2825 - val_acc: 0.9444 - val_f1: 0.9441\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4142 - acc: 0.8261 - f1: 0.8040 - val_loss: 0.2803 - val_acc: 0.9466 - val_f1: 0.9473\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4075 - acc: 0.8305 - f1: 0.8106 - val_loss: 0.3081 - val_acc: 0.9203 - val_f1: 0.9166\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4215 - acc: 0.8180 - f1: 0.7935 - val_loss: 0.2711 - val_acc: 0.9472 - val_f1: 0.9477\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4139 - acc: 0.8206 - f1: 0.7973 - val_loss: 0.2621 - val_acc: 0.9488 - val_f1: 0.9479\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4068 - acc: 0.8282 - f1: 0.8068 - val_loss: 0.2535 - val_acc: 0.9491 - val_f1: 0.9514\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3966 - acc: 0.8339 - f1: 0.8143 - val_loss: 0.2723 - val_acc: 0.9359 - val_f1: 0.9353\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4033 - acc: 0.8314 - f1: 0.8115 - val_loss: 0.2625 - val_acc: 0.9419 - val_f1: 0.9416\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4008 - acc: 0.8275 - f1: 0.8057 - val_loss: 0.2568 - val_acc: 0.9478 - val_f1: 0.9482\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4035 - acc: 0.8289 - f1: 0.8079 - val_loss: 0.2410 - val_acc: 0.9534 - val_f1: 0.9551\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.4056 - acc: 0.8257 - f1: 0.8037 - val_loss: 0.2541 - val_acc: 0.9466 - val_f1: 0.9461\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4047 - acc: 0.8255 - f1: 0.8028 - val_loss: 0.2396 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3917 - acc: 0.8342 - f1: 0.8146 - val_loss: 0.2682 - val_acc: 0.9328 - val_f1: 0.9309\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3971 - acc: 0.8320 - f1: 0.8120 - val_loss: 0.2356 - val_acc: 0.9519 - val_f1: 0.9538\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3935 - acc: 0.8328 - f1: 0.8130 - val_loss: 0.2370 - val_acc: 0.9531 - val_f1: 0.9541\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4023 - acc: 0.8287 - f1: 0.8072 - val_loss: 0.2310 - val_acc: 0.9506 - val_f1: 0.9524\n",
      "Epoch 31/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3973 - acc: 0.8302 - f1: 0.8104 - val_loss: 0.2369 - val_acc: 0.9488 - val_f1: 0.9496\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3958 - acc: 0.8298 - f1: 0.8085 - val_loss: 0.2326 - val_acc: 0.9519 - val_f1: 0.9520\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3863 - acc: 0.8363 - f1: 0.8171 - val_loss: 0.2253 - val_acc: 0.9575 - val_f1: 0.9591\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3911 - acc: 0.8333 - f1: 0.8127 - val_loss: 0.2284 - val_acc: 0.9519 - val_f1: 0.9524\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4060 - acc: 0.8235 - f1: 0.7996 - val_loss: 0.2559 - val_acc: 0.9350 - val_f1: 0.9336\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3938 - acc: 0.8312 - f1: 0.8104 - val_loss: 0.2437 - val_acc: 0.9453 - val_f1: 0.9446\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3922 - acc: 0.8320 - f1: 0.8121 - val_loss: 0.2252 - val_acc: 0.9553 - val_f1: 0.9560\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3901 - acc: 0.8356 - f1: 0.8151 - val_loss: 0.2312 - val_acc: 0.9509 - val_f1: 0.9510\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3878 - acc: 0.8332 - f1: 0.8125 - val_loss: 0.2429 - val_acc: 0.9419 - val_f1: 0.9411\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3859 - acc: 0.8375 - f1: 0.8179 - val_loss: 0.2498 - val_acc: 0.9381 - val_f1: 0.9377\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3998 - acc: 0.8284 - f1: 0.8064 - val_loss: 0.2207 - val_acc: 0.9572 - val_f1: 0.9572\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3911 - acc: 0.8338 - f1: 0.8133 - val_loss: 0.2423 - val_acc: 0.9406 - val_f1: 0.9442\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3914 - acc: 0.8315 - f1: 0.8107 - val_loss: 0.2324 - val_acc: 0.9478 - val_f1: 0.9471\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3860 - acc: 0.8359 - f1: 0.8154 - val_loss: 0.2213 - val_acc: 0.9550 - val_f1: 0.9559\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3924 - acc: 0.8303 - f1: 0.8096 - val_loss: 0.2167 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3897 - acc: 0.8341 - f1: 0.8143 - val_loss: 0.2246 - val_acc: 0.9534 - val_f1: 0.9543\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3798 - acc: 0.8371 - f1: 0.8174 - val_loss: 0.2221 - val_acc: 0.9528 - val_f1: 0.9537\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3897 - acc: 0.8334 - f1: 0.8132 - val_loss: 0.2362 - val_acc: 0.9419 - val_f1: 0.9407\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3868 - acc: 0.8366 - f1: 0.8168 - val_loss: 0.2153 - val_acc: 0.9563 - val_f1: 0.9574\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3871 - acc: 0.8361 - f1: 0.8163 - val_loss: 0.2213 - val_acc: 0.9550 - val_f1: 0.9561\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3850 - acc: 0.8367 - f1: 0.8170 - val_loss: 0.2145 - val_acc: 0.9578 - val_f1: 0.9595\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3853 - acc: 0.8354 - f1: 0.8156 - val_loss: 0.2190 - val_acc: 0.9566 - val_f1: 0.9573\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3902 - acc: 0.8341 - f1: 0.8132 - val_loss: 0.2212 - val_acc: 0.9531 - val_f1: 0.9534\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3845 - acc: 0.8384 - f1: 0.8205 - val_loss: 0.2296 - val_acc: 0.9509 - val_f1: 0.9507\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.3817 - acc: 0.8391 - f1: 0.8195 - val_loss: 0.2170 - val_acc: 0.9566 - val_f1: 0.9573\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3958 - acc: 0.8276 - f1: 0.8041 - val_loss: 0.2152 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3843 - acc: 0.8345 - f1: 0.8145 - val_loss: 0.2158 - val_acc: 0.9578 - val_f1: 0.9584\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3853 - acc: 0.8364 - f1: 0.8160 - val_loss: 0.2196 - val_acc: 0.9550 - val_f1: 0.9562\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3779 - acc: 0.8404 - f1: 0.8226 - val_loss: 0.2142 - val_acc: 0.9566 - val_f1: 0.9583\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3732 - acc: 0.8428 - f1: 0.8252 - val_loss: 0.2110 - val_acc: 0.9563 - val_f1: 0.9575\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 77us/sample - loss: 0.5002 - acc: 0.7407 - f1: 0.7518 - val_loss: 0.2583 - val_acc: 0.8972 - val_f1: 0.9003\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.2443 - acc: 0.9042 - f1: 0.9071 - val_loss: 0.1887 - val_acc: 0.9291 - val_f1: 0.9335\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1938 - acc: 0.9241 - f1: 0.9265 - val_loss: 0.1520 - val_acc: 0.9444 - val_f1: 0.9467\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1656 - acc: 0.9370 - f1: 0.9386 - val_loss: 0.1541 - val_acc: 0.9444 - val_f1: 0.9475\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1650 - acc: 0.9377 - f1: 0.9396 - val_loss: 0.1340 - val_acc: 0.9478 - val_f1: 0.9491\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1539 - acc: 0.9413 - f1: 0.9432 - val_loss: 0.1327 - val_acc: 0.9491 - val_f1: 0.9517\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1434 - acc: 0.9466 - f1: 0.9483 - val_loss: 0.1279 - val_acc: 0.9534 - val_f1: 0.9546\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1410 - acc: 0.9472 - f1: 0.9488 - val_loss: 0.1819 - val_acc: 0.9309 - val_f1: 0.9364\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1360 - acc: 0.9506 - f1: 0.9524 - val_loss: 0.1286 - val_acc: 0.9516 - val_f1: 0.9536\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1323 - acc: 0.9507 - f1: 0.9520 - val_loss: 0.1142 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1291 - acc: 0.9528 - f1: 0.9540 - val_loss: 0.1413 - val_acc: 0.9459 - val_f1: 0.9491\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1220 - acc: 0.9546 - f1: 0.9559 - val_loss: 0.1153 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1255 - acc: 0.9556 - f1: 0.9573 - val_loss: 0.1123 - val_acc: 0.9594 - val_f1: 0.9607\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1233 - acc: 0.9549 - f1: 0.9562 - val_loss: 0.1261 - val_acc: 0.9531 - val_f1: 0.9538\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1166 - acc: 0.9584 - f1: 0.9595 - val_loss: 0.1094 - val_acc: 0.9581 - val_f1: 0.9592\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1199 - acc: 0.9549 - f1: 0.9562 - val_loss: 0.1090 - val_acc: 0.9563 - val_f1: 0.9572\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1166 - acc: 0.9553 - f1: 0.9567 - val_loss: 0.1159 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.1114 - acc: 0.9589 - f1: 0.9601 - val_loss: 0.1034 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 19/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1138 - acc: 0.9580 - f1: 0.9591 - val_loss: 0.1055 - val_acc: 0.9609 - val_f1: 0.9631\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1114 - acc: 0.9595 - f1: 0.9608 - val_loss: 0.1020 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 1s 58us/sample - loss: 0.1098 - acc: 0.9577 - f1: 0.9587 - val_loss: 0.1039 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 1s 59us/sample - loss: 0.1100 - acc: 0.9591 - f1: 0.9606 - val_loss: 0.1045 - val_acc: 0.9597 - val_f1: 0.9608\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1100 - acc: 0.9582 - f1: 0.9594 - val_loss: 0.1122 - val_acc: 0.9566 - val_f1: 0.9568\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1077 - acc: 0.9598 - f1: 0.9610 - val_loss: 0.1414 - val_acc: 0.9469 - val_f1: 0.9498\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 1s 61us/sample - loss: 0.1113 - acc: 0.9581 - f1: 0.9594 - val_loss: 0.1061 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1021 - acc: 0.9636 - f1: 0.9649 - val_loss: 0.1075 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1012 - acc: 0.9617 - f1: 0.9627 - val_loss: 0.1136 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 1s 65us/sample - loss: 0.1044 - acc: 0.9601 - f1: 0.9612 - val_loss: 0.1079 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1003 - acc: 0.9619 - f1: 0.9631 - val_loss: 0.1111 - val_acc: 0.9597 - val_f1: 0.9601\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1070 - acc: 0.9592 - f1: 0.9604 - val_loss: 0.1008 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.1049 - acc: 0.9616 - f1: 0.9628 - val_loss: 0.1019 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.1012 - acc: 0.9638 - f1: 0.9647 - val_loss: 0.0966 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.1007 - acc: 0.9623 - f1: 0.9632 - val_loss: 0.0955 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0965 - acc: 0.9641 - f1: 0.9653 - val_loss: 0.1013 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0964 - acc: 0.9637 - f1: 0.9651 - val_loss: 0.0952 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0964 - acc: 0.9643 - f1: 0.9655 - val_loss: 0.1124 - val_acc: 0.9559 - val_f1: 0.9556\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0941 - acc: 0.9662 - f1: 0.9671 - val_loss: 0.0979 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0956 - acc: 0.9643 - f1: 0.9654 - val_loss: 0.1008 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0943 - acc: 0.9663 - f1: 0.9673 - val_loss: 0.1130 - val_acc: 0.9606 - val_f1: 0.9611\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0965 - acc: 0.9634 - f1: 0.9645 - val_loss: 0.1071 - val_acc: 0.9609 - val_f1: 0.9618\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0945 - acc: 0.9655 - f1: 0.9662 - val_loss: 0.1001 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0911 - acc: 0.9659 - f1: 0.9669 - val_loss: 0.1043 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0937 - acc: 0.9662 - f1: 0.9673 - val_loss: 0.1075 - val_acc: 0.9609 - val_f1: 0.9613\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0940 - acc: 0.9668 - f1: 0.9676 - val_loss: 0.1083 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0907 - acc: 0.9663 - f1: 0.9675 - val_loss: 0.1107 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0900 - acc: 0.9660 - f1: 0.9670 - val_loss: 0.1078 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0897 - acc: 0.9675 - f1: 0.9685 - val_loss: 0.1202 - val_acc: 0.9581 - val_f1: 0.9589\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0857 - acc: 0.9696 - f1: 0.9706 - val_loss: 0.1044 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0877 - acc: 0.9666 - f1: 0.9675 - val_loss: 0.1051 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0847 - acc: 0.9694 - f1: 0.9703 - val_loss: 0.1093 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0820 - acc: 0.9705 - f1: 0.9718 - val_loss: 0.1021 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0865 - acc: 0.9677 - f1: 0.9685 - val_loss: 0.1060 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0852 - acc: 0.9691 - f1: 0.9700 - val_loss: 0.1013 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 1s 62us/sample - loss: 0.0829 - acc: 0.9701 - f1: 0.9709 - val_loss: 0.1032 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0863 - acc: 0.9687 - f1: 0.9695 - val_loss: 0.1020 - val_acc: 0.9669 - val_f1: 0.9670\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0935 - acc: 0.9667 - f1: 0.9679 - val_loss: 0.1126 - val_acc: 0.9591 - val_f1: 0.9602\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 1s 60us/sample - loss: 0.0841 - acc: 0.9698 - f1: 0.9708 - val_loss: 0.1078 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 1s 63us/sample - loss: 0.0819 - acc: 0.9696 - f1: 0.9705 - val_loss: 0.1186 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 1s 65us/sample - loss: 0.0845 - acc: 0.9701 - f1: 0.9711 - val_loss: 0.1198 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.0809 - acc: 0.9711 - f1: 0.9718 - val_loss: 0.1057 - val_acc: 0.9634 - val_f1: 0.9642\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "nb_perceptrons_range = [[5, 4, 4],[100, 100, 2],[500, 500, 500]]                                                                                                                      \n",
    "\n",
    "for nb_perceptrons in nb_perceptrons_range:                                                                                                                                                  \n",
    "    model = RN_model(nb_perceptrons, dropout, learning_rate)                                                                                                                              \n",
    "    #### Apprentissage                                                                                                                                                             \n",
    "    start = time.time()                                                                                                                                                            \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test))                                                             \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    training_delay_RN.append(end - start)                                                                                                                                          \n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                \n",
    "    start = time.time()                                                                                                                                                            \n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    predicting_delay_RN.append(end - start)    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in nb_perceptrons_range]                                                                                                                                          \n",
    "\n",
    "titre = \"RN : HyperParam = layer size\"   \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Nous remarquons qu'avec trois couches, les performances d'accuracy et de f1_score sont meilleurs dans le cas de [500,500,500] (dépassant les 95%). On remarque également que la perte (\"loss\") est, en quelque sorte, inversement proportionnelle aux f1_score et accuracy dans ce cas. C'est à dire que pour un f1_score et une accuracy plus faible (nombre de perceptrons inférieur) la valeur de perte sera plus importante que les architectures avec plus de perceptrons.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "\n",
    "En revanche, ajouter un nombre de perceptrons par couche important influence grandement le temps d'entrainement et de prediction.\n",
    "\n",
    "\n",
    "1 - b:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 49us/sample - loss: 0.6234 - acc: 0.6728 - f1: 0.7001 - val_loss: 0.4902 - val_acc: 0.8391 - val_f1: 0.8390\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4013 - acc: 0.8518 - f1: 0.8558 - val_loss: 0.3231 - val_acc: 0.8778 - val_f1: 0.8792\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3019 - acc: 0.8876 - f1: 0.8905 - val_loss: 0.2578 - val_acc: 0.9103 - val_f1: 0.9156\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.2532 - acc: 0.9087 - f1: 0.9110 - val_loss: 0.2169 - val_acc: 0.9237 - val_f1: 0.9281\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.2171 - acc: 0.9202 - f1: 0.9224 - val_loss: 0.1956 - val_acc: 0.9216 - val_f1: 0.9213\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1957 - acc: 0.9275 - f1: 0.9298 - val_loss: 0.1773 - val_acc: 0.9388 - val_f1: 0.9418\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1810 - acc: 0.9345 - f1: 0.9364 - val_loss: 0.1783 - val_acc: 0.9272 - val_f1: 0.9266\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1706 - acc: 0.9395 - f1: 0.9410 - val_loss: 0.1547 - val_acc: 0.9416 - val_f1: 0.9422\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1645 - acc: 0.9408 - f1: 0.9427 - val_loss: 0.1581 - val_acc: 0.9434 - val_f1: 0.9463\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1559 - acc: 0.9436 - f1: 0.9453 - val_loss: 0.1585 - val_acc: 0.9362 - val_f1: 0.9358\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1528 - acc: 0.9459 - f1: 0.9476 - val_loss: 0.1456 - val_acc: 0.9469 - val_f1: 0.9493\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1509 - acc: 0.9451 - f1: 0.9469 - val_loss: 0.1367 - val_acc: 0.9481 - val_f1: 0.9495\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.1480 - acc: 0.9469 - f1: 0.9482 - val_loss: 0.1334 - val_acc: 0.9481 - val_f1: 0.9495\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.1481 - acc: 0.9454 - f1: 0.9472 - val_loss: 0.1313 - val_acc: 0.9491 - val_f1: 0.9512\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 25us/sample - loss: 0.1428 - acc: 0.9469 - f1: 0.9484 - val_loss: 0.1288 - val_acc: 0.9516 - val_f1: 0.9531\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1376 - acc: 0.9516 - f1: 0.9530 - val_loss: 0.1295 - val_acc: 0.9506 - val_f1: 0.9532\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1363 - acc: 0.9505 - f1: 0.9517 - val_loss: 0.1278 - val_acc: 0.9522 - val_f1: 0.9540\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1359 - acc: 0.9493 - f1: 0.9510 - val_loss: 0.1307 - val_acc: 0.9475 - val_f1: 0.9486\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.1336 - acc: 0.9515 - f1: 0.9530 - val_loss: 0.1305 - val_acc: 0.9509 - val_f1: 0.9536\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.1319 - acc: 0.9515 - f1: 0.9525 - val_loss: 0.1223 - val_acc: 0.9522 - val_f1: 0.9525\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1310 - acc: 0.9516 - f1: 0.9531 - val_loss: 0.1375 - val_acc: 0.9513 - val_f1: 0.9542\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1297 - acc: 0.9539 - f1: 0.9555 - val_loss: 0.1260 - val_acc: 0.9531 - val_f1: 0.9555\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1335 - acc: 0.9495 - f1: 0.9506 - val_loss: 0.1233 - val_acc: 0.9547 - val_f1: 0.9569\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1295 - acc: 0.9539 - f1: 0.9551 - val_loss: 0.1223 - val_acc: 0.9538 - val_f1: 0.9545\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1276 - acc: 0.9527 - f1: 0.9538 - val_loss: 0.1170 - val_acc: 0.9569 - val_f1: 0.9575\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1264 - acc: 0.9541 - f1: 0.9553 - val_loss: 0.1200 - val_acc: 0.9559 - val_f1: 0.9572\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1255 - acc: 0.9560 - f1: 0.9575 - val_loss: 0.1151 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1202 - acc: 0.9562 - f1: 0.9576 - val_loss: 0.1196 - val_acc: 0.9559 - val_f1: 0.9576\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1238 - acc: 0.9557 - f1: 0.9568 - val_loss: 0.1156 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1200 - acc: 0.9572 - f1: 0.9588 - val_loss: 0.1179 - val_acc: 0.9566 - val_f1: 0.9572\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1213 - acc: 0.9566 - f1: 0.9578 - val_loss: 0.1132 - val_acc: 0.9566 - val_f1: 0.9577\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1241 - acc: 0.9556 - f1: 0.9568 - val_loss: 0.1120 - val_acc: 0.9578 - val_f1: 0.9597\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1180 - acc: 0.9590 - f1: 0.9601 - val_loss: 0.1279 - val_acc: 0.9525 - val_f1: 0.9533\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1235 - acc: 0.9530 - f1: 0.9544 - val_loss: 0.1330 - val_acc: 0.9506 - val_f1: 0.9511\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1189 - acc: 0.9563 - f1: 0.9575 - val_loss: 0.1106 - val_acc: 0.9581 - val_f1: 0.9588\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.1183 - acc: 0.9584 - f1: 0.9595 - val_loss: 0.1215 - val_acc: 0.9547 - val_f1: 0.9572\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1163 - acc: 0.9573 - f1: 0.9586 - val_loss: 0.1123 - val_acc: 0.9544 - val_f1: 0.9557\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1134 - acc: 0.9609 - f1: 0.9620 - val_loss: 0.1103 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1196 - acc: 0.9584 - f1: 0.9596 - val_loss: 0.1255 - val_acc: 0.9547 - val_f1: 0.9563\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1139 - acc: 0.9605 - f1: 0.9617 - val_loss: 0.1067 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1134 - acc: 0.9583 - f1: 0.9599 - val_loss: 0.1143 - val_acc: 0.9594 - val_f1: 0.9596\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1177 - acc: 0.9584 - f1: 0.9594 - val_loss: 0.1065 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1114 - acc: 0.9594 - f1: 0.9607 - val_loss: 0.1097 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.1135 - acc: 0.9589 - f1: 0.9603 - val_loss: 0.1110 - val_acc: 0.9597 - val_f1: 0.9610\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1124 - acc: 0.9577 - f1: 0.9588 - val_loss: 0.1184 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1154 - acc: 0.9588 - f1: 0.9597 - val_loss: 0.1300 - val_acc: 0.9544 - val_f1: 0.9574\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1132 - acc: 0.9591 - f1: 0.9604 - val_loss: 0.1093 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1101 - acc: 0.9605 - f1: 0.9616 - val_loss: 0.1112 - val_acc: 0.9603 - val_f1: 0.9620\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1091 - acc: 0.9613 - f1: 0.9624 - val_loss: 0.1123 - val_acc: 0.9544 - val_f1: 0.9546\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1133 - acc: 0.9581 - f1: 0.9597 - val_loss: 0.1062 - val_acc: 0.9591 - val_f1: 0.9603\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1111 - acc: 0.9606 - f1: 0.9618 - val_loss: 0.1046 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1069 - acc: 0.9612 - f1: 0.9626 - val_loss: 0.1056 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1068 - acc: 0.9614 - f1: 0.9627 - val_loss: 0.1040 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 14us/sample - loss: 0.1098 - acc: 0.9605 - f1: 0.9616 - val_loss: 0.1028 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1049 - acc: 0.9613 - f1: 0.9621 - val_loss: 0.1063 - val_acc: 0.9588 - val_f1: 0.9598\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1039 - acc: 0.9614 - f1: 0.9625 - val_loss: 0.1081 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1071 - acc: 0.9618 - f1: 0.9632 - val_loss: 0.1028 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1044 - acc: 0.9617 - f1: 0.9624 - val_loss: 0.1087 - val_acc: 0.9578 - val_f1: 0.9588\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1067 - acc: 0.9606 - f1: 0.9618 - val_loss: 0.1027 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 13us/sample - loss: 0.1053 - acc: 0.9626 - f1: 0.9639 - val_loss: 0.1039 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 64us/sample - loss: 0.6801 - acc: 0.5645 - f1: 0.5767 - val_loss: 0.6230 - val_acc: 0.7716 - val_f1: 0.7336\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.6025 - acc: 0.7311 - f1: 0.7464 - val_loss: 0.5195 - val_acc: 0.8697 - val_f1: 0.8713\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.5444 - acc: 0.7798 - f1: 0.8062 - val_loss: 0.4548 - val_acc: 0.9016 - val_f1: 0.9060\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 25us/sample - loss: 0.5091 - acc: 0.8049 - f1: 0.8299 - val_loss: 0.4139 - val_acc: 0.9112 - val_f1: 0.9126\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4869 - acc: 0.8131 - f1: 0.8392 - val_loss: 0.3903 - val_acc: 0.9234 - val_f1: 0.9265\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 24us/sample - loss: 0.4749 - acc: 0.8159 - f1: 0.8413 - val_loss: 0.3837 - val_acc: 0.9266 - val_f1: 0.9318\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 23us/sample - loss: 0.4667 - acc: 0.8217 - f1: 0.8463 - val_loss: 0.3526 - val_acc: 0.9334 - val_f1: 0.9365\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4616 - acc: 0.8180 - f1: 0.8436 - val_loss: 0.3472 - val_acc: 0.9356 - val_f1: 0.9396\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4536 - acc: 0.8226 - f1: 0.8479 - val_loss: 0.3377 - val_acc: 0.9300 - val_f1: 0.9309\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.4442 - acc: 0.8255 - f1: 0.8502 - val_loss: 0.3254 - val_acc: 0.9366 - val_f1: 0.9388\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4350 - acc: 0.8279 - f1: 0.8522 - val_loss: 0.3167 - val_acc: 0.9375 - val_f1: 0.9389\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 21us/sample - loss: 0.4381 - acc: 0.8241 - f1: 0.8495 - val_loss: 0.3120 - val_acc: 0.9388 - val_f1: 0.9423\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.4259 - acc: 0.8315 - f1: 0.8556 - val_loss: 0.2967 - val_acc: 0.9444 - val_f1: 0.9466\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.4224 - acc: 0.8289 - f1: 0.8534 - val_loss: 0.3143 - val_acc: 0.9316 - val_f1: 0.9368\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.4162 - acc: 0.8330 - f1: 0.8569 - val_loss: 0.2900 - val_acc: 0.9419 - val_f1: 0.9454\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.4216 - acc: 0.8295 - f1: 0.8543 - val_loss: 0.2830 - val_acc: 0.9469 - val_f1: 0.9500\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 21us/sample - loss: 0.4098 - acc: 0.8355 - f1: 0.8583 - val_loss: 0.2831 - val_acc: 0.9428 - val_f1: 0.9462\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.4078 - acc: 0.8370 - f1: 0.8594 - val_loss: 0.2722 - val_acc: 0.9450 - val_f1: 0.9474\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3982 - acc: 0.8401 - f1: 0.8621 - val_loss: 0.2714 - val_acc: 0.9431 - val_f1: 0.9469\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.4080 - acc: 0.8335 - f1: 0.8569 - val_loss: 0.3117 - val_acc: 0.9228 - val_f1: 0.9293\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3958 - acc: 0.8415 - f1: 0.8629 - val_loss: 0.2535 - val_acc: 0.9488 - val_f1: 0.9509\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3858 - acc: 0.8458 - f1: 0.8665 - val_loss: 0.2677 - val_acc: 0.9378 - val_f1: 0.9417\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3888 - acc: 0.8443 - f1: 0.8655 - val_loss: 0.2516 - val_acc: 0.9500 - val_f1: 0.9523\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3944 - acc: 0.8398 - f1: 0.8617 - val_loss: 0.2618 - val_acc: 0.9425 - val_f1: 0.9428\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3952 - acc: 0.8377 - f1: 0.8599 - val_loss: 0.2476 - val_acc: 0.9441 - val_f1: 0.9447\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3888 - acc: 0.8413 - f1: 0.8631 - val_loss: 0.2349 - val_acc: 0.9538 - val_f1: 0.9556\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3965 - acc: 0.8373 - f1: 0.8596 - val_loss: 0.2330 - val_acc: 0.9525 - val_f1: 0.9533\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3915 - acc: 0.8400 - f1: 0.8622 - val_loss: 0.2321 - val_acc: 0.9519 - val_f1: 0.9544\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3874 - acc: 0.8416 - f1: 0.8633 - val_loss: 0.2295 - val_acc: 0.9519 - val_f1: 0.9539\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3945 - acc: 0.8377 - f1: 0.8610 - val_loss: 0.2557 - val_acc: 0.9428 - val_f1: 0.9472\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3776 - acc: 0.8489 - f1: 0.8689 - val_loss: 0.2238 - val_acc: 0.9534 - val_f1: 0.9550\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3847 - acc: 0.8454 - f1: 0.8664 - val_loss: 0.2259 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3895 - acc: 0.8402 - f1: 0.8624 - val_loss: 0.2205 - val_acc: 0.9547 - val_f1: 0.9564\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3820 - acc: 0.8459 - f1: 0.8669 - val_loss: 0.2347 - val_acc: 0.9497 - val_f1: 0.9520\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3834 - acc: 0.8430 - f1: 0.8647 - val_loss: 0.2222 - val_acc: 0.9519 - val_f1: 0.9542\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3833 - acc: 0.8428 - f1: 0.8642 - val_loss: 0.2527 - val_acc: 0.9381 - val_f1: 0.9426\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3859 - acc: 0.8422 - f1: 0.8645 - val_loss: 0.2379 - val_acc: 0.9447 - val_f1: 0.9482\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3869 - acc: 0.8382 - f1: 0.8610 - val_loss: 0.2206 - val_acc: 0.9522 - val_f1: 0.9544\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3839 - acc: 0.8444 - f1: 0.8659 - val_loss: 0.2275 - val_acc: 0.9513 - val_f1: 0.9524\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3855 - acc: 0.8418 - f1: 0.8640 - val_loss: 0.2237 - val_acc: 0.9519 - val_f1: 0.9525\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3874 - acc: 0.8393 - f1: 0.8621 - val_loss: 0.2166 - val_acc: 0.9578 - val_f1: 0.9590\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3864 - acc: 0.8430 - f1: 0.8650 - val_loss: 0.2208 - val_acc: 0.9528 - val_f1: 0.9552\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3811 - acc: 0.8460 - f1: 0.8679 - val_loss: 0.2227 - val_acc: 0.9531 - val_f1: 0.9536\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 23us/sample - loss: 0.3765 - acc: 0.8474 - f1: 0.8686 - val_loss: 0.2209 - val_acc: 0.9547 - val_f1: 0.9568\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 21us/sample - loss: 0.3735 - acc: 0.8479 - f1: 0.8683 - val_loss: 0.2162 - val_acc: 0.9541 - val_f1: 0.9564\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3795 - acc: 0.8465 - f1: 0.8677 - val_loss: 0.2231 - val_acc: 0.9538 - val_f1: 0.9562\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 23us/sample - loss: 0.3782 - acc: 0.8452 - f1: 0.8664 - val_loss: 0.2186 - val_acc: 0.9550 - val_f1: 0.9572\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3787 - acc: 0.8445 - f1: 0.8658 - val_loss: 0.2172 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3840 - acc: 0.8435 - f1: 0.8646 - val_loss: 0.2316 - val_acc: 0.9491 - val_f1: 0.9520\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3751 - acc: 0.8493 - f1: 0.8700 - val_loss: 0.2173 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3802 - acc: 0.8452 - f1: 0.8668 - val_loss: 0.2134 - val_acc: 0.9569 - val_f1: 0.9581\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3753 - acc: 0.8469 - f1: 0.8679 - val_loss: 0.2177 - val_acc: 0.9544 - val_f1: 0.9566\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3747 - acc: 0.8502 - f1: 0.8702 - val_loss: 0.2154 - val_acc: 0.9559 - val_f1: 0.9586\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3749 - acc: 0.8476 - f1: 0.8691 - val_loss: 0.2174 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3827 - acc: 0.8439 - f1: 0.8658 - val_loss: 0.2259 - val_acc: 0.9519 - val_f1: 0.9542\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3802 - acc: 0.8451 - f1: 0.8666 - val_loss: 0.2192 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3778 - acc: 0.8461 - f1: 0.8676 - val_loss: 0.2162 - val_acc: 0.9541 - val_f1: 0.9562\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3792 - acc: 0.8445 - f1: 0.8661 - val_loss: 0.2139 - val_acc: 0.9566 - val_f1: 0.9586\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3843 - acc: 0.8445 - f1: 0.8662 - val_loss: 0.2479 - val_acc: 0.9394 - val_f1: 0.9437\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3761 - acc: 0.8471 - f1: 0.8683 - val_loss: 0.2140 - val_acc: 0.9584 - val_f1: 0.9602\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 1s 91us/sample - loss: 0.6961 - acc: 0.5202 - f1: 0.6512 - val_loss: 0.6928 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6929 - acc: 0.5204 - f1: 0.6772 - val_loss: 0.6926 - val_acc: 0.5191 - val_f1: 0.6821\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6927 - acc: 0.5202 - f1: 0.6792 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6816\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.6925 - acc: 0.5197 - f1: 0.6808 - val_loss: 0.6925 - val_acc: 0.5191 - val_f1: 0.6819\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6923 - acc: 0.5202 - f1: 0.6810 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6818\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.6920 - acc: 0.5223 - f1: 0.6774 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6825\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.6917 - acc: 0.5276 - f1: 0.6780 - val_loss: 0.6924 - val_acc: 0.5191 - val_f1: 0.6817\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.6526 - acc: 0.6195 - f1: 0.7059 - val_loss: 0.5656 - val_acc: 0.8644 - val_f1: 0.8783\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5973 - acc: 0.6858 - f1: 0.7527 - val_loss: 0.4498 - val_acc: 0.9053 - val_f1: 0.9084\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5744 - acc: 0.7038 - f1: 0.7688 - val_loss: 0.4466 - val_acc: 0.9125 - val_f1: 0.9198\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5622 - acc: 0.7113 - f1: 0.7743 - val_loss: 0.4367 - val_acc: 0.9209 - val_f1: 0.9271\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5568 - acc: 0.7101 - f1: 0.7745 - val_loss: 0.3757 - val_acc: 0.9222 - val_f1: 0.9245\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5432 - acc: 0.7222 - f1: 0.7820 - val_loss: 0.4654 - val_acc: 0.8719 - val_f1: 0.8889\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5436 - acc: 0.7184 - f1: 0.7803 - val_loss: 0.3672 - val_acc: 0.9347 - val_f1: 0.9379\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5423 - acc: 0.7169 - f1: 0.7799 - val_loss: 0.3754 - val_acc: 0.9284 - val_f1: 0.9329\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5388 - acc: 0.7247 - f1: 0.7843 - val_loss: 0.3733 - val_acc: 0.9316 - val_f1: 0.9357\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5358 - acc: 0.7231 - f1: 0.7841 - val_loss: 0.3820 - val_acc: 0.9284 - val_f1: 0.9332\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5310 - acc: 0.7242 - f1: 0.7846 - val_loss: 0.3489 - val_acc: 0.9388 - val_f1: 0.9411\n",
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5364 - acc: 0.7214 - f1: 0.7826 - val_loss: 0.4229 - val_acc: 0.8988 - val_f1: 0.9102\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5332 - acc: 0.7250 - f1: 0.7848 - val_loss: 0.3517 - val_acc: 0.9375 - val_f1: 0.9410\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5332 - acc: 0.7227 - f1: 0.7839 - val_loss: 0.3972 - val_acc: 0.9062 - val_f1: 0.9160\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5318 - acc: 0.7241 - f1: 0.7853 - val_loss: 0.3486 - val_acc: 0.9362 - val_f1: 0.9398\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5279 - acc: 0.7265 - f1: 0.7861 - val_loss: 0.3342 - val_acc: 0.9409 - val_f1: 0.9443\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5307 - acc: 0.7259 - f1: 0.7854 - val_loss: 0.3438 - val_acc: 0.9375 - val_f1: 0.9406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5287 - acc: 0.7259 - f1: 0.7857 - val_loss: 0.3444 - val_acc: 0.9372 - val_f1: 0.9408\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5243 - acc: 0.7303 - f1: 0.7884 - val_loss: 0.3826 - val_acc: 0.9259 - val_f1: 0.9325\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5258 - acc: 0.7291 - f1: 0.7882 - val_loss: 0.3278 - val_acc: 0.9425 - val_f1: 0.9454\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5251 - acc: 0.7270 - f1: 0.7870 - val_loss: 0.3137 - val_acc: 0.9438 - val_f1: 0.9465\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5326 - acc: 0.7207 - f1: 0.7824 - val_loss: 0.3718 - val_acc: 0.9281 - val_f1: 0.9347\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 26us/sample - loss: 0.5188 - acc: 0.7345 - f1: 0.7916 - val_loss: 0.3437 - val_acc: 0.9416 - val_f1: 0.9448\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5152 - acc: 0.7361 - f1: 0.7924 - val_loss: 0.3122 - val_acc: 0.9466 - val_f1: 0.9484\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5231 - acc: 0.7328 - f1: 0.7905 - val_loss: 0.3597 - val_acc: 0.9344 - val_f1: 0.9395\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5217 - acc: 0.7312 - f1: 0.7896 - val_loss: 0.3127 - val_acc: 0.9466 - val_f1: 0.9480\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5188 - acc: 0.7318 - f1: 0.7903 - val_loss: 0.3580 - val_acc: 0.9350 - val_f1: 0.9402\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5208 - acc: 0.7341 - f1: 0.7914 - val_loss: 0.3215 - val_acc: 0.9500 - val_f1: 0.9516\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 27us/sample - loss: 0.5207 - acc: 0.7300 - f1: 0.7884 - val_loss: 0.3114 - val_acc: 0.9456 - val_f1: 0.9476\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5158 - acc: 0.7344 - f1: 0.7923 - val_loss: 0.3061 - val_acc: 0.9506 - val_f1: 0.9524\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5251 - acc: 0.7255 - f1: 0.7856 - val_loss: 0.3468 - val_acc: 0.9434 - val_f1: 0.9472\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5167 - acc: 0.7350 - f1: 0.7922 - val_loss: 0.3601 - val_acc: 0.9291 - val_f1: 0.9344\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 30us/sample - loss: 0.5178 - acc: 0.7329 - f1: 0.7911 - val_loss: 0.3414 - val_acc: 0.9444 - val_f1: 0.9481\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 31us/sample - loss: 0.5153 - acc: 0.7352 - f1: 0.7923 - val_loss: 0.3719 - val_acc: 0.9200 - val_f1: 0.9272\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5203 - acc: 0.7327 - f1: 0.7907 - val_loss: 0.3036 - val_acc: 0.9509 - val_f1: 0.9517\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 30us/sample - loss: 0.5226 - acc: 0.7305 - f1: 0.7884 - val_loss: 0.3444 - val_acc: 0.9447 - val_f1: 0.9487\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5194 - acc: 0.7323 - f1: 0.7900 - val_loss: 0.3271 - val_acc: 0.9488 - val_f1: 0.9503\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 31us/sample - loss: 0.5161 - acc: 0.7360 - f1: 0.7927 - val_loss: 0.3309 - val_acc: 0.9400 - val_f1: 0.9436\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 32us/sample - loss: 0.5098 - acc: 0.7410 - f1: 0.7957 - val_loss: 0.3329 - val_acc: 0.9472 - val_f1: 0.9505\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 28us/sample - loss: 0.5182 - acc: 0.7362 - f1: 0.7928 - val_loss: 0.3071 - val_acc: 0.9522 - val_f1: 0.9539\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 29us/sample - loss: 0.5236 - acc: 0.7279 - f1: 0.7874 - val_loss: 0.3856 - val_acc: 0.9275 - val_f1: 0.9336\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5135 - acc: 0.7355 - f1: 0.7919 - val_loss: 0.3201 - val_acc: 0.9509 - val_f1: 0.9533\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5246 - acc: 0.7248 - f1: 0.7861 - val_loss: 0.3415 - val_acc: 0.9431 - val_f1: 0.9471\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 34us/sample - loss: 0.5186 - acc: 0.7323 - f1: 0.7905 - val_loss: 0.4025 - val_acc: 0.9103 - val_f1: 0.9200\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 33us/sample - loss: 0.5182 - acc: 0.7334 - f1: 0.7911 - val_loss: 0.3630 - val_acc: 0.9447 - val_f1: 0.9486\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5163 - acc: 0.7343 - f1: 0.7916 - val_loss: 0.3052 - val_acc: 0.9209 - val_f1: 0.9186\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 37us/sample - loss: 0.5204 - acc: 0.7319 - f1: 0.7894 - val_loss: 0.3206 - val_acc: 0.9553 - val_f1: 0.9577\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 1s 41us/sample - loss: 0.5172 - acc: 0.7340 - f1: 0.7913 - val_loss: 0.3283 - val_acc: 0.9509 - val_f1: 0.9524\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 1s 48us/sample - loss: 0.5166 - acc: 0.7377 - f1: 0.7938 - val_loss: 0.3338 - val_acc: 0.9522 - val_f1: 0.9543\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 37us/sample - loss: 0.5169 - acc: 0.7345 - f1: 0.7914 - val_loss: 0.4471 - val_acc: 0.8959 - val_f1: 0.9084\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 33us/sample - loss: 0.5112 - acc: 0.7384 - f1: 0.7943 - val_loss: 0.3278 - val_acc: 0.9550 - val_f1: 0.9569\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.5165 - acc: 0.7333 - f1: 0.7918 - val_loss: 0.3223 - val_acc: 0.9509 - val_f1: 0.9535\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 38us/sample - loss: 0.5164 - acc: 0.7330 - f1: 0.7903 - val_loss: 0.3055 - val_acc: 0.9500 - val_f1: 0.9500\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "layer_sizes_range = [[100],[100, 100, 2],[100, 100, 100, 100, 100, 2]]\n",
    "\n",
    "for layer_s in layer_sizes_range:\n",
    "    model = RN_model(layer_s, dropout, learning_rate)\n",
    "    #### Apprentissage                                                                                                                                                               \n",
    "    start = time.time()                                                                                                                   \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test))\n",
    "\n",
    "    end = time.time()\n",
    "    training_delay_RN.append(end - start)\n",
    "\n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                  \n",
    "    start = time.time()\n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)\n",
    "\n",
    "    end = time.time()\n",
    "    predicting_delay_RN.append(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'layer_sizes_range' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-f13cfc91e535>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mho\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mho\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mleg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlayer_sizes_range\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtitre\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"RN : HyperParam = number of layer\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'layer_sizes_range' is not defined"
     ]
    }
   ],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in layer_sizes_range]                                                                                                                                              \n",
    "\n",
    "titre = \"RN : HyperParam = number of layer\"                                                                                                                                         \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Dans notre problème de classification de galaxies, on note que le les valeurs des accuracy et des f1_scores tendent vers les mêmes performances sur les jeux de données de tests qu'il y ait une, trois ou six couches (nb de perceptrons constant par couche). On remarque également que la valeur de perte est moins importante dans le cas où il y le moins de couche. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%% md\n"
    }
   },
   "source": [
    "Ici, nous remarquons que : plus le nombre de couche est important plus le temps d'entrainement et de prediction sont élevés.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [],
   "source": [
    "\n",
    "################################## Learning rate                                                                                                                                     \n",
    "\n",
    "#l_rate_range = [0.00001,0.0005,0.1]                                                                                                                                                          \n",
    "\n",
    "# for l_rate in l_rate_range:                                                                                                                                                        \n",
    "#     model = RN_model(layer_sizes, dropout, l_rate)                                                                                                                                 \n",
    "#     #### Apprentissage                                                                                                                                                             \n",
    "#     start = time.time()                                                                                                                                                            \n",
    "#     #model.fit(X_train, Y_train, batch_size = 100, epochs = 60)                                                                                                                    \n",
    "#     hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test))                                                             \n",
    "#                                                                                                                                                                                    \n",
    "#     end = time.time()                                                                                                                                                              \n",
    "#     training_delay_RN.append(end - start)                                                                                                                                          \n",
    "#                                                                                                                                                                                    \n",
    "#     history_obj.append( list(hist_obj.history.values()))                                                                                                                           \n",
    "#                                                                                                                                                                                    \n",
    "#     #### Prédiction                                                                                                                                                                \n",
    "#     start = time.time()                                                                                                                                                            \n",
    "#                                                                                                                                                                                    \n",
    "#     Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "#                                                                                                                                                                                    \n",
    "#     end = time.time()                                                                                                                                                              \n",
    "#     predicting_delay_RN.append(end - start)   \n",
    "# \n",
    "#   \n",
    "\n",
    "# Traitement pour affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "                                                                                                                                      \n",
    "leg = [str(i) for i in l_rate_range]                                                                                                                                                \n",
    "                                                                                                                                    \n",
    "titre = \"RN : HyperParam = learning rate\"                                                                                                                                           \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)\n",
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "La fonction de coût que nous avons choisie est \"Binary Cross-Entropy Loss\". En effet, nous avons choisi cette fonction car nos valeurs cibles sont 0 ou 1, soit \"smooth\" ou \"spiral\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 4\n",
    "(L’analyse est claire et l’équipe démontre une compréhension du phénomène de sur-apprentissage. Il le phénomène est correctement décrit et montré dans le graphique dans la mesure du possible.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/30\n",
      "12800/12800 [==============================] - 0s 35us/sample - loss: 0.6914 - acc: 0.5196 - f1: 0.5394 - val_loss: 0.6674 - val_acc: 0.6288 - val_f1: 0.7314\n",
      "Epoch 2/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.6181 - acc: 0.6126 - f1: 0.6093 - val_loss: 0.4916 - val_acc: 0.8550 - val_f1: 0.8533\n",
      "Epoch 3/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.5316 - acc: 0.6757 - f1: 0.5877 - val_loss: 0.3570 - val_acc: 0.9041 - val_f1: 0.9079\n",
      "Epoch 4/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4955 - acc: 0.6856 - f1: 0.5981 - val_loss: 0.3395 - val_acc: 0.8966 - val_f1: 0.8922\n",
      "Epoch 5/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4658 - acc: 0.6995 - f1: 0.6151 - val_loss: 0.2713 - val_acc: 0.9325 - val_f1: 0.9354\n",
      "Epoch 6/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4485 - acc: 0.7016 - f1: 0.6162 - val_loss: 0.2564 - val_acc: 0.9266 - val_f1: 0.9251\n",
      "Epoch 7/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4474 - acc: 0.7170 - f1: 0.7582 - val_loss: 0.2378 - val_acc: 0.9413 - val_f1: 0.9441\n",
      "Epoch 8/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4422 - acc: 0.7257 - f1: 0.7818 - val_loss: 0.2394 - val_acc: 0.9359 - val_f1: 0.9359\n",
      "Epoch 9/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4318 - acc: 0.7313 - f1: 0.7868 - val_loss: 0.2380 - val_acc: 0.9362 - val_f1: 0.9368\n",
      "Epoch 10/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4315 - acc: 0.7325 - f1: 0.7877 - val_loss: 0.2053 - val_acc: 0.9469 - val_f1: 0.9481\n",
      "Epoch 11/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4235 - acc: 0.7335 - f1: 0.7886 - val_loss: 0.1909 - val_acc: 0.9478 - val_f1: 0.9506\n",
      "Epoch 12/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4229 - acc: 0.7327 - f1: 0.7888 - val_loss: 0.2138 - val_acc: 0.9375 - val_f1: 0.9373\n",
      "Epoch 13/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4310 - acc: 0.7237 - f1: 0.7824 - val_loss: 0.2130 - val_acc: 0.9434 - val_f1: 0.9474\n",
      "Epoch 14/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4252 - acc: 0.7325 - f1: 0.7886 - val_loss: 0.1942 - val_acc: 0.9481 - val_f1: 0.9508\n",
      "Epoch 15/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4227 - acc: 0.7320 - f1: 0.7884 - val_loss: 0.2159 - val_acc: 0.9463 - val_f1: 0.9464\n",
      "Epoch 16/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4234 - acc: 0.7300 - f1: 0.7874 - val_loss: 0.2117 - val_acc: 0.9278 - val_f1: 0.9254\n",
      "Epoch 17/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4217 - acc: 0.7298 - f1: 0.7870 - val_loss: 0.1834 - val_acc: 0.9516 - val_f1: 0.9533\n",
      "Epoch 18/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4222 - acc: 0.7270 - f1: 0.7854 - val_loss: 0.1798 - val_acc: 0.9528 - val_f1: 0.9548\n",
      "Epoch 19/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4129 - acc: 0.7391 - f1: 0.7928 - val_loss: 0.1804 - val_acc: 0.9522 - val_f1: 0.9528\n",
      "Epoch 20/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4176 - acc: 0.7307 - f1: 0.7880 - val_loss: 0.1632 - val_acc: 0.9553 - val_f1: 0.9569\n",
      "Epoch 21/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4153 - acc: 0.7330 - f1: 0.7896 - val_loss: 0.1730 - val_acc: 0.9494 - val_f1: 0.9520\n",
      "Epoch 22/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4155 - acc: 0.7350 - f1: 0.7906 - val_loss: 0.2071 - val_acc: 0.9337 - val_f1: 0.9322\n",
      "Epoch 23/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4193 - acc: 0.7335 - f1: 0.7892 - val_loss: 0.1755 - val_acc: 0.9506 - val_f1: 0.9525\n",
      "Epoch 24/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4141 - acc: 0.7368 - f1: 0.7927 - val_loss: 0.1682 - val_acc: 0.9503 - val_f1: 0.9510\n",
      "Epoch 25/30\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4122 - acc: 0.7355 - f1: 0.7905 - val_loss: 0.1561 - val_acc: 0.9525 - val_f1: 0.9542\n",
      "Epoch 26/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4137 - acc: 0.7309 - f1: 0.7885 - val_loss: 0.1567 - val_acc: 0.9569 - val_f1: 0.9580\n",
      "Epoch 27/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4147 - acc: 0.7339 - f1: 0.7911 - val_loss: 0.1680 - val_acc: 0.9544 - val_f1: 0.9551\n",
      "Epoch 28/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4083 - acc: 0.7375 - f1: 0.7932 - val_loss: 0.1620 - val_acc: 0.9544 - val_f1: 0.9562\n",
      "Epoch 29/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4111 - acc: 0.7351 - f1: 0.7915 - val_loss: 0.1648 - val_acc: 0.9566 - val_f1: 0.9580\n",
      "Epoch 30/30\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4148 - acc: 0.7369 - f1: 0.7924 - val_loss: 0.1572 - val_acc: 0.9563 - val_f1: 0.9577\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/60\n",
      "12800/12800 [==============================] - 0s 36us/sample - loss: 0.6791 - acc: 0.5435 - f1: 0.5851 - val_loss: 0.6254 - val_acc: 0.8259 - val_f1: 0.8365\n",
      "Epoch 2/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5923 - acc: 0.7173 - f1: 0.7109 - val_loss: 0.5351 - val_acc: 0.8628 - val_f1: 0.8569\n",
      "Epoch 3/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5307 - acc: 0.7768 - f1: 0.7586 - val_loss: 0.4271 - val_acc: 0.9053 - val_f1: 0.9116\n",
      "Epoch 4/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4985 - acc: 0.7922 - f1: 0.7702 - val_loss: 0.3911 - val_acc: 0.9078 - val_f1: 0.9135\n",
      "Epoch 5/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4779 - acc: 0.8046 - f1: 0.7820 - val_loss: 0.3639 - val_acc: 0.9316 - val_f1: 0.9348\n",
      "Epoch 6/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4637 - acc: 0.8102 - f1: 0.7879 - val_loss: 0.3501 - val_acc: 0.9409 - val_f1: 0.9420\n",
      "Epoch 7/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4511 - acc: 0.8146 - f1: 0.7917 - val_loss: 0.3378 - val_acc: 0.9431 - val_f1: 0.9441\n",
      "Epoch 8/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4471 - acc: 0.8169 - f1: 0.7955 - val_loss: 0.3270 - val_acc: 0.9422 - val_f1: 0.9428\n",
      "Epoch 9/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4342 - acc: 0.8204 - f1: 0.7989 - val_loss: 0.3581 - val_acc: 0.9109 - val_f1: 0.9073\n",
      "Epoch 10/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4238 - acc: 0.8249 - f1: 0.8042 - val_loss: 0.3014 - val_acc: 0.9463 - val_f1: 0.9468\n",
      "Epoch 11/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4206 - acc: 0.8243 - f1: 0.8022 - val_loss: 0.3258 - val_acc: 0.9269 - val_f1: 0.9251\n",
      "Epoch 12/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4239 - acc: 0.8213 - f1: 0.7989 - val_loss: 0.2911 - val_acc: 0.9456 - val_f1: 0.9463\n",
      "Epoch 13/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4278 - acc: 0.8186 - f1: 0.7946 - val_loss: 0.2794 - val_acc: 0.9506 - val_f1: 0.9520\n",
      "Epoch 14/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4140 - acc: 0.8252 - f1: 0.8044 - val_loss: 0.2766 - val_acc: 0.9491 - val_f1: 0.9517\n",
      "Epoch 15/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4120 - acc: 0.8266 - f1: 0.8058 - val_loss: 0.3027 - val_acc: 0.9322 - val_f1: 0.9304\n",
      "Epoch 16/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4037 - acc: 0.8320 - f1: 0.8121 - val_loss: 0.2758 - val_acc: 0.9456 - val_f1: 0.9457\n",
      "Epoch 17/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4036 - acc: 0.8320 - f1: 0.8120 - val_loss: 0.2561 - val_acc: 0.9547 - val_f1: 0.9552\n",
      "Epoch 18/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4057 - acc: 0.8272 - f1: 0.8056 - val_loss: 0.2518 - val_acc: 0.9547 - val_f1: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3978 - acc: 0.8338 - f1: 0.8147 - val_loss: 0.2567 - val_acc: 0.9519 - val_f1: 0.9532\n",
      "Epoch 20/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4058 - acc: 0.8241 - f1: 0.8023 - val_loss: 0.2704 - val_acc: 0.9378 - val_f1: 0.9363\n",
      "Epoch 21/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3990 - acc: 0.8291 - f1: 0.8078 - val_loss: 0.2408 - val_acc: 0.9569 - val_f1: 0.9584\n",
      "Epoch 22/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4000 - acc: 0.8280 - f1: 0.8068 - val_loss: 0.2412 - val_acc: 0.9544 - val_f1: 0.9552\n",
      "Epoch 23/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3924 - acc: 0.8316 - f1: 0.8107 - val_loss: 0.2397 - val_acc: 0.9544 - val_f1: 0.9554\n",
      "Epoch 24/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4002 - acc: 0.8291 - f1: 0.8078 - val_loss: 0.2452 - val_acc: 0.9513 - val_f1: 0.9507\n",
      "Epoch 25/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3977 - acc: 0.8305 - f1: 0.8093 - val_loss: 0.2909 - val_acc: 0.9147 - val_f1: 0.9100\n",
      "Epoch 26/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3983 - acc: 0.8305 - f1: 0.8099 - val_loss: 0.2298 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 27/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3918 - acc: 0.8316 - f1: 0.8116 - val_loss: 0.2383 - val_acc: 0.9500 - val_f1: 0.9502\n",
      "Epoch 28/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4053 - acc: 0.8255 - f1: 0.8027 - val_loss: 0.2258 - val_acc: 0.9575 - val_f1: 0.9581\n",
      "Epoch 29/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3911 - acc: 0.8341 - f1: 0.8138 - val_loss: 0.2366 - val_acc: 0.9478 - val_f1: 0.9481\n",
      "Epoch 30/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4002 - acc: 0.8279 - f1: 0.8064 - val_loss: 0.2527 - val_acc: 0.9384 - val_f1: 0.9377\n",
      "Epoch 31/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3949 - acc: 0.8297 - f1: 0.8086 - val_loss: 0.2302 - val_acc: 0.9541 - val_f1: 0.9542\n",
      "Epoch 32/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3970 - acc: 0.8302 - f1: 0.8089 - val_loss: 0.2194 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 33/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4016 - acc: 0.8258 - f1: 0.8027 - val_loss: 0.2378 - val_acc: 0.9500 - val_f1: 0.9503\n",
      "Epoch 34/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3874 - acc: 0.8355 - f1: 0.8162 - val_loss: 0.2209 - val_acc: 0.9569 - val_f1: 0.9587\n",
      "Epoch 35/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3967 - acc: 0.8283 - f1: 0.8067 - val_loss: 0.2354 - val_acc: 0.9500 - val_f1: 0.9502\n",
      "Epoch 36/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3901 - acc: 0.8344 - f1: 0.8147 - val_loss: 0.2615 - val_acc: 0.9312 - val_f1: 0.9300\n",
      "Epoch 37/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3884 - acc: 0.8330 - f1: 0.8123 - val_loss: 0.2177 - val_acc: 0.9594 - val_f1: 0.9602\n",
      "Epoch 38/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3933 - acc: 0.8352 - f1: 0.8158 - val_loss: 0.2136 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 39/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3907 - acc: 0.8338 - f1: 0.8137 - val_loss: 0.2174 - val_acc: 0.9578 - val_f1: 0.9595\n",
      "Epoch 40/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3867 - acc: 0.8353 - f1: 0.8154 - val_loss: 0.2335 - val_acc: 0.9491 - val_f1: 0.9483\n",
      "Epoch 41/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3872 - acc: 0.8354 - f1: 0.8160 - val_loss: 0.2133 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 42/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3900 - acc: 0.8340 - f1: 0.8142 - val_loss: 0.2182 - val_acc: 0.9578 - val_f1: 0.9594\n",
      "Epoch 43/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3888 - acc: 0.8341 - f1: 0.8137 - val_loss: 0.2131 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 44/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3847 - acc: 0.8383 - f1: 0.8192 - val_loss: 0.2222 - val_acc: 0.9575 - val_f1: 0.9582\n",
      "Epoch 45/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3848 - acc: 0.8363 - f1: 0.8161 - val_loss: 0.2175 - val_acc: 0.9566 - val_f1: 0.9569\n",
      "Epoch 46/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3890 - acc: 0.8338 - f1: 0.8141 - val_loss: 0.2103 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 47/60\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3914 - acc: 0.8329 - f1: 0.8125 - val_loss: 0.2128 - val_acc: 0.9609 - val_f1: 0.9616\n",
      "Epoch 48/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3773 - acc: 0.8409 - f1: 0.8233 - val_loss: 0.2119 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 49/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3856 - acc: 0.8354 - f1: 0.8152 - val_loss: 0.2095 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 50/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3837 - acc: 0.8377 - f1: 0.8170 - val_loss: 0.2298 - val_acc: 0.9475 - val_f1: 0.9479\n",
      "Epoch 51/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3823 - acc: 0.8381 - f1: 0.8185 - val_loss: 0.2094 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 52/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3802 - acc: 0.8409 - f1: 0.8236 - val_loss: 0.2090 - val_acc: 0.9591 - val_f1: 0.9598\n",
      "Epoch 53/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3882 - acc: 0.8341 - f1: 0.8134 - val_loss: 0.2727 - val_acc: 0.9244 - val_f1: 0.9221\n",
      "Epoch 54/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3870 - acc: 0.8355 - f1: 0.8152 - val_loss: 0.2119 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 55/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3820 - acc: 0.8387 - f1: 0.8201 - val_loss: 0.2115 - val_acc: 0.9606 - val_f1: 0.9612\n",
      "Epoch 56/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3791 - acc: 0.8398 - f1: 0.8214 - val_loss: 0.2079 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 57/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3769 - acc: 0.8408 - f1: 0.8219 - val_loss: 0.2156 - val_acc: 0.9575 - val_f1: 0.9580\n",
      "Epoch 58/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3901 - acc: 0.8340 - f1: 0.8138 - val_loss: 0.2057 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 59/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3846 - acc: 0.8366 - f1: 0.8163 - val_loss: 0.2338 - val_acc: 0.9472 - val_f1: 0.9471\n",
      "Epoch 60/60\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3884 - acc: 0.8312 - f1: 0.8100 - val_loss: 0.2197 - val_acc: 0.9559 - val_f1: 0.9558\n",
      "Train on 12800 samples, validate on 3200 samples\n",
      "Epoch 1/5000\n",
      "12800/12800 [==============================] - 0s 38us/sample - loss: 0.6835 - acc: 0.5594 - f1: 0.6350 - val_loss: 0.6208 - val_acc: 0.7309 - val_f1: 0.7025\n",
      "Epoch 2/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5963 - acc: 0.7306 - f1: 0.7546 - val_loss: 0.5075 - val_acc: 0.8872 - val_f1: 0.8950\n",
      "Epoch 3/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5336 - acc: 0.7848 - f1: 0.8129 - val_loss: 0.4412 - val_acc: 0.9041 - val_f1: 0.9100\n",
      "Epoch 4/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.5098 - acc: 0.8003 - f1: 0.8279 - val_loss: 0.4109 - val_acc: 0.9131 - val_f1: 0.9173\n",
      "Epoch 5/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4841 - acc: 0.8131 - f1: 0.8399 - val_loss: 0.3830 - val_acc: 0.9241 - val_f1: 0.9286\n",
      "Epoch 6/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4714 - acc: 0.8163 - f1: 0.8430 - val_loss: 0.3656 - val_acc: 0.9225 - val_f1: 0.9233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4668 - acc: 0.8155 - f1: 0.8425 - val_loss: 0.3501 - val_acc: 0.9362 - val_f1: 0.9390\n",
      "Epoch 8/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4544 - acc: 0.8248 - f1: 0.8497 - val_loss: 0.3380 - val_acc: 0.9344 - val_f1: 0.9373\n",
      "Epoch 9/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4514 - acc: 0.8207 - f1: 0.8469 - val_loss: 0.3306 - val_acc: 0.9362 - val_f1: 0.9384\n",
      "Epoch 10/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4338 - acc: 0.8320 - f1: 0.8548 - val_loss: 0.3279 - val_acc: 0.9375 - val_f1: 0.9416\n",
      "Epoch 11/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4344 - acc: 0.8300 - f1: 0.8540 - val_loss: 0.3064 - val_acc: 0.9394 - val_f1: 0.9415\n",
      "Epoch 12/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4189 - acc: 0.8359 - f1: 0.8589 - val_loss: 0.3015 - val_acc: 0.9431 - val_f1: 0.9448\n",
      "Epoch 13/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4269 - acc: 0.8279 - f1: 0.8521 - val_loss: 0.3102 - val_acc: 0.9291 - val_f1: 0.9288\n",
      "Epoch 14/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4287 - acc: 0.8257 - f1: 0.8512 - val_loss: 0.2927 - val_acc: 0.9428 - val_f1: 0.9459\n",
      "Epoch 15/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4065 - acc: 0.8405 - f1: 0.8624 - val_loss: 0.2777 - val_acc: 0.9441 - val_f1: 0.9444\n",
      "Epoch 16/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4081 - acc: 0.8370 - f1: 0.8595 - val_loss: 0.2820 - val_acc: 0.9406 - val_f1: 0.9435\n",
      "Epoch 17/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4008 - acc: 0.8424 - f1: 0.8638 - val_loss: 0.2645 - val_acc: 0.9459 - val_f1: 0.9479\n",
      "Epoch 18/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4027 - acc: 0.8384 - f1: 0.8603 - val_loss: 0.2598 - val_acc: 0.9475 - val_f1: 0.9500\n",
      "Epoch 19/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4028 - acc: 0.8377 - f1: 0.8603 - val_loss: 0.2855 - val_acc: 0.9325 - val_f1: 0.9381\n",
      "Epoch 20/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3999 - acc: 0.8370 - f1: 0.8597 - val_loss: 0.2550 - val_acc: 0.9475 - val_f1: 0.9478\n",
      "Epoch 21/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.4015 - acc: 0.8375 - f1: 0.8600 - val_loss: 0.2568 - val_acc: 0.9484 - val_f1: 0.9514\n",
      "Epoch 22/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3898 - acc: 0.8420 - f1: 0.8640 - val_loss: 0.2615 - val_acc: 0.9419 - val_f1: 0.9451\n",
      "Epoch 23/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3966 - acc: 0.8360 - f1: 0.8595 - val_loss: 0.2412 - val_acc: 0.9478 - val_f1: 0.9503\n",
      "Epoch 24/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4031 - acc: 0.8305 - f1: 0.8545 - val_loss: 0.2500 - val_acc: 0.9428 - val_f1: 0.9464\n",
      "Epoch 25/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.4024 - acc: 0.8327 - f1: 0.8567 - val_loss: 0.2534 - val_acc: 0.9419 - val_f1: 0.9458\n",
      "Epoch 26/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3964 - acc: 0.8367 - f1: 0.8594 - val_loss: 0.2767 - val_acc: 0.9278 - val_f1: 0.9334\n",
      "Epoch 27/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3912 - acc: 0.8438 - f1: 0.8650 - val_loss: 0.2322 - val_acc: 0.9519 - val_f1: 0.9540\n",
      "Epoch 28/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3881 - acc: 0.8403 - f1: 0.8621 - val_loss: 0.2369 - val_acc: 0.9466 - val_f1: 0.9498\n",
      "Epoch 29/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3850 - acc: 0.8440 - f1: 0.8651 - val_loss: 0.2572 - val_acc: 0.9334 - val_f1: 0.9378\n",
      "Epoch 30/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3921 - acc: 0.8379 - f1: 0.8611 - val_loss: 0.2391 - val_acc: 0.9441 - val_f1: 0.9479\n",
      "Epoch 31/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3852 - acc: 0.8439 - f1: 0.8658 - val_loss: 0.2189 - val_acc: 0.9550 - val_f1: 0.9565\n",
      "Epoch 32/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3852 - acc: 0.8423 - f1: 0.8642 - val_loss: 0.2204 - val_acc: 0.9556 - val_f1: 0.9572\n",
      "Epoch 33/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3903 - acc: 0.8408 - f1: 0.8633 - val_loss: 0.2392 - val_acc: 0.9419 - val_f1: 0.9458\n",
      "Epoch 34/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3884 - acc: 0.8405 - f1: 0.8620 - val_loss: 0.2345 - val_acc: 0.9406 - val_f1: 0.9450\n",
      "Epoch 35/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3832 - acc: 0.8410 - f1: 0.8629 - val_loss: 0.2208 - val_acc: 0.9506 - val_f1: 0.9528\n",
      "Epoch 36/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3858 - acc: 0.8405 - f1: 0.8632 - val_loss: 0.2138 - val_acc: 0.9547 - val_f1: 0.9560\n",
      "Epoch 37/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3859 - acc: 0.8427 - f1: 0.8649 - val_loss: 0.2200 - val_acc: 0.9544 - val_f1: 0.9562\n",
      "Epoch 38/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3839 - acc: 0.8440 - f1: 0.8654 - val_loss: 0.2147 - val_acc: 0.9547 - val_f1: 0.9571\n",
      "Epoch 39/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3835 - acc: 0.8424 - f1: 0.8644 - val_loss: 0.2118 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 40/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8449 - f1: 0.8667 - val_loss: 0.2181 - val_acc: 0.9528 - val_f1: 0.9561\n",
      "Epoch 41/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3799 - acc: 0.8448 - f1: 0.8660 - val_loss: 0.2280 - val_acc: 0.9434 - val_f1: 0.9475\n",
      "Epoch 42/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3784 - acc: 0.8462 - f1: 0.8675 - val_loss: 0.2160 - val_acc: 0.9538 - val_f1: 0.9569\n",
      "Epoch 43/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3821 - acc: 0.8427 - f1: 0.8645 - val_loss: 0.2072 - val_acc: 0.9563 - val_f1: 0.9569\n",
      "Epoch 44/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3831 - acc: 0.8432 - f1: 0.8649 - val_loss: 0.2121 - val_acc: 0.9575 - val_f1: 0.9596\n",
      "Epoch 45/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8478 - f1: 0.8685 - val_loss: 0.2090 - val_acc: 0.9553 - val_f1: 0.9565\n",
      "Epoch 46/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3796 - acc: 0.8456 - f1: 0.8673 - val_loss: 0.2067 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 47/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3761 - acc: 0.8456 - f1: 0.8667 - val_loss: 0.2039 - val_acc: 0.9597 - val_f1: 0.9611\n",
      "Epoch 48/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3685 - acc: 0.8514 - f1: 0.8714 - val_loss: 0.2046 - val_acc: 0.9581 - val_f1: 0.9587\n",
      "Epoch 49/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8457 - f1: 0.8673 - val_loss: 0.2266 - val_acc: 0.9425 - val_f1: 0.9463\n",
      "Epoch 50/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3827 - acc: 0.8429 - f1: 0.8654 - val_loss: 0.2062 - val_acc: 0.9578 - val_f1: 0.9593\n",
      "Epoch 51/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3834 - acc: 0.8434 - f1: 0.8651 - val_loss: 0.2125 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 52/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3816 - acc: 0.8441 - f1: 0.8651 - val_loss: 0.2121 - val_acc: 0.9516 - val_f1: 0.9519\n",
      "Epoch 53/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3807 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2320 - val_acc: 0.9375 - val_f1: 0.9422\n",
      "Epoch 54/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3798 - acc: 0.8441 - f1: 0.8658 - val_loss: 0.2118 - val_acc: 0.9559 - val_f1: 0.9580\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 55/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3771 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2483 - val_acc: 0.9353 - val_f1: 0.9407\n",
      "Epoch 56/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3681 - acc: 0.8505 - f1: 0.8710 - val_loss: 0.2095 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 57/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3770 - acc: 0.8467 - f1: 0.8675 - val_loss: 0.2199 - val_acc: 0.9472 - val_f1: 0.9505\n",
      "Epoch 58/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3778 - acc: 0.8461 - f1: 0.8675 - val_loss: 0.2065 - val_acc: 0.9578 - val_f1: 0.9591\n",
      "Epoch 59/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3802 - acc: 0.8440 - f1: 0.8660 - val_loss: 0.2077 - val_acc: 0.9572 - val_f1: 0.9580\n",
      "Epoch 60/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3676 - acc: 0.8542 - f1: 0.8736 - val_loss: 0.2079 - val_acc: 0.9528 - val_f1: 0.9547\n",
      "Epoch 61/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3691 - acc: 0.8511 - f1: 0.8715 - val_loss: 0.2110 - val_acc: 0.9519 - val_f1: 0.9547\n",
      "Epoch 62/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3770 - acc: 0.8462 - f1: 0.8675 - val_loss: 0.1991 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 63/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3714 - acc: 0.8503 - f1: 0.8708 - val_loss: 0.2180 - val_acc: 0.9478 - val_f1: 0.9512\n",
      "Epoch 64/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3711 - acc: 0.8489 - f1: 0.8699 - val_loss: 0.2142 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 65/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3700 - acc: 0.8496 - f1: 0.8703 - val_loss: 0.2031 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 66/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3750 - acc: 0.8486 - f1: 0.8692 - val_loss: 0.2080 - val_acc: 0.9547 - val_f1: 0.9557\n",
      "Epoch 67/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3716 - acc: 0.8504 - f1: 0.8711 - val_loss: 0.2561 - val_acc: 0.9256 - val_f1: 0.9322\n",
      "Epoch 68/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3728 - acc: 0.8482 - f1: 0.8685 - val_loss: 0.1979 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 69/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3835 - acc: 0.8427 - f1: 0.8648 - val_loss: 0.2036 - val_acc: 0.9559 - val_f1: 0.9570\n",
      "Epoch 70/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8477 - f1: 0.8688 - val_loss: 0.2008 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 71/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3779 - acc: 0.8450 - f1: 0.8662 - val_loss: 0.2050 - val_acc: 0.9563 - val_f1: 0.9571\n",
      "Epoch 72/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3714 - acc: 0.8493 - f1: 0.8699 - val_loss: 0.2074 - val_acc: 0.9550 - val_f1: 0.9566\n",
      "Epoch 73/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3697 - acc: 0.8498 - f1: 0.8705 - val_loss: 0.2015 - val_acc: 0.9591 - val_f1: 0.9596\n",
      "Epoch 74/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3708 - acc: 0.8498 - f1: 0.8707 - val_loss: 0.2119 - val_acc: 0.9528 - val_f1: 0.9556\n",
      "Epoch 75/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3736 - acc: 0.8484 - f1: 0.8685 - val_loss: 0.2417 - val_acc: 0.9381 - val_f1: 0.9426\n",
      "Epoch 76/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3757 - acc: 0.8474 - f1: 0.8684 - val_loss: 0.2050 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 77/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8495 - f1: 0.8700 - val_loss: 0.2006 - val_acc: 0.9594 - val_f1: 0.9603\n",
      "Epoch 78/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3713 - acc: 0.8491 - f1: 0.8698 - val_loss: 0.2217 - val_acc: 0.9438 - val_f1: 0.9478\n",
      "Epoch 79/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8501 - f1: 0.8705 - val_loss: 0.2002 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 80/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3792 - acc: 0.8461 - f1: 0.8676 - val_loss: 0.1979 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 81/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3759 - acc: 0.8459 - f1: 0.8675 - val_loss: 0.2029 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 82/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3735 - acc: 0.8496 - f1: 0.8701 - val_loss: 0.1990 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 83/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3739 - acc: 0.8474 - f1: 0.8682 - val_loss: 0.1985 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 84/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3740 - acc: 0.8470 - f1: 0.8684 - val_loss: 0.2028 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 85/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3697 - acc: 0.8491 - f1: 0.8701 - val_loss: 0.2159 - val_acc: 0.9500 - val_f1: 0.9530\n",
      "Epoch 86/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3712 - acc: 0.8503 - f1: 0.8706 - val_loss: 0.1968 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 87/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8502 - f1: 0.8707 - val_loss: 0.2014 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 88/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8552 - f1: 0.8746 - val_loss: 0.2195 - val_acc: 0.9478 - val_f1: 0.9512\n",
      "Epoch 89/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3575 - acc: 0.8567 - f1: 0.8762 - val_loss: 0.2225 - val_acc: 0.9469 - val_f1: 0.9503\n",
      "Epoch 90/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8514 - f1: 0.8717 - val_loss: 0.1978 - val_acc: 0.9588 - val_f1: 0.9613\n",
      "Epoch 91/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3672 - acc: 0.8509 - f1: 0.8716 - val_loss: 0.2056 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 92/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8534 - f1: 0.8726 - val_loss: 0.1968 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 93/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3643 - acc: 0.8520 - f1: 0.8718 - val_loss: 0.2083 - val_acc: 0.9525 - val_f1: 0.9554\n",
      "Epoch 94/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3751 - acc: 0.8478 - f1: 0.8686 - val_loss: 0.1975 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 95/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3693 - acc: 0.8513 - f1: 0.8722 - val_loss: 0.2022 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 96/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8499 - f1: 0.8703 - val_loss: 0.2025 - val_acc: 0.9550 - val_f1: 0.9571\n",
      "Epoch 97/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8544 - f1: 0.8743 - val_loss: 0.2397 - val_acc: 0.9334 - val_f1: 0.9393\n",
      "Epoch 98/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8527 - f1: 0.8728 - val_loss: 0.1953 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 99/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3703 - acc: 0.8497 - f1: 0.8706 - val_loss: 0.1972 - val_acc: 0.9584 - val_f1: 0.9600\n",
      "Epoch 100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3619 - acc: 0.8563 - f1: 0.8756 - val_loss: 0.1963 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3673 - acc: 0.8509 - f1: 0.8714 - val_loss: 0.2137 - val_acc: 0.9503 - val_f1: 0.9534\n",
      "Epoch 102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3758 - acc: 0.8463 - f1: 0.8676 - val_loss: 0.1952 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8527 - f1: 0.8727 - val_loss: 0.1943 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3718 - acc: 0.8477 - f1: 0.8685 - val_loss: 0.2003 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3661 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.2049 - val_acc: 0.9538 - val_f1: 0.9570\n",
      "Epoch 106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3646 - acc: 0.8513 - f1: 0.8720 - val_loss: 0.1983 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3662 - acc: 0.8521 - f1: 0.8720 - val_loss: 0.2004 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3624 - acc: 0.8541 - f1: 0.8734 - val_loss: 0.1929 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3594 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.1985 - val_acc: 0.9575 - val_f1: 0.9585\n",
      "Epoch 110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3639 - acc: 0.8538 - f1: 0.8742 - val_loss: 0.1937 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3641 - acc: 0.8545 - f1: 0.8744 - val_loss: 0.2114 - val_acc: 0.9500 - val_f1: 0.9531\n",
      "Epoch 112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3591 - acc: 0.8543 - f1: 0.8747 - val_loss: 0.2183 - val_acc: 0.9469 - val_f1: 0.9506\n",
      "Epoch 113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8542 - f1: 0.8740 - val_loss: 0.1992 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3621 - acc: 0.8542 - f1: 0.8745 - val_loss: 0.2116 - val_acc: 0.9488 - val_f1: 0.9522\n",
      "Epoch 115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3690 - acc: 0.8505 - f1: 0.8710 - val_loss: 0.2225 - val_acc: 0.9453 - val_f1: 0.9491\n",
      "Epoch 116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3693 - acc: 0.8490 - f1: 0.8706 - val_loss: 0.1971 - val_acc: 0.9597 - val_f1: 0.9604\n",
      "Epoch 117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3667 - acc: 0.8507 - f1: 0.8712 - val_loss: 0.1958 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.1960 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8535 - f1: 0.8730 - val_loss: 0.2118 - val_acc: 0.9559 - val_f1: 0.9569\n",
      "Epoch 120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3745 - acc: 0.8462 - f1: 0.8678 - val_loss: 0.1980 - val_acc: 0.9563 - val_f1: 0.9589\n",
      "Epoch 121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3638 - acc: 0.8522 - f1: 0.8724 - val_loss: 0.1983 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3672 - acc: 0.8495 - f1: 0.8705 - val_loss: 0.1966 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3622 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.1973 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3648 - acc: 0.8512 - f1: 0.8716 - val_loss: 0.1955 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3628 - acc: 0.8532 - f1: 0.8735 - val_loss: 0.1951 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8547 - f1: 0.8744 - val_loss: 0.1976 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3611 - acc: 0.8525 - f1: 0.8726 - val_loss: 0.1935 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3570 - acc: 0.8546 - f1: 0.8744 - val_loss: 0.1922 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8552 - f1: 0.8754 - val_loss: 0.1982 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3558 - acc: 0.8555 - f1: 0.8753 - val_loss: 0.1979 - val_acc: 0.9594 - val_f1: 0.9604\n",
      "Epoch 131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3642 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.1940 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3665 - acc: 0.8494 - f1: 0.8697 - val_loss: 0.2251 - val_acc: 0.9409 - val_f1: 0.9444\n",
      "Epoch 133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3652 - acc: 0.8540 - f1: 0.8743 - val_loss: 0.1999 - val_acc: 0.9603 - val_f1: 0.9613\n",
      "Epoch 134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3640 - acc: 0.8530 - f1: 0.8734 - val_loss: 0.1994 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8530 - f1: 0.8734 - val_loss: 0.1930 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3702 - acc: 0.8469 - f1: 0.8680 - val_loss: 0.1974 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3505 - acc: 0.8609 - f1: 0.8794 - val_loss: 0.1999 - val_acc: 0.9569 - val_f1: 0.9587\n",
      "Epoch 138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3649 - acc: 0.8527 - f1: 0.8730 - val_loss: 0.2098 - val_acc: 0.9550 - val_f1: 0.9569\n",
      "Epoch 139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8498 - f1: 0.8712 - val_loss: 0.2051 - val_acc: 0.9538 - val_f1: 0.9562\n",
      "Epoch 140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3569 - acc: 0.8550 - f1: 0.8744 - val_loss: 0.1949 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3688 - acc: 0.8502 - f1: 0.8710 - val_loss: 0.1959 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3707 - acc: 0.8484 - f1: 0.8699 - val_loss: 0.2571 - val_acc: 0.9272 - val_f1: 0.9333\n",
      "Epoch 143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3682 - acc: 0.8493 - f1: 0.8701 - val_loss: 0.1935 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8538 - f1: 0.8737 - val_loss: 0.1959 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8579 - f1: 0.8764 - val_loss: 0.1991 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8541 - f1: 0.8743 - val_loss: 0.2022 - val_acc: 0.9606 - val_f1: 0.9614\n",
      "Epoch 147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.2013 - val_acc: 0.9597 - val_f1: 0.9608\n",
      "Epoch 148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3720 - acc: 0.8488 - f1: 0.8699 - val_loss: 0.1927 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 149/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3609 - acc: 0.8530 - f1: 0.8732 - val_loss: 0.2022 - val_acc: 0.9547 - val_f1: 0.9576\n",
      "Epoch 150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3676 - acc: 0.8499 - f1: 0.8709 - val_loss: 0.2003 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3573 - acc: 0.8559 - f1: 0.8760 - val_loss: 0.2017 - val_acc: 0.9547 - val_f1: 0.9566\n",
      "Epoch 152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8558 - f1: 0.8748 - val_loss: 0.1992 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.1945 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8530 - f1: 0.8730 - val_loss: 0.1915 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8590 - f1: 0.8779 - val_loss: 0.1992 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3662 - acc: 0.8524 - f1: 0.8729 - val_loss: 0.1997 - val_acc: 0.9566 - val_f1: 0.9592\n",
      "Epoch 157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3621 - acc: 0.8545 - f1: 0.8742 - val_loss: 0.1962 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3625 - acc: 0.8527 - f1: 0.8726 - val_loss: 0.2021 - val_acc: 0.9553 - val_f1: 0.9574\n",
      "Epoch 159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3644 - acc: 0.8524 - f1: 0.8728 - val_loss: 0.1991 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3553 - acc: 0.8591 - f1: 0.8778 - val_loss: 0.1984 - val_acc: 0.9606 - val_f1: 0.9632\n",
      "Epoch 161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3595 - acc: 0.8549 - f1: 0.8751 - val_loss: 0.2330 - val_acc: 0.9397 - val_f1: 0.9442\n",
      "Epoch 162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3683 - acc: 0.8496 - f1: 0.8709 - val_loss: 0.2145 - val_acc: 0.9494 - val_f1: 0.9528\n",
      "Epoch 163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8555 - f1: 0.8752 - val_loss: 0.2330 - val_acc: 0.9384 - val_f1: 0.9432\n",
      "Epoch 164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8578 - f1: 0.8761 - val_loss: 0.1979 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8580 - f1: 0.8769 - val_loss: 0.2038 - val_acc: 0.9547 - val_f1: 0.9574\n",
      "Epoch 166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8517 - f1: 0.8722 - val_loss: 0.1938 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3630 - acc: 0.8534 - f1: 0.8740 - val_loss: 0.1958 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8621 - f1: 0.8807 - val_loss: 0.1950 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8571 - f1: 0.8763 - val_loss: 0.1922 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3544 - acc: 0.8575 - f1: 0.8771 - val_loss: 0.2037 - val_acc: 0.9553 - val_f1: 0.9582\n",
      "Epoch 171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8520 - f1: 0.8725 - val_loss: 0.2044 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8516 - f1: 0.8724 - val_loss: 0.2051 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3626 - acc: 0.8536 - f1: 0.8737 - val_loss: 0.1951 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3596 - acc: 0.8548 - f1: 0.8745 - val_loss: 0.1927 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3607 - acc: 0.8545 - f1: 0.8742 - val_loss: 0.2081 - val_acc: 0.9538 - val_f1: 0.9567\n",
      "Epoch 176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3625 - acc: 0.8538 - f1: 0.8739 - val_loss: 0.2036 - val_acc: 0.9556 - val_f1: 0.9583\n",
      "Epoch 177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8578 - f1: 0.8769 - val_loss: 0.1955 - val_acc: 0.9603 - val_f1: 0.9628\n",
      "Epoch 178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3503 - acc: 0.8606 - f1: 0.8793 - val_loss: 0.1928 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.2012 - val_acc: 0.9559 - val_f1: 0.9586\n",
      "Epoch 180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8573 - f1: 0.8766 - val_loss: 0.1942 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8590 - f1: 0.8778 - val_loss: 0.1939 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8553 - f1: 0.8754 - val_loss: 0.1939 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3623 - acc: 0.8529 - f1: 0.8732 - val_loss: 0.1945 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3602 - acc: 0.8534 - f1: 0.8737 - val_loss: 0.2036 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3577 - acc: 0.8554 - f1: 0.8746 - val_loss: 0.2154 - val_acc: 0.9491 - val_f1: 0.9526\n",
      "Epoch 186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3609 - acc: 0.8516 - f1: 0.8725 - val_loss: 0.2007 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8601 - f1: 0.8790 - val_loss: 0.1953 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3605 - acc: 0.8537 - f1: 0.8738 - val_loss: 0.1936 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8535 - f1: 0.8735 - val_loss: 0.2287 - val_acc: 0.9422 - val_f1: 0.9462\n",
      "Epoch 190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3623 - acc: 0.8521 - f1: 0.8727 - val_loss: 0.2022 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3554 - acc: 0.8567 - f1: 0.8760 - val_loss: 0.1915 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3604 - acc: 0.8534 - f1: 0.8734 - val_loss: 0.1974 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3631 - acc: 0.8527 - f1: 0.8727 - val_loss: 0.1956 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3618 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.1956 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3535 - acc: 0.8591 - f1: 0.8782 - val_loss: 0.2101 - val_acc: 0.9575 - val_f1: 0.9589\n",
      "Epoch 196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8582 - f1: 0.8775 - val_loss: 0.1949 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3539 - acc: 0.8577 - f1: 0.8771 - val_loss: 0.1946 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8539 - f1: 0.8741 - val_loss: 0.1964 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3635 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.1910 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8600 - f1: 0.8791 - val_loss: 0.2062 - val_acc: 0.9522 - val_f1: 0.9548\n",
      "Epoch 201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3563 - acc: 0.8564 - f1: 0.8757 - val_loss: 0.1924 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3602 - acc: 0.8542 - f1: 0.8746 - val_loss: 0.2406 - val_acc: 0.9325 - val_f1: 0.9383\n",
      "Epoch 203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3603 - acc: 0.8538 - f1: 0.8740 - val_loss: 0.1977 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3654 - acc: 0.8520 - f1: 0.8723 - val_loss: 0.1998 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8550 - f1: 0.8751 - val_loss: 0.1920 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3627 - acc: 0.8525 - f1: 0.8733 - val_loss: 0.1943 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3510 - acc: 0.8585 - f1: 0.8777 - val_loss: 0.2053 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3605 - acc: 0.8559 - f1: 0.8757 - val_loss: 0.1954 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3618 - acc: 0.8539 - f1: 0.8739 - val_loss: 0.1951 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8596 - f1: 0.8787 - val_loss: 0.2144 - val_acc: 0.9491 - val_f1: 0.9521\n",
      "Epoch 211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8549 - f1: 0.8750 - val_loss: 0.2054 - val_acc: 0.9547 - val_f1: 0.9575\n",
      "Epoch 212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3584 - acc: 0.8552 - f1: 0.8751 - val_loss: 0.1978 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3548 - acc: 0.8568 - f1: 0.8767 - val_loss: 0.1965 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3579 - acc: 0.8562 - f1: 0.8757 - val_loss: 0.1974 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.1924 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8567 - f1: 0.8764 - val_loss: 0.2011 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3707 - acc: 0.8487 - f1: 0.8703 - val_loss: 0.1957 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8585 - f1: 0.8778 - val_loss: 0.1933 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8570 - f1: 0.8764 - val_loss: 0.1959 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3514 - acc: 0.8596 - f1: 0.8785 - val_loss: 0.1953 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8516 - f1: 0.8724 - val_loss: 0.1948 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3528 - acc: 0.8600 - f1: 0.8788 - val_loss: 0.1910 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3637 - acc: 0.8520 - f1: 0.8729 - val_loss: 0.1951 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8564 - f1: 0.8762 - val_loss: 0.2045 - val_acc: 0.9566 - val_f1: 0.9591\n",
      "Epoch 225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8567 - f1: 0.8764 - val_loss: 0.2000 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3668 - acc: 0.8510 - f1: 0.8716 - val_loss: 0.2015 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3545 - acc: 0.8573 - f1: 0.8768 - val_loss: 0.2254 - val_acc: 0.9478 - val_f1: 0.9518\n",
      "Epoch 228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8581 - f1: 0.8777 - val_loss: 0.2003 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3573 - acc: 0.8545 - f1: 0.8750 - val_loss: 0.2016 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8585 - f1: 0.8773 - val_loss: 0.1982 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8577 - f1: 0.8770 - val_loss: 0.1937 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8542 - f1: 0.8748 - val_loss: 0.2024 - val_acc: 0.9581 - val_f1: 0.9596\n",
      "Epoch 233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3546 - acc: 0.8566 - f1: 0.8764 - val_loss: 0.2035 - val_acc: 0.9588 - val_f1: 0.9611\n",
      "Epoch 234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3689 - acc: 0.8502 - f1: 0.8715 - val_loss: 0.2398 - val_acc: 0.9316 - val_f1: 0.9373\n",
      "Epoch 235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3633 - acc: 0.8537 - f1: 0.8737 - val_loss: 0.2044 - val_acc: 0.9550 - val_f1: 0.9574\n",
      "Epoch 236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3525 - acc: 0.8573 - f1: 0.8768 - val_loss: 0.1930 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.2093 - val_acc: 0.9531 - val_f1: 0.9564\n",
      "Epoch 238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8616 - f1: 0.8797 - val_loss: 0.2008 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8517 - f1: 0.8725 - val_loss: 0.1983 - val_acc: 0.9591 - val_f1: 0.9609\n",
      "Epoch 240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3574 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.1966 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8563 - f1: 0.8762 - val_loss: 0.2380 - val_acc: 0.9350 - val_f1: 0.9406\n",
      "Epoch 242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8591 - f1: 0.8780 - val_loss: 0.2096 - val_acc: 0.9522 - val_f1: 0.9550\n",
      "Epoch 243/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3627 - acc: 0.8514 - f1: 0.8723 - val_loss: 0.2042 - val_acc: 0.9563 - val_f1: 0.9589\n",
      "Epoch 244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1992 - val_acc: 0.9613 - val_f1: 0.9639\n",
      "Epoch 245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2264 - val_acc: 0.9422 - val_f1: 0.9460\n",
      "Epoch 246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8594 - f1: 0.8785 - val_loss: 0.1938 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3482 - acc: 0.8616 - f1: 0.8795 - val_loss: 0.1965 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3535 - acc: 0.8582 - f1: 0.8774 - val_loss: 0.2144 - val_acc: 0.9450 - val_f1: 0.9491\n",
      "Epoch 249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8568 - f1: 0.8766 - val_loss: 0.1967 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3599 - acc: 0.8545 - f1: 0.8749 - val_loss: 0.2032 - val_acc: 0.9594 - val_f1: 0.9592\n",
      "Epoch 251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8609 - f1: 0.8795 - val_loss: 0.1893 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8608 - f1: 0.8795 - val_loss: 0.1913 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3559 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.1871 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.1932 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8571 - f1: 0.8766 - val_loss: 0.2118 - val_acc: 0.9506 - val_f1: 0.9543\n",
      "Epoch 256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3636 - acc: 0.8514 - f1: 0.8722 - val_loss: 0.1922 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8586 - f1: 0.8780 - val_loss: 0.1966 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8547 - f1: 0.8745 - val_loss: 0.2010 - val_acc: 0.9597 - val_f1: 0.9604\n",
      "Epoch 259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8601 - f1: 0.8786 - val_loss: 0.2023 - val_acc: 0.9550 - val_f1: 0.9580\n",
      "Epoch 260/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3583 - acc: 0.8548 - f1: 0.8748 - val_loss: 0.1953 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8562 - f1: 0.8756 - val_loss: 0.1912 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3574 - acc: 0.8546 - f1: 0.8746 - val_loss: 0.2043 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3561 - acc: 0.8571 - f1: 0.8769 - val_loss: 0.1948 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8560 - f1: 0.8755 - val_loss: 0.1990 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 265/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3541 - acc: 0.8577 - f1: 0.8768 - val_loss: 0.2037 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3600 - acc: 0.8535 - f1: 0.8744 - val_loss: 0.2014 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3590 - acc: 0.8553 - f1: 0.8753 - val_loss: 0.1965 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3606 - acc: 0.8530 - f1: 0.8729 - val_loss: 0.1957 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8557 - f1: 0.8758 - val_loss: 0.2070 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8602 - f1: 0.8788 - val_loss: 0.1975 - val_acc: 0.9638 - val_f1: 0.9661\n",
      "Epoch 271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8574 - f1: 0.8768 - val_loss: 0.2003 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8584 - f1: 0.8773 - val_loss: 0.1966 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3572 - acc: 0.8562 - f1: 0.8764 - val_loss: 0.2154 - val_acc: 0.9584 - val_f1: 0.9597\n",
      "Epoch 274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8531 - f1: 0.8733 - val_loss: 0.2032 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3656 - acc: 0.8518 - f1: 0.8724 - val_loss: 0.1956 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 276/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3578 - acc: 0.8552 - f1: 0.8755 - val_loss: 0.1942 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 277/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3485 - acc: 0.8608 - f1: 0.8794 - val_loss: 0.2089 - val_acc: 0.9528 - val_f1: 0.9559\n",
      "Epoch 278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3560 - acc: 0.8573 - f1: 0.8766 - val_loss: 0.1949 - val_acc: 0.9653 - val_f1: 0.9675\n",
      "Epoch 279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.1919 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 280/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3513 - acc: 0.8593 - f1: 0.8784 - val_loss: 0.1941 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3565 - acc: 0.8570 - f1: 0.8769 - val_loss: 0.2006 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 282/5000\n",
      "12800/12800 [==============================] - 0s 18us/sample - loss: 0.3470 - acc: 0.8625 - f1: 0.8807 - val_loss: 0.1956 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8582 - f1: 0.8768 - val_loss: 0.1939 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3612 - acc: 0.8527 - f1: 0.8737 - val_loss: 0.1926 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3590 - acc: 0.8537 - f1: 0.8740 - val_loss: 0.2080 - val_acc: 0.9519 - val_f1: 0.9554\n",
      "Epoch 286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8570 - f1: 0.8764 - val_loss: 0.1975 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8573 - f1: 0.8764 - val_loss: 0.1975 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8573 - f1: 0.8765 - val_loss: 0.2046 - val_acc: 0.9588 - val_f1: 0.9617\n",
      "Epoch 289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8600 - f1: 0.8792 - val_loss: 0.1953 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.1988 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8602 - f1: 0.8789 - val_loss: 0.1943 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3570 - acc: 0.8546 - f1: 0.8742 - val_loss: 0.2023 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3651 - acc: 0.8517 - f1: 0.8725 - val_loss: 0.1973 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8577 - f1: 0.8774 - val_loss: 0.2019 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8615 - f1: 0.8802 - val_loss: 0.1970 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8620 - f1: 0.8803 - val_loss: 0.1956 - val_acc: 0.9666 - val_f1: 0.9683\n",
      "Epoch 297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.2058 - val_acc: 0.9522 - val_f1: 0.9548\n",
      "Epoch 298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3568 - acc: 0.8562 - f1: 0.8761 - val_loss: 0.1998 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8615 - f1: 0.8801 - val_loss: 0.1975 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3616 - acc: 0.8523 - f1: 0.8729 - val_loss: 0.2118 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2068 - val_acc: 0.9606 - val_f1: 0.9610\n",
      "Epoch 302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1991 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3553 - acc: 0.8582 - f1: 0.8780 - val_loss: 0.1916 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3557 - acc: 0.8569 - f1: 0.8761 - val_loss: 0.1981 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8556 - f1: 0.8757 - val_loss: 0.2030 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8594 - f1: 0.8789 - val_loss: 0.1954 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8610 - f1: 0.8797 - val_loss: 0.1979 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8614 - f1: 0.8800 - val_loss: 0.2108 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8589 - f1: 0.8780 - val_loss: 0.1973 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8586 - f1: 0.8778 - val_loss: 0.1992 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8609 - f1: 0.8796 - val_loss: 0.2013 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8599 - f1: 0.8790 - val_loss: 0.2078 - val_acc: 0.9541 - val_f1: 0.9572\n",
      "Epoch 313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3481 - acc: 0.8615 - f1: 0.8802 - val_loss: 0.1964 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8555 - f1: 0.8754 - val_loss: 0.2027 - val_acc: 0.9603 - val_f1: 0.9611\n",
      "Epoch 315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8559 - f1: 0.8751 - val_loss: 0.2140 - val_acc: 0.9497 - val_f1: 0.9532\n",
      "Epoch 316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3582 - acc: 0.8545 - f1: 0.8749 - val_loss: 0.2001 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3586 - acc: 0.8572 - f1: 0.8765 - val_loss: 0.1966 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3582 - acc: 0.8562 - f1: 0.8760 - val_loss: 0.1962 - val_acc: 0.9691 - val_f1: 0.9704\n",
      "Epoch 319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8585 - f1: 0.8782 - val_loss: 0.2013 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8646 - f1: 0.8823 - val_loss: 0.2010 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8572 - f1: 0.8766 - val_loss: 0.1982 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8582 - f1: 0.8782 - val_loss: 0.2072 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8581 - f1: 0.8773 - val_loss: 0.2186 - val_acc: 0.9469 - val_f1: 0.9504\n",
      "Epoch 324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.2011 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8596 - f1: 0.8779 - val_loss: 0.1957 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3550 - acc: 0.8570 - f1: 0.8769 - val_loss: 0.2155 - val_acc: 0.9531 - val_f1: 0.9563\n",
      "Epoch 327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8641 - f1: 0.8817 - val_loss: 0.1979 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8592 - f1: 0.8787 - val_loss: 0.1989 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8588 - f1: 0.8781 - val_loss: 0.2039 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3529 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2010 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3567 - acc: 0.8550 - f1: 0.8749 - val_loss: 0.2158 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8575 - f1: 0.8767 - val_loss: 0.2015 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3540 - acc: 0.8575 - f1: 0.8765 - val_loss: 0.2078 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.1983 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3544 - acc: 0.8562 - f1: 0.8764 - val_loss: 0.2037 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8602 - f1: 0.8791 - val_loss: 0.2017 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 337/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3594 - acc: 0.8540 - f1: 0.8741 - val_loss: 0.2015 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.1952 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8598 - f1: 0.8787 - val_loss: 0.2082 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3452 - acc: 0.8619 - f1: 0.8802 - val_loss: 0.2034 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8548 - f1: 0.8751 - val_loss: 0.2038 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8651 - f1: 0.8831 - val_loss: 0.1966 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3599 - acc: 0.8550 - f1: 0.8752 - val_loss: 0.2008 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8570 - f1: 0.8765 - val_loss: 0.2052 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 345/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3505 - acc: 0.8579 - f1: 0.8773 - val_loss: 0.2027 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3539 - acc: 0.8570 - f1: 0.8771 - val_loss: 0.2008 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3485 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.1981 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8612 - f1: 0.8798 - val_loss: 0.1965 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3559 - acc: 0.8551 - f1: 0.8751 - val_loss: 0.2153 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3528 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2009 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3514 - acc: 0.8591 - f1: 0.8784 - val_loss: 0.2195 - val_acc: 0.9453 - val_f1: 0.9499\n",
      "Epoch 352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8560 - f1: 0.8760 - val_loss: 0.2395 - val_acc: 0.9362 - val_f1: 0.9416\n",
      "Epoch 353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3529 - acc: 0.8586 - f1: 0.8783 - val_loss: 0.2024 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8589 - f1: 0.8774 - val_loss: 0.1994 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8608 - f1: 0.8795 - val_loss: 0.1975 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8634 - f1: 0.8817 - val_loss: 0.1958 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3541 - acc: 0.8572 - f1: 0.8767 - val_loss: 0.1986 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8623 - f1: 0.8810 - val_loss: 0.2013 - val_acc: 0.9622 - val_f1: 0.9626\n",
      "Epoch 359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3542 - acc: 0.8581 - f1: 0.8775 - val_loss: 0.1959 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8569 - f1: 0.8766 - val_loss: 0.1932 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8572 - f1: 0.8772 - val_loss: 0.2014 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8561 - f1: 0.8756 - val_loss: 0.2026 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3556 - acc: 0.8577 - f1: 0.8769 - val_loss: 0.1954 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.1986 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3451 - acc: 0.8601 - f1: 0.8788 - val_loss: 0.1977 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8589 - f1: 0.8784 - val_loss: 0.2021 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3562 - acc: 0.8564 - f1: 0.8762 - val_loss: 0.2154 - val_acc: 0.9513 - val_f1: 0.9545\n",
      "Epoch 368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3604 - acc: 0.8555 - f1: 0.8756 - val_loss: 0.2056 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3538 - acc: 0.8572 - f1: 0.8769 - val_loss: 0.2010 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8609 - f1: 0.8795 - val_loss: 0.1954 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3501 - acc: 0.8591 - f1: 0.8783 - val_loss: 0.2113 - val_acc: 0.9538 - val_f1: 0.9563\n",
      "Epoch 372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8667 - f1: 0.8841 - val_loss: 0.2029 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3578 - acc: 0.8552 - f1: 0.8756 - val_loss: 0.2061 - val_acc: 0.9519 - val_f1: 0.9545\n",
      "Epoch 374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8620 - f1: 0.8803 - val_loss: 0.2025 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3551 - acc: 0.8564 - f1: 0.8763 - val_loss: 0.1999 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8606 - f1: 0.8791 - val_loss: 0.2240 - val_acc: 0.9453 - val_f1: 0.9489\n",
      "Epoch 377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8620 - f1: 0.8804 - val_loss: 0.2032 - val_acc: 0.9581 - val_f1: 0.9607\n",
      "Epoch 378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.1953 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8583 - f1: 0.8775 - val_loss: 0.1953 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8637 - f1: 0.8818 - val_loss: 0.2075 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8578 - f1: 0.8778 - val_loss: 0.1932 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3496 - acc: 0.8591 - f1: 0.8781 - val_loss: 0.2084 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.1971 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8611 - f1: 0.8802 - val_loss: 0.1998 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8657 - f1: 0.8838 - val_loss: 0.2070 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.1938 - val_acc: 0.9659 - val_f1: 0.9681\n",
      "Epoch 387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8610 - f1: 0.8796 - val_loss: 0.2109 - val_acc: 0.9572 - val_f1: 0.9592\n",
      "Epoch 388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8575 - f1: 0.8773 - val_loss: 0.2180 - val_acc: 0.9513 - val_f1: 0.9546\n",
      "Epoch 389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3613 - acc: 0.8533 - f1: 0.8739 - val_loss: 0.1977 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8614 - f1: 0.8801 - val_loss: 0.1976 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3566 - acc: 0.8559 - f1: 0.8757 - val_loss: 0.1984 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8662 - f1: 0.8837 - val_loss: 0.1989 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8584 - f1: 0.8772 - val_loss: 0.2089 - val_acc: 0.9575 - val_f1: 0.9602\n",
      "Epoch 394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8574 - f1: 0.8765 - val_loss: 0.1981 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2036 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3659 - acc: 0.8505 - f1: 0.8712 - val_loss: 0.2004 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3585 - acc: 0.8559 - f1: 0.8754 - val_loss: 0.1972 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8579 - f1: 0.8772 - val_loss: 0.1956 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8641 - f1: 0.8822 - val_loss: 0.1955 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8611 - f1: 0.8800 - val_loss: 0.1964 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2079 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8628 - f1: 0.8811 - val_loss: 0.1996 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8604 - f1: 0.8794 - val_loss: 0.1952 - val_acc: 0.9691 - val_f1: 0.9705\n",
      "Epoch 404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3537 - acc: 0.8590 - f1: 0.8780 - val_loss: 0.1966 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8594 - f1: 0.8777 - val_loss: 0.2066 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8636 - f1: 0.8818 - val_loss: 0.1997 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8595 - f1: 0.8788 - val_loss: 0.2028 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8583 - f1: 0.8775 - val_loss: 0.1998 - val_acc: 0.9609 - val_f1: 0.9631\n",
      "Epoch 409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8557 - f1: 0.8756 - val_loss: 0.2010 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8579 - f1: 0.8779 - val_loss: 0.2112 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8587 - f1: 0.8779 - val_loss: 0.2031 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8591 - f1: 0.8780 - val_loss: 0.2012 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2008 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3520 - acc: 0.8572 - f1: 0.8770 - val_loss: 0.1989 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8612 - f1: 0.8794 - val_loss: 0.1989 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8574 - f1: 0.8769 - val_loss: 0.2002 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8614 - f1: 0.8799 - val_loss: 0.2083 - val_acc: 0.9575 - val_f1: 0.9594\n",
      "Epoch 418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.1999 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8596 - f1: 0.8791 - val_loss: 0.1941 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8614 - f1: 0.8799 - val_loss: 0.1986 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2185 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8623 - f1: 0.8807 - val_loss: 0.1989 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8555 - f1: 0.8759 - val_loss: 0.2022 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3536 - acc: 0.8590 - f1: 0.8786 - val_loss: 0.2065 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3532 - acc: 0.8577 - f1: 0.8775 - val_loss: 0.1992 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2036 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8802 - val_loss: 0.1969 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8593 - f1: 0.8788 - val_loss: 0.1946 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2006 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8616 - f1: 0.8805 - val_loss: 0.2026 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 431/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8589 - f1: 0.8786 - val_loss: 0.1964 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8805 - val_loss: 0.2115 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8579 - f1: 0.8771 - val_loss: 0.2042 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8627 - f1: 0.8808 - val_loss: 0.2059 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3513 - acc: 0.8587 - f1: 0.8776 - val_loss: 0.2047 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8580 - f1: 0.8772 - val_loss: 0.2024 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8646 - f1: 0.8824 - val_loss: 0.2053 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3519 - acc: 0.8584 - f1: 0.8779 - val_loss: 0.2126 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2084 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8612 - f1: 0.8792 - val_loss: 0.2349 - val_acc: 0.9403 - val_f1: 0.9451\n",
      "Epoch 441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8616 - f1: 0.8805 - val_loss: 0.2032 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8595 - f1: 0.8786 - val_loss: 0.2012 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8607 - f1: 0.8794 - val_loss: 0.1998 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8643 - f1: 0.8824 - val_loss: 0.2110 - val_acc: 0.9566 - val_f1: 0.9585\n",
      "Epoch 445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2083 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8611 - f1: 0.8795 - val_loss: 0.1992 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8588 - f1: 0.8779 - val_loss: 0.1966 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8623 - f1: 0.8806 - val_loss: 0.2007 - val_acc: 0.9606 - val_f1: 0.9635\n",
      "Epoch 449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3527 - acc: 0.8576 - f1: 0.8770 - val_loss: 0.1946 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8586 - f1: 0.8778 - val_loss: 0.1935 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.1989 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8587 - f1: 0.8784 - val_loss: 0.2059 - val_acc: 0.9588 - val_f1: 0.9614\n",
      "Epoch 453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3545 - acc: 0.8571 - f1: 0.8769 - val_loss: 0.2146 - val_acc: 0.9522 - val_f1: 0.9547\n",
      "Epoch 454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.1980 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8624 - f1: 0.8807 - val_loss: 0.1935 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8580 - f1: 0.8776 - val_loss: 0.2096 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3478 - acc: 0.8599 - f1: 0.8788 - val_loss: 0.2154 - val_acc: 0.9613 - val_f1: 0.9621\n",
      "Epoch 458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2109 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8570 - f1: 0.8766 - val_loss: 0.2008 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8650 - f1: 0.8828 - val_loss: 0.2016 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8542 - f1: 0.8745 - val_loss: 0.2080 - val_acc: 0.9569 - val_f1: 0.9596\n",
      "Epoch 462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8616 - f1: 0.8803 - val_loss: 0.2076 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2031 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2049 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8617 - f1: 0.8808 - val_loss: 0.2013 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8613 - f1: 0.8800 - val_loss: 0.2052 - val_acc: 0.9603 - val_f1: 0.9627\n",
      "Epoch 467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8796 - val_loss: 0.2074 - val_acc: 0.9563 - val_f1: 0.9585\n",
      "Epoch 468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8613 - f1: 0.8801 - val_loss: 0.2172 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8611 - f1: 0.8799 - val_loss: 0.2010 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8608 - f1: 0.8792 - val_loss: 0.2047 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3555 - acc: 0.8549 - f1: 0.8750 - val_loss: 0.2018 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8593 - f1: 0.8784 - val_loss: 0.2042 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8658 - f1: 0.8832 - val_loss: 0.1973 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8576 - f1: 0.8771 - val_loss: 0.2175 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8602 - f1: 0.8788 - val_loss: 0.2049 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.1957 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8600 - f1: 0.8789 - val_loss: 0.2041 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8633 - f1: 0.8809 - val_loss: 0.2113 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8602 - f1: 0.8795 - val_loss: 0.1948 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2118 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.2016 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8641 - f1: 0.8819 - val_loss: 0.2008 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8678 - f1: 0.8854 - val_loss: 0.2019 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8620 - f1: 0.8812 - val_loss: 0.2003 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.2038 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2101 - val_acc: 0.9578 - val_f1: 0.9600\n",
      "Epoch 487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2001 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8612 - f1: 0.8802 - val_loss: 0.2075 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2051 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8614 - f1: 0.8803 - val_loss: 0.2002 - val_acc: 0.9669 - val_f1: 0.9688\n",
      "Epoch 491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3484 - acc: 0.8612 - f1: 0.8798 - val_loss: 0.2093 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8580 - f1: 0.8772 - val_loss: 0.2113 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3526 - acc: 0.8554 - f1: 0.8753 - val_loss: 0.2056 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3504 - acc: 0.8588 - f1: 0.8786 - val_loss: 0.2068 - val_acc: 0.9631 - val_f1: 0.9651\n",
      "Epoch 495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2139 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8569 - f1: 0.8764 - val_loss: 0.2068 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2216 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 498/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3452 - acc: 0.8617 - f1: 0.8804 - val_loss: 0.2105 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8632 - f1: 0.8812 - val_loss: 0.2116 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 500/5000\n",
      "12800/12800 [==============================] - 0s 22us/sample - loss: 0.3439 - acc: 0.8609 - f1: 0.8801 - val_loss: 0.2090 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 501/5000\n",
      "12800/12800 [==============================] - 0s 20us/sample - loss: 0.3478 - acc: 0.8584 - f1: 0.8780 - val_loss: 0.2111 - val_acc: 0.9556 - val_f1: 0.9583\n",
      "Epoch 502/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3544 - acc: 0.8565 - f1: 0.8759 - val_loss: 0.2189 - val_acc: 0.9503 - val_f1: 0.9537\n",
      "Epoch 503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2060 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8660 - f1: 0.8833 - val_loss: 0.2015 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8608 - f1: 0.8797 - val_loss: 0.2121 - val_acc: 0.9591 - val_f1: 0.9608\n",
      "Epoch 506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2090 - val_acc: 0.9613 - val_f1: 0.9635\n",
      "Epoch 507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8607 - f1: 0.8794 - val_loss: 0.2160 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8798 - val_loss: 0.2045 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8590 - f1: 0.8785 - val_loss: 0.2040 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 510/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2040 - val_acc: 0.9600 - val_f1: 0.9623\n",
      "Epoch 511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2031 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8644 - f1: 0.8826 - val_loss: 0.2039 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8598 - f1: 0.8792 - val_loss: 0.2109 - val_acc: 0.9553 - val_f1: 0.9578\n",
      "Epoch 514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3517 - acc: 0.8596 - f1: 0.8786 - val_loss: 0.2077 - val_acc: 0.9591 - val_f1: 0.9616\n",
      "Epoch 515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8597 - f1: 0.8788 - val_loss: 0.2026 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8659 - f1: 0.8832 - val_loss: 0.2062 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3518 - acc: 0.8566 - f1: 0.8761 - val_loss: 0.2031 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2143 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 519/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3435 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2132 - val_acc: 0.9531 - val_f1: 0.9557\n",
      "Epoch 520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8610 - f1: 0.8802 - val_loss: 0.2189 - val_acc: 0.9550 - val_f1: 0.9568\n",
      "Epoch 521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8651 - f1: 0.8826 - val_loss: 0.2039 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 522/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8627 - f1: 0.8807 - val_loss: 0.2058 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3534 - acc: 0.8572 - f1: 0.8772 - val_loss: 0.2015 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8615 - f1: 0.8801 - val_loss: 0.2177 - val_acc: 0.9541 - val_f1: 0.9563\n",
      "Epoch 525/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3492 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2025 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3598 - acc: 0.8547 - f1: 0.8747 - val_loss: 0.2074 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 527/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8622 - f1: 0.8811 - val_loss: 0.2019 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2049 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8624 - f1: 0.8813 - val_loss: 0.2188 - val_acc: 0.9506 - val_f1: 0.9535\n",
      "Epoch 530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2052 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8571 - f1: 0.8770 - val_loss: 0.1971 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8647 - f1: 0.8827 - val_loss: 0.2015 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8646 - f1: 0.8830 - val_loss: 0.2027 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2199 - val_acc: 0.9491 - val_f1: 0.9526\n",
      "Epoch 535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8603 - f1: 0.8795 - val_loss: 0.1990 - val_acc: 0.9631 - val_f1: 0.9654\n",
      "Epoch 536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8606 - f1: 0.8798 - val_loss: 0.2063 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3494 - acc: 0.8592 - f1: 0.8788 - val_loss: 0.2045 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2063 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3452 - acc: 0.8600 - f1: 0.8789 - val_loss: 0.2049 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 540/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3405 - acc: 0.8645 - f1: 0.8825 - val_loss: 0.2201 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 541/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3426 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2110 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 542/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3461 - acc: 0.8618 - f1: 0.8804 - val_loss: 0.2094 - val_acc: 0.9578 - val_f1: 0.9600\n",
      "Epoch 543/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8650 - f1: 0.8827 - val_loss: 0.2057 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8575 - f1: 0.8772 - val_loss: 0.2201 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3577 - acc: 0.8556 - f1: 0.8755 - val_loss: 0.2020 - val_acc: 0.9644 - val_f1: 0.9665\n",
      "Epoch 546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8571 - f1: 0.8768 - val_loss: 0.2058 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2086 - val_acc: 0.9559 - val_f1: 0.9581\n",
      "Epoch 548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8618 - f1: 0.8806 - val_loss: 0.2069 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2031 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8633 - f1: 0.8819 - val_loss: 0.2202 - val_acc: 0.9534 - val_f1: 0.9569\n",
      "Epoch 551/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3542 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2009 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8607 - f1: 0.8799 - val_loss: 0.2132 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8628 - f1: 0.8815 - val_loss: 0.2056 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8584 - f1: 0.8781 - val_loss: 0.2008 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8611 - f1: 0.8803 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8631 - f1: 0.8816 - val_loss: 0.2142 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2049 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8578 - f1: 0.8769 - val_loss: 0.2080 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8612 - f1: 0.8797 - val_loss: 0.2189 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8659 - f1: 0.8835 - val_loss: 0.2036 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8609 - f1: 0.8796 - val_loss: 0.2057 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8581 - f1: 0.8771 - val_loss: 0.2082 - val_acc: 0.9681 - val_f1: 0.9699\n",
      "Epoch 563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8625 - f1: 0.8808 - val_loss: 0.2112 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8607 - f1: 0.8792 - val_loss: 0.2103 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8588 - f1: 0.8788 - val_loss: 0.2126 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3541 - acc: 0.8555 - f1: 0.8751 - val_loss: 0.2026 - val_acc: 0.9691 - val_f1: 0.9709\n",
      "Epoch 567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.2154 - val_acc: 0.9544 - val_f1: 0.9572\n",
      "Epoch 568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3450 - acc: 0.8601 - f1: 0.8796 - val_loss: 0.2026 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8613 - f1: 0.8803 - val_loss: 0.2060 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8664 - f1: 0.8841 - val_loss: 0.2095 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8573 - f1: 0.8769 - val_loss: 0.2081 - val_acc: 0.9609 - val_f1: 0.9632\n",
      "Epoch 572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2088 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8645 - f1: 0.8826 - val_loss: 0.2153 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8609 - f1: 0.8801 - val_loss: 0.2102 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3543 - acc: 0.8557 - f1: 0.8760 - val_loss: 0.1987 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2018 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2080 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3508 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.2098 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2064 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8811 - val_loss: 0.1959 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2075 - val_acc: 0.9566 - val_f1: 0.9589\n",
      "Epoch 582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8609 - f1: 0.8798 - val_loss: 0.2078 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8672 - f1: 0.8847 - val_loss: 0.2204 - val_acc: 0.9603 - val_f1: 0.9618\n",
      "Epoch 584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3522 - acc: 0.8572 - f1: 0.8771 - val_loss: 0.2025 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2077 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2150 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8581 - f1: 0.8777 - val_loss: 0.2049 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8583 - f1: 0.8779 - val_loss: 0.2027 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8608 - f1: 0.8800 - val_loss: 0.2020 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8597 - f1: 0.8785 - val_loss: 0.2018 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2160 - val_acc: 0.9500 - val_f1: 0.9527\n",
      "Epoch 592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8575 - f1: 0.8774 - val_loss: 0.2175 - val_acc: 0.9544 - val_f1: 0.9571\n",
      "Epoch 593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8826 - val_loss: 0.2176 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3482 - acc: 0.8588 - f1: 0.8782 - val_loss: 0.2063 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8595 - f1: 0.8793 - val_loss: 0.2049 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.2066 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3509 - acc: 0.8563 - f1: 0.8763 - val_loss: 0.2093 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2128 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2201 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8611 - f1: 0.8796 - val_loss: 0.2020 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8627 - f1: 0.8812 - val_loss: 0.2145 - val_acc: 0.9559 - val_f1: 0.9581\n",
      "Epoch 603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2090 - val_acc: 0.9622 - val_f1: 0.9646\n",
      "Epoch 604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2032 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8643 - f1: 0.8823 - val_loss: 0.2001 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2128 - val_acc: 0.9588 - val_f1: 0.9602\n",
      "Epoch 607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3556 - acc: 0.8575 - f1: 0.8772 - val_loss: 0.2096 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3502 - acc: 0.8585 - f1: 0.8779 - val_loss: 0.2016 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8674 - f1: 0.8849 - val_loss: 0.1988 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8654 - f1: 0.8834 - val_loss: 0.2065 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8673 - f1: 0.8845 - val_loss: 0.2080 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3439 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2001 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2049 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8673 - f1: 0.8841 - val_loss: 0.2108 - val_acc: 0.9525 - val_f1: 0.9554\n",
      "Epoch 615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.1988 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8642 - f1: 0.8825 - val_loss: 0.2109 - val_acc: 0.9541 - val_f1: 0.9574\n",
      "Epoch 617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8610 - f1: 0.8802 - val_loss: 0.2082 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8650 - f1: 0.8829 - val_loss: 0.2112 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 619/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8636 - f1: 0.8821 - val_loss: 0.2054 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3475 - acc: 0.8599 - f1: 0.8795 - val_loss: 0.2136 - val_acc: 0.9581 - val_f1: 0.9607\n",
      "Epoch 621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8612 - f1: 0.8800 - val_loss: 0.2098 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8650 - f1: 0.8830 - val_loss: 0.2060 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8598 - f1: 0.8791 - val_loss: 0.2014 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8655 - f1: 0.8835 - val_loss: 0.2140 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3499 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2090 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8827 - val_loss: 0.2127 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3547 - acc: 0.8560 - f1: 0.8760 - val_loss: 0.2078 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8628 - f1: 0.8818 - val_loss: 0.2063 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8613 - f1: 0.8805 - val_loss: 0.2118 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2108 - val_acc: 0.9581 - val_f1: 0.9597\n",
      "Epoch 631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8619 - f1: 0.8806 - val_loss: 0.2102 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8644 - f1: 0.8827 - val_loss: 0.2183 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3524 - acc: 0.8569 - f1: 0.8767 - val_loss: 0.2106 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2122 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8583 - f1: 0.8777 - val_loss: 0.2080 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3455 - acc: 0.8610 - f1: 0.8797 - val_loss: 0.2053 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8661 - f1: 0.8837 - val_loss: 0.2012 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8664 - f1: 0.8839 - val_loss: 0.2056 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2093 - val_acc: 0.9597 - val_f1: 0.9621\n",
      "Epoch 640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8637 - f1: 0.8819 - val_loss: 0.2113 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8611 - f1: 0.8800 - val_loss: 0.2075 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8609 - f1: 0.8798 - val_loss: 0.2157 - val_acc: 0.9556 - val_f1: 0.9579\n",
      "Epoch 643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2103 - val_acc: 0.9569 - val_f1: 0.9595\n",
      "Epoch 644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8605 - f1: 0.8800 - val_loss: 0.2059 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2052 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8631 - f1: 0.8817 - val_loss: 0.2182 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8595 - f1: 0.8788 - val_loss: 0.2089 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2093 - val_acc: 0.9566 - val_f1: 0.9594\n",
      "Epoch 649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8634 - f1: 0.8809 - val_loss: 0.2094 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2016 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3505 - acc: 0.8571 - f1: 0.8770 - val_loss: 0.2094 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 652/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2180 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2090 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3465 - acc: 0.8595 - f1: 0.8784 - val_loss: 0.2023 - val_acc: 0.9684 - val_f1: 0.9696\n",
      "Epoch 655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3465 - acc: 0.8618 - f1: 0.8802 - val_loss: 0.2176 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 656/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8625 - f1: 0.8811 - val_loss: 0.2065 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2076 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 658/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2153 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3509 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2004 - val_acc: 0.9691 - val_f1: 0.9705\n",
      "Epoch 660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8613 - f1: 0.8802 - val_loss: 0.2033 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 661/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3436 - acc: 0.8617 - f1: 0.8804 - val_loss: 0.2092 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 662/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3502 - acc: 0.8579 - f1: 0.8776 - val_loss: 0.2066 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8634 - f1: 0.8815 - val_loss: 0.2229 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8679 - f1: 0.8852 - val_loss: 0.2098 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8613 - f1: 0.8807 - val_loss: 0.2049 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 666/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3454 - acc: 0.8637 - f1: 0.8820 - val_loss: 0.2056 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 667/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8623 - f1: 0.8809 - val_loss: 0.2041 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8605 - f1: 0.8795 - val_loss: 0.2101 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2064 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 670/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2063 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3471 - acc: 0.8607 - f1: 0.8795 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 672/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3442 - acc: 0.8620 - f1: 0.8802 - val_loss: 0.2204 - val_acc: 0.9547 - val_f1: 0.9575\n",
      "Epoch 673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8575 - f1: 0.8769 - val_loss: 0.2173 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3497 - acc: 0.8576 - f1: 0.8772 - val_loss: 0.2086 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8600 - f1: 0.8795 - val_loss: 0.2181 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 676/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3476 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2124 - val_acc: 0.9563 - val_f1: 0.9584\n",
      "Epoch 677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8642 - f1: 0.8823 - val_loss: 0.2179 - val_acc: 0.9528 - val_f1: 0.9553\n",
      "Epoch 678/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3570 - acc: 0.8548 - f1: 0.8750 - val_loss: 0.2123 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8660 - f1: 0.8838 - val_loss: 0.2081 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.2117 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 681/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3349 - acc: 0.8668 - f1: 0.8844 - val_loss: 0.2094 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 682/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8689 - f1: 0.8858 - val_loss: 0.2081 - val_acc: 0.9575 - val_f1: 0.9597\n",
      "Epoch 683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3578 - acc: 0.8533 - f1: 0.8747 - val_loss: 0.2173 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3469 - acc: 0.8594 - f1: 0.8791 - val_loss: 0.2300 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8614 - f1: 0.8805 - val_loss: 0.2108 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2322 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2027 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8605 - f1: 0.8798 - val_loss: 0.2026 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3491 - acc: 0.8598 - f1: 0.8790 - val_loss: 0.2111 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2281 - val_acc: 0.9606 - val_f1: 0.9611\n",
      "Epoch 691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2058 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2043 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8593 - f1: 0.8779 - val_loss: 0.2106 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8611 - f1: 0.8798 - val_loss: 0.2048 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8642 - f1: 0.8823 - val_loss: 0.2227 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 696/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3451 - acc: 0.8612 - f1: 0.8806 - val_loss: 0.2143 - val_acc: 0.9544 - val_f1: 0.9568\n",
      "Epoch 697/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2110 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3500 - acc: 0.8580 - f1: 0.8779 - val_loss: 0.2070 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8658 - f1: 0.8835 - val_loss: 0.2074 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8619 - f1: 0.8811 - val_loss: 0.2116 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8657 - f1: 0.8838 - val_loss: 0.2120 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8606 - f1: 0.8802 - val_loss: 0.2116 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 703/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2088 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3521 - acc: 0.8564 - f1: 0.8765 - val_loss: 0.2055 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 705/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3441 - acc: 0.8609 - f1: 0.8806 - val_loss: 0.2096 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8808 - val_loss: 0.2129 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 707/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2059 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2105 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 709/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3380 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2103 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2087 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8635 - f1: 0.8818 - val_loss: 0.2162 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8591 - f1: 0.8783 - val_loss: 0.2061 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 713/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8632 - f1: 0.8812 - val_loss: 0.2132 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2092 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8612 - f1: 0.8800 - val_loss: 0.2099 - val_acc: 0.9578 - val_f1: 0.9607\n",
      "Epoch 716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8598 - f1: 0.8794 - val_loss: 0.2114 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 717/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3441 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2126 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8594 - f1: 0.8787 - val_loss: 0.2161 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2010 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2086 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8627 - f1: 0.8811 - val_loss: 0.2229 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8631 - f1: 0.8818 - val_loss: 0.2143 - val_acc: 0.9609 - val_f1: 0.9634\n",
      "Epoch 723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3507 - acc: 0.8567 - f1: 0.8771 - val_loss: 0.2132 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3483 - acc: 0.8595 - f1: 0.8783 - val_loss: 0.2040 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2056 - val_acc: 0.9656 - val_f1: 0.9677\n",
      "Epoch 726/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3358 - acc: 0.8646 - f1: 0.88 - 0s 16us/sample - loss: 0.3361 - acc: 0.8646 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3379 - acc: 0.8649 - f1: 0.8828 - val_loss: 0.2113 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 728/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3466 - acc: 0.8602 - f1: 0.8791 - val_loss: 0.2064 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 729/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3473 - acc: 0.8599 - f1: 0.88 - 0s 16us/sample - loss: 0.3463 - acc: 0.8598 - f1: 0.8795 - val_loss: 0.2076 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2140 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2138 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8650 - f1: 0.8829 - val_loss: 0.2074 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8629 - f1: 0.8817 - val_loss: 0.2089 - val_acc: 0.9553 - val_f1: 0.9575\n",
      "Epoch 734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2130 - val_acc: 0.9663 - val_f1: 0.9664\n",
      "Epoch 735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8608 - f1: 0.8797 - val_loss: 0.2120 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2150 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 737/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3505 - acc: 0.8591 - f1: 0.8785 - val_loss: 0.2220 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 738/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8628 - f1: 0.8814 - val_loss: 0.2072 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8613 - f1: 0.8801 - val_loss: 0.2090 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 740/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3383 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2016 - val_acc: 0.9606 - val_f1: 0.9632\n",
      "Epoch 741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8630 - f1: 0.8813 - val_loss: 0.2057 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8570 - f1: 0.8772 - val_loss: 0.2088 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3493 - acc: 0.8577 - f1: 0.8772 - val_loss: 0.2099 - val_acc: 0.9638 - val_f1: 0.9660\n",
      "Epoch 744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8810 - val_loss: 0.2114 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8645 - f1: 0.8825 - val_loss: 0.2222 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3398 - acc: 0.8653 - f1: 0.8829 - val_loss: 0.2226 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2126 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2273 - val_acc: 0.9447 - val_f1: 0.9485\n",
      "Epoch 749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8652 - f1: 0.8826 - val_loss: 0.2140 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8607 - f1: 0.8797 - val_loss: 0.2130 - val_acc: 0.9634 - val_f1: 0.9640\n",
      "Epoch 751/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8641 - f1: 0.8822 - val_loss: 0.2094 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 752/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2082 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8609 - f1: 0.8797 - val_loss: 0.2090 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 754/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3368 - acc: 0.8649 - f1: 0.8830 - val_loss: 0.2142 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2098 - val_acc: 0.9688 - val_f1: 0.9706\n",
      "Epoch 756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8660 - f1: 0.8836 - val_loss: 0.2222 - val_acc: 0.9531 - val_f1: 0.9560\n",
      "Epoch 757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8590 - f1: 0.8787 - val_loss: 0.2150 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 758/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3536 - acc: 0.8563 - f1: 0.8762 - val_loss: 0.2097 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8641 - f1: 0.8821 - val_loss: 0.2199 - val_acc: 0.9522 - val_f1: 0.9548\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8642 - f1: 0.8824 - val_loss: 0.2088 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 761/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3380 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2097 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 762/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3370 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2050 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2122 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 764/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2053 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 765/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2059 - val_acc: 0.9584 - val_f1: 0.9600\n",
      "Epoch 766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8611 - f1: 0.8801 - val_loss: 0.2278 - val_acc: 0.9556 - val_f1: 0.9575\n",
      "Epoch 769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8638 - f1: 0.8819 - val_loss: 0.2096 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8593 - f1: 0.8791 - val_loss: 0.2141 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8639 - f1: 0.8815 - val_loss: 0.2209 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8669 - f1: 0.8850 - val_loss: 0.2400 - val_acc: 0.9606 - val_f1: 0.9614\n",
      "Epoch 773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8692 - f1: 0.8862 - val_loss: 0.2163 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2201 - val_acc: 0.9553 - val_f1: 0.9577\n",
      "Epoch 775/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3411 - acc: 0.8639 - f1: 0.8821 - val_loss: 0.2156 - val_acc: 0.9522 - val_f1: 0.9550\n",
      "Epoch 776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8615 - f1: 0.8803 - val_loss: 0.2063 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8602 - f1: 0.8794 - val_loss: 0.2038 - val_acc: 0.9669 - val_f1: 0.9688\n",
      "Epoch 778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8609 - f1: 0.8799 - val_loss: 0.2095 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2147 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8607 - f1: 0.8798 - val_loss: 0.2081 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8625 - f1: 0.8812 - val_loss: 0.2057 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2053 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8647 - f1: 0.8828 - val_loss: 0.2080 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2075 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8628 - f1: 0.8817 - val_loss: 0.2137 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2162 - val_acc: 0.9556 - val_f1: 0.9576\n",
      "Epoch 787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8603 - f1: 0.8797 - val_loss: 0.2202 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2110 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2072 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3503 - acc: 0.8570 - f1: 0.8772 - val_loss: 0.2230 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8612 - f1: 0.8802 - val_loss: 0.2142 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8618 - f1: 0.8809 - val_loss: 0.2155 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3530 - acc: 0.8580 - f1: 0.8771 - val_loss: 0.2197 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2045 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2081 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 796/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3406 - acc: 0.8624 - f1: 0.88 - 0s 16us/sample - loss: 0.3411 - acc: 0.8625 - f1: 0.8815 - val_loss: 0.2230 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 797/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8642 - f1: 0.8821 - val_loss: 0.2250 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 798/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3457 - acc: 0.8612 - f1: 0.8806 - val_loss: 0.2124 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 799/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3485 - acc: 0.8587 - f1: 0.8783 - val_loss: 0.2104 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 800/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3477 - acc: 0.8592 - f1: 0.8787 - val_loss: 0.2077 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8618 - f1: 0.8802 - val_loss: 0.2086 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8654 - f1: 0.8827 - val_loss: 0.2181 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2177 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8622 - f1: 0.8815 - val_loss: 0.2085 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2235 - val_acc: 0.9484 - val_f1: 0.9518\n",
      "Epoch 806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2035 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 807/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3477 - acc: 0.8590 - f1: 0.8788 - val_loss: 0.2070 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2040 - val_acc: 0.9672 - val_f1: 0.9691\n",
      "Epoch 809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2304 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2091 - val_acc: 0.9609 - val_f1: 0.9625\n",
      "Epoch 811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8640 - f1: 0.8822 - val_loss: 0.2075 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8655 - f1: 0.8831 - val_loss: 0.2062 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2082 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8597 - f1: 0.8790 - val_loss: 0.2084 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2139 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8703 - f1: 0.8874 - val_loss: 0.2156 - val_acc: 0.9522 - val_f1: 0.9553\n",
      "Epoch 817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2122 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8832 - val_loss: 0.2247 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8624 - f1: 0.8812 - val_loss: 0.2135 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2096 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3531 - acc: 0.8562 - f1: 0.8766 - val_loss: 0.2279 - val_acc: 0.9631 - val_f1: 0.9637\n",
      "Epoch 822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2076 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2027 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8675 - f1: 0.8851 - val_loss: 0.2136 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8665 - f1: 0.8843 - val_loss: 0.2218 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2100 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2113 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2112 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8610 - f1: 0.8801 - val_loss: 0.2111 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2076 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3430 - acc: 0.8637 - f1: 0.8821 - val_loss: 0.2091 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3506 - acc: 0.8580 - f1: 0.8776 - val_loss: 0.2191 - val_acc: 0.9491 - val_f1: 0.9523\n",
      "Epoch 833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3511 - acc: 0.8587 - f1: 0.8781 - val_loss: 0.2082 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2126 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3476 - acc: 0.8595 - f1: 0.8784 - val_loss: 0.2131 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2081 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2064 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8658 - f1: 0.8835 - val_loss: 0.2091 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8660 - f1: 0.8839 - val_loss: 0.2087 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2195 - val_acc: 0.9559 - val_f1: 0.9584\n",
      "Epoch 841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2085 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2164 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8653 - f1: 0.8832 - val_loss: 0.2078 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8696 - f1: 0.8865 - val_loss: 0.2097 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2131 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 846/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3324 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2106 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8636 - f1: 0.8823 - val_loss: 0.2289 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8641 - f1: 0.8832 - val_loss: 0.2114 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2048 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2151 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8624 - f1: 0.8814 - val_loss: 0.2127 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2320 - val_acc: 0.9416 - val_f1: 0.9453\n",
      "Epoch 853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8622 - f1: 0.8808 - val_loss: 0.2040 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2001 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2069 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2059 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 857/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3299 - acc: 0.8702 - f1: 0.8868 - val_loss: 0.2129 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2077 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2136 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3587 - acc: 0.8528 - f1: 0.8736 - val_loss: 0.2071 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8636 - f1: 0.8818 - val_loss: 0.2133 - val_acc: 0.9547 - val_f1: 0.9572\n",
      "Epoch 862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8637 - f1: 0.8821 - val_loss: 0.2138 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 863/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3385 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2092 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8651 - f1: 0.8830 - val_loss: 0.2166 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 865/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2090 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8576 - f1: 0.8776 - val_loss: 0.2155 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3450 - acc: 0.8610 - f1: 0.8803 - val_loss: 0.2127 - val_acc: 0.9566 - val_f1: 0.9592\n",
      "Epoch 868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2094 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2103 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2135 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8621 - f1: 0.8810 - val_loss: 0.2117 - val_acc: 0.9550 - val_f1: 0.9572\n",
      "Epoch 872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8824 - val_loss: 0.2041 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 874/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2158 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 875/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2085 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8598 - f1: 0.8792 - val_loss: 0.2175 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2076 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8657 - f1: 0.8835 - val_loss: 0.2035 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2065 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8627 - f1: 0.8813 - val_loss: 0.2132 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8630 - f1: 0.8816 - val_loss: 0.2087 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2134 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8625 - f1: 0.8809 - val_loss: 0.2155 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8598 - f1: 0.8789 - val_loss: 0.2148 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2128 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8677 - f1: 0.8850 - val_loss: 0.2080 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 887/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3317 - acc: 0.8692 - f1: 0.8859 - val_loss: 0.2132 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 888/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3427 - acc: 0.8616 - f1: 0.8801 - val_loss: 0.2244 - val_acc: 0.9497 - val_f1: 0.9526\n",
      "Epoch 889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8629 - f1: 0.8816 - val_loss: 0.2104 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 890/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3345 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2160 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 891/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2162 - val_acc: 0.9531 - val_f1: 0.9563\n",
      "Epoch 892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2247 - val_acc: 0.9541 - val_f1: 0.9567\n",
      "Epoch 893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8612 - f1: 0.8804 - val_loss: 0.2075 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8661 - f1: 0.8842 - val_loss: 0.2240 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 895/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3366 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2052 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2110 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2119 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 898/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3402 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 899/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3426 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2352 - val_acc: 0.9447 - val_f1: 0.9486\n",
      "Epoch 900/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3357 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2103 - val_acc: 0.9566 - val_f1: 0.9593\n",
      "Epoch 901/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8607 - f1: 0.8799 - val_loss: 0.2154 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2099 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2529 - val_acc: 0.9613 - val_f1: 0.9617\n",
      "Epoch 904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8667 - f1: 0.8842 - val_loss: 0.2133 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8637 - f1: 0.8818 - val_loss: 0.2169 - val_acc: 0.9650 - val_f1: 0.9652\n",
      "Epoch 906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2198 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2204 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 908/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3452 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2270 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2188 - val_acc: 0.9572 - val_f1: 0.9595\n",
      "Epoch 910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8614 - f1: 0.8800 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 911/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3376 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2088 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8631 - f1: 0.8822 - val_loss: 0.2185 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2064 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2128 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2093 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 916/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3344 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2122 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 917/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3375 - acc: 0.8663 - f1: 0.8843 - val_loss: 0.2089 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 918/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8835 - val_loss: 0.1988 - val_acc: 0.9659 - val_f1: 0.9682\n",
      "Epoch 919/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8672 - f1: 0.8848 - val_loss: 0.2133 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8615 - f1: 0.8805 - val_loss: 0.2094 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8639 - f1: 0.8829 - val_loss: 0.2173 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 922/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2189 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 923/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2109 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 924/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3421 - acc: 0.8624 - f1: 0.8813 - val_loss: 0.2227 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8661 - f1: 0.8843 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 926/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8643 - f1: 0.8829 - val_loss: 0.2102 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8638 - f1: 0.8815 - val_loss: 0.2134 - val_acc: 0.9625 - val_f1: 0.9647\n",
      "Epoch 928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2140 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2123 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8698 - f1: 0.8865 - val_loss: 0.2170 - val_acc: 0.9594 - val_f1: 0.9619\n",
      "Epoch 931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8609 - f1: 0.8804 - val_loss: 0.2073 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3495 - acc: 0.8584 - f1: 0.8781 - val_loss: 0.2229 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8644 - f1: 0.8828 - val_loss: 0.2261 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2149 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8638 - f1: 0.8827 - val_loss: 0.2068 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 936/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3396 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2207 - val_acc: 0.9600 - val_f1: 0.9609\n",
      "Epoch 937/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3526 - acc: 0.8566 - f1: 0.8772 - val_loss: 0.2285 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2183 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 939/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3472 - acc: 0.8588 - f1: 0.8778 - val_loss: 0.2154 - val_acc: 0.9575 - val_f1: 0.9600\n",
      "Epoch 940/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3462 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2146 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 941/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3385 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2240 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 942/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2185 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 943/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2053 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 944/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3427 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2391 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8648 - f1: 0.8839 - val_loss: 0.2041 - val_acc: 0.9647 - val_f1: 0.9666\n",
      "Epoch 946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2098 - val_acc: 0.9650 - val_f1: 0.9670\n",
      "Epoch 947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8624 - f1: 0.8812 - val_loss: 0.2168 - val_acc: 0.9556 - val_f1: 0.9577\n",
      "Epoch 948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8639 - f1: 0.8824 - val_loss: 0.2062 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8631 - f1: 0.8817 - val_loss: 0.2055 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8630 - f1: 0.8814 - val_loss: 0.2101 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 951/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3389 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2218 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2168 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3511 - acc: 0.8569 - f1: 0.8773 - val_loss: 0.2132 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2253 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2144 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 956/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3431 - acc: 0.8630 - f1: 0.8815 - val_loss: 0.2186 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 957/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3378 - acc: 0.8658 - f1: 0.8839 - val_loss: 0.2118 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8667 - f1: 0.8842 - val_loss: 0.2139 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8652 - f1: 0.8830 - val_loss: 0.2045 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2232 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8625 - f1: 0.8813 - val_loss: 0.2221 - val_acc: 0.9522 - val_f1: 0.9555\n",
      "Epoch 962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8630 - f1: 0.8816 - val_loss: 0.2143 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2073 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2114 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8635 - f1: 0.8821 - val_loss: 0.2103 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8602 - f1: 0.8794 - val_loss: 0.2117 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2071 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2049 - val_acc: 0.9669 - val_f1: 0.9689\n",
      "Epoch 969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2130 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 970/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3407 - acc: 0.8640 - f1: 0.8823 - val_loss: 0.2119 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 971/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2119 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 972/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3333 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2065 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 973/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3371 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2113 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 974/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2157 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8689 - f1: 0.8858 - val_loss: 0.2111 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8648 - f1: 0.8827 - val_loss: 0.2075 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8651 - f1: 0.8832 - val_loss: 0.2176 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 978/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2102 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 979/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8700 - f1: 0.8871 - val_loss: 0.2106 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2030 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 981/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3411 - acc: 0.8625 - f1: 0.88 - 0s 16us/sample - loss: 0.3374 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2078 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8806 - val_loss: 0.2087 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3523 - acc: 0.8571 - f1: 0.8775 - val_loss: 0.2237 - val_acc: 0.9438 - val_f1: 0.9476\n",
      "Epoch 984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8612 - f1: 0.8801 - val_loss: 0.2006 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8677 - f1: 0.8847 - val_loss: 0.2067 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2196 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2164 - val_acc: 0.9550 - val_f1: 0.9575\n",
      "Epoch 988/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3366 - acc: 0.8650 - f1: 0.8833 - val_loss: 0.2244 - val_acc: 0.9606 - val_f1: 0.9616\n",
      "Epoch 989/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2208 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 990/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3432 - acc: 0.8623 - f1: 0.8811 - val_loss: 0.2069 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2128 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2167 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8625 - f1: 0.8813 - val_loss: 0.2276 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 994/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3361 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2132 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 995/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8645 - f1: 0.8834 - val_loss: 0.2136 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3429 - acc: 0.8616 - f1: 0.8808 - val_loss: 0.2107 - val_acc: 0.9659 - val_f1: 0.9679\n",
      "Epoch 997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8673 - f1: 0.8848 - val_loss: 0.2336 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2525 - val_acc: 0.9522 - val_f1: 0.9533\n",
      "Epoch 999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8580 - f1: 0.8781 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2112 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2316 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8857 - val_loss: 0.2244 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2152 - val_acc: 0.9566 - val_f1: 0.9585\n",
      "Epoch 1004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8631 - f1: 0.8818 - val_loss: 0.2248 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 1005/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3364 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2246 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2173 - val_acc: 0.9600 - val_f1: 0.9619\n",
      "Epoch 1007/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3514 - acc: 0.8582 - f1: 0.8775 - val_loss: 0.2212 - val_acc: 0.9663 - val_f1: 0.9666\n",
      "Epoch 1008/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2345 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1009/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8686 - f1: 0.8859 - val_loss: 0.2108 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1010/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2110 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8643 - f1: 0.8830 - val_loss: 0.2078 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2063 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 1013/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3368 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2287 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2173 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2051 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2076 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Epoch 1017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8809 - val_loss: 0.2058 - val_acc: 0.9659 - val_f1: 0.9681\n",
      "Epoch 1018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2252 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8603 - f1: 0.8796 - val_loss: 0.2113 - val_acc: 0.9566 - val_f1: 0.9590\n",
      "Epoch 1020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3488 - acc: 0.8584 - f1: 0.8782 - val_loss: 0.2300 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8696 - f1: 0.8867 - val_loss: 0.2123 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 1022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8643 - f1: 0.8826 - val_loss: 0.2098 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 1023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2130 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8659 - f1: 0.8836 - val_loss: 0.2065 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8665 - f1: 0.8850 - val_loss: 0.2196 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8654 - f1: 0.8833 - val_loss: 0.2175 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1027/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3542 - acc: 0.8573 - f1: 0.8767 - val_loss: 0.2257 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 1028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2124 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 1029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2115 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 1030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8615 - f1: 0.8805 - val_loss: 0.2561 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 1031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2212 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2313 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 1033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8655 - f1: 0.8833 - val_loss: 0.2161 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2187 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 1035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8684 - f1: 0.8858 - val_loss: 0.2098 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 1036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2107 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2041 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8593 - f1: 0.8791 - val_loss: 0.2216 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3457 - acc: 0.8607 - f1: 0.8800 - val_loss: 0.2201 - val_acc: 0.9525 - val_f1: 0.9550\n",
      "Epoch 1040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8632 - f1: 0.8813 - val_loss: 0.2124 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2094 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2144 - val_acc: 0.9703 - val_f1: 0.9719\n",
      "Epoch 1043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2378 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2077 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8668 - f1: 0.8843 - val_loss: 0.2251 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8640 - f1: 0.8826 - val_loss: 0.2181 - val_acc: 0.9634 - val_f1: 0.9659\n",
      "Epoch 1047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3489 - acc: 0.8579 - f1: 0.8778 - val_loss: 0.2189 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8678 - f1: 0.8854 - val_loss: 0.2064 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 1049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8848 - val_loss: 0.2027 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 1050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2092 - val_acc: 0.9625 - val_f1: 0.9645\n",
      "Epoch 1051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2124 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 1052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2210 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 1053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2125 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3442 - acc: 0.8613 - f1: 0.8803 - val_loss: 0.2142 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2062 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 1056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8668 - f1: 0.8843 - val_loss: 0.2061 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2128 - val_acc: 0.9547 - val_f1: 0.9573\n",
      "Epoch 1058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3525 - acc: 0.8567 - f1: 0.8766 - val_loss: 0.2255 - val_acc: 0.9556 - val_f1: 0.9567\n",
      "Epoch 1059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8644 - f1: 0.8824 - val_loss: 0.2240 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2108 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8670 - f1: 0.8846 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 1062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8620 - f1: 0.8808 - val_loss: 0.2197 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8665 - f1: 0.8839 - val_loss: 0.2186 - val_acc: 0.9566 - val_f1: 0.9582\n",
      "Epoch 1064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8635 - f1: 0.8824 - val_loss: 0.2088 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2177 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2234 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 1067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8616 - f1: 0.8811 - val_loss: 0.2157 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 1068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2170 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3451 - acc: 0.8610 - f1: 0.8804 - val_loss: 0.2105 - val_acc: 0.9613 - val_f1: 0.9633\n",
      "Epoch 1070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8629 - f1: 0.8812 - val_loss: 0.2056 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 1071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8698 - f1: 0.8864 - val_loss: 0.2192 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 1072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2097 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8708 - f1: 0.8875 - val_loss: 0.2136 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1074/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8636 - f1: 0.8823 - val_loss: 0.2186 - val_acc: 0.9588 - val_f1: 0.9605\n",
      "Epoch 1075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8851 - val_loss: 0.2213 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2127 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1077/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2265 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2066 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8669 - f1: 0.8847 - val_loss: 0.2190 - val_acc: 0.9550 - val_f1: 0.9570\n",
      "Epoch 1080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2061 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2148 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8648 - f1: 0.8829 - val_loss: 0.2395 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8675 - f1: 0.8849 - val_loss: 0.2078 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 1084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2106 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1085/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8602 - f1: 0.8799 - val_loss: 0.2149 - val_acc: 0.9609 - val_f1: 0.9625\n",
      "Epoch 1086/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2120 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1087/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2184 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1088/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2068 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1089/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8632 - f1: 0.8819 - val_loss: 0.2302 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2252 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 1091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8646 - f1: 0.8833 - val_loss: 0.2329 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 1092/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3464 - acc: 0.8599 - f1: 0.8794 - val_loss: 0.2165 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 1093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8634 - f1: 0.8819 - val_loss: 0.2128 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 1094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2141 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 1095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2159 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2221 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1097/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8646 - f1: 0.8832 - val_loss: 0.2232 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8676 - f1: 0.8851 - val_loss: 0.2191 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2176 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8865 - val_loss: 0.2100 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2266 - val_acc: 0.9566 - val_f1: 0.9579\n",
      "Epoch 1102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2236 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8653 - f1: 0.8833 - val_loss: 0.2189 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8696 - f1: 0.8867 - val_loss: 0.2198 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 1105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2140 - val_acc: 0.9666 - val_f1: 0.9684\n",
      "Epoch 1106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8646 - f1: 0.8829 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8845 - val_loss: 0.2137 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2221 - val_acc: 0.9553 - val_f1: 0.9580\n",
      "Epoch 1109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3428 - acc: 0.8630 - f1: 0.8815 - val_loss: 0.2187 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 1111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2247 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2221 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2175 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2201 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2196 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8645 - f1: 0.8828 - val_loss: 0.2395 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 1118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8648 - f1: 0.8834 - val_loss: 0.2308 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2294 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2118 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8632 - f1: 0.8819 - val_loss: 0.2179 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 1122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2288 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2326 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8640 - f1: 0.8826 - val_loss: 0.2198 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2159 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8599 - f1: 0.8793 - val_loss: 0.2210 - val_acc: 0.9519 - val_f1: 0.9545\n",
      "Epoch 1127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8640 - f1: 0.8820 - val_loss: 0.2124 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8640 - f1: 0.8822 - val_loss: 0.2153 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8629 - f1: 0.8816 - val_loss: 0.2129 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8656 - f1: 0.8834 - val_loss: 0.2102 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 1131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2168 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 1132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8665 - f1: 0.8843 - val_loss: 0.2119 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 1133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8603 - f1: 0.8800 - val_loss: 0.2174 - val_acc: 0.9575 - val_f1: 0.9594\n",
      "Epoch 1134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8843 - val_loss: 0.2221 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2392 - val_acc: 0.9616 - val_f1: 0.9623\n",
      "Epoch 1136/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2197 - val_acc: 0.9534 - val_f1: 0.9563\n",
      "Epoch 1137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2073 - val_acc: 0.9622 - val_f1: 0.9645\n",
      "Epoch 1138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8623 - f1: 0.8814 - val_loss: 0.2210 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8737 - f1: 0.8898 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8643 - f1: 0.8831 - val_loss: 0.2123 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3458 - acc: 0.8610 - f1: 0.8800 - val_loss: 0.2251 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1142/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3346 - acc: 0.8685 - f1: 0.8858 - val_loss: 0.2358 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1143/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2309 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 1144/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8627 - f1: 0.8815 - val_loss: 0.2147 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2114 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8720 - f1: 0.8886 - val_loss: 0.2137 - val_acc: 0.9597 - val_f1: 0.9619\n",
      "Epoch 1147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8674 - f1: 0.8849 - val_loss: 0.2125 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 1148/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2288 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 1149/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8851 - val_loss: 0.2166 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1150/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3359 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2220 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 1151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2019 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8659 - f1: 0.8837 - val_loss: 0.2125 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1153/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3471 - acc: 0.8595 - f1: 0.8793 - val_loss: 0.2061 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1154/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3435 - acc: 0.8602 - f1: 0.8797 - val_loss: 0.2257 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8642 - f1: 0.8820 - val_loss: 0.2190 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1156/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8851 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9670\n",
      "Epoch 1157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8647 - f1: 0.8828 - val_loss: 0.2174 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1158/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8816 - val_loss: 0.2212 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1159/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3443 - acc: 0.8606 - f1: 0.8800 - val_loss: 0.2117 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 1160/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8644 - f1: 0.8825 - val_loss: 0.2312 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2164 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1162/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3400 - acc: 0.8650 - f1: 0.8830 - val_loss: 0.2250 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8704 - f1: 0.8873 - val_loss: 0.2145 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 1164/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8638 - f1: 0.8824 - val_loss: 0.2189 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 1165/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2427 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 1166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2156 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8651 - f1: 0.8830 - val_loss: 0.2142 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1168/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3360 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2251 - val_acc: 0.9588 - val_f1: 0.9612\n",
      "Epoch 1169/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3431 - acc: 0.8622 - f1: 0.8815 - val_loss: 0.2178 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 1170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2186 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1171/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3301 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2127 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 1172/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2163 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1173/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3419 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2104 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1174/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3447 - acc: 0.8605 - f1: 0.8807 - val_loss: 0.2120 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2488 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 1176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2242 - val_acc: 0.9669 - val_f1: 0.9672\n",
      "Epoch 1177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2262 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 1178/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3358 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2293 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1179/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2405 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 1180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8627 - f1: 0.8817 - val_loss: 0.2534 - val_acc: 0.9606 - val_f1: 0.9615\n",
      "Epoch 1181/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3391 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2076 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 1182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2142 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 1183/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2178 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1185/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8728 - f1: 0.8893 - val_loss: 0.2366 - val_acc: 0.9394 - val_f1: 0.9437\n",
      "Epoch 1186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3496 - acc: 0.8601 - f1: 0.8791 - val_loss: 0.2057 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2121 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 1188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2154 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 1189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8672 - f1: 0.8850 - val_loss: 0.2305 - val_acc: 0.9531 - val_f1: 0.9551\n",
      "Epoch 1190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2334 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 1191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8626 - f1: 0.8811 - val_loss: 0.2286 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8657 - f1: 0.8834 - val_loss: 0.2281 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 1193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2073 - val_acc: 0.9572 - val_f1: 0.9594\n",
      "Epoch 1194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8618 - f1: 0.8808 - val_loss: 0.2194 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2226 - val_acc: 0.9578 - val_f1: 0.9593\n",
      "Epoch 1196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8624 - f1: 0.8814 - val_loss: 0.2193 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2159 - val_acc: 0.9594 - val_f1: 0.9618\n",
      "Epoch 1198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3466 - acc: 0.8593 - f1: 0.8793 - val_loss: 0.2155 - val_acc: 0.9522 - val_f1: 0.9557\n",
      "Epoch 1199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2199 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8671 - f1: 0.8854 - val_loss: 0.2160 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2199 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8654 - f1: 0.8834 - val_loss: 0.2221 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2282 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2287 - val_acc: 0.9550 - val_f1: 0.9579\n",
      "Epoch 1205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2341 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 1206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2214 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 1207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2193 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2279 - val_acc: 0.9678 - val_f1: 0.9683\n",
      "Epoch 1209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.2169 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 1210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2225 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2111 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 1212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2109 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2703 - val_acc: 0.9581 - val_f1: 0.9582\n",
      "Epoch 1214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3468 - acc: 0.8600 - f1: 0.8794 - val_loss: 0.2094 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8840 - val_loss: 0.2225 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2213 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 1217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2226 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8642 - f1: 0.8822 - val_loss: 0.2210 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2406 - val_acc: 0.9609 - val_f1: 0.9618\n",
      "Epoch 1220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2134 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8652 - f1: 0.8837 - val_loss: 0.2159 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8639 - f1: 0.8825 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8655 - f1: 0.8833 - val_loss: 0.2170 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 1224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2321 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2106 - val_acc: 0.9656 - val_f1: 0.9677\n",
      "Epoch 1226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2276 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 1227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8646 - f1: 0.8827 - val_loss: 0.2147 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8849 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9658\n",
      "Epoch 1229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2216 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8689 - f1: 0.8861 - val_loss: 0.2229 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2182 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2390 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 1234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2164 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1235/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3395 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2357 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 1236/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3381 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2247 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8672 - f1: 0.8843 - val_loss: 0.2493 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 1238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2185 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 1239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2233 - val_acc: 0.9563 - val_f1: 0.9587\n",
      "Epoch 1240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2233 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2392 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 1242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2101 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 1243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2529 - val_acc: 0.9563 - val_f1: 0.9568\n",
      "Epoch 1244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8640 - f1: 0.8821 - val_loss: 0.2147 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8704 - f1: 0.8873 - val_loss: 0.2240 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2144 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 1247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2223 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 1248/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3422 - acc: 0.8620 - f1: 0.8806 - val_loss: 0.2153 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 1249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2300 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 1250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2095 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2089 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2121 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3490 - acc: 0.8601 - f1: 0.8793 - val_loss: 0.2135 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2207 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2377 - val_acc: 0.9397 - val_f1: 0.9442\n",
      "Epoch 1256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3516 - acc: 0.8577 - f1: 0.8775 - val_loss: 0.2194 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 1257/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3382 - acc: 0.8640 - f1: 0.8830 - val_loss: 0.2110 - val_acc: 0.9591 - val_f1: 0.9617\n",
      "Epoch 1258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2319 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 1259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2099 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 1260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2118 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 1261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8704 - f1: 0.8868 - val_loss: 0.2180 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 1262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2107 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 1263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8636 - f1: 0.8825 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1264/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2240 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8627 - f1: 0.8809 - val_loss: 0.2127 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2069 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 1267/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3429 - acc: 0.8621 - f1: 0.8814 - val_loss: 0.2109 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2128 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1269/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2286 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2286 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2396 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2121 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1273/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3444 - acc: 0.8602 - f1: 0.8797 - val_loss: 0.2106 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 1274/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3357 - acc: 0.8651 - f1: 0.8834 - val_loss: 0.2204 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1275/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3369 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2423 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 1276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3533 - acc: 0.8561 - f1: 0.8762 - val_loss: 0.2129 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1277/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2158 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8639 - f1: 0.8824 - val_loss: 0.2336 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 1279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8639 - f1: 0.8820 - val_loss: 0.2163 - val_acc: 0.9581 - val_f1: 0.9608\n",
      "Epoch 1280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8694 - f1: 0.8863 - val_loss: 0.2039 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2183 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 1282/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8635 - f1: 0.8825 - val_loss: 0.2298 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 1283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2129 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8655 - f1: 0.8836 - val_loss: 0.2467 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2172 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8696 - f1: 0.8868 - val_loss: 0.2132 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2235 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2117 - val_acc: 0.9613 - val_f1: 0.9636\n",
      "Epoch 1289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2321 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2234 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 1291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2353 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2118 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2224 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 1294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3443 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2081 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 1295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2105 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 1296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2066 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 1297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8639 - f1: 0.8827 - val_loss: 0.2216 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3449 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2334 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 1299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2285 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2101 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2152 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 1302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2069 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2116 - val_acc: 0.9581 - val_f1: 0.9602\n",
      "Epoch 1304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8681 - f1: 0.8855 - val_loss: 0.2288 - val_acc: 0.9494 - val_f1: 0.9530\n",
      "Epoch 1305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3444 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2117 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2208 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8716 - f1: 0.8881 - val_loss: 0.2210 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2177 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 1309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2188 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2282 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8668 - f1: 0.8846 - val_loss: 0.2225 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8609 - f1: 0.8800 - val_loss: 0.2398 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2090 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 1314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2489 - val_acc: 0.9319 - val_f1: 0.9371\n",
      "Epoch 1315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3564 - acc: 0.8551 - f1: 0.8752 - val_loss: 0.2128 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2324 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 1317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2302 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 1318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2228 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8650 - f1: 0.8828 - val_loss: 0.2155 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2133 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 1321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2259 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8638 - f1: 0.8824 - val_loss: 0.2269 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2105 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 1324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2173 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2259 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 1327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2199 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8622 - f1: 0.8814 - val_loss: 0.2213 - val_acc: 0.9578 - val_f1: 0.9605\n",
      "Epoch 1329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8810 - val_loss: 0.2132 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2233 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8620 - f1: 0.8811 - val_loss: 0.2108 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2224 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2202 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 1334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2136 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8693 - f1: 0.8865 - val_loss: 0.2256 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3424 - acc: 0.8611 - f1: 0.8803 - val_loss: 0.2350 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 1337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2177 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2076 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 1339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2403 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 1340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2291 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3415 - acc: 0.8617 - f1: 0.8806 - val_loss: 0.2237 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2368 - val_acc: 0.9475 - val_f1: 0.9504\n",
      "Epoch 1343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3515 - acc: 0.8558 - f1: 0.8769 - val_loss: 0.2143 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8648 - f1: 0.8828 - val_loss: 0.2156 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2115 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8705 - f1: 0.8872 - val_loss: 0.2303 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8874 - val_loss: 0.2134 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8693 - f1: 0.8863 - val_loss: 0.2177 - val_acc: 0.9534 - val_f1: 0.9560\n",
      "Epoch 1349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2147 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 1350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2106 - val_acc: 0.9625 - val_f1: 0.9648\n",
      "Epoch 1351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8665 - f1: 0.8842 - val_loss: 0.2227 - val_acc: 0.9553 - val_f1: 0.9584\n",
      "Epoch 1352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3434 - acc: 0.8618 - f1: 0.8807 - val_loss: 0.2178 - val_acc: 0.9519 - val_f1: 0.9544\n",
      "Epoch 1353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2158 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2435 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8649 - f1: 0.8830 - val_loss: 0.2434 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3437 - acc: 0.8624 - f1: 0.8809 - val_loss: 0.2112 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2215 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 1358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8633 - f1: 0.8824 - val_loss: 0.2139 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2336 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 1361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2181 - val_acc: 0.9675 - val_f1: 0.9693\n",
      "Epoch 1362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8714 - f1: 0.8880 - val_loss: 0.2357 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 1363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2111 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2137 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2438 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 1366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2292 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 1367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8656 - f1: 0.8837 - val_loss: 0.2189 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8845 - val_loss: 0.2269 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8660 - f1: 0.8840 - val_loss: 0.2255 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2358 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1371/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2209 - val_acc: 0.9572 - val_f1: 0.9589\n",
      "Epoch 1372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2198 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2141 - val_acc: 0.9594 - val_f1: 0.9619\n",
      "Epoch 1374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8670 - f1: 0.8854 - val_loss: 0.2241 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8656 - f1: 0.8842 - val_loss: 0.2109 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 1376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2282 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8668 - f1: 0.8845 - val_loss: 0.2249 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8656 - f1: 0.8836 - val_loss: 0.2137 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 1379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8635 - f1: 0.8824 - val_loss: 0.2323 - val_acc: 0.9431 - val_f1: 0.9475\n",
      "Epoch 1380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3420 - acc: 0.8632 - f1: 0.8818 - val_loss: 0.2120 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2156 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 1382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2422 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8627 - f1: 0.8817 - val_loss: 0.2187 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 1384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8646 - f1: 0.8826 - val_loss: 0.2221 - val_acc: 0.9588 - val_f1: 0.9614\n",
      "Epoch 1385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2163 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 1387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8615 - f1: 0.8804 - val_loss: 0.2265 - val_acc: 0.9478 - val_f1: 0.9513\n",
      "Epoch 1388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2388 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 1389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2274 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2256 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 1391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2201 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 1392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8625 - f1: 0.8814 - val_loss: 0.2183 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8675 - f1: 0.8849 - val_loss: 0.2152 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 1394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8672 - f1: 0.8848 - val_loss: 0.2128 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 1395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2736 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 1396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3413 - acc: 0.8627 - f1: 0.8815 - val_loss: 0.2214 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2192 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 1398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2270 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8649 - f1: 0.8838 - val_loss: 0.2127 - val_acc: 0.9597 - val_f1: 0.9620\n",
      "Epoch 1400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8853 - val_loss: 0.2325 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2311 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 1402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8644 - f1: 0.8833 - val_loss: 0.2056 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 1403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8674 - f1: 0.8848 - val_loss: 0.2149 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 1404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2462 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 1405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2281 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 1406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2229 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2073 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2213 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2213 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8653 - f1: 0.8839 - val_loss: 0.2257 - val_acc: 0.9578 - val_f1: 0.9594\n",
      "Epoch 1411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2125 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 1412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8755 - f1: 0.8916 - val_loss: 0.2099 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2129 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8633 - f1: 0.8818 - val_loss: 0.2094 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2146 - val_acc: 0.9644 - val_f1: 0.9665\n",
      "Epoch 1416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8652 - f1: 0.8836 - val_loss: 0.2290 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2232 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8640 - f1: 0.8827 - val_loss: 0.2134 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 1419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8633 - f1: 0.8824 - val_loss: 0.2203 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 1420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2193 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8629 - f1: 0.8822 - val_loss: 0.2087 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2298 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8671 - f1: 0.8858 - val_loss: 0.2125 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 1424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8721 - f1: 0.8888 - val_loss: 0.2129 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 1425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8622 - f1: 0.8813 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2184 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 1427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3459 - acc: 0.8604 - f1: 0.8798 - val_loss: 0.2410 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2160 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 1429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8679 - f1: 0.8856 - val_loss: 0.2327 - val_acc: 0.9569 - val_f1: 0.9586\n",
      "Epoch 1430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8623 - f1: 0.8813 - val_loss: 0.2231 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2214 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 1432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8667 - f1: 0.8848 - val_loss: 0.2385 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1433/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8846 - val_loss: 0.2181 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 1434/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3394 - acc: 0.8643 - f1: 0.8828 - val_loss: 0.2336 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1435/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2161 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1436/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2195 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 1437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8674 - f1: 0.8858 - val_loss: 0.2270 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 1438/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8711 - f1: 0.8876 - val_loss: 0.2447 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8634 - f1: 0.8824 - val_loss: 0.2582 - val_acc: 0.9616 - val_f1: 0.9619\n",
      "Epoch 1440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8653 - f1: 0.8838 - val_loss: 0.2498 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 1441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8687 - f1: 0.8857 - val_loss: 0.2177 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2191 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 1443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2263 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 1444/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3469 - acc: 0.8604 - f1: 0.8800 - val_loss: 0.2338 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8659 - f1: 0.8834 - val_loss: 0.2116 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2188 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8653 - f1: 0.8836 - val_loss: 0.2316 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 1448/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3280 - acc: 0.8706 - f1: 0.8876 - val_loss: 0.2256 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 1449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2478 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3487 - acc: 0.8606 - f1: 0.8799 - val_loss: 0.2159 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8640 - f1: 0.8825 - val_loss: 0.2134 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2145 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1453/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3279 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2283 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1454/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2304 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2420 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 1456/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3255 - acc: 0.8721 - f1: 0.8886 - val_loss: 0.2293 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 1457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2244 - val_acc: 0.9513 - val_f1: 0.9545\n",
      "Epoch 1458/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8612 - f1: 0.8803 - val_loss: 0.2116 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8710 - f1: 0.8877 - val_loss: 0.2216 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 1460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2245 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1461/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2336 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 1462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2238 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 1463/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8694 - f1: 0.8866 - val_loss: 0.2096 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 1465/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8849 - val_loss: 0.2183 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8655 - f1: 0.8834 - val_loss: 0.2232 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8641 - f1: 0.8831 - val_loss: 0.2172 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 1468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 1469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8648 - f1: 0.8835 - val_loss: 0.2143 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2248 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2277 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 1472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2175 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 1473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8666 - f1: 0.8851 - val_loss: 0.2258 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2165 - val_acc: 0.9594 - val_f1: 0.9620\n",
      "Epoch 1475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2136 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 1476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2150 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 1477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2213 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2293 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2255 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8636 - f1: 0.8819 - val_loss: 0.2332 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8637 - f1: 0.8826 - val_loss: 0.2273 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8748 - f1: 0.8904 - val_loss: 0.2274 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 1483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2413 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 1484/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3391 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2300 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 1485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2214 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 1486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2234 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 1487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2191 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 1488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2213 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2144 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2285 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2110 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2112 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 1493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2233 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 1494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2159 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2135 - val_acc: 0.9581 - val_f1: 0.9608\n",
      "Epoch 1496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2331 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 1497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8676 - f1: 0.8851 - val_loss: 0.2158 - val_acc: 0.9594 - val_f1: 0.9607\n",
      "Epoch 1498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8637 - f1: 0.8830 - val_loss: 0.2268 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8632 - f1: 0.8818 - val_loss: 0.2176 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 1500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2268 - val_acc: 0.9591 - val_f1: 0.9605\n",
      "Epoch 1501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8640 - f1: 0.8831 - val_loss: 0.2369 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8688 - f1: 0.8860 - val_loss: 0.2293 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 1503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2396 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2296 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2248 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8622 - f1: 0.8812 - val_loss: 0.2265 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 1507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2359 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2106 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 1509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2207 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 1510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2149 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8685 - f1: 0.8859 - val_loss: 0.2243 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2232 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8649 - f1: 0.8833 - val_loss: 0.2208 - val_acc: 0.9603 - val_f1: 0.9615\n",
      "Epoch 1514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8708 - f1: 0.8874 - val_loss: 0.2259 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 1515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2354 - val_acc: 0.9456 - val_f1: 0.9494\n",
      "Epoch 1516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8614 - f1: 0.8805 - val_loss: 0.2125 - val_acc: 0.9597 - val_f1: 0.9620\n",
      "Epoch 1517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2218 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2248 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 1519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8672 - f1: 0.8855 - val_loss: 0.2471 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2162 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8653 - f1: 0.8835 - val_loss: 0.2199 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8633 - f1: 0.8823 - val_loss: 0.2209 - val_acc: 0.9544 - val_f1: 0.9572\n",
      "Epoch 1523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2365 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2134 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2265 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 1526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2294 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2256 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 1528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2342 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2238 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 1531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2547 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 1532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2130 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8761 - f1: 0.8916 - val_loss: 0.2177 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 1534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2055 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 1535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8647 - f1: 0.8833 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2100 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 1537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8754 - f1: 0.8917 - val_loss: 0.2399 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 1538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8689 - f1: 0.8868 - val_loss: 0.2245 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 1539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2497 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2255 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 1541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8628 - f1: 0.8817 - val_loss: 0.2183 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2216 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2273 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 1544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8656 - f1: 0.8843 - val_loss: 0.2229 - val_acc: 0.9559 - val_f1: 0.9580\n",
      "Epoch 1545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2383 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 1546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2363 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 1547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8650 - f1: 0.8832 - val_loss: 0.2193 - val_acc: 0.9556 - val_f1: 0.9580\n",
      "Epoch 1549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8651 - f1: 0.8841 - val_loss: 0.2337 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2195 - val_acc: 0.9603 - val_f1: 0.9630\n",
      "Epoch 1551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2195 - val_acc: 0.9578 - val_f1: 0.9606\n",
      "Epoch 1552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8672 - f1: 0.8851 - val_loss: 0.2331 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 1553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2481 - val_acc: 0.9381 - val_f1: 0.9425\n",
      "Epoch 1554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3492 - acc: 0.8605 - f1: 0.8796 - val_loss: 0.2060 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8617 - f1: 0.8807 - val_loss: 0.2180 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 1556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8619 - f1: 0.8809 - val_loss: 0.2264 - val_acc: 0.9691 - val_f1: 0.9697\n",
      "Epoch 1557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2302 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 1558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2138 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1559/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2175 - val_acc: 0.9594 - val_f1: 0.9615\n",
      "Epoch 1560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3486 - acc: 0.8585 - f1: 0.8783 - val_loss: 0.2077 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 1561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2395 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8864 - val_loss: 0.2416 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 1563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8677 - f1: 0.8860 - val_loss: 0.2112 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2387 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2179 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2321 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2371 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2416 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2158 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 1570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8652 - f1: 0.8830 - val_loss: 0.2166 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2165 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2273 - val_acc: 0.9647 - val_f1: 0.9668\n",
      "Epoch 1573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8676 - f1: 0.8857 - val_loss: 0.2180 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2318 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2128 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2323 - val_acc: 0.9703 - val_f1: 0.9714\n",
      "Epoch 1577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8658 - f1: 0.8842 - val_loss: 0.2269 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2331 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8644 - f1: 0.8830 - val_loss: 0.2332 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2124 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2222 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2211 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8621 - f1: 0.8813 - val_loss: 0.2419 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 1584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2124 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 1586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8656 - f1: 0.8839 - val_loss: 0.2299 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 1587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2191 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 1588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3447 - acc: 0.8631 - f1: 0.8816 - val_loss: 0.2300 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2100 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2321 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 1591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2214 - val_acc: 0.9538 - val_f1: 0.9566\n",
      "Epoch 1592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2165 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2255 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2152 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 1595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2185 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 1596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8620 - f1: 0.8807 - val_loss: 0.2085 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2209 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2530 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 1599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2384 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2184 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2232 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2334 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2392 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8634 - f1: 0.8820 - val_loss: 0.2238 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 1605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2390 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2275 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 1607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8836 - val_loss: 0.2356 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2136 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8640 - f1: 0.8825 - val_loss: 0.2092 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2366 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2272 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2150 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2209 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 1614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2223 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 1615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2365 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 1616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2206 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2106 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2333 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 1619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2288 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2243 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8739 - f1: 0.8903 - val_loss: 0.2204 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2417 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 1623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8654 - f1: 0.8839 - val_loss: 0.2328 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 1624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2386 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2206 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2220 - val_acc: 0.9581 - val_f1: 0.9606\n",
      "Epoch 1627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2116 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3445 - acc: 0.8606 - f1: 0.8801 - val_loss: 0.2360 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2126 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8743 - f1: 0.8908 - val_loss: 0.2186 - val_acc: 0.9703 - val_f1: 0.9715\n",
      "Epoch 1631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8637 - f1: 0.8823 - val_loss: 0.2175 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 1632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2372 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8668 - f1: 0.8851 - val_loss: 0.2409 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 1634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2163 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2260 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 1636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8660 - f1: 0.8842 - val_loss: 0.2193 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 1637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2325 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 1638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2287 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 1639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2247 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 1640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8630 - f1: 0.8818 - val_loss: 0.2195 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2247 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2213 - val_acc: 0.9531 - val_f1: 0.9556\n",
      "Epoch 1643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2325 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 1644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8696 - f1: 0.8873 - val_loss: 0.2197 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 1645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3440 - acc: 0.8602 - f1: 0.8793 - val_loss: 0.2196 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 1646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2202 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 1647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8752 - f1: 0.8912 - val_loss: 0.2375 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 1648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2198 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2562 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3369 - acc: 0.8655 - f1: 0.8834 - val_loss: 0.2223 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2368 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 1652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2247 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 1653/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2224 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3456 - acc: 0.8613 - f1: 0.8807 - val_loss: 0.2118 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 1655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2268 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 1656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8631 - f1: 0.8820 - val_loss: 0.2256 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2236 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 1658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8662 - f1: 0.8848 - val_loss: 0.2204 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 1659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2157 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 1660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2246 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8671 - f1: 0.8845 - val_loss: 0.2069 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 1662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8662 - f1: 0.8849 - val_loss: 0.2339 - val_acc: 0.9688 - val_f1: 0.9692\n",
      "Epoch 1663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2142 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2892 - val_acc: 0.9603 - val_f1: 0.9612\n",
      "Epoch 1665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3571 - acc: 0.8552 - f1: 0.8757 - val_loss: 0.2222 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2119 - val_acc: 0.9606 - val_f1: 0.9628\n",
      "Epoch 1667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2097 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2165 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 1669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2250 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2226 - val_acc: 0.9616 - val_f1: 0.9642\n",
      "Epoch 1671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2412 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 1672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2246 - val_acc: 0.9628 - val_f1: 0.9650\n",
      "Epoch 1673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2255 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1674/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8627 - f1: 0.8818 - val_loss: 0.2273 - val_acc: 0.9631 - val_f1: 0.9636\n",
      "Epoch 1675/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2338 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 1676/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2170 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 1677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2221 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 1678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8745 - f1: 0.8904 - val_loss: 0.2453 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 1679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2189 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 1680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2090 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 1681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8585 - f1: 0.8783 - val_loss: 0.2215 - val_acc: 0.9584 - val_f1: 0.9608\n",
      "Epoch 1682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2490 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 1683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2389 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8753 - f1: 0.8911 - val_loss: 0.2358 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8641 - f1: 0.8826 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2243 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2357 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 1688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2477 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 1689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2394 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8631 - f1: 0.8821 - val_loss: 0.2216 - val_acc: 0.9575 - val_f1: 0.9593\n",
      "Epoch 1691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8634 - f1: 0.8816 - val_loss: 0.2293 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 1692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8638 - f1: 0.8821 - val_loss: 0.2250 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 1693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8618 - f1: 0.8812 - val_loss: 0.2183 - val_acc: 0.9534 - val_f1: 0.9564\n",
      "Epoch 1694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8629 - f1: 0.8820 - val_loss: 0.2289 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 1695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8706 - f1: 0.8882 - val_loss: 0.2308 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8657 - f1: 0.8836 - val_loss: 0.2339 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 1698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2291 - val_acc: 0.9506 - val_f1: 0.9539\n",
      "Epoch 1699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2288 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2267 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1701/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3294 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2173 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 1702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8589 - f1: 0.8793 - val_loss: 0.2277 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 1703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8675 - f1: 0.8850 - val_loss: 0.2327 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2338 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2487 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 1706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2239 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 1707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2456 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2422 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 1709/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3352 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2287 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1710/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3363 - acc: 0.8650 - f1: 0.8834 - val_loss: 0.2416 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 1711/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2177 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 1712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2177 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 1713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2262 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 1714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8594 - f1: 0.8785 - val_loss: 0.2206 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8653 - f1: 0.8840 - val_loss: 0.2189 - val_acc: 0.9681 - val_f1: 0.9684\n",
      "Epoch 1716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2269 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2187 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 1718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2258 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2168 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 1720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8698 - f1: 0.8877 - val_loss: 0.2367 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 1721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2162 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 1722/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2156 - val_acc: 0.9672 - val_f1: 0.9690\n",
      "Epoch 1723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8705 - f1: 0.8871 - val_loss: 0.2068 - val_acc: 0.9584 - val_f1: 0.9607\n",
      "Epoch 1724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8650 - f1: 0.8835 - val_loss: 0.2196 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2294 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2200 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 1727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8649 - f1: 0.8831 - val_loss: 0.2099 - val_acc: 0.9606 - val_f1: 0.9629\n",
      "Epoch 1728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8700 - f1: 0.8869 - val_loss: 0.2249 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8669 - f1: 0.8845 - val_loss: 0.2323 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 1730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2274 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 1731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2378 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 1732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2556 - val_acc: 0.9572 - val_f1: 0.9585\n",
      "Epoch 1733/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2125 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8663 - f1: 0.8840 - val_loss: 0.2191 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2147 - val_acc: 0.9625 - val_f1: 0.9645\n",
      "Epoch 1736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2478 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 1737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2251 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 1738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3432 - acc: 0.8620 - f1: 0.8809 - val_loss: 0.2281 - val_acc: 0.9591 - val_f1: 0.9606\n",
      "Epoch 1739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8707 - f1: 0.8876 - val_loss: 0.2308 - val_acc: 0.9547 - val_f1: 0.9571\n",
      "Epoch 1740/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3401 - acc: 0.8629 - f1: 0.8814 - val_loss: 0.2273 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 1741/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3356 - acc: 0.8657 - f1: 0.8842 - val_loss: 0.2245 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1742/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3247 - acc: 0.8728 - f1: 0.88 - 0s 16us/sample - loss: 0.3268 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2193 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2257 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 1744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2493 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1745/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8618 - f1: 0.8812 - val_loss: 0.2256 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3213 - acc: 0.8738 - f1: 0.8898 - val_loss: 0.2323 - val_acc: 0.9663 - val_f1: 0.9674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8640 - f1: 0.8827 - val_loss: 0.2190 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2366 - val_acc: 0.9603 - val_f1: 0.9619\n",
      "Epoch 1749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2214 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 1750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8631 - f1: 0.8824 - val_loss: 0.2145 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 1751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8627 - f1: 0.8814 - val_loss: 0.2580 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 1752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2121 - val_acc: 0.9619 - val_f1: 0.9641\n",
      "Epoch 1753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2260 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2169 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 1755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2275 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 1756/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2125 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1758/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8655 - f1: 0.8840 - val_loss: 0.2201 - val_acc: 0.9619 - val_f1: 0.9642\n",
      "Epoch 1759/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3296 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2196 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 1760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2189 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 1761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2192 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1762/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2358 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2238 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1764/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2351 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1765/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2459 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1766/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2299 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1767/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3277 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2417 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1768/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2342 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1769/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3410 - acc: 0.8634 - f1: 0.8827 - val_loss: 0.2302 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 1770/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3353 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2266 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 1771/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2349 - val_acc: 0.9691 - val_f1: 0.9699\n",
      "Epoch 1772/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2241 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 1773/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2490 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 1774/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3334 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2234 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 1775/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2215 - val_acc: 0.9594 - val_f1: 0.9609\n",
      "Epoch 1776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2149 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 1777/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8652 - f1: 0.8832 - val_loss: 0.2226 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 1778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2238 - val_acc: 0.9550 - val_f1: 0.9574\n",
      "Epoch 1779/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3393 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2233 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 1780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8703 - f1: 0.8868 - val_loss: 0.2537 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1781/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8634 - f1: 0.8824 - val_loss: 0.2176 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1782/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3424 - acc: 0.8620 - f1: 0.8808 - val_loss: 0.2168 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 1783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2245 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 1784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2226 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 1785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2387 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 1786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2241 - val_acc: 0.9509 - val_f1: 0.9538\n",
      "Epoch 1787/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8871 - val_loss: 0.2407 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 1788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2483 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2213 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 1790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2249 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 1791/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2342 - val_acc: 0.9684 - val_f1: 0.9692\n",
      "Epoch 1792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2567 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 1793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2210 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 1794/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8679 - f1: 0.8853 - val_loss: 0.2136 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2301 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 1796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2234 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 1797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2291 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 1798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 1799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2192 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 1800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2364 - val_acc: 0.9675 - val_f1: 0.9692\n",
      "Epoch 1801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8718 - f1: 0.8883 - val_loss: 0.2186 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 1802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8637 - f1: 0.8827 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 1803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8640 - f1: 0.8828 - val_loss: 0.2135 - val_acc: 0.9659 - val_f1: 0.9663\n",
      "Epoch 1804/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2186 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1805/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2217 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 1806/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3285 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2200 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1807/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2300 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2283 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 1809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8679 - f1: 0.8858 - val_loss: 0.2290 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1810/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2144 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1811/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2299 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 1812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2196 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 1813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3478 - acc: 0.8595 - f1: 0.8790 - val_loss: 0.2155 - val_acc: 0.9603 - val_f1: 0.9618\n",
      "Epoch 1814/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2331 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 1815/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2216 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 1816/5000\n",
      "12800/12800 [==============================] - 0s 19us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2329 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1817/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3369 - acc: 0.8661 - f1: 0.8842 - val_loss: 0.2213 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1818/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2250 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 1819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 1820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2213 - val_acc: 0.9453 - val_f1: 0.9491\n",
      "Epoch 1821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2273 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 1822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2203 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2351 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 1824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2249 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 1825/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3354 - acc: 0.8683 - f1: 0.8858 - val_loss: 0.2346 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1826/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3384 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2285 - val_acc: 0.9581 - val_f1: 0.9596\n",
      "Epoch 1827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2128 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 1828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2270 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2198 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 1830/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2181 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2540 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2375 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 1833/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2231 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2206 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2346 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 1836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8619 - f1: 0.8814 - val_loss: 0.2199 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2379 - val_acc: 0.9681 - val_f1: 0.9687\n",
      "Epoch 1838/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3301 - acc: 0.8681 - f1: 0.8854 - val_loss: 0.2363 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 1839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3380 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2192 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2295 - val_acc: 0.9478 - val_f1: 0.9515\n",
      "Epoch 1841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2138 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 1842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2224 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 1843/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3225 - acc: 0.8746 - f1: 0.8906 - val_loss: 0.2281 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1844/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2265 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 1845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2263 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1846/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3343 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2300 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2148 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 1848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2142 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 1849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8674 - f1: 0.8850 - val_loss: 0.2174 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 1850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8659 - f1: 0.8847 - val_loss: 0.2388 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 1851/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2424 - val_acc: 0.9666 - val_f1: 0.9667\n",
      "Epoch 1852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2264 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 1853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2393 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2300 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 1855/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3344 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2272 - val_acc: 0.9597 - val_f1: 0.9616\n",
      "Epoch 1856/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3463 - acc: 0.8613 - f1: 0.8806 - val_loss: 0.2274 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 1857/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3276 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2311 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1858/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3258 - acc: 0.8710 - f1: 0.8878 - val_loss: 0.2286 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1859/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8694 - f1: 0.8866 - val_loss: 0.2144 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 1860/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3270 - acc: 0.8706 - f1: 0.88 - 0s 15us/sample - loss: 0.3287 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2375 - val_acc: 0.9688 - val_f1: 0.9703\n",
      "Epoch 1861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8605 - f1: 0.8797 - val_loss: 0.2388 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 1862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2536 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 1863/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2269 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 1864/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2290 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 1865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2181 - val_acc: 0.9650 - val_f1: 0.9673\n",
      "Epoch 1866/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3361 - acc: 0.8665 - f1: 0.8845 - val_loss: 0.2134 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 1867/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2345 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1868/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3356 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2138 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 1869/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2459 - val_acc: 0.9669 - val_f1: 0.9686\n",
      "Epoch 1870/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3305 - acc: 0.8686 - f1: 0.8866 - val_loss: 0.2208 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1871/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8845 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 1872/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2123 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 1873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2264 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 1874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8641 - f1: 0.8823 - val_loss: 0.2191 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 1875/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2167 - val_acc: 0.9641 - val_f1: 0.9661\n",
      "Epoch 1876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2158 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2272 - val_acc: 0.9678 - val_f1: 0.9693\n",
      "Epoch 1878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2256 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 1879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2296 - val_acc: 0.9631 - val_f1: 0.9653\n",
      "Epoch 1880/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3388 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2124 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 1881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2301 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 1882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2444 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 1883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2349 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 1885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2336 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 1886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2204 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8644 - f1: 0.8831 - val_loss: 0.2462 - val_acc: 0.9663 - val_f1: 0.9675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2498 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 1889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2320 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 1890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2290 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2467 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1892/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3329 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2222 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 1893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8673 - f1: 0.8849 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 1894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3416 - acc: 0.8635 - f1: 0.8823 - val_loss: 0.2166 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 1895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2300 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1896/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2272 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1897/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2258 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 1898/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3373 - acc: 0.8645 - f1: 0.8834 - val_loss: 0.2238 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 1899/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3341 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2347 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2235 - val_acc: 0.9625 - val_f1: 0.9627\n",
      "Epoch 1901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2072 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 1902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2328 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 1903/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2314 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 1904/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2276 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 1905/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8881 - val_loss: 0.2271 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 1906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2183 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 1907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8876 - val_loss: 0.2348 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2236 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 1909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8678 - f1: 0.8853 - val_loss: 0.2656 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2340 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 1911/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2314 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1912/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3318 - acc: 0.8693 - f1: 0.8863 - val_loss: 0.2347 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 1913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8650 - f1: 0.8838 - val_loss: 0.2283 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 1914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8652 - f1: 0.8835 - val_loss: 0.2400 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 1915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2278 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 1916/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2156 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 1917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2257 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 1918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2324 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2245 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 1920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2269 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 1921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2429 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 1922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2401 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 1923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2304 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 1924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2743 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 1925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8658 - f1: 0.8843 - val_loss: 0.2212 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 1926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2235 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 1927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2378 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 1928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8658 - f1: 0.8836 - val_loss: 0.2560 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2368 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 1930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2258 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 1931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2260 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 1932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2173 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 1933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2236 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 1934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2390 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 1935/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2241 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2220 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 1937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2213 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 1938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2243 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 1939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8641 - f1: 0.8825 - val_loss: 0.2199 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 1940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2167 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 1941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8685 - f1: 0.8862 - val_loss: 0.2550 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1942/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3479 - acc: 0.8610 - f1: 0.8800 - val_loss: 0.2135 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2182 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 1944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8697 - f1: 0.8871 - val_loss: 0.2526 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 1945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2176 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 1946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2378 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 1947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2292 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 1948/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8738 - f1: 0.8901 - val_loss: 0.2562 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 1949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2273 - val_acc: 0.9584 - val_f1: 0.9604\n",
      "Epoch 1950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2253 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 1951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2157 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 1952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8711 - f1: 0.8876 - val_loss: 0.2234 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 1953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2242 - val_acc: 0.9653 - val_f1: 0.9674\n",
      "Epoch 1954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2319 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 1955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2322 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 1956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2217 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 1957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3467 - acc: 0.8600 - f1: 0.8787 - val_loss: 0.2094 - val_acc: 0.9616 - val_f1: 0.9638\n",
      "Epoch 1958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8651 - f1: 0.8832 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 1959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2305 - val_acc: 0.9697 - val_f1: 0.9710\n",
      "Epoch 1960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2727 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 1961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8642 - f1: 0.8826 - val_loss: 0.2464 - val_acc: 0.9600 - val_f1: 0.9611\n",
      "Epoch 1962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2123 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 1963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2319 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 1964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2215 - val_acc: 0.9550 - val_f1: 0.9573\n",
      "Epoch 1965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8598 - f1: 0.8798 - val_loss: 0.2575 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 1966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8750 - f1: 0.8914 - val_loss: 0.2296 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 1968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2484 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 1969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2346 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2318 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 1971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2321 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 1972/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2147 - val_acc: 0.9591 - val_f1: 0.9613\n",
      "Epoch 1973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2341 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 1974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2250 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 1975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2509 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 1976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 1977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2221 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 1978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2098 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 1979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2474 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 1980/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3420 - acc: 0.8616 - f1: 0.8810 - val_loss: 0.2141 - val_acc: 0.9575 - val_f1: 0.9602\n",
      "Epoch 1981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2267 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 1982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2060 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 1983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2195 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 1984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2563 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 1985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8739 - f1: 0.8906 - val_loss: 0.2317 - val_acc: 0.9488 - val_f1: 0.9519\n",
      "Epoch 1986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8667 - f1: 0.8844 - val_loss: 0.2335 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 1987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2323 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 1988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2297 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 1989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2333 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 1990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2213 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 1991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 1992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2173 - val_acc: 0.9613 - val_f1: 0.9634\n",
      "Epoch 1993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8661 - f1: 0.8845 - val_loss: 0.2433 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 1994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2107 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 1995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8621 - f1: 0.8811 - val_loss: 0.2651 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 1996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2279 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 1997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2408 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 1998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2340 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 1999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2315 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2241 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8719 - f1: 0.8885 - val_loss: 0.2183 - val_acc: 0.9634 - val_f1: 0.9657\n",
      "Epoch 2002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2428 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2181 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2239 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2005/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2360 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 2006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2365 - val_acc: 0.9681 - val_f1: 0.9687\n",
      "Epoch 2007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2437 - val_acc: 0.9566 - val_f1: 0.9588\n",
      "Epoch 2008/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2316 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3438 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2325 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 2010/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8669 - f1: 0.8851 - val_loss: 0.2097 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2363 - val_acc: 0.9691 - val_f1: 0.9707\n",
      "Epoch 2012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2331 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 2013/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2139 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 2014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2276 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2324 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2276 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2137 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 2018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8633 - f1: 0.8822 - val_loss: 0.2245 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2290 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2470 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 2021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2259 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2230 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 2023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2323 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8672 - f1: 0.8846 - val_loss: 0.2383 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8700 - f1: 0.8870 - val_loss: 0.2201 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8690 - f1: 0.8871 - val_loss: 0.2320 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2521 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2463 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2029/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8647 - f1: 0.8835 - val_loss: 0.2374 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8647 - f1: 0.8834 - val_loss: 0.2297 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8648 - f1: 0.8833 - val_loss: 0.2173 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8746 - f1: 0.8910 - val_loss: 0.2166 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8887 - val_loss: 0.2293 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8775 - f1: 0.8932 - val_loss: 0.2545 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2389 - val_acc: 0.9638 - val_f1: 0.9641\n",
      "Epoch 2036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2295 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2256 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2514 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2253 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 2040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9672\n",
      "Epoch 2041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2302 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2873 - val_acc: 0.9625 - val_f1: 0.9631\n",
      "Epoch 2043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8670 - f1: 0.8855 - val_loss: 0.2308 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 2044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2151 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2242 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2284 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2216 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2343 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8722 - f1: 0.8890 - val_loss: 0.2239 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2484 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 2051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2214 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2373 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2400 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2376 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2385 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8746 - f1: 0.8908 - val_loss: 0.2319 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 2057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2173 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8707 - f1: 0.8875 - val_loss: 0.2111 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 2059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8642 - f1: 0.8827 - val_loss: 0.2274 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2258 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8748 - f1: 0.8905 - val_loss: 0.2210 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 2062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8671 - f1: 0.8850 - val_loss: 0.2434 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 2063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2608 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 2064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8641 - f1: 0.8832 - val_loss: 0.2549 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2065/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3225 - acc: 0.8735 - f1: 0.89 - 0s 16us/sample - loss: 0.3211 - acc: 0.8736 - f1: 0.8898 - val_loss: 0.2286 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 2066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2267 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8674 - f1: 0.8856 - val_loss: 0.2665 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2260 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8740 - f1: 0.8907 - val_loss: 0.2352 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2169 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 2071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2519 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8654 - f1: 0.8840 - val_loss: 0.2240 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 2073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2182 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2074/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2405 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8683 - f1: 0.8863 - val_loss: 0.2267 - val_acc: 0.9616 - val_f1: 0.9632\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8715 - f1: 0.8880 - val_loss: 0.2219 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2077/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2246 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2230 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2268 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 2080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2286 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2133 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2871 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 2083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2338 - val_acc: 0.9681 - val_f1: 0.9686\n",
      "Epoch 2084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2131 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 2085/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2332 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2086/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2188 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2087/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2369 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 2088/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8684 - f1: 0.8852 - val_loss: 0.2194 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2089/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2428 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2169 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2354 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 2092/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3348 - acc: 0.8657 - f1: 0.8844 - val_loss: 0.2246 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 2093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2393 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2276 - val_acc: 0.9556 - val_f1: 0.9586\n",
      "Epoch 2095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2333 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2096/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8740 - f1: 0.8906 - val_loss: 0.2591 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2097/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2080 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 2098/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3269 - acc: 0.8708 - f1: 0.88 - 0s 16us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2090 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2099/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2242 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8740 - f1: 0.8910 - val_loss: 0.2655 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8677 - f1: 0.8850 - val_loss: 0.2380 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 2103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8697 - f1: 0.8876 - val_loss: 0.2317 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8857 - val_loss: 0.2352 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2429 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2340 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2107/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3189 - acc: 0.8755 - f1: 0.8919 - val_loss: 0.2388 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2108/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3319 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2368 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 2109/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2701 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 2110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8728 - f1: 0.8893 - val_loss: 0.2221 - val_acc: 0.9597 - val_f1: 0.9622\n",
      "Epoch 2111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8732 - f1: 0.8895 - val_loss: 0.2361 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2112/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2167 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2139 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2227 - val_acc: 0.9622 - val_f1: 0.9643\n",
      "Epoch 2116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2287 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2268 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2252 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 2119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2336 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8623 - f1: 0.8812 - val_loss: 0.2377 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 2121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8619 - f1: 0.8810 - val_loss: 0.2310 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2190 - val_acc: 0.9619 - val_f1: 0.9637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2575 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2187 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2218 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2306 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8655 - f1: 0.8838 - val_loss: 0.2328 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 2128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3473 - acc: 0.8612 - f1: 0.8805 - val_loss: 0.2193 - val_acc: 0.9597 - val_f1: 0.9617\n",
      "Epoch 2129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2244 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2130/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8717 - f1: 0.8886 - val_loss: 0.2435 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 2131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8844 - val_loss: 0.2207 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 2132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2421 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2325 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8855 - val_loss: 0.2909 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 2135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2256 - val_acc: 0.9550 - val_f1: 0.9570\n",
      "Epoch 2136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2366 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 2137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8752 - f1: 0.8913 - val_loss: 0.2339 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 2138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2186 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2270 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2140/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2495 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2695 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 2142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2453 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8707 - f1: 0.8876 - val_loss: 0.2621 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8607 - f1: 0.8802 - val_loss: 0.2322 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 2145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2510 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8632 - f1: 0.8823 - val_loss: 0.2264 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 2147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2261 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2148/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3324 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2267 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2123 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2255 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2305 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8873 - val_loss: 0.2483 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 2153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2276 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 2154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2582 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8670 - f1: 0.8854 - val_loss: 0.2435 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8658 - f1: 0.8840 - val_loss: 0.2305 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2157/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3223 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2653 - val_acc: 0.9609 - val_f1: 0.9616\n",
      "Epoch 2158/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3319 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2388 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2159/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3312 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2464 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2160/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2491 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2161/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3351 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2233 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 2162/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2248 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2163/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3144 - acc: 0.8781 - f1: 0.89 - 0s 16us/sample - loss: 0.3156 - acc: 0.8775 - f1: 0.8931 - val_loss: 0.2299 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 2164/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2398 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 2165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2213 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3470 - acc: 0.8608 - f1: 0.8800 - val_loss: 0.2232 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2396 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 2168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2240 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2181 - val_acc: 0.9603 - val_f1: 0.9621\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2279 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 2171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3165 - acc: 0.8767 - f1: 0.8927 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2320 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2173/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2422 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 2174/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3273 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2309 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 2175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2301 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2328 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 2177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8637 - f1: 0.8822 - val_loss: 0.2144 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2319 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2189 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2146 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2479 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8656 - f1: 0.8843 - val_loss: 0.2146 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2409 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 2184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8721 - f1: 0.8887 - val_loss: 0.2446 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 2185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2244 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8725 - f1: 0.8892 - val_loss: 0.2379 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8654 - f1: 0.8839 - val_loss: 0.2360 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2236 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8657 - f1: 0.8841 - val_loss: 0.2255 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8848 - val_loss: 0.2281 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 2191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2321 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2192/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2269 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2193/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8661 - f1: 0.8846 - val_loss: 0.2254 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2194/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3508 - acc: 0.8584 - f1: 0.8786 - val_loss: 0.2161 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 2195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2335 - val_acc: 0.9688 - val_f1: 0.9694\n",
      "Epoch 2196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2305 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2297 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2330 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 2199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2351 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8691 - f1: 0.8860 - val_loss: 0.2128 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8680 - f1: 0.8854 - val_loss: 0.2249 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 2202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8711 - f1: 0.8880 - val_loss: 0.2351 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8648 - f1: 0.8830 - val_loss: 0.2258 - val_acc: 0.9684 - val_f1: 0.9698\n",
      "Epoch 2204/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2299 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2205/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3313 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2270 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2206/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3298 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2346 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2372 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 2208/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2484 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 2209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2554 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 2210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2262 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2413 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2212/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3430 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2198 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 2213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2373 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2214/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2325 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3408 - acc: 0.8623 - f1: 0.8816 - val_loss: 0.2209 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2343 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2217/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2239 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2530 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2181 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8640 - f1: 0.8828 - val_loss: 0.2182 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8641 - f1: 0.8828 - val_loss: 0.2200 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8679 - f1: 0.8855 - val_loss: 0.2232 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2290 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2401 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 2226/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2230 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8869 - val_loss: 0.2389 - val_acc: 0.9678 - val_f1: 0.9683\n",
      "Epoch 2228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2409 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8640 - f1: 0.8824 - val_loss: 0.2326 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8721 - f1: 0.8888 - val_loss: 0.2351 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 2231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2505 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 2232/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2366 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 2233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2330 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2744 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 2235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8638 - f1: 0.8826 - val_loss: 0.2282 - val_acc: 0.9509 - val_f1: 0.9542\n",
      "Epoch 2236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2512 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2226 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2238/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2800 - val_acc: 0.9609 - val_f1: 0.9615\n",
      "Epoch 2239/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3283 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2471 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2353 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2314 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2700 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2243/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8711 - f1: 0.8878 - val_loss: 0.2410 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2668 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2529 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2246/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3326 - acc: 0.8674 - f1: 0.8851 - val_loss: 0.2719 - val_acc: 0.9200 - val_f1: 0.9278\n",
      "Epoch 2247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3448 - acc: 0.8612 - f1: 0.8807 - val_loss: 0.2218 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2248/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2359 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2273 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2289 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2251/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2684 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 2252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8708 - f1: 0.8873 - val_loss: 0.2557 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 2253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3371 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2220 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 2254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2308 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 2255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2329 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 2256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8672 - f1: 0.8853 - val_loss: 0.2211 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 2257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8637 - f1: 0.8825 - val_loss: 0.2238 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2105 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2251 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2504 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 2261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8754 - f1: 0.8915 - val_loss: 0.2451 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2394 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 2263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2384 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 2264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2353 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2492 - val_acc: 0.9619 - val_f1: 0.9629\n",
      "Epoch 2266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2329 - val_acc: 0.9672 - val_f1: 0.9675\n",
      "Epoch 2267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3425 - acc: 0.8621 - f1: 0.8809 - val_loss: 0.2540 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 2268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2305 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 2269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2388 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2270/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2121 - val_acc: 0.9603 - val_f1: 0.9631\n",
      "Epoch 2271/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8632 - f1: 0.8820 - val_loss: 0.2644 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 2272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8650 - f1: 0.8837 - val_loss: 0.2301 - val_acc: 0.9675 - val_f1: 0.9692\n",
      "Epoch 2273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2150 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2508 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8747 - f1: 0.8909 - val_loss: 0.2351 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2274 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2310 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2095 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8696 - f1: 0.8866 - val_loss: 0.2201 - val_acc: 0.9594 - val_f1: 0.9611\n",
      "Epoch 2280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8681 - f1: 0.8863 - val_loss: 0.2458 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2568 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2282/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2419 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2490 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2161 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8892 - val_loss: 0.2664 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8645 - f1: 0.8828 - val_loss: 0.2367 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 2287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2531 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2135 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 2289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8687 - f1: 0.8860 - val_loss: 0.2222 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2145 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 2291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8634 - f1: 0.8819 - val_loss: 0.2259 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2235 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2293/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8879 - val_loss: 0.2386 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8691 - f1: 0.8861 - val_loss: 0.2394 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2282 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2499 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2163 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 2298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8655 - f1: 0.8841 - val_loss: 0.2469 - val_acc: 0.9631 - val_f1: 0.9650\n",
      "Epoch 2299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2226 - val_acc: 0.9606 - val_f1: 0.9626\n",
      "Epoch 2300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8685 - f1: 0.8860 - val_loss: 0.2221 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2487 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8667 - f1: 0.8844 - val_loss: 0.2663 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 2303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2237 - val_acc: 0.9534 - val_f1: 0.9558\n",
      "Epoch 2304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2114 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 2305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8666 - f1: 0.8844 - val_loss: 0.2800 - val_acc: 0.9616 - val_f1: 0.9620\n",
      "Epoch 2306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2427 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 2307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2532 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8651 - f1: 0.8840 - val_loss: 0.2445 - val_acc: 0.9341 - val_f1: 0.9394\n",
      "Epoch 2309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2204 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8746 - f1: 0.8905 - val_loss: 0.2366 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 2311/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8630 - f1: 0.8819 - val_loss: 0.2150 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2598 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2259 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2287 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3382 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2204 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8844 - val_loss: 0.2365 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2327 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 2318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8889 - val_loss: 0.2445 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 2319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2364 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 2320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8854 - val_loss: 0.2420 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 2321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8766 - f1: 0.8925 - val_loss: 0.2212 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8679 - f1: 0.8858 - val_loss: 0.2321 - val_acc: 0.9547 - val_f1: 0.9570\n",
      "Epoch 2323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2265 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8758 - f1: 0.8921 - val_loss: 0.2561 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8701 - f1: 0.8868 - val_loss: 0.2156 - val_acc: 0.9553 - val_f1: 0.9579\n",
      "Epoch 2326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8696 - f1: 0.8868 - val_loss: 0.2121 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2347 - val_acc: 0.9688 - val_f1: 0.9700\n",
      "Epoch 2328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2334 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 2329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2550 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8626 - f1: 0.8815 - val_loss: 0.2242 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8637 - f1: 0.8828 - val_loss: 0.2309 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2326 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 2333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2478 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2288 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8718 - f1: 0.8884 - val_loss: 0.2451 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2472 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2350 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8679 - f1: 0.8854 - val_loss: 0.2373 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8616 - f1: 0.8809 - val_loss: 0.2437 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 2340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8711 - f1: 0.8877 - val_loss: 0.2346 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 2341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2548 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2242 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2383 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 2344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2400 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2414 - val_acc: 0.9684 - val_f1: 0.9691\n",
      "Epoch 2346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2381 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 2347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2158 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 2348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2240 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2508 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2281 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2371 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 2352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2490 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.2478 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8664 - f1: 0.8844 - val_loss: 0.2262 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2179 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 2356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2292 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 2357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2198 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 2358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8628 - f1: 0.8816 - val_loss: 0.2477 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 2359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2273 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2486 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8882 - val_loss: 0.2447 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2412 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 2363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2917 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 2364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2494 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2417 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8708 - f1: 0.8871 - val_loss: 0.2151 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2353 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2368/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8662 - f1: 0.8844 - val_loss: 0.2591 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 2369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2311 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2196 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2302 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2215 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 2373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8607 - f1: 0.8811 - val_loss: 0.2167 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2374/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8862 - val_loss: 0.2368 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 2375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2332 - val_acc: 0.9619 - val_f1: 0.9622\n",
      "Epoch 2376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2343 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2271 - val_acc: 0.9528 - val_f1: 0.9554\n",
      "Epoch 2378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2350 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2200 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8636 - f1: 0.8830 - val_loss: 0.2968 - val_acc: 0.9597 - val_f1: 0.9606\n",
      "Epoch 2381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3453 - acc: 0.8638 - f1: 0.8825 - val_loss: 0.2285 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 2382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2338 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8752 - f1: 0.8915 - val_loss: 0.2346 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 2384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2361 - val_acc: 0.9594 - val_f1: 0.9617\n",
      "Epoch 2385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2162 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3381 - acc: 0.8633 - f1: 0.8821 - val_loss: 0.2310 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2480 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 2388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2422 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8884 - val_loss: 0.2400 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 2390/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2204 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2151 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8648 - f1: 0.8835 - val_loss: 0.2252 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8657 - f1: 0.8842 - val_loss: 0.2240 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 2394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8667 - f1: 0.8843 - val_loss: 0.2157 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 2395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2365 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 2396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8626 - f1: 0.8821 - val_loss: 0.2099 - val_acc: 0.9603 - val_f1: 0.9626\n",
      "Epoch 2397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8636 - f1: 0.8824 - val_loss: 0.2124 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8639 - f1: 0.8828 - val_loss: 0.2212 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2512 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 2400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2447 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.2428 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 2402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2579 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2334 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2616 - val_acc: 0.9641 - val_f1: 0.9647\n",
      "Epoch 2405/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8901 - val_loss: 0.2259 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2300 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 2407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2496 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2459 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2270 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8642 - f1: 0.8833 - val_loss: 0.2317 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8646 - f1: 0.8828 - val_loss: 0.2323 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 2413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8678 - f1: 0.8856 - val_loss: 0.2605 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8743 - f1: 0.8909 - val_loss: 0.2479 - val_acc: 0.9644 - val_f1: 0.9646\n",
      "Epoch 2415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2183 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 2416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2323 - val_acc: 0.9488 - val_f1: 0.9519\n",
      "Epoch 2417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8591 - f1: 0.8790 - val_loss: 0.2261 - val_acc: 0.9544 - val_f1: 0.9569\n",
      "Epoch 2418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2318 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2419 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8839 - val_loss: 0.2716 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 2421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2521 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2205 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2509 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2704 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 2425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2607 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 2426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2360 - val_acc: 0.9663 - val_f1: 0.9679\n",
      "Epoch 2427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2378 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8648 - f1: 0.8834 - val_loss: 0.2534 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 2429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3512 - acc: 0.8563 - f1: 0.8768 - val_loss: 0.2392 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 2430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2332 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 2431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8661 - f1: 0.8841 - val_loss: 0.2380 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2232 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8676 - f1: 0.8850 - val_loss: 0.2160 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2351 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 2435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2418 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2676 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 2437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2373 - val_acc: 0.9675 - val_f1: 0.9681\n",
      "Epoch 2438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2188 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3096 - acc: 0.8813 - f1: 0.8962 - val_loss: 0.2372 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2185 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 2441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2297 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2448 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 2443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2604 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 2444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2291 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 2446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2414 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2300 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3472 - acc: 0.8595 - f1: 0.8791 - val_loss: 0.2288 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8672 - f1: 0.8851 - val_loss: 0.2337 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 2450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3390 - acc: 0.8639 - f1: 0.8830 - val_loss: 0.2286 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8681 - f1: 0.8855 - val_loss: 0.2447 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8875 - val_loss: 0.2825 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 2453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2189 - val_acc: 0.9575 - val_f1: 0.9601\n",
      "Epoch 2454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2438 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2420 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2442 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 2458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8850 - val_loss: 0.2293 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 2459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2443 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2164 - val_acc: 0.9625 - val_f1: 0.9646\n",
      "Epoch 2461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2098 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8855 - val_loss: 0.2464 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8675 - f1: 0.8848 - val_loss: 0.2221 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8689 - f1: 0.8869 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8895 - val_loss: 0.2477 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8696 - f1: 0.8871 - val_loss: 0.2272 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3135 - acc: 0.8789 - f1: 0.8941 - val_loss: 0.2600 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2342 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 2470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2197 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2236 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8658 - f1: 0.8838 - val_loss: 0.2232 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2243 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 2474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2289 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2377 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8606 - f1: 0.8799 - val_loss: 0.2384 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 2478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8822 - val_loss: 0.2614 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8654 - f1: 0.8836 - val_loss: 0.2462 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 2480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2331 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 2481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2349 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8739 - f1: 0.8901 - val_loss: 0.2194 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3461 - acc: 0.8600 - f1: 0.8793 - val_loss: 0.2188 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2327 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2404 - val_acc: 0.9669 - val_f1: 0.9672\n",
      "Epoch 2486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2264 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8761 - f1: 0.8922 - val_loss: 0.2507 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 2488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2405 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 2489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2242 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8688 - f1: 0.8860 - val_loss: 0.2310 - val_acc: 0.9566 - val_f1: 0.9587\n",
      "Epoch 2491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2366 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2295 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 2493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2459 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2366 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 2495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2622 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8651 - f1: 0.8838 - val_loss: 0.2379 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2455 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2789 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 2499/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8665 - f1: 0.8848 - val_loss: 0.2169 - val_acc: 0.9619 - val_f1: 0.9642\n",
      "Epoch 2500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8680 - f1: 0.8863 - val_loss: 0.2415 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2130 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3366 - acc: 0.8642 - f1: 0.8829 - val_loss: 0.2279 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2503/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2311 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2351 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2300 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 2506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8665 - f1: 0.8844 - val_loss: 0.2172 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2483 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8717 - f1: 0.8887 - val_loss: 0.2367 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2887 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 2510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3124 - acc: 0.8786 - f1: 0.8941 - val_loss: 0.2596 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2264 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2184 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 2513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3364 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2367 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2502 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 2515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2357 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 2516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 2517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8668 - f1: 0.8849 - val_loss: 0.2430 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 2518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2228 - val_acc: 0.9563 - val_f1: 0.9590\n",
      "Epoch 2519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2197 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2469 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2337 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2270 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2458 - val_acc: 0.9684 - val_f1: 0.9694\n",
      "Epoch 2524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2339 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 2525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2348 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2263 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2504 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2276 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2315 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 2530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2495 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 2531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2391 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2472 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 2533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8861 - val_loss: 0.2324 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 2534/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2348 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2387 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 2536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2352 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 2537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2624 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 2538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2361 - val_acc: 0.9663 - val_f1: 0.9679\n",
      "Epoch 2539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2384 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 2540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8672 - f1: 0.8854 - val_loss: 0.2488 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 2541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3362 - acc: 0.8646 - f1: 0.8834 - val_loss: 0.2261 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8901 - val_loss: 0.2374 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8762 - f1: 0.8917 - val_loss: 0.2388 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 2544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2303 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 2545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8620 - f1: 0.8810 - val_loss: 0.2184 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2238 - val_acc: 0.9538 - val_f1: 0.9567\n",
      "Epoch 2547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2373 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2342 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 2549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2481 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2178 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2667 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 2553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2350 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2450 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 2555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2435 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8854 - val_loss: 0.2437 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2338 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2261 - val_acc: 0.9569 - val_f1: 0.9592\n",
      "Epoch 2559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2314 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 2560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2264 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2421 - val_acc: 0.9688 - val_f1: 0.9703\n",
      "Epoch 2562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8738 - f1: 0.8900 - val_loss: 0.2299 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2369 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2341 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 2565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2571 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2185 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2125 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2301 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 2569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2344 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8755 - f1: 0.8916 - val_loss: 0.2139 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 2571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8652 - f1: 0.8839 - val_loss: 0.2182 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8709 - f1: 0.8877 - val_loss: 0.2507 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2341 - val_acc: 0.9653 - val_f1: 0.9673\n",
      "Epoch 2574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2333 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 2575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8652 - f1: 0.8833 - val_loss: 0.2160 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2290 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2386 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8710 - f1: 0.8879 - val_loss: 0.2947 - val_acc: 0.9616 - val_f1: 0.9617\n",
      "Epoch 2579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2264 - val_acc: 0.9538 - val_f1: 0.9565\n",
      "Epoch 2580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2281 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2968 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2262 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 2583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2234 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 2584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2592 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2080 - val_acc: 0.9581 - val_f1: 0.9604\n",
      "Epoch 2586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 2587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2241 - val_acc: 0.9594 - val_f1: 0.9610\n",
      "Epoch 2588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3355 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2188 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2379 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8884 - val_loss: 0.2306 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8764 - f1: 0.8921 - val_loss: 0.2408 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8643 - f1: 0.8831 - val_loss: 0.2298 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2593/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8723 - f1: 0.8886 - val_loss: 0.2276 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 2594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2243 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2378 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2260 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 2597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2398 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8752 - f1: 0.8918 - val_loss: 0.2572 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8660 - f1: 0.8841 - val_loss: 0.2337 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2387 - val_acc: 0.9594 - val_f1: 0.9609\n",
      "Epoch 2601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2708 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 2602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2622 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 2603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3385 - acc: 0.8640 - f1: 0.8829 - val_loss: 0.2252 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 2604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2490 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8724 - f1: 0.8897 - val_loss: 0.2393 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8757 - f1: 0.8911 - val_loss: 0.2363 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2392 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8718 - f1: 0.8884 - val_loss: 0.2381 - val_acc: 0.9656 - val_f1: 0.9676\n",
      "Epoch 2609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2506 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2374 - val_acc: 0.9616 - val_f1: 0.9636\n",
      "Epoch 2611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2484 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2312 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8729 - f1: 0.8893 - val_loss: 0.2357 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 2614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2480 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 2615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2621 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 2616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2496 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 2617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2294 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 2618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3498 - acc: 0.8602 - f1: 0.8796 - val_loss: 0.2352 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 2619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8670 - f1: 0.8847 - val_loss: 0.2230 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8633 - f1: 0.8825 - val_loss: 0.2511 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2772 - val_acc: 0.9591 - val_f1: 0.9603\n",
      "Epoch 2622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8648 - f1: 0.8831 - val_loss: 0.2517 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 2623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8637 - f1: 0.8824 - val_loss: 0.2290 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2248 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 2625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2276 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 2626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2382 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2552 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 2628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2332 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2482 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 2630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8751 - f1: 0.8916 - val_loss: 0.2232 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 2631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8657 - f1: 0.8841 - val_loss: 0.2466 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2375 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8725 - f1: 0.8899 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8668 - f1: 0.8850 - val_loss: 0.2519 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2182 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2365 - val_acc: 0.9600 - val_f1: 0.9613\n",
      "Epoch 2637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2202 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2329 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2505 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2273 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8744 - f1: 0.8911 - val_loss: 0.2448 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 2643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8654 - f1: 0.8838 - val_loss: 0.2845 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 2644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2348 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 2645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2344 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2326 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 2647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2279 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2625 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 2649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8674 - f1: 0.8857 - val_loss: 0.2200 - val_acc: 0.9578 - val_f1: 0.9596\n",
      "Epoch 2650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8634 - f1: 0.8822 - val_loss: 0.2270 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2313 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3360 - acc: 0.8646 - f1: 0.8830 - val_loss: 0.2439 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2337 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 2654/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2306 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8674 - f1: 0.8851 - val_loss: 0.2415 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 2656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2486 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2343 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 2658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2360 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2631 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8716 - f1: 0.8883 - val_loss: 0.2362 - val_acc: 0.9694 - val_f1: 0.9710\n",
      "Epoch 2661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8747 - f1: 0.8917 - val_loss: 0.2805 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 2662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8658 - f1: 0.8841 - val_loss: 0.2131 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 2663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8706 - f1: 0.8874 - val_loss: 0.2291 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8683 - f1: 0.8860 - val_loss: 0.2396 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8652 - f1: 0.8836 - val_loss: 0.2195 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 2666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2466 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2375 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 2668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2298 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 2669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8753 - f1: 0.8916 - val_loss: 0.2317 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 2670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2875 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2236 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8651 - f1: 0.8833 - val_loss: 0.2510 - val_acc: 0.9597 - val_f1: 0.9612\n",
      "Epoch 2673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2494 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 2674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2615 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 2675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2348 - val_acc: 0.9553 - val_f1: 0.9574\n",
      "Epoch 2676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8685 - f1: 0.8857 - val_loss: 0.2395 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2411 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2307 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2355 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 2680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2596 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.3258 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 2682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2284 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 2683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8650 - f1: 0.8840 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2527 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2212 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2313 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 2687/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8689 - f1: 0.8863 - val_loss: 0.2531 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 2688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2293 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 2689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2184 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 2690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.2368 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2384 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2394 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 2693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2384 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8748 - f1: 0.8913 - val_loss: 0.2364 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 2695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2239 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 2696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2285 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8723 - f1: 0.8887 - val_loss: 0.2361 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8680 - f1: 0.8852 - val_loss: 0.2421 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 2701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2364 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2197 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2227 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 2704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2225 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8693 - f1: 0.8865 - val_loss: 0.2520 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8711 - f1: 0.8884 - val_loss: 0.2350 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 2707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2333 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2396 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8738 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 2710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2546 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 2711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2184 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2712/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3307 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2357 - val_acc: 0.9594 - val_f1: 0.9601\n",
      "Epoch 2713/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3354 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2283 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 2714/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2395 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 2715/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3335 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2313 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8697 - f1: 0.8873 - val_loss: 0.2287 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 2717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2498 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2718/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2350 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 2719/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2397 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 2720/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3357 - acc: 0.8673 - f1: 0.88 - 0s 16us/sample - loss: 0.3327 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2350 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 2721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2188 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2592 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 2723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2589 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 2724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2484 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2293 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 2726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8732 - f1: 0.8903 - val_loss: 0.2396 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 2727/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2402 - val_acc: 0.9678 - val_f1: 0.9682\n",
      "Epoch 2728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8651 - f1: 0.8840 - val_loss: 0.2796 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8844 - val_loss: 0.2424 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 2730/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3179 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2329 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2211 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 2732/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3242 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2240 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2486 - val_acc: 0.9678 - val_f1: 0.9692\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8766 - f1: 0.8923 - val_loss: 0.2609 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2309 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 2736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8886 - val_loss: 0.2255 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2193 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8649 - f1: 0.8836 - val_loss: 0.2478 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 2739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2524 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8689 - f1: 0.8864 - val_loss: 0.2485 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 2741/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2307 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8701 - f1: 0.8877 - val_loss: 0.2374 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2254 - val_acc: 0.9563 - val_f1: 0.9588\n",
      "Epoch 2744/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3392 - acc: 0.8643 - f1: 0.8828 - val_loss: 0.2487 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8688 - f1: 0.8861 - val_loss: 0.2432 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 2746/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2480 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 2747/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3322 - acc: 0.8686 - f1: 0.8858 - val_loss: 0.2224 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 2748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2749/5000\n",
      "12800/12800 [==============================] - 0s 17us/sample - loss: 0.3236 - acc: 0.8719 - f1: 0.8894 - val_loss: 0.2335 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 2750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2155 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 2751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2130 - val_acc: 0.9597 - val_f1: 0.9619\n",
      "Epoch 2752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2260 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 2753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2470 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3370 - acc: 0.8666 - f1: 0.8843 - val_loss: 0.2837 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2202 - val_acc: 0.9606 - val_f1: 0.9627\n",
      "Epoch 2756/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3289 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2215 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 2757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8711 - f1: 0.8879 - val_loss: 0.2252 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 2758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2410 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2759/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.3001 - val_acc: 0.9616 - val_f1: 0.9622\n",
      "Epoch 2760/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2465 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 2761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2532 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 2762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2242 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 2763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8710 - f1: 0.8880 - val_loss: 0.2299 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 2764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2670 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 2765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2309 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 2766/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2328 - val_acc: 0.9609 - val_f1: 0.9633\n",
      "Epoch 2767/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3310 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2219 - val_acc: 0.9553 - val_f1: 0.9578\n",
      "Epoch 2768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8616 - f1: 0.8807 - val_loss: 0.2215 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 2769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2105 - val_acc: 0.9619 - val_f1: 0.9640\n",
      "Epoch 2770/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8865 - val_loss: 0.2296 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2771/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2727 - val_acc: 0.9647 - val_f1: 0.9650\n",
      "Epoch 2772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2203 - val_acc: 0.9631 - val_f1: 0.9651\n",
      "Epoch 2773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2504 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2774/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2460 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 2775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2345 - val_acc: 0.9666 - val_f1: 0.9684\n",
      "Epoch 2776/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2773 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 2777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2397 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2778/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3374 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2301 - val_acc: 0.9584 - val_f1: 0.9605\n",
      "Epoch 2779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2171 - val_acc: 0.9603 - val_f1: 0.9617\n",
      "Epoch 2780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2119 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 2781/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8673 - f1: 0.8847 - val_loss: 0.2284 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 2782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2271 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 2783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2650 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2611 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 2785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8682 - f1: 0.8858 - val_loss: 0.2269 - val_acc: 0.9578 - val_f1: 0.9599\n",
      "Epoch 2786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2258 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 2787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8735 - f1: 0.8905 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 2788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2282 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2267 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2416 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 2791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2521 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2618 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 2793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8730 - f1: 0.8894 - val_loss: 0.2503 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8700 - f1: 0.8879 - val_loss: 0.2264 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 2795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8709 - f1: 0.8878 - val_loss: 0.2562 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2358 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 2797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2254 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 2798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8814 - val_loss: 0.2255 - val_acc: 0.9684 - val_f1: 0.9692\n",
      "Epoch 2799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8639 - f1: 0.8826 - val_loss: 0.2176 - val_acc: 0.9578 - val_f1: 0.9603\n",
      "Epoch 2800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2307 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2376 - val_acc: 0.9678 - val_f1: 0.9695\n",
      "Epoch 2802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8728 - f1: 0.8898 - val_loss: 0.2323 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 2803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2271 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 2804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8663 - f1: 0.8842 - val_loss: 0.2458 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2255 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 2806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8684 - f1: 0.8858 - val_loss: 0.2200 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8686 - f1: 0.8859 - val_loss: 0.2240 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 2808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2378 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 2809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2304 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 2810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2122 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 2812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2198 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 2813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2229 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2958 - val_acc: 0.9647 - val_f1: 0.9647\n",
      "Epoch 2815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2297 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 2816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8667 - f1: 0.8852 - val_loss: 0.2530 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 2817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2354 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 2818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8760 - f1: 0.8920 - val_loss: 0.2212 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 2819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2202 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 2820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2433 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 2821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2444 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 2822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8764 - f1: 0.8923 - val_loss: 0.2264 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 2823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8868 - val_loss: 0.2293 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 2824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8896 - val_loss: 0.2310 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2347 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 2826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8731 - f1: 0.8895 - val_loss: 0.2458 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 2827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2292 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2484 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8723 - f1: 0.8887 - val_loss: 0.2579 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 2830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2336 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8736 - f1: 0.8899 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 2833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8635 - f1: 0.8826 - val_loss: 0.2506 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 2834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2472 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 2835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.3032 - val_acc: 0.9603 - val_f1: 0.9611\n",
      "Epoch 2836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8649 - f1: 0.8835 - val_loss: 0.2563 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 2837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2284 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2188 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 2839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2409 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8666 - f1: 0.8857 - val_loss: 0.2273 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 2841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2514 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 2843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2190 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 2844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2273 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 2845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2435 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8615 - f1: 0.8811 - val_loss: 0.2375 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2647 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 2848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8758 - f1: 0.8921 - val_loss: 0.2299 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 2849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2318 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 2850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8666 - f1: 0.8849 - val_loss: 0.2325 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 2851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2499 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8699 - f1: 0.8879 - val_loss: 0.2583 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2446 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 2854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2371 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2251 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 2856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2461 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 2857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2405 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 2858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2656 - val_acc: 0.9544 - val_f1: 0.9560\n",
      "Epoch 2859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8661 - f1: 0.8840 - val_loss: 0.2322 - val_acc: 0.9688 - val_f1: 0.9697\n",
      "Epoch 2860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8645 - f1: 0.8833 - val_loss: 0.2216 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 2861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2293 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2447 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2505 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 2864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2382 - val_acc: 0.9688 - val_f1: 0.9695\n",
      "Epoch 2865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8723 - f1: 0.8888 - val_loss: 0.2473 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 2866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3119 - acc: 0.8793 - f1: 0.8946 - val_loss: 0.2499 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2628 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 2868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2377 - val_acc: 0.9656 - val_f1: 0.9658\n",
      "Epoch 2869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2563 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 2870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2436 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 2871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2508 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2404 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8725 - f1: 0.8893 - val_loss: 0.2371 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 2874/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3342 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2364 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2875/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2261 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2485 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 2877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 2878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3422 - acc: 0.8618 - f1: 0.8808 - val_loss: 0.2188 - val_acc: 0.9569 - val_f1: 0.9590\n",
      "Epoch 2879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8692 - f1: 0.8872 - val_loss: 0.2458 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 2880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8706 - f1: 0.8883 - val_loss: 0.2534 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 2881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2477 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 2882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2266 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 2883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2366 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8703 - f1: 0.8874 - val_loss: 0.2462 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 2885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2815 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2469 - val_acc: 0.9613 - val_f1: 0.9628\n",
      "Epoch 2887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8758 - f1: 0.8919 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9678\n",
      "Epoch 2888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8722 - f1: 0.8889 - val_loss: 0.2454 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 2889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2509 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 2890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2517 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2312 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 2892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2825 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2357 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 2894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8659 - f1: 0.8840 - val_loss: 0.2744 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 2895/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8850 - val_loss: 0.2454 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2386 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8695 - f1: 0.8871 - val_loss: 0.2337 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 2898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2307 - val_acc: 0.9591 - val_f1: 0.9612\n",
      "Epoch 2899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2583 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 2900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2731 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 2901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2655 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2365 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 2903/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3249 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2441 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 2904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2317 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 2905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8742 - f1: 0.8908 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 2906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2488 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 2907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8699 - f1: 0.8877 - val_loss: 0.2472 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 2908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8644 - f1: 0.8827 - val_loss: 0.2310 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 2909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2299 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 2910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2210 - val_acc: 0.9581 - val_f1: 0.9603\n",
      "Epoch 2911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2395 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 2912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8685 - f1: 0.8869 - val_loss: 0.2310 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 2913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 2914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2465 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 2915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2283 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 2916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2591 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 2917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3378 - acc: 0.8645 - f1: 0.8832 - val_loss: 0.2464 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 2918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8699 - f1: 0.8870 - val_loss: 0.2281 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 2919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2686 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 2920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2388 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 2921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2450 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 2922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2303 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 2923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2558 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3411 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2366 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 2925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2345 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 2926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2367 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 2927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3410 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2263 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 2928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2442 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 2929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2794 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 2930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8679 - f1: 0.8861 - val_loss: 0.2317 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 2931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2294 - val_acc: 0.9644 - val_f1: 0.9664\n",
      "Epoch 2932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2526 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 2933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8922 - val_loss: 0.2494 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 2934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8751 - f1: 0.8918 - val_loss: 0.2266 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 2935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2174 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 2936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8766 - f1: 0.8924 - val_loss: 0.2399 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 2937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2609 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2415 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 2939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2477 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 2940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8660 - f1: 0.8844 - val_loss: 0.2320 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 2941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8645 - f1: 0.8829 - val_loss: 0.2869 - val_acc: 0.9622 - val_f1: 0.9629\n",
      "Epoch 2942/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2367 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 2943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2302 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 2944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8676 - f1: 0.8852 - val_loss: 0.2276 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 2945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2838 - val_acc: 0.9634 - val_f1: 0.9637\n",
      "Epoch 2946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2597 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8688 - f1: 0.8862 - val_loss: 0.2469 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 2948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2518 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 2949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2487 - val_acc: 0.9366 - val_f1: 0.9407\n",
      "Epoch 2950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3406 - acc: 0.8621 - f1: 0.8813 - val_loss: 0.2293 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 2951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8863 - val_loss: 0.2511 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 2952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2380 - val_acc: 0.9616 - val_f1: 0.9637\n",
      "Epoch 2953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2724 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 2954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2571 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 2955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8682 - f1: 0.8856 - val_loss: 0.2286 - val_acc: 0.9613 - val_f1: 0.9623\n",
      "Epoch 2956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2247 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2281 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 2958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2282 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 2959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2278 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 2960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2498 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 2961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2490 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 2962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2471 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 2963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2437 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 2964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2607 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 2965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2539 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 2966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 2967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2542 - val_acc: 0.9681 - val_f1: 0.9696\n",
      "Epoch 2968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2566 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 2969/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2427 - val_acc: 0.9531 - val_f1: 0.9555\n",
      "Epoch 2970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2331 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 2971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2598 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 2972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2481 - val_acc: 0.9631 - val_f1: 0.9639\n",
      "Epoch 2973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2511 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 2974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2635 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 2975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2400 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 2976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2558 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 2977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2577 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 2978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8873 - val_loss: 0.2363 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 2979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2443 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 2980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2462 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 2981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2397 - val_acc: 0.9625 - val_f1: 0.9644\n",
      "Epoch 2982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2346 - val_acc: 0.9675 - val_f1: 0.9691\n",
      "Epoch 2983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3401 - acc: 0.8648 - f1: 0.8837 - val_loss: 0.2388 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 2984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8679 - f1: 0.8852 - val_loss: 0.2458 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 2985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2420 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 2986/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3277 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2169 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 2987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2179 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 2988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8856 - val_loss: 0.2320 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 2989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8739 - f1: 0.8902 - val_loss: 0.2808 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 2990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2199 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 2991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2513 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 2992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2129 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 2993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2320 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 2994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8718 - f1: 0.8885 - val_loss: 0.2654 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 2995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2439 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 2996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2381 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 2997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3427 - acc: 0.8623 - f1: 0.8815 - val_loss: 0.2265 - val_acc: 0.9669 - val_f1: 0.9684\n",
      "Epoch 2998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2663 - val_acc: 0.9616 - val_f1: 0.9626\n",
      "Epoch 2999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2264 - val_acc: 0.9591 - val_f1: 0.9609\n",
      "Epoch 3000/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8677 - f1: 0.8852 - val_loss: 0.2377 - val_acc: 0.9666 - val_f1: 0.9682\n",
      "Epoch 3001/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3182 - acc: 0.8753 - f1: 0.8910 - val_loss: 0.2490 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3002/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3323 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2706 - val_acc: 0.9631 - val_f1: 0.9637\n",
      "Epoch 3003/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2269 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 3004/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3486 - acc: 0.8616 - f1: 0.8811 - val_loss: 0.2519 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3005/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2752 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2296 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8742 - f1: 0.8908 - val_loss: 0.2381 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3008/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3168 - acc: 0.8760 - f1: 0.8921 - val_loss: 0.2376 - val_acc: 0.9606 - val_f1: 0.9623\n",
      "Epoch 3009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8673 - f1: 0.8856 - val_loss: 0.2502 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3010/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2213 - val_acc: 0.9594 - val_f1: 0.9616\n",
      "Epoch 3011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2358 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 3012/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2317 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3013/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2304 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3014/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2487 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 3015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2464 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2454 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 3017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2449 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8859 - val_loss: 0.2408 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8703 - f1: 0.8873 - val_loss: 0.2276 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2673 - val_acc: 0.9622 - val_f1: 0.9630\n",
      "Epoch 3021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2330 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2391 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.3286 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 3024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8639 - f1: 0.8822 - val_loss: 0.2289 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2264 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2474 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2287 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2296 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8728 - f1: 0.8897 - val_loss: 0.2693 - val_acc: 0.9541 - val_f1: 0.9561\n",
      "Epoch 3030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2468 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3031/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2461 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2401 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2625 - val_acc: 0.9609 - val_f1: 0.9622\n",
      "Epoch 3034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2207 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3035/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3036/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8912 - val_loss: 0.2166 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3037/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8690 - f1: 0.8865 - val_loss: 0.2451 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3038/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8659 - f1: 0.8846 - val_loss: 0.2596 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2609 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2340 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2122 - val_acc: 0.9588 - val_f1: 0.9607\n",
      "Epoch 3042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3426 - acc: 0.8637 - f1: 0.8826 - val_loss: 0.2328 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2829 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 3044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2791 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 3045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2379 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3046/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3304 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2330 - val_acc: 0.9675 - val_f1: 0.9688\n",
      "Epoch 3047/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8899 - val_loss: 0.2304 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3048/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3183 - acc: 0.8754 - f1: 0.8919 - val_loss: 0.2376 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 3049/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2476 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3050/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3257 - acc: 0.8713 - f1: 0.8884 - val_loss: 0.2261 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3051/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3377 - acc: 0.8642 - f1: 0.8828 - val_loss: 0.2218 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 3052/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8853 - val_loss: 0.2439 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 3053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2710 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2669 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3055/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2334 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3056/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8675 - f1: 0.8860 - val_loss: 0.2276 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3057/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2407 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8724 - f1: 0.8893 - val_loss: 0.2467 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2318 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8678 - f1: 0.8862 - val_loss: 0.2423 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8711 - f1: 0.8878 - val_loss: 0.2220 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 3063/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2439 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3064/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3173 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2410 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2338 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2386 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3067/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2417 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2412 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3069/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8743 - f1: 0.8905 - val_loss: 0.2485 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2506 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3071/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8681 - f1: 0.8860 - val_loss: 0.2582 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2502 - val_acc: 0.9588 - val_f1: 0.9600\n",
      "Epoch 3073/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2504 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3074/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8635 - f1: 0.8823 - val_loss: 0.2749 - val_acc: 0.9663 - val_f1: 0.9664\n",
      "Epoch 3075/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2290 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3076/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2297 - val_acc: 0.9656 - val_f1: 0.9675\n",
      "Epoch 3077/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2413 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3078/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2840 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 3079/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2904 - val_acc: 0.9600 - val_f1: 0.9609\n",
      "Epoch 3080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3446 - acc: 0.8624 - f1: 0.8816 - val_loss: 0.2917 - val_acc: 0.9603 - val_f1: 0.9602\n",
      "Epoch 3081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2404 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3082/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2486 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3083/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8772 - f1: 0.8930 - val_loss: 0.2539 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2652 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3085/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2306 - val_acc: 0.9694 - val_f1: 0.9701\n",
      "Epoch 3086/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3333 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2301 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3087/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2647 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3088/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3273 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2386 - val_acc: 0.9709 - val_f1: 0.9722\n",
      "Epoch 3089/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2466 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2709 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 3091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8714 - f1: 0.8880 - val_loss: 0.2239 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 3092/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2485 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2537 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2374 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3095/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2270 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 3096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2231 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3097/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2820 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 3098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8868 - val_loss: 0.2486 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2212 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2221 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 3101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8657 - f1: 0.8837 - val_loss: 0.2645 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2340 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8735 - f1: 0.8901 - val_loss: 0.2288 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8655 - f1: 0.8837 - val_loss: 0.2464 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8669 - f1: 0.8853 - val_loss: 0.2321 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2366 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2351 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2317 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8675 - f1: 0.8858 - val_loss: 0.2453 - val_acc: 0.9609 - val_f1: 0.9619\n",
      "Epoch 3110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2339 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8725 - f1: 0.8889 - val_loss: 0.2361 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 3112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2175 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 3113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2289 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2458 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 3115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2267 - val_acc: 0.9638 - val_f1: 0.9659\n",
      "Epoch 3116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8719 - f1: 0.8892 - val_loss: 0.2506 - val_acc: 0.9625 - val_f1: 0.9628\n",
      "Epoch 3117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2561 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2358 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 3119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2344 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2363 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8672 - f1: 0.8853 - val_loss: 0.2366 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 3122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3419 - acc: 0.8632 - f1: 0.8820 - val_loss: 0.2363 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 3123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2589 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2527 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3387 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2501 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 3127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2426 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2302 - val_acc: 0.9578 - val_f1: 0.9602\n",
      "Epoch 3129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2257 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 3130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2429 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8656 - f1: 0.8845 - val_loss: 0.2691 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2570 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8709 - f1: 0.8878 - val_loss: 0.2218 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2452 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 3135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8764 - f1: 0.8928 - val_loss: 0.2474 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2253 - val_acc: 0.9572 - val_f1: 0.9590\n",
      "Epoch 3137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2274 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 3138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2374 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8693 - f1: 0.8866 - val_loss: 0.2279 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2241 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8852 - val_loss: 0.2268 - val_acc: 0.9594 - val_f1: 0.9612\n",
      "Epoch 3142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8697 - f1: 0.8869 - val_loss: 0.2268 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2394 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2316 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2655 - val_acc: 0.9631 - val_f1: 0.9635\n",
      "Epoch 3146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8704 - f1: 0.8880 - val_loss: 0.2292 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 3147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2171 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8670 - f1: 0.8845 - val_loss: 0.2187 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 3149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2392 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 3150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2510 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2424 - val_acc: 0.9647 - val_f1: 0.9665\n",
      "Epoch 3152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3436 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2129 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 3153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8667 - f1: 0.8848 - val_loss: 0.2398 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8754 - f1: 0.8919 - val_loss: 0.2745 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2413 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2255 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3157/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2291 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2573 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8740 - f1: 0.8910 - val_loss: 0.2742 - val_acc: 0.9613 - val_f1: 0.9622\n",
      "Epoch 3160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3395 - acc: 0.8652 - f1: 0.8831 - val_loss: 0.2449 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2393 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2656 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2504 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2468 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8678 - f1: 0.8862 - val_loss: 0.2509 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2654 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 3167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2659 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8692 - f1: 0.8870 - val_loss: 0.2284 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2637 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8668 - f1: 0.8847 - val_loss: 0.2267 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2281 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2707 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2472 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.2506 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2533 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8627 - f1: 0.8821 - val_loss: 0.2392 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 3178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2526 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2507 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3149 - acc: 0.8786 - f1: 0.8944 - val_loss: 0.2459 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8636 - f1: 0.8825 - val_loss: 0.2292 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2348 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2348 - val_acc: 0.9672 - val_f1: 0.9688\n",
      "Epoch 3184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2444 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2713 - val_acc: 0.9653 - val_f1: 0.9658\n",
      "Epoch 3186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8631 - f1: 0.8819 - val_loss: 0.2767 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2417 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 3188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8731 - f1: 0.8894 - val_loss: 0.2418 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8664 - f1: 0.8848 - val_loss: 0.2606 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 3190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8732 - f1: 0.8896 - val_loss: 0.2490 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3191/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2272 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8773 - f1: 0.8927 - val_loss: 0.2336 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2456 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2427 - val_acc: 0.9697 - val_f1: 0.9703\n",
      "Epoch 3195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2495 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 3196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2421 - val_acc: 0.9694 - val_f1: 0.9710\n",
      "Epoch 3197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2122 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8673 - f1: 0.8854 - val_loss: 0.2372 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8749 - f1: 0.8909 - val_loss: 0.2665 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2565 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8688 - f1: 0.8867 - val_loss: 0.2423 - val_acc: 0.9656 - val_f1: 0.9660\n",
      "Epoch 3202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8670 - f1: 0.8851 - val_loss: 0.2524 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2500 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2643 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2425 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 3206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2498 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 3207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2397 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2247 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8763 - f1: 0.8928 - val_loss: 0.2463 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2293 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.2589 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2529 - val_acc: 0.9666 - val_f1: 0.9669\n",
      "Epoch 3213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8691 - f1: 0.8873 - val_loss: 0.2311 - val_acc: 0.9541 - val_f1: 0.9571\n",
      "Epoch 3214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8664 - f1: 0.8842 - val_loss: 0.2193 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 3215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2542 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8872 - val_loss: 0.2392 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2424 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2569 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2338 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2266 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8867 - val_loss: 0.2445 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3222/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3289 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2561 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3223/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2354 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 3224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2558 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 3225/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3164 - acc: 0.8765 - f1: 0.8928 - val_loss: 0.2526 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3226/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2211 - val_acc: 0.9616 - val_f1: 0.9640\n",
      "Epoch 3227/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2265 - val_acc: 0.9575 - val_f1: 0.9596\n",
      "Epoch 3228/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3268 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2349 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3229/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8740 - f1: 0.8906 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3230/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2355 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3231/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8714 - f1: 0.8881 - val_loss: 0.2850 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8678 - f1: 0.8851 - val_loss: 0.2251 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2291 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2439 - val_acc: 0.9669 - val_f1: 0.9673\n",
      "Epoch 3235/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8868 - val_loss: 0.2200 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2361 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3237/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2444 - val_acc: 0.9638 - val_f1: 0.9640\n",
      "Epoch 3238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2223 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3239/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2227 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3240/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3205 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2359 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 3241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2415 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8706 - f1: 0.8881 - val_loss: 0.2312 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 3243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2198 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2379 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8858 - val_loss: 0.2165 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2627 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3247/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2278 - val_acc: 0.9547 - val_f1: 0.9570\n",
      "Epoch 3248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2307 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 3249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2453 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2205 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3251/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8691 - f1: 0.8871 - val_loss: 0.2364 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 3252/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8685 - f1: 0.8857 - val_loss: 0.2288 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3253/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8736 - f1: 0.8903 - val_loss: 0.2406 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2401 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2280 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 3256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8715 - f1: 0.8883 - val_loss: 0.2755 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2367 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3258/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8725 - f1: 0.8899 - val_loss: 0.2589 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3259/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2285 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8698 - f1: 0.8876 - val_loss: 0.2340 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3261/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2386 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 3262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2491 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3263/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8882 - val_loss: 0.3088 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2616 - val_acc: 0.9653 - val_f1: 0.9657\n",
      "Epoch 3265/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8698 - f1: 0.8867 - val_loss: 0.2501 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2607 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3267/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2408 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3268/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8677 - f1: 0.8853 - val_loss: 0.2218 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 3269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3399 - acc: 0.8625 - f1: 0.8815 - val_loss: 0.2655 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3270/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3260 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2388 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3271/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3428 - acc: 0.8616 - f1: 0.8812 - val_loss: 0.2577 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 3272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8762 - f1: 0.8918 - val_loss: 0.2508 - val_acc: 0.9650 - val_f1: 0.9669\n",
      "Epoch 3273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8692 - f1: 0.8872 - val_loss: 0.2175 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2652 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 3276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8702 - f1: 0.8871 - val_loss: 0.2464 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8671 - f1: 0.8852 - val_loss: 0.2673 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3278/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2408 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2301 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 3280/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2469 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2183 - val_acc: 0.9628 - val_f1: 0.9646\n",
      "Epoch 3282/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3266 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2333 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 3283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2529 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2370 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 3285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3435 - acc: 0.8626 - f1: 0.8816 - val_loss: 0.2311 - val_acc: 0.9572 - val_f1: 0.9587\n",
      "Epoch 3286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2546 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 3287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2743 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3288/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2717 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3146 - acc: 0.8781 - f1: 0.8937 - val_loss: 0.2486 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2517 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 3291/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2490 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3292/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2805 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3293/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2564 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 3294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8682 - f1: 0.8857 - val_loss: 0.2501 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3295/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8656 - f1: 0.8838 - val_loss: 0.2389 - val_acc: 0.9663 - val_f1: 0.9685\n",
      "Epoch 3296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2600 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2268 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 3298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2456 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2396 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8673 - f1: 0.8851 - val_loss: 0.2496 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2276 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3302/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2476 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3303/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2444 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8746 - f1: 0.8908 - val_loss: 0.2713 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2694 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 3306/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2367 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 3307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2563 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8706 - f1: 0.8879 - val_loss: 0.2388 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3309/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8656 - f1: 0.8842 - val_loss: 0.2205 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 3310/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2505 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2439 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3312/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8617 - f1: 0.8803 - val_loss: 0.2239 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3313/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2361 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2351 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2108 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2474 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3317/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2553 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2688 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 3319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2451 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3320/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3321/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2595 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2606 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 3323/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8718 - f1: 0.8885 - val_loss: 0.2507 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3324/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8727 - f1: 0.8896 - val_loss: 0.2524 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 3325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2656 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3326/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8662 - f1: 0.8841 - val_loss: 0.2272 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3365 - acc: 0.8659 - f1: 0.8843 - val_loss: 0.2314 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3328/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2493 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3329/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8890 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3330/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2411 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2380 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3332/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8656 - f1: 0.8840 - val_loss: 0.2534 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 3333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2708 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9669\n",
      "Epoch 3335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2606 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2574 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 3337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2578 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2335 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2362 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2697 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2716 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3339 - acc: 0.8677 - f1: 0.8854 - val_loss: 0.2301 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2701 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8750 - f1: 0.8915 - val_loss: 0.2517 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3345/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2356 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 3346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8749 - f1: 0.8910 - val_loss: 0.2380 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8876 - val_loss: 0.2371 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8747 - f1: 0.8915 - val_loss: 0.2381 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8747 - f1: 0.8914 - val_loss: 0.2493 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 3350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2371 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2558 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3352/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8629 - f1: 0.8821 - val_loss: 0.2407 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3353/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8702 - f1: 0.8876 - val_loss: 0.2536 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3354/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8733 - f1: 0.8896 - val_loss: 0.2516 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8710 - f1: 0.8881 - val_loss: 0.2309 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2549 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 3357/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8673 - f1: 0.8859 - val_loss: 0.2616 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8750 - f1: 0.8913 - val_loss: 0.2437 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 3359/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2228 - val_acc: 0.9616 - val_f1: 0.9635\n",
      "Epoch 3360/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2602 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3361/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2602 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3362/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8750 - f1: 0.8917 - val_loss: 0.2476 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3363/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2452 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2601 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3365/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2606 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8758 - f1: 0.8920 - val_loss: 0.2824 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 3367/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3280 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2424 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3368/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2579 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3369/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2404 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3370/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2475 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2432 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3372/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2308 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2330 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8653 - f1: 0.8839 - val_loss: 0.2618 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 3375/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2198 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 3376/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3393 - acc: 0.8651 - f1: 0.8833 - val_loss: 0.2312 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3377/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2352 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8748 - f1: 0.8913 - val_loss: 0.2327 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 3379/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8738 - f1: 0.8899 - val_loss: 0.2446 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2276 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2266 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2888 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8690 - f1: 0.8862 - val_loss: 0.2360 - val_acc: 0.9581 - val_f1: 0.9598\n",
      "Epoch 3384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2624 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2574 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 3386/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8672 - f1: 0.8850 - val_loss: 0.2953 - val_acc: 0.9616 - val_f1: 0.9628\n",
      "Epoch 3387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2424 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8769 - f1: 0.8931 - val_loss: 0.2793 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8755 - f1: 0.8915 - val_loss: 0.2370 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2447 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 3391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2248 - val_acc: 0.9584 - val_f1: 0.9602\n",
      "Epoch 3392/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2460 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2445 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 3394/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2544 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 3395/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8673 - f1: 0.8857 - val_loss: 0.2483 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3396/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2477 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2353 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2386 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 3399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2351 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2401 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8893 - val_loss: 0.2592 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3402/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2281 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 3403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8683 - f1: 0.8863 - val_loss: 0.2568 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8909 - val_loss: 0.2331 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3405/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2521 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8886 - val_loss: 0.2396 - val_acc: 0.9581 - val_f1: 0.9599\n",
      "Epoch 3407/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8651 - f1: 0.8836 - val_loss: 0.2273 - val_acc: 0.9581 - val_f1: 0.9605\n",
      "Epoch 3408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8634 - f1: 0.8818 - val_loss: 0.2359 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3409/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2526 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8716 - f1: 0.8885 - val_loss: 0.2908 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 3411/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2391 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3412/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8671 - f1: 0.8858 - val_loss: 0.2372 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3413/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8688 - f1: 0.8866 - val_loss: 0.2603 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2627 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3415/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3134 - acc: 0.8794 - f1: 0.8952 - val_loss: 0.2343 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8874 - val_loss: 0.2365 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3417/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2392 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3418/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2313 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 3419/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2524 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3420/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2930 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 3421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2457 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3422/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8707 - f1: 0.8881 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8646 - f1: 0.8832 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3424/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3358 - acc: 0.8644 - f1: 0.8835 - val_loss: 0.2722 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3425/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2226 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 3426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2458 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 3427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8702 - f1: 0.8881 - val_loss: 0.2351 - val_acc: 0.9603 - val_f1: 0.9614\n",
      "Epoch 3428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2490 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 3429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8732 - f1: 0.8896 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2837 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 3431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2554 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2313 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2200 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 3434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2514 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2284 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 3436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8761 - f1: 0.8926 - val_loss: 0.2395 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2218 - val_acc: 0.9591 - val_f1: 0.9615\n",
      "Epoch 3439/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2391 - val_acc: 0.9678 - val_f1: 0.9680\n",
      "Epoch 3440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8659 - f1: 0.8838 - val_loss: 0.2671 - val_acc: 0.9688 - val_f1: 0.9693\n",
      "Epoch 3441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2397 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 3442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8709 - f1: 0.8888 - val_loss: 0.2370 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2593 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8696 - f1: 0.8865 - val_loss: 0.2300 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2461 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2703 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 3447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2383 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 3448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2556 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2570 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2503 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 3451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8677 - f1: 0.8860 - val_loss: 0.2248 - val_acc: 0.9691 - val_f1: 0.9702\n",
      "Epoch 3452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2549 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3402 - acc: 0.8644 - f1: 0.8834 - val_loss: 0.2244 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 3454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2452 - val_acc: 0.9619 - val_f1: 0.9633\n",
      "Epoch 3455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2309 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2305 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 3457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2209 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.3002 - val_acc: 0.9622 - val_f1: 0.9625\n",
      "Epoch 3459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8688 - f1: 0.8864 - val_loss: 0.2299 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 3460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2479 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2529 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2443 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2640 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2202 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2397 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2714 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2454 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8746 - f1: 0.8910 - val_loss: 0.2255 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8749 - f1: 0.8915 - val_loss: 0.2425 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8756 - f1: 0.8917 - val_loss: 0.2336 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8768 - f1: 0.8927 - val_loss: 0.2661 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3472/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2265 - val_acc: 0.9578 - val_f1: 0.9598\n",
      "Epoch 3473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8668 - f1: 0.8842 - val_loss: 0.2375 - val_acc: 0.9616 - val_f1: 0.9624\n",
      "Epoch 3474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8685 - f1: 0.8869 - val_loss: 0.2553 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8732 - f1: 0.8897 - val_loss: 0.2439 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8749 - f1: 0.8914 - val_loss: 0.2517 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2669 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2406 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 3479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2464 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 3480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2377 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 3481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2362 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2423 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 3483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2399 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8691 - f1: 0.8872 - val_loss: 0.2134 - val_acc: 0.9569 - val_f1: 0.9594\n",
      "Epoch 3485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8701 - f1: 0.8878 - val_loss: 0.2753 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2487 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8733 - f1: 0.8899 - val_loss: 0.2343 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2297 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 3489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2455 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 3490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8692 - f1: 0.8870 - val_loss: 0.2378 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8700 - f1: 0.8878 - val_loss: 0.2440 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 3492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2523 - val_acc: 0.9644 - val_f1: 0.9663\n",
      "Epoch 3493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8668 - f1: 0.8849 - val_loss: 0.2427 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2377 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 3495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2463 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2329 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8685 - f1: 0.8861 - val_loss: 0.2417 - val_acc: 0.9494 - val_f1: 0.9521\n",
      "Epoch 3499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2322 - val_acc: 0.9675 - val_f1: 0.9686\n",
      "Epoch 3500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2524 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2361 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2699 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2359 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8671 - f1: 0.8850 - val_loss: 0.2565 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3505/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2578 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3506/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2362 - val_acc: 0.9572 - val_f1: 0.9593\n",
      "Epoch 3507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2318 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3508/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8868 - val_loss: 0.2609 - val_acc: 0.9613 - val_f1: 0.9619\n",
      "Epoch 3509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8737 - f1: 0.8899 - val_loss: 0.2397 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8693 - f1: 0.8864 - val_loss: 0.2703 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2654 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 3512/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8725 - f1: 0.8897 - val_loss: 0.2627 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2894 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 3514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2883 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8729 - f1: 0.8901 - val_loss: 0.2851 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 3516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2787 - val_acc: 0.9659 - val_f1: 0.9664\n",
      "Epoch 3517/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8746 - f1: 0.8913 - val_loss: 0.2900 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 3518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8640 - f1: 0.8830 - val_loss: 0.2870 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8762 - f1: 0.8924 - val_loss: 0.2264 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2341 - val_acc: 0.9588 - val_f1: 0.9606\n",
      "Epoch 3521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3368 - acc: 0.8664 - f1: 0.8845 - val_loss: 0.2497 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 3522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8627 - f1: 0.8819 - val_loss: 0.2407 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2457 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 3524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8710 - f1: 0.8888 - val_loss: 0.2239 - val_acc: 0.9656 - val_f1: 0.9674\n",
      "Epoch 3525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2339 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 3526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2376 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 3528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2115 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8686 - f1: 0.8860 - val_loss: 0.2438 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8704 - f1: 0.8872 - val_loss: 0.2292 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2711 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3532/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3201 - acc: 0.8741 - f1: 0.8902 - val_loss: 0.2615 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3533/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8763 - f1: 0.8920 - val_loss: 0.2612 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3534/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2521 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2406 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 3536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3132 - acc: 0.8782 - f1: 0.8941 - val_loss: 0.2580 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2581 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8716 - f1: 0.8882 - val_loss: 0.2382 - val_acc: 0.9594 - val_f1: 0.9608\n",
      "Epoch 3539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8660 - f1: 0.8843 - val_loss: 0.2589 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 3540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8696 - f1: 0.8869 - val_loss: 0.2757 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2517 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2838 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 3543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3397 - acc: 0.8654 - f1: 0.8841 - val_loss: 0.2321 - val_acc: 0.9581 - val_f1: 0.9597\n",
      "Epoch 3544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8661 - f1: 0.8839 - val_loss: 0.2498 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 3545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2483 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8690 - f1: 0.8870 - val_loss: 0.2662 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8690 - f1: 0.8871 - val_loss: 0.2474 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 3548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8686 - f1: 0.8862 - val_loss: 0.2314 - val_acc: 0.9563 - val_f1: 0.9586\n",
      "Epoch 3549/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3451 - acc: 0.8625 - f1: 0.8812 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3550/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3347 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2727 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3383 - acc: 0.8641 - f1: 0.8827 - val_loss: 0.2297 - val_acc: 0.9681 - val_f1: 0.9694\n",
      "Epoch 3552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3347 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2465 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3553/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8836 - val_loss: 0.2427 - val_acc: 0.9644 - val_f1: 0.9662\n",
      "Epoch 3554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8757 - f1: 0.8920 - val_loss: 0.2724 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3555/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8685 - f1: 0.8864 - val_loss: 0.2468 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 3556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8739 - f1: 0.8903 - val_loss: 0.2205 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 3557/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8729 - f1: 0.8893 - val_loss: 0.2428 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3558/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8917 - val_loss: 0.2678 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3559/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3265 - acc: 0.8706 - f1: 0.8884 - val_loss: 0.2538 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3560/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3205 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2618 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3561/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2379 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3562/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3281 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2464 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3563/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3201 - acc: 0.8746 - f1: 0.8911 - val_loss: 0.2430 - val_acc: 0.9663 - val_f1: 0.9682\n",
      "Epoch 3564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2357 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 3565/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3219 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2342 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3566/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8697 - f1: 0.8870 - val_loss: 0.2340 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 3567/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3208 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 3568/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3245 - acc: 0.8708 - f1: 0.8879 - val_loss: 0.2509 - val_acc: 0.9700 - val_f1: 0.9703\n",
      "Epoch 3569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8766 - f1: 0.8924 - val_loss: 0.2394 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 3570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2376 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3571/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3223 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2258 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2482 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3573/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8733 - f1: 0.8902 - val_loss: 0.2459 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 3574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2393 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3575/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3187 - acc: 0.8762 - f1: 0.8917 - val_loss: 0.2547 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 3576/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3390 - acc: 0.8646 - f1: 0.8829 - val_loss: 0.2408 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 3577/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3247 - acc: 0.8719 - f1: 0.8895 - val_loss: 0.2532 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 3578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2456 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 3579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8737 - f1: 0.8896 - val_loss: 0.2499 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 3580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2320 - val_acc: 0.9556 - val_f1: 0.9578\n",
      "Epoch 3581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2232 - val_acc: 0.9622 - val_f1: 0.9641\n",
      "Epoch 3582/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2642 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3431 - acc: 0.8615 - f1: 0.8804 - val_loss: 0.2291 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8715 - f1: 0.8879 - val_loss: 0.2274 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 3585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2355 - val_acc: 0.9613 - val_f1: 0.9632\n",
      "Epoch 3586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8659 - f1: 0.8842 - val_loss: 0.2673 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2344 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8890 - val_loss: 0.2432 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2632 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2389 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 3591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8696 - f1: 0.8875 - val_loss: 0.2289 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 3592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2302 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3593/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8704 - f1: 0.8876 - val_loss: 0.2411 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3594/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2668 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3595/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2430 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3596/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3279 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2497 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3597/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3302 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2703 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3598/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8683 - f1: 0.8856 - val_loss: 0.2886 - val_acc: 0.9600 - val_f1: 0.9608\n",
      "Epoch 3599/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3293 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2482 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3600/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3185 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2691 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 3601/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8724 - f1: 0.8898 - val_loss: 0.2781 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 3602/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3297 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2430 - val_acc: 0.9581 - val_f1: 0.9601\n",
      "Epoch 3603/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3288 - acc: 0.8697 - f1: 0.8872 - val_loss: 0.2586 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 3604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8651 - f1: 0.8837 - val_loss: 0.2594 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2498 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 3606/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2768 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 3607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2708 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 3608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8741 - f1: 0.8898 - val_loss: 0.2689 - val_acc: 0.9688 - val_f1: 0.9699\n",
      "Epoch 3609/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2239 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3610/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2411 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 3611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8693 - f1: 0.8864 - val_loss: 0.2493 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 3612/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3352 - acc: 0.8658 - f1: 0.8844 - val_loss: 0.2557 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3613/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3321 - acc: 0.8678 - f1: 0.8859 - val_loss: 0.2434 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3614/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3214 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2530 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3615/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8851 - val_loss: 0.2392 - val_acc: 0.9525 - val_f1: 0.9552\n",
      "Epoch 3616/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3330 - acc: 0.8674 - f1: 0.8854 - val_loss: 0.2381 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 3617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2486 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2554 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 3619/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3195 - acc: 0.8741 - f1: 0.8911 - val_loss: 0.2585 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3620/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2521 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 3621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3184 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2666 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 3622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8746 - f1: 0.8912 - val_loss: 0.2700 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8681 - f1: 0.8861 - val_loss: 0.2800 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3624/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3370 - acc: 0.8655 - f1: 0.8844 - val_loss: 0.2475 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 3625/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3360 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2508 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3626/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 3627/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2604 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 3629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8707 - f1: 0.8877 - val_loss: 0.2388 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 3630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8683 - f1: 0.8859 - val_loss: 0.2326 - val_acc: 0.9634 - val_f1: 0.9657\n",
      "Epoch 3631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8711 - f1: 0.8884 - val_loss: 0.2479 - val_acc: 0.9666 - val_f1: 0.9670\n",
      "Epoch 3632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2259 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 3633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2345 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2338 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2421 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 3637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2355 - val_acc: 0.9588 - val_f1: 0.9603\n",
      "Epoch 3638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2240 - val_acc: 0.9622 - val_f1: 0.9642\n",
      "Epoch 3639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8770 - f1: 0.8926 - val_loss: 0.2462 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 3640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3134 - acc: 0.8779 - f1: 0.8937 - val_loss: 0.2472 - val_acc: 0.9694 - val_f1: 0.9704\n",
      "Epoch 3641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8694 - f1: 0.8872 - val_loss: 0.2303 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 3642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8662 - f1: 0.8843 - val_loss: 0.2320 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 3644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8665 - f1: 0.8851 - val_loss: 0.2750 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 3645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2475 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 3646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3143 - acc: 0.8774 - f1: 0.8932 - val_loss: 0.2801 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2741 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 3648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8875 - val_loss: 0.2601 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 3649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2657 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2428 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8730 - f1: 0.8903 - val_loss: 0.2439 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2520 - val_acc: 0.9691 - val_f1: 0.9697\n",
      "Epoch 3653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2617 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2556 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 3655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2451 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8671 - f1: 0.8847 - val_loss: 0.2496 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2349 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 3658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2298 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 3659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8861 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3660/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3142 - acc: 0.8780 - f1: 0.8939 - val_loss: 0.2654 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 3661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2765 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8695 - f1: 0.8876 - val_loss: 0.2297 - val_acc: 0.9541 - val_f1: 0.9567\n",
      "Epoch 3663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8685 - f1: 0.8865 - val_loss: 0.2380 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 3664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3414 - acc: 0.8634 - f1: 0.8823 - val_loss: 0.2290 - val_acc: 0.9609 - val_f1: 0.9629\n",
      "Epoch 3665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2295 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2476 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2378 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2544 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 3669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2477 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8728 - f1: 0.8901 - val_loss: 0.2405 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2360 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2400 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 3673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2550 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3147 - acc: 0.8773 - f1: 0.8926 - val_loss: 0.2473 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2916 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 3676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2632 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 3677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2147 - val_acc: 0.9600 - val_f1: 0.9622\n",
      "Epoch 3678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3403 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2242 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3392 - acc: 0.8629 - f1: 0.8819 - val_loss: 0.2293 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 3680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2498 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 3681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2629 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 3682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8731 - f1: 0.8901 - val_loss: 0.2320 - val_acc: 0.9456 - val_f1: 0.9496\n",
      "Epoch 3683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8652 - f1: 0.8838 - val_loss: 0.2514 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2435 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3166 - acc: 0.8761 - f1: 0.8925 - val_loss: 0.2420 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 3686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2429 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8667 - f1: 0.8851 - val_loss: 0.2424 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2553 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2405 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2380 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 3691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8678 - f1: 0.8857 - val_loss: 0.2486 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8724 - f1: 0.8893 - val_loss: 0.2462 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2619 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3169 - acc: 0.8763 - f1: 0.8926 - val_loss: 0.2511 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 3695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2366 - val_acc: 0.9641 - val_f1: 0.9662\n",
      "Epoch 3696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2666 - val_acc: 0.9603 - val_f1: 0.9616\n",
      "Epoch 3697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2496 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8693 - f1: 0.8873 - val_loss: 0.3386 - val_acc: 0.9569 - val_f1: 0.9582\n",
      "Epoch 3699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2187 - val_acc: 0.9597 - val_f1: 0.9618\n",
      "Epoch 3700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2527 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2403 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 3702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2373 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 3703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3165 - acc: 0.8772 - f1: 0.8933 - val_loss: 0.2639 - val_acc: 0.9681 - val_f1: 0.9679\n",
      "Epoch 3704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2446 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2297 - val_acc: 0.9491 - val_f1: 0.9525\n",
      "Epoch 3706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8669 - f1: 0.8854 - val_loss: 0.2331 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2415 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2785 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2514 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2931 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3412 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2525 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2376 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2258 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 3714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2610 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 3715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2319 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8737 - f1: 0.8908 - val_loss: 0.2534 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 3717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8704 - f1: 0.8877 - val_loss: 0.2329 - val_acc: 0.9634 - val_f1: 0.9652\n",
      "Epoch 3718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2252 - val_acc: 0.9669 - val_f1: 0.9687\n",
      "Epoch 3719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2494 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 3720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3721/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2772 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2501 - val_acc: 0.9584 - val_f1: 0.9606\n",
      "Epoch 3723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8694 - f1: 0.8865 - val_loss: 0.2359 - val_acc: 0.9638 - val_f1: 0.9657\n",
      "Epoch 3724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2513 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3725/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3232 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2799 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 3726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2578 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3727/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2347 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 3728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2505 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3418 - acc: 0.8630 - f1: 0.8817 - val_loss: 0.2152 - val_acc: 0.9628 - val_f1: 0.9651\n",
      "Epoch 3730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2346 - val_acc: 0.9669 - val_f1: 0.9671\n",
      "Epoch 3731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8726 - f1: 0.8895 - val_loss: 0.2478 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8675 - f1: 0.8852 - val_loss: 0.2622 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2515 - val_acc: 0.9684 - val_f1: 0.9695\n",
      "Epoch 3734/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2750 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 3735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8728 - f1: 0.8898 - val_loss: 0.2358 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 3736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2565 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 3737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8689 - f1: 0.8869 - val_loss: 0.2313 - val_acc: 0.9597 - val_f1: 0.9609\n",
      "Epoch 3738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2288 - val_acc: 0.9578 - val_f1: 0.9601\n",
      "Epoch 3739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2535 - val_acc: 0.9481 - val_f1: 0.9519\n",
      "Epoch 3740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8727 - f1: 0.8892 - val_loss: 0.2714 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 3741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3349 - acc: 0.8660 - f1: 0.8845 - val_loss: 0.2288 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3291 - acc: 0.8687 - f1: 0.8863 - val_loss: 0.2362 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8716 - f1: 0.8883 - val_loss: 0.2488 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 3744/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2289 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 3745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2667 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3746/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8668 - f1: 0.8852 - val_loss: 0.2165 - val_acc: 0.9556 - val_f1: 0.9576\n",
      "Epoch 3747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8669 - f1: 0.8846 - val_loss: 0.2328 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2558 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8767 - f1: 0.8927 - val_loss: 0.2502 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 3750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3157 - acc: 0.8770 - f1: 0.8934 - val_loss: 0.2623 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2541 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3752/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2313 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8676 - f1: 0.8860 - val_loss: 0.2705 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3754/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2794 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2487 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8757 - f1: 0.8918 - val_loss: 0.2460 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2448 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8691 - f1: 0.8870 - val_loss: 0.2514 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 3759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2384 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2580 - val_acc: 0.9647 - val_f1: 0.9646\n",
      "Epoch 3761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8663 - f1: 0.8847 - val_loss: 0.2499 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2566 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 3763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2411 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8703 - f1: 0.8876 - val_loss: 0.2595 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2366 - val_acc: 0.9600 - val_f1: 0.9620\n",
      "Epoch 3766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8705 - f1: 0.8875 - val_loss: 0.2538 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2594 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8735 - f1: 0.8904 - val_loss: 0.2318 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8671 - f1: 0.8848 - val_loss: 0.2258 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8674 - f1: 0.8855 - val_loss: 0.2558 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2538 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 3772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8749 - f1: 0.8908 - val_loss: 0.2478 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 3773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2491 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2494 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 3775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8718 - f1: 0.8893 - val_loss: 0.2609 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.3224 - val_acc: 0.9591 - val_f1: 0.9595\n",
      "Epoch 3777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3352 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2405 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2639 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 3779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.3000 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 3780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3128 - acc: 0.8797 - f1: 0.8951 - val_loss: 0.2539 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 3781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8865 - val_loss: 0.2494 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3163 - acc: 0.8760 - f1: 0.8921 - val_loss: 0.2625 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8652 - f1: 0.8841 - val_loss: 0.2540 - val_acc: 0.9638 - val_f1: 0.9655\n",
      "Epoch 3784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2468 - val_acc: 0.9628 - val_f1: 0.9649\n",
      "Epoch 3785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8692 - f1: 0.8873 - val_loss: 0.2824 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 3786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2722 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8691 - f1: 0.8864 - val_loss: 0.2414 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8897 - val_loss: 0.2507 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8651 - f1: 0.8835 - val_loss: 0.2497 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2445 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 3791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2373 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 3792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2577 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8692 - f1: 0.8862 - val_loss: 0.2660 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8759 - f1: 0.8922 - val_loss: 0.2418 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 3795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2813 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8756 - f1: 0.8920 - val_loss: 0.2535 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3454 - acc: 0.8610 - f1: 0.8803 - val_loss: 0.2504 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 3799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2518 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 3800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8698 - f1: 0.8869 - val_loss: 0.2399 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 3801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2507 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 3802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2548 - val_acc: 0.9653 - val_f1: 0.9657\n",
      "Epoch 3803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2480 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2514 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2709 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 3807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2296 - val_acc: 0.9594 - val_f1: 0.9614\n",
      "Epoch 3808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2364 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8771 - f1: 0.8926 - val_loss: 0.2470 - val_acc: 0.9684 - val_f1: 0.9697\n",
      "Epoch 3810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8667 - f1: 0.8849 - val_loss: 0.2701 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2283 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8690 - f1: 0.8863 - val_loss: 0.2799 - val_acc: 0.9644 - val_f1: 0.9647\n",
      "Epoch 3813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2259 - val_acc: 0.9691 - val_f1: 0.9702\n",
      "Epoch 3814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2670 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 3815/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8678 - f1: 0.8858 - val_loss: 0.2445 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 3816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8707 - f1: 0.8878 - val_loss: 0.2410 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 3817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8651 - f1: 0.8839 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 3818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8741 - f1: 0.8904 - val_loss: 0.2525 - val_acc: 0.9684 - val_f1: 0.9689\n",
      "Epoch 3819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2267 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 3820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2549 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 3821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8767 - f1: 0.8932 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 3822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2457 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2938 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8726 - f1: 0.8893 - val_loss: 0.2547 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 3825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2437 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8703 - f1: 0.8880 - val_loss: 0.2451 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 3827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2494 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 3828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3314 - acc: 0.8680 - f1: 0.8857 - val_loss: 0.2422 - val_acc: 0.9622 - val_f1: 0.9640\n",
      "Epoch 3829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3153 - acc: 0.8764 - f1: 0.8929 - val_loss: 0.2675 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8859 - val_loss: 0.2424 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 3832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2459 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 3833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3136 - acc: 0.8778 - f1: 0.8935 - val_loss: 0.2743 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2896 - val_acc: 0.9563 - val_f1: 0.9567\n",
      "Epoch 3835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8659 - f1: 0.8841 - val_loss: 0.2416 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 3836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8658 - f1: 0.8837 - val_loss: 0.2326 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 3837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2300 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 3838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2343 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 3839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2343 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 3840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2580 - val_acc: 0.9672 - val_f1: 0.9675\n",
      "Epoch 3841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2532 - val_acc: 0.9678 - val_f1: 0.9692\n",
      "Epoch 3842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3143 - acc: 0.8783 - f1: 0.8940 - val_loss: 0.2416 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8757 - f1: 0.8922 - val_loss: 0.2256 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 3844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3376 - acc: 0.8652 - f1: 0.8841 - val_loss: 0.2533 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8643 - f1: 0.8830 - val_loss: 0.2936 - val_acc: 0.9597 - val_f1: 0.9600\n",
      "Epoch 3846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8675 - f1: 0.8854 - val_loss: 0.2622 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 3847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8740 - f1: 0.8907 - val_loss: 0.2664 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3848/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2448 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2544 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 3850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2723 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3851/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8674 - f1: 0.8852 - val_loss: 0.2683 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 3852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8754 - f1: 0.8917 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2580 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8679 - f1: 0.8857 - val_loss: 0.2559 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8656 - f1: 0.8841 - val_loss: 0.2085 - val_acc: 0.9584 - val_f1: 0.9609\n",
      "Epoch 3856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3433 - acc: 0.8643 - f1: 0.8829 - val_loss: 0.2140 - val_acc: 0.9606 - val_f1: 0.9622\n",
      "Epoch 3857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3374 - acc: 0.8634 - f1: 0.8822 - val_loss: 0.2359 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 3858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2257 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3859/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2199 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 3860/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8668 - f1: 0.8848 - val_loss: 0.2230 - val_acc: 0.9603 - val_f1: 0.9624\n",
      "Epoch 3861/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2786 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8736 - f1: 0.8902 - val_loss: 0.2395 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 3863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2476 - val_acc: 0.9684 - val_f1: 0.9694\n",
      "Epoch 3864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2438 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 3865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3148 - acc: 0.8769 - f1: 0.8930 - val_loss: 0.2778 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 3866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2692 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 3867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2432 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 3868/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8734 - f1: 0.8898 - val_loss: 0.2433 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8714 - f1: 0.8882 - val_loss: 0.2996 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 3870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2753 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 3872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2202 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 3873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2517 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 3874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8743 - f1: 0.8908 - val_loss: 0.2606 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3875/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2784 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 3876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8710 - f1: 0.8882 - val_loss: 0.2471 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3877/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2317 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 3878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2343 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3351 - acc: 0.8669 - f1: 0.8849 - val_loss: 0.2903 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3880/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8743 - f1: 0.8909 - val_loss: 0.2334 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8654 - f1: 0.8837 - val_loss: 0.2399 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 3882/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8719 - f1: 0.8891 - val_loss: 0.2429 - val_acc: 0.9613 - val_f1: 0.9627\n",
      "Epoch 3883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8757 - f1: 0.8919 - val_loss: 0.2382 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 3884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2614 - val_acc: 0.9616 - val_f1: 0.9629\n",
      "Epoch 3885/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8682 - f1: 0.8863 - val_loss: 0.2563 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 3886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8769 - f1: 0.8925 - val_loss: 0.2554 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2527 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 3888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8714 - f1: 0.8884 - val_loss: 0.2301 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 3889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2488 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 3890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8910 - val_loss: 0.2487 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 3891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2455 - val_acc: 0.9591 - val_f1: 0.9608\n",
      "Epoch 3892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8713 - f1: 0.8878 - val_loss: 0.2242 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8662 - f1: 0.8845 - val_loss: 0.2392 - val_acc: 0.9694 - val_f1: 0.9700\n",
      "Epoch 3894/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2619 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 3895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2552 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 3896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8707 - f1: 0.8875 - val_loss: 0.2336 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 3897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2666 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 3898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8749 - f1: 0.8914 - val_loss: 0.2327 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8721 - f1: 0.8897 - val_loss: 0.2752 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2368 - val_acc: 0.9613 - val_f1: 0.9620\n",
      "Epoch 3901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2185 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 3902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3394 - acc: 0.8638 - f1: 0.8822 - val_loss: 0.2419 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 3903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8704 - f1: 0.8879 - val_loss: 0.2397 - val_acc: 0.9644 - val_f1: 0.9663\n",
      "Epoch 3904/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2629 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 3905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2385 - val_acc: 0.9631 - val_f1: 0.9649\n",
      "Epoch 3906/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3225 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2301 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3907/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3193 - acc: 0.8748 - f1: 0.8909 - val_loss: 0.2482 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 3908/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3233 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2312 - val_acc: 0.9631 - val_f1: 0.9652\n",
      "Epoch 3909/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2416 - val_acc: 0.9666 - val_f1: 0.9669\n",
      "Epoch 3910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8765 - f1: 0.8927 - val_loss: 0.2517 - val_acc: 0.9684 - val_f1: 0.9699\n",
      "Epoch 3911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2431 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 3912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3361 - acc: 0.8654 - f1: 0.8842 - val_loss: 0.2246 - val_acc: 0.9600 - val_f1: 0.9618\n",
      "Epoch 3913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2315 - val_acc: 0.9569 - val_f1: 0.9593\n",
      "Epoch 3914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8673 - f1: 0.8855 - val_loss: 0.2411 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 3915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2436 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 3916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3144 - acc: 0.8774 - f1: 0.8935 - val_loss: 0.2411 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 3917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8669 - f1: 0.8853 - val_loss: 0.2716 - val_acc: 0.9678 - val_f1: 0.9687\n",
      "Epoch 3918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8651 - f1: 0.8837 - val_loss: 0.2634 - val_acc: 0.9603 - val_f1: 0.9610\n",
      "Epoch 3919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2310 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 3920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2443 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3121 - acc: 0.8791 - f1: 0.8947 - val_loss: 0.2731 - val_acc: 0.9647 - val_f1: 0.9650\n",
      "Epoch 3922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.2192 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 3923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2900 - val_acc: 0.9638 - val_f1: 0.9639\n",
      "Epoch 3924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8748 - f1: 0.8908 - val_loss: 0.2396 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8698 - f1: 0.8879 - val_loss: 0.2280 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 3926/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2303 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 3927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2496 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 3928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2648 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 3929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8708 - f1: 0.8876 - val_loss: 0.2444 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8671 - f1: 0.8854 - val_loss: 0.2435 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 3931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2555 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 3932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2691 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 3933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2412 - val_acc: 0.9634 - val_f1: 0.9644\n",
      "Epoch 3934/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2642 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 3935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8641 - f1: 0.8829 - val_loss: 0.2484 - val_acc: 0.9681 - val_f1: 0.9692\n",
      "Epoch 3936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2403 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 3937/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3237 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2354 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 3938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2673 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 3939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2483 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8621 - f1: 0.8815 - val_loss: 0.2700 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 3941/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3264 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2324 - val_acc: 0.9606 - val_f1: 0.9625\n",
      "Epoch 3942/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8895 - val_loss: 0.2505 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 3943/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2366 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3944/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3294 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.2320 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 3945/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3303 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2534 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 3946/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2708 - val_acc: 0.9694 - val_f1: 0.9708\n",
      "Epoch 3947/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3309 - acc: 0.8683 - f1: 0.8864 - val_loss: 0.3023 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 3948/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3336 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2404 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3949/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3316 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2400 - val_acc: 0.9619 - val_f1: 0.9639\n",
      "Epoch 3950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8682 - f1: 0.8854 - val_loss: 0.2486 - val_acc: 0.9616 - val_f1: 0.9630\n",
      "Epoch 3951/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8873 - val_loss: 0.2477 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 3952/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3283 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2795 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 3953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8726 - f1: 0.8898 - val_loss: 0.2312 - val_acc: 0.9625 - val_f1: 0.9649\n",
      "Epoch 3954/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2535 - val_acc: 0.9681 - val_f1: 0.9691\n",
      "Epoch 3955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2588 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 3956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2511 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 3957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8740 - f1: 0.8905 - val_loss: 0.2305 - val_acc: 0.9619 - val_f1: 0.9634\n",
      "Epoch 3958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2489 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 3959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 3960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2467 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 3961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8762 - f1: 0.8923 - val_loss: 0.2323 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 3962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2617 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 3963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8672 - f1: 0.8852 - val_loss: 0.2190 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 3964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8673 - f1: 0.8853 - val_loss: 0.2471 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 3965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8721 - f1: 0.8897 - val_loss: 0.2316 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 3966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2387 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 3967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8653 - f1: 0.8834 - val_loss: 0.2584 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 3968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2592 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 3969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2287 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8683 - f1: 0.8861 - val_loss: 0.2544 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 3971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8665 - f1: 0.8846 - val_loss: 0.2508 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 3972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8692 - f1: 0.8869 - val_loss: 0.2495 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 3973/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2330 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 3974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8682 - f1: 0.8862 - val_loss: 0.2400 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2266 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 3976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2377 - val_acc: 0.9600 - val_f1: 0.9616\n",
      "Epoch 3977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8704 - f1: 0.8875 - val_loss: 0.2408 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8728 - f1: 0.8902 - val_loss: 0.2420 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 3979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2309 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 3980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2639 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 3981/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8673 - f1: 0.8859 - val_loss: 0.2468 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 3982/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2390 - val_acc: 0.9588 - val_f1: 0.9609\n",
      "Epoch 3983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2571 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 3984/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2426 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 3985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8684 - f1: 0.8868 - val_loss: 0.2572 - val_acc: 0.9691 - val_f1: 0.9703\n",
      "Epoch 3986/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8676 - f1: 0.8859 - val_loss: 0.2403 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 3987/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2307 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 3988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8880 - val_loss: 0.2307 - val_acc: 0.9559 - val_f1: 0.9582\n",
      "Epoch 3989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8722 - f1: 0.8892 - val_loss: 0.2367 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 3990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2647 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 3991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2520 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 3992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8730 - f1: 0.8895 - val_loss: 0.2883 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 3993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2445 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 3994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2481 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 3995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8900 - val_loss: 0.2541 - val_acc: 0.9672 - val_f1: 0.9678\n",
      "Epoch 3996/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8884 - val_loss: 0.2403 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 3997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8717 - f1: 0.8886 - val_loss: 0.2369 - val_acc: 0.9531 - val_f1: 0.9559\n",
      "Epoch 3998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2397 - val_acc: 0.9616 - val_f1: 0.9625\n",
      "Epoch 3999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8899 - val_loss: 0.2315 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 4000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3341 - acc: 0.8667 - f1: 0.8847 - val_loss: 0.2611 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4001/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8711 - f1: 0.8885 - val_loss: 0.2602 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4002/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2418 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4003/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8697 - f1: 0.8871 - val_loss: 0.2446 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4004/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2557 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4005/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2543 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4006/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8733 - f1: 0.8903 - val_loss: 0.2336 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 4007/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8719 - f1: 0.8889 - val_loss: 0.2470 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4008/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2403 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4009/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3389 - acc: 0.8653 - f1: 0.8837 - val_loss: 0.2140 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 4010/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8718 - f1: 0.8887 - val_loss: 0.2367 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4011/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2492 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4012/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3194 - acc: 0.8748 - f1: 0.89 - 0s 16us/sample - loss: 0.3195 - acc: 0.8753 - f1: 0.8918 - val_loss: 0.2366 - val_acc: 0.9594 - val_f1: 0.9610\n",
      "Epoch 4013/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3212 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2568 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4014/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2662 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4015/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8709 - f1: 0.8876 - val_loss: 0.2254 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 4016/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2481 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4017/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8725 - f1: 0.8889 - val_loss: 0.2345 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4018/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2432 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4019/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8744 - f1: 0.8908 - val_loss: 0.2406 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4020/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2600 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4021/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2367 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4022/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2814 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 4023/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8696 - f1: 0.8876 - val_loss: 0.2320 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 4024/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2582 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4025/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2454 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4026/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8684 - f1: 0.8863 - val_loss: 0.2700 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4027/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2548 - val_acc: 0.9609 - val_f1: 0.9627\n",
      "Epoch 4028/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8677 - f1: 0.8856 - val_loss: 0.2390 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 4029/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2658 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4030/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2604 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4031/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2480 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4032/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2245 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4033/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2449 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4034/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8746 - f1: 0.8907 - val_loss: 0.2311 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 4035/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8737 - f1: 0.8899 - val_loss: 0.2860 - val_acc: 0.9634 - val_f1: 0.9638\n",
      "Epoch 4036/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.2364 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4037/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8706 - f1: 0.8884 - val_loss: 0.2391 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4038/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2411 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4039/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2688 - val_acc: 0.9653 - val_f1: 0.9655\n",
      "Epoch 4040/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2374 - val_acc: 0.9628 - val_f1: 0.9647\n",
      "Epoch 4041/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2659 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4042/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8773 - f1: 0.8931 - val_loss: 0.2509 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4043/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4044/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8743 - f1: 0.8907 - val_loss: 0.2620 - val_acc: 0.9656 - val_f1: 0.9660\n",
      "Epoch 4045/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2997 - val_acc: 0.9619 - val_f1: 0.9625\n",
      "Epoch 4046/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2367 - val_acc: 0.9628 - val_f1: 0.9637\n",
      "Epoch 4047/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3409 - acc: 0.8634 - f1: 0.8825 - val_loss: 0.2441 - val_acc: 0.9613 - val_f1: 0.9630\n",
      "Epoch 4048/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2934 - val_acc: 0.9647 - val_f1: 0.9647\n",
      "Epoch 4049/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8899 - val_loss: 0.2606 - val_acc: 0.9647 - val_f1: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4050/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2599 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4051/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8712 - f1: 0.8889 - val_loss: 0.2609 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4052/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8682 - f1: 0.8864 - val_loss: 0.2656 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4053/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8711 - f1: 0.8879 - val_loss: 0.2493 - val_acc: 0.9622 - val_f1: 0.9639\n",
      "Epoch 4054/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2590 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 4055/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2272 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4056/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8721 - f1: 0.8887 - val_loss: 0.2707 - val_acc: 0.9669 - val_f1: 0.9673\n",
      "Epoch 4057/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8880 - val_loss: 0.2453 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4058/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2528 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4059/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2616 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4060/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8654 - f1: 0.8835 - val_loss: 0.2244 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4061/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3334 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2407 - val_acc: 0.9600 - val_f1: 0.9621\n",
      "Epoch 4062/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8698 - f1: 0.8870 - val_loss: 0.2563 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4063/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8688 - f1: 0.8868 - val_loss: 0.2547 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4064/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3200 - acc: 0.8743 - f1: 0.8905 - val_loss: 0.2728 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4065/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2539 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4066/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8716 - f1: 0.8887 - val_loss: 0.2587 - val_acc: 0.9634 - val_f1: 0.9641\n",
      "Epoch 4067/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3166 - acc: 0.8763 - f1: 0.8923 - val_loss: 0.2686 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4068/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2637 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4069/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3404 - acc: 0.8648 - f1: 0.8832 - val_loss: 0.2492 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4070/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8704 - f1: 0.8872 - val_loss: 0.2495 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4071/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8744 - f1: 0.8913 - val_loss: 0.2689 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4072/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8696 - f1: 0.8870 - val_loss: 0.3028 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4073/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3127 - acc: 0.8796 - f1: 0.8947 - val_loss: 0.2665 - val_acc: 0.9641 - val_f1: 0.9648\n",
      "Epoch 4074/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3258 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2459 - val_acc: 0.9659 - val_f1: 0.9673\n",
      "Epoch 4075/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8735 - f1: 0.8907 - val_loss: 0.2587 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4076/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3141 - acc: 0.8779 - f1: 0.8938 - val_loss: 0.2819 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4077/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2525 - val_acc: 0.9638 - val_f1: 0.9654\n",
      "Epoch 4078/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3261 - acc: 0.8704 - f1: 0.8881 - val_loss: 0.2817 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4079/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2510 - val_acc: 0.9606 - val_f1: 0.9624\n",
      "Epoch 4080/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8670 - f1: 0.8848 - val_loss: 0.2629 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4081/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8889 - val_loss: 0.2557 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4082/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3287 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2426 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4083/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3229 - acc: 0.8736 - f1: 0.8900 - val_loss: 0.2478 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4084/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3128 - acc: 0.8780 - f1: 0.8936 - val_loss: 0.2410 - val_acc: 0.9613 - val_f1: 0.9624\n",
      "Epoch 4085/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3394 - acc: 0.8647 - f1: 0.8836 - val_loss: 0.2186 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4086/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3328 - acc: 0.8669 - f1: 0.8848 - val_loss: 0.2367 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4087/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3188 - acc: 0.8757 - f1: 0.8917 - val_loss: 0.2986 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4088/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3152 - acc: 0.8770 - f1: 0.8929 - val_loss: 0.2479 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4089/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2605 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4090/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3386 - acc: 0.8657 - f1: 0.8843 - val_loss: 0.2549 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4091/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2407 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4092/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8861 - val_loss: 0.2522 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4093/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3111 - acc: 0.8797 - f1: 0.8949 - val_loss: 0.2395 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4094/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8729 - f1: 0.8895 - val_loss: 0.2684 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4095/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3256 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2790 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4096/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8885 - val_loss: 0.2446 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4097/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.2743 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4098/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8742 - f1: 0.8906 - val_loss: 0.2581 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4099/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8729 - f1: 0.8895 - val_loss: 0.2540 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4100/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2511 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4101/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2635 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4102/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2603 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4103/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2544 - val_acc: 0.9681 - val_f1: 0.9686\n",
      "Epoch 4104/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2318 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4105/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2576 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4106/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2410 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 4107/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2474 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4108/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8744 - f1: 0.8909 - val_loss: 0.2680 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 4109/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8724 - f1: 0.8895 - val_loss: 0.2428 - val_acc: 0.9500 - val_f1: 0.9529\n",
      "Epoch 4110/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.2669 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 4111/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8667 - f1: 0.8852 - val_loss: 0.2564 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4112/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8702 - f1: 0.8874 - val_loss: 0.2565 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4113/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8766 - f1: 0.8930 - val_loss: 0.2361 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4114/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8753 - f1: 0.8916 - val_loss: 0.2628 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4115/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3188 - acc: 0.8753 - f1: 0.8914 - val_loss: 0.2622 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4116/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8891 - val_loss: 0.2425 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4117/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8679 - f1: 0.8860 - val_loss: 0.2452 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4118/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2667 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4119/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2753 - val_acc: 0.9606 - val_f1: 0.9616\n",
      "Epoch 4120/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8708 - f1: 0.8876 - val_loss: 0.2555 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4121/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2364 - val_acc: 0.9588 - val_f1: 0.9610\n",
      "Epoch 4122/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8732 - f1: 0.8899 - val_loss: 0.2775 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4123/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2371 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4124/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.3054 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4125/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2820 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4126/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8729 - f1: 0.8900 - val_loss: 0.2579 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4127/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2487 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 4128/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2493 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4129/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8872 - val_loss: 0.2640 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4130/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8894 - val_loss: 0.2635 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4131/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8751 - f1: 0.8914 - val_loss: 0.2564 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4132/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2360 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4133/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8676 - f1: 0.8856 - val_loss: 0.2653 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 4134/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8681 - f1: 0.8862 - val_loss: 0.2224 - val_acc: 0.9563 - val_f1: 0.9580\n",
      "Epoch 4135/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8716 - f1: 0.8892 - val_loss: 0.2354 - val_acc: 0.9575 - val_f1: 0.9590\n",
      "Epoch 4136/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2911 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4137/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2441 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4138/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2704 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4139/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2870 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4140/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2563 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4141/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8718 - f1: 0.8889 - val_loss: 0.2556 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4142/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2558 - val_acc: 0.9656 - val_f1: 0.9661\n",
      "Epoch 4143/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2614 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 4144/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8752 - f1: 0.8911 - val_loss: 0.2697 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4145/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2492 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4146/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8662 - f1: 0.8842 - val_loss: 0.2388 - val_acc: 0.9609 - val_f1: 0.9624\n",
      "Epoch 4147/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2713 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4148/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8731 - f1: 0.8899 - val_loss: 0.2431 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4149/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8733 - f1: 0.8897 - val_loss: 0.2262 - val_acc: 0.9591 - val_f1: 0.9611\n",
      "Epoch 4150/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2374 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 4151/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2589 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4152/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8724 - f1: 0.8897 - val_loss: 0.2451 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4153/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2604 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4154/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8688 - f1: 0.8869 - val_loss: 0.2470 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4155/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2522 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 4156/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2538 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4157/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8675 - f1: 0.8855 - val_loss: 0.2376 - val_acc: 0.9653 - val_f1: 0.9671\n",
      "Epoch 4158/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2700 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4159/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8750 - f1: 0.8911 - val_loss: 0.2662 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4160/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8652 - f1: 0.8840 - val_loss: 0.2715 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4161/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8762 - f1: 0.8922 - val_loss: 0.2559 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 4162/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2564 - val_acc: 0.9609 - val_f1: 0.9621\n",
      "Epoch 4163/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8720 - f1: 0.8894 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4164/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2725 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4165/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8690 - f1: 0.8870 - val_loss: 0.2465 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4166/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8768 - f1: 0.8927 - val_loss: 0.2531 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4167/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8715 - f1: 0.8882 - val_loss: 0.2355 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4168/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2556 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4169/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2445 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 4170/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8865 - val_loss: 0.3111 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4171/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8649 - f1: 0.8838 - val_loss: 0.2660 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4172/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3421 - acc: 0.8630 - f1: 0.8820 - val_loss: 0.2476 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4173/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8785 - f1: 0.8940 - val_loss: 0.2512 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4174/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8694 - f1: 0.8868 - val_loss: 0.2580 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4175/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8725 - f1: 0.8894 - val_loss: 0.2393 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4176/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2415 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4177/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8711 - f1: 0.8881 - val_loss: 0.2459 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4178/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2748 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 4179/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8706 - f1: 0.8882 - val_loss: 0.2466 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4180/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2296 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4181/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8664 - f1: 0.8846 - val_loss: 0.2280 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4182/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2554 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4183/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8734 - f1: 0.8900 - val_loss: 0.2558 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4184/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8738 - f1: 0.8908 - val_loss: 0.2356 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4185/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2426 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4186/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8855 - val_loss: 0.2504 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4187/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3150 - acc: 0.8770 - f1: 0.8927 - val_loss: 0.2413 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4188/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8728 - f1: 0.8895 - val_loss: 0.2581 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4189/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2663 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4190/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2443 - val_acc: 0.9622 - val_f1: 0.9644\n",
      "Epoch 4191/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8720 - f1: 0.8886 - val_loss: 0.2667 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4192/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2534 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4193/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2527 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4194/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2502 - val_acc: 0.9675 - val_f1: 0.9693\n",
      "Epoch 4195/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2559 - val_acc: 0.9641 - val_f1: 0.9654\n",
      "Epoch 4196/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8732 - f1: 0.8903 - val_loss: 0.2408 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4197/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2619 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4198/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2642 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4199/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2456 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4200/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2517 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4201/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8752 - f1: 0.8913 - val_loss: 0.2400 - val_acc: 0.9663 - val_f1: 0.9680\n",
      "Epoch 4202/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2884 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4203/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8733 - f1: 0.8900 - val_loss: 0.2375 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4204/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8678 - f1: 0.8863 - val_loss: 0.2222 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4205/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2482 - val_acc: 0.9672 - val_f1: 0.9679\n",
      "Epoch 4206/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8771 - f1: 0.8932 - val_loss: 0.2551 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4207/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8683 - f1: 0.8857 - val_loss: 0.2668 - val_acc: 0.9647 - val_f1: 0.9655\n",
      "Epoch 4208/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8677 - f1: 0.8855 - val_loss: 0.2688 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4209/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8784 - f1: 0.8936 - val_loss: 0.2271 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4210/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2355 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4211/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8709 - f1: 0.8886 - val_loss: 0.2206 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4212/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3151 - acc: 0.8777 - f1: 0.8935 - val_loss: 0.2312 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 4213/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8896 - val_loss: 0.2644 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 4214/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2372 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4215/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2308 - val_acc: 0.9600 - val_f1: 0.9614\n",
      "Epoch 4216/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8730 - f1: 0.8900 - val_loss: 0.2192 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4217/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2343 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4218/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2442 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4219/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8745 - f1: 0.8913 - val_loss: 0.2331 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4220/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2603 - val_acc: 0.9691 - val_f1: 0.9701\n",
      "Epoch 4221/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8714 - f1: 0.8885 - val_loss: 0.2683 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4222/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2371 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4223/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.2372 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4224/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2738 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4225/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2276 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4226/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3234 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2313 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4227/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.3094 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4228/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8670 - f1: 0.8849 - val_loss: 0.2329 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4229/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2444 - val_acc: 0.9694 - val_f1: 0.9697\n",
      "Epoch 4230/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2610 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4231/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8751 - f1: 0.8918 - val_loss: 0.2588 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4232/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8661 - f1: 0.8838 - val_loss: 0.2495 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4233/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8741 - f1: 0.8908 - val_loss: 0.2620 - val_acc: 0.9688 - val_f1: 0.9698\n",
      "Epoch 4234/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2295 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4235/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3203 - acc: 0.8748 - f1: 0.89 - 0s 16us/sample - loss: 0.3184 - acc: 0.8756 - f1: 0.8921 - val_loss: 0.2449 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4236/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2532 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4237/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3282 - acc: 0.8695 - f1: 0.88 - 0s 16us/sample - loss: 0.3299 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2526 - val_acc: 0.9647 - val_f1: 0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4238/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2488 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4239/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8752 - f1: 0.8916 - val_loss: 0.2877 - val_acc: 0.9616 - val_f1: 0.9627\n",
      "Epoch 4240/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2735 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4241/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2385 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4242/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8768 - f1: 0.8929 - val_loss: 0.2438 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4243/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2427 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4244/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8692 - f1: 0.8868 - val_loss: 0.2282 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4245/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8686 - f1: 0.8861 - val_loss: 0.2672 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4246/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3363 - acc: 0.8649 - f1: 0.8835 - val_loss: 0.2355 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4247/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8707 - f1: 0.8883 - val_loss: 0.2475 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4248/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8701 - f1: 0.8874 - val_loss: 0.2445 - val_acc: 0.9681 - val_f1: 0.9695\n",
      "Epoch 4249/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3121 - acc: 0.8783 - f1: 0.8940 - val_loss: 0.2655 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4250/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2569 - val_acc: 0.9691 - val_f1: 0.9700\n",
      "Epoch 4251/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3206 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2376 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 4252/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3290 - acc: 0.8703 - f1: 0.88 - 0s 16us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8889 - val_loss: 0.2951 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 4253/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8689 - f1: 0.8863 - val_loss: 0.2490 - val_acc: 0.9609 - val_f1: 0.9620\n",
      "Epoch 4254/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2871 - val_acc: 0.9638 - val_f1: 0.9647\n",
      "Epoch 4255/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8735 - f1: 0.8902 - val_loss: 0.2713 - val_acc: 0.9638 - val_f1: 0.9645\n",
      "Epoch 4256/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8699 - f1: 0.8876 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4257/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8731 - f1: 0.8902 - val_loss: 0.2385 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4258/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2572 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4259/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3272 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2650 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4260/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2280 - val_acc: 0.9619 - val_f1: 0.9637\n",
      "Epoch 4261/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2581 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4262/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2598 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4263/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8875 - val_loss: 0.2695 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 4264/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8750 - f1: 0.8918 - val_loss: 0.2444 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4265/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3327 - acc: 0.8665 - f1: 0.8847 - val_loss: 0.2532 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4266/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8701 - f1: 0.8877 - val_loss: 0.2615 - val_acc: 0.9678 - val_f1: 0.9690\n",
      "Epoch 4267/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8874 - val_loss: 0.2673 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4268/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3340 - acc: 0.8683 - f1: 0.8857 - val_loss: 0.2505 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4269/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8722 - f1: 0.8895 - val_loss: 0.2936 - val_acc: 0.9638 - val_f1: 0.9634\n",
      "Epoch 4270/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2541 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4271/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8742 - f1: 0.8909 - val_loss: 0.2319 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4272/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3388 - acc: 0.8641 - f1: 0.8831 - val_loss: 0.2578 - val_acc: 0.9628 - val_f1: 0.9635\n",
      "Epoch 4273/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3320 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2332 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 4274/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2429 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4275/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4276/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8708 - f1: 0.8882 - val_loss: 0.2567 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4277/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2635 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4278/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8765 - f1: 0.8924 - val_loss: 0.2485 - val_acc: 0.9675 - val_f1: 0.9690\n",
      "Epoch 4279/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2644 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4280/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8686 - f1: 0.8864 - val_loss: 0.2337 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4281/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8720 - f1: 0.8889 - val_loss: 0.2576 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4282/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3362 - acc: 0.8643 - f1: 0.8832 - val_loss: 0.2516 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4283/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2322 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4284/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8689 - f1: 0.8865 - val_loss: 0.2289 - val_acc: 0.9650 - val_f1: 0.9663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4285/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8669 - f1: 0.8851 - val_loss: 0.2455 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 4286/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2415 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4287/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2334 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 4288/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2854 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4289/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8732 - f1: 0.8898 - val_loss: 0.2651 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4290/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2565 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4291/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3227 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2470 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4292/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8675 - f1: 0.8856 - val_loss: 0.2440 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4293/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3208 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2414 - val_acc: 0.9684 - val_f1: 0.9701\n",
      "Epoch 4294/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3407 - acc: 0.8647 - f1: 0.8832 - val_loss: 0.2330 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 4295/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3297 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2250 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4296/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8680 - f1: 0.8858 - val_loss: 0.2684 - val_acc: 0.9619 - val_f1: 0.9628\n",
      "Epoch 4297/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2549 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4298/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3316 - acc: 0.8682 - f1: 0.8861 - val_loss: 0.2365 - val_acc: 0.9619 - val_f1: 0.9627\n",
      "Epoch 4299/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8659 - f1: 0.8844 - val_loss: 0.2509 - val_acc: 0.9672 - val_f1: 0.9686\n",
      "Epoch 4300/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8900 - val_loss: 0.2681 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4301/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2364 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 4302/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2626 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4303/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3231 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2704 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4304/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8716 - f1: 0.8888 - val_loss: 0.2592 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4305/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8752 - f1: 0.8910 - val_loss: 0.2512 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4306/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8735 - f1: 0.8900 - val_loss: 0.2711 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4307/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3159 - acc: 0.8767 - f1: 0.8931 - val_loss: 0.2369 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4308/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2403 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4309/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2520 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4310/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3182 - acc: 0.8758 - f1: 0.8920 - val_loss: 0.2578 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4311/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2393 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4312/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2233 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4313/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8713 - f1: 0.88 - 0s 16us/sample - loss: 0.3224 - acc: 0.8732 - f1: 0.8901 - val_loss: 0.2778 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4314/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8683 - f1: 0.8865 - val_loss: 0.2309 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4315/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8771 - f1: 0.8933 - val_loss: 0.2545 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4316/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2480 - val_acc: 0.9625 - val_f1: 0.9633\n",
      "Epoch 4317/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2322 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4318/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2607 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4319/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8739 - f1: 0.8905 - val_loss: 0.2534 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4320/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3342 - acc: 0.8665 - f1: 0.8848 - val_loss: 0.2499 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4321/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3387 - acc: 0.8643 - f1: 0.8833 - val_loss: 0.2716 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4322/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8657 - f1: 0.8840 - val_loss: 0.2375 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4323/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3239 - acc: 0.8734 - f1: 0.8899 - val_loss: 0.2586 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4324/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8881 - val_loss: 0.2440 - val_acc: 0.9600 - val_f1: 0.9612\n",
      "Epoch 4325/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2364 - val_acc: 0.9628 - val_f1: 0.9648\n",
      "Epoch 4326/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2620 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4327/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8691 - f1: 0.8868 - val_loss: 0.2351 - val_acc: 0.9619 - val_f1: 0.9626\n",
      "Epoch 4328/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3334 - acc: 0.8672 - f1: 0.8856 - val_loss: 0.2307 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4329/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3282 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2360 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 4330/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3296 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2483 - val_acc: 0.9613 - val_f1: 0.9625\n",
      "Epoch 4331/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8767 - f1: 0.8928 - val_loss: 0.2538 - val_acc: 0.9647 - val_f1: 0.9660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4332/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3215 - acc: 0.8744 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9588 - val_f1: 0.9611\n",
      "Epoch 4333/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2555 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4334/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2409 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4335/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2438 - val_acc: 0.9609 - val_f1: 0.9626\n",
      "Epoch 4336/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8759 - f1: 0.8923 - val_loss: 0.2776 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4337/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2565 - val_acc: 0.9628 - val_f1: 0.9639\n",
      "Epoch 4338/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2630 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4339/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2719 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 4340/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8683 - f1: 0.8862 - val_loss: 0.2544 - val_acc: 0.9650 - val_f1: 0.9666\n",
      "Epoch 4341/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2518 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4342/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2489 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4343/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2397 - val_acc: 0.9616 - val_f1: 0.9631\n",
      "Epoch 4344/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2567 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4345/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2714 - val_acc: 0.9672 - val_f1: 0.9689\n",
      "Epoch 4346/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2287 - val_acc: 0.9531 - val_f1: 0.9561\n",
      "Epoch 4347/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3474 - acc: 0.8612 - f1: 0.8803 - val_loss: 0.2480 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4348/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8670 - f1: 0.8852 - val_loss: 0.2423 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4349/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8670 - f1: 0.8855 - val_loss: 0.2719 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4350/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8910 - val_loss: 0.2976 - val_acc: 0.9644 - val_f1: 0.9645\n",
      "Epoch 4351/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2613 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4352/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2644 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4353/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8880 - val_loss: 0.2632 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4354/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2485 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4355/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8740 - f1: 0.8904 - val_loss: 0.2655 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4356/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2561 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4357/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3271 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2584 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4358/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2596 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4359/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3251 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2458 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4360/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3241 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2382 - val_acc: 0.9634 - val_f1: 0.9656\n",
      "Epoch 4361/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3202 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2638 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4362/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3311 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2707 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 4363/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3246 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2626 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 4364/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2754 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4365/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3244 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2548 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4366/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2354 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 4367/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2406 - val_acc: 0.9628 - val_f1: 0.9631\n",
      "Epoch 4368/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3236 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2618 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4369/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3216 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2534 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 4370/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3267 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2594 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 4371/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8692 - f1: 0.8871 - val_loss: 0.3016 - val_acc: 0.9625 - val_f1: 0.9637\n",
      "Epoch 4372/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2535 - val_acc: 0.9675 - val_f1: 0.9689\n",
      "Epoch 4373/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3379 - acc: 0.8657 - f1: 0.8839 - val_loss: 0.2541 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4374/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2530 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4375/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3255 - acc: 0.8707 - f1: 0.8882 - val_loss: 0.3054 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4376/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2835 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4377/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2603 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4378/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8735 - f1: 0.8896 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4379/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2325 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 4380/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8687 - f1: 0.8864 - val_loss: 0.2580 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4381/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2672 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4382/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8722 - f1: 0.8888 - val_loss: 0.2360 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4383/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8718 - f1: 0.8888 - val_loss: 0.2520 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4384/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3417 - acc: 0.8652 - f1: 0.8834 - val_loss: 0.2308 - val_acc: 0.9628 - val_f1: 0.9642\n",
      "Epoch 4385/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2434 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4386/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3320 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2302 - val_acc: 0.9631 - val_f1: 0.9648\n",
      "Epoch 4387/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8675 - f1: 0.8858 - val_loss: 0.2520 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4388/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8745 - f1: 0.8914 - val_loss: 0.2328 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4389/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2502 - val_acc: 0.9684 - val_f1: 0.9698\n",
      "Epoch 4390/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8753 - f1: 0.8917 - val_loss: 0.2380 - val_acc: 0.9666 - val_f1: 0.9680\n",
      "Epoch 4391/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2536 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4392/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8721 - f1: 0.8892 - val_loss: 0.2469 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4393/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2777 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4394/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3218 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2485 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4395/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3188 - acc: 0.8755 - f1: 0.8913 - val_loss: 0.2502 - val_acc: 0.9678 - val_f1: 0.9681\n",
      "Epoch 4396/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3248 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2346 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4397/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8741 - f1: 0.8903 - val_loss: 0.2499 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4398/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3110 - acc: 0.8795 - f1: 0.8949 - val_loss: 0.2642 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4399/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2517 - val_acc: 0.9647 - val_f1: 0.9662\n",
      "Epoch 4400/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8742 - f1: 0.8905 - val_loss: 0.2638 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4401/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8698 - f1: 0.8868 - val_loss: 0.2637 - val_acc: 0.9666 - val_f1: 0.9673\n",
      "Epoch 4402/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3305 - acc: 0.8680 - f1: 0.8865 - val_loss: 0.2768 - val_acc: 0.9581 - val_f1: 0.9590\n",
      "Epoch 4403/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8689 - f1: 0.8871 - val_loss: 0.2738 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4404/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8727 - f1: 0.8897 - val_loss: 0.2825 - val_acc: 0.9650 - val_f1: 0.9653\n",
      "Epoch 4405/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3355 - acc: 0.8666 - f1: 0.8845 - val_loss: 0.2433 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4406/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2562 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4407/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3165 - acc: 0.8765 - f1: 0.8928 - val_loss: 0.2463 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4408/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2390 - val_acc: 0.9631 - val_f1: 0.9643\n",
      "Epoch 4409/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3207 - acc: 0.8745 - f1: 0.8906 - val_loss: 0.2412 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4410/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2536 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4411/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3228 - acc: 0.8729 - f1: 0.8900 - val_loss: 0.2601 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4412/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3134 - acc: 0.8785 - f1: 0.8945 - val_loss: 0.2684 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4413/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3251 - acc: 0.8719 - f1: 0.88 - 0s 16us/sample - loss: 0.3292 - acc: 0.8693 - f1: 0.8867 - val_loss: 0.2419 - val_acc: 0.9584 - val_f1: 0.9603\n",
      "Epoch 4414/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3372 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2221 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4415/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3270 - acc: 0.8717 - f1: 0.8888 - val_loss: 0.2444 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4416/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2497 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4417/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3314 - acc: 0.8679 - f1: 0.8862 - val_loss: 0.2721 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4418/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2547 - val_acc: 0.9619 - val_f1: 0.9622\n",
      "Epoch 4419/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3230 - acc: 0.8736 - f1: 0.89 - 0s 16us/sample - loss: 0.3248 - acc: 0.8722 - f1: 0.8887 - val_loss: 0.2462 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4420/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3263 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2500 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4421/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2413 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4422/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3302 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2792 - val_acc: 0.9606 - val_f1: 0.9617\n",
      "Epoch 4423/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8886 - val_loss: 0.2518 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4424/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3242 - acc: 0.8724 - f1: 0.8890 - val_loss: 0.2233 - val_acc: 0.9625 - val_f1: 0.9643\n",
      "Epoch 4425/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3278 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2249 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4426/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2826 - val_acc: 0.9634 - val_f1: 0.9639\n",
      "Epoch 4427/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2544 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4428/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8739 - f1: 0.8906 - val_loss: 0.2467 - val_acc: 0.9634 - val_f1: 0.9654\n",
      "Epoch 4429/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8684 - f1: 0.8866 - val_loss: 0.2285 - val_acc: 0.9566 - val_f1: 0.9584\n",
      "Epoch 4430/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2770 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 4431/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3166 - acc: 0.8758 - f1: 0.8923 - val_loss: 0.2742 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 4432/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8666 - f1: 0.8850 - val_loss: 0.2360 - val_acc: 0.9634 - val_f1: 0.9655\n",
      "Epoch 4433/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3309 - acc: 0.8695 - f1: 0.8876 - val_loss: 0.2383 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4434/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8703 - f1: 0.8873 - val_loss: 0.2534 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4435/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8902 - val_loss: 0.2645 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4436/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8719 - f1: 0.8893 - val_loss: 0.2376 - val_acc: 0.9656 - val_f1: 0.9666\n",
      "Epoch 4437/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8703 - f1: 0.8878 - val_loss: 0.2479 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4438/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2827 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4439/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8719 - f1: 0.8887 - val_loss: 0.2727 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4440/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8688 - f1: 0.8863 - val_loss: 0.2367 - val_acc: 0.9653 - val_f1: 0.9672\n",
      "Epoch 4441/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8727 - f1: 0.8895 - val_loss: 0.2547 - val_acc: 0.9613 - val_f1: 0.9629\n",
      "Epoch 4442/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8689 - f1: 0.8866 - val_loss: 0.2402 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4443/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2538 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4444/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8691 - f1: 0.8872 - val_loss: 0.2435 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 4445/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2505 - val_acc: 0.9684 - val_f1: 0.9691\n",
      "Epoch 4446/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3172 - acc: 0.8761 - f1: 0.8925 - val_loss: 0.2510 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4447/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3344 - acc: 0.8666 - f1: 0.8847 - val_loss: 0.2763 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4448/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3263 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2789 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4449/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8684 - f1: 0.8859 - val_loss: 0.2650 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4450/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3328 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2487 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4451/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8717 - f1: 0.8889 - val_loss: 0.2535 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4452/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8700 - f1: 0.8873 - val_loss: 0.2582 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4453/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8715 - f1: 0.8886 - val_loss: 0.2577 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4454/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8694 - f1: 0.8871 - val_loss: 0.2782 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4455/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2425 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4456/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2281 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4457/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8693 - f1: 0.8862 - val_loss: 0.2411 - val_acc: 0.9697 - val_f1: 0.9706\n",
      "Epoch 4458/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2553 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4459/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3367 - acc: 0.8642 - f1: 0.8830 - val_loss: 0.2291 - val_acc: 0.9575 - val_f1: 0.9592\n",
      "Epoch 4460/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2676 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4461/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2444 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4462/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2540 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4463/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2445 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4464/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8712 - f1: 0.8883 - val_loss: 0.2392 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 4465/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2506 - val_acc: 0.9653 - val_f1: 0.9665\n",
      "Epoch 4466/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8755 - f1: 0.8922 - val_loss: 0.2704 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4467/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8670 - f1: 0.8856 - val_loss: 0.2456 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4468/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8888 - val_loss: 0.2466 - val_acc: 0.9625 - val_f1: 0.9636\n",
      "Epoch 4469/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8713 - f1: 0.8883 - val_loss: 0.2459 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4470/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8882 - val_loss: 0.2293 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4471/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8765 - f1: 0.8925 - val_loss: 0.2755 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4472/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2344 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4473/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2494 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4474/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2421 - val_acc: 0.9553 - val_f1: 0.9572\n",
      "Epoch 4475/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2465 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4476/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8719 - f1: 0.8888 - val_loss: 0.2746 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4477/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2385 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4478/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2422 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4479/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2591 - val_acc: 0.9678 - val_f1: 0.9686\n",
      "Epoch 4480/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8855 - val_loss: 0.2386 - val_acc: 0.9581 - val_f1: 0.9605\n",
      "Epoch 4481/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8685 - f1: 0.8863 - val_loss: 0.2351 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4482/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8777 - f1: 0.8936 - val_loss: 0.2633 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4483/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8747 - f1: 0.8914 - val_loss: 0.2482 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4484/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2411 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4485/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3138 - acc: 0.8782 - f1: 0.8938 - val_loss: 0.2247 - val_acc: 0.9656 - val_f1: 0.9673\n",
      "Epoch 4486/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2658 - val_acc: 0.9681 - val_f1: 0.9685\n",
      "Epoch 4487/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8707 - f1: 0.8884 - val_loss: 0.2458 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4488/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2387 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4489/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2291 - val_acc: 0.9628 - val_f1: 0.9644\n",
      "Epoch 4490/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2316 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4491/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2399 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4492/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8745 - f1: 0.8907 - val_loss: 0.2244 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 4493/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2121 - val_acc: 0.9616 - val_f1: 0.9634\n",
      "Epoch 4494/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8727 - f1: 0.8894 - val_loss: 0.2259 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4495/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8697 - f1: 0.8875 - val_loss: 0.2207 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4496/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8747 - f1: 0.8910 - val_loss: 0.2324 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4497/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2365 - val_acc: 0.9556 - val_f1: 0.9582\n",
      "Epoch 4498/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3463 - acc: 0.8624 - f1: 0.8815 - val_loss: 0.2593 - val_acc: 0.9594 - val_f1: 0.9601\n",
      "Epoch 4499/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3423 - acc: 0.8627 - f1: 0.8820 - val_loss: 0.2469 - val_acc: 0.9653 - val_f1: 0.9656\n",
      "Epoch 4500/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2363 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4501/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8694 - f1: 0.8867 - val_loss: 0.2364 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4502/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8708 - f1: 0.8883 - val_loss: 0.2542 - val_acc: 0.9675 - val_f1: 0.9687\n",
      "Epoch 4503/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2581 - val_acc: 0.9659 - val_f1: 0.9665\n",
      "Epoch 4504/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8736 - f1: 0.8904 - val_loss: 0.2608 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 4505/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8879 - val_loss: 0.2505 - val_acc: 0.9650 - val_f1: 0.9654\n",
      "Epoch 4506/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3220 - acc: 0.8732 - f1: 0.8904 - val_loss: 0.2528 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4507/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8717 - f1: 0.8887 - val_loss: 0.2525 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4508/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3300 - acc: 0.8687 - f1: 0.8860 - val_loss: 0.2484 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4509/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8695 - f1: 0.8872 - val_loss: 0.2477 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4510/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8700 - f1: 0.8877 - val_loss: 0.2449 - val_acc: 0.9616 - val_f1: 0.9633\n",
      "Epoch 4511/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2490 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4512/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8713 - f1: 0.8880 - val_loss: 0.2582 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4513/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2732 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4514/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8730 - f1: 0.8897 - val_loss: 0.2397 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4515/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8703 - f1: 0.8877 - val_loss: 0.2359 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4516/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8691 - f1: 0.8860 - val_loss: 0.2448 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4517/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3243 - acc: 0.8716 - f1: 0.8891 - val_loss: 0.2470 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4518/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2408 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4519/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8857 - val_loss: 0.2528 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4520/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8726 - f1: 0.8897 - val_loss: 0.2833 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4521/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3375 - acc: 0.8650 - f1: 0.8836 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4522/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3279 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2677 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4523/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2455 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4524/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2711 - val_acc: 0.9672 - val_f1: 0.9683\n",
      "Epoch 4525/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8669 - f1: 0.8857 - val_loss: 0.2624 - val_acc: 0.9669 - val_f1: 0.9683\n",
      "Epoch 4526/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2416 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4527/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8749 - f1: 0.8908 - val_loss: 0.2486 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4528/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8747 - f1: 0.8911 - val_loss: 0.2461 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4529/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8880 - val_loss: 0.2611 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4530/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8692 - f1: 0.8867 - val_loss: 0.2311 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4531/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2340 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4532/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8736 - f1: 0.8901 - val_loss: 0.2305 - val_acc: 0.9694 - val_f1: 0.9701\n",
      "Epoch 4533/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2410 - val_acc: 0.9653 - val_f1: 0.9670\n",
      "Epoch 4534/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2321 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4535/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8755 - f1: 0.8921 - val_loss: 0.2366 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4536/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2638 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 4537/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3185 - acc: 0.8752 - f1: 0.8917 - val_loss: 0.2180 - val_acc: 0.9588 - val_f1: 0.9608\n",
      "Epoch 4538/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2674 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4539/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8732 - f1: 0.8894 - val_loss: 0.2621 - val_acc: 0.9638 - val_f1: 0.9652\n",
      "Epoch 4540/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8705 - f1: 0.8883 - val_loss: 0.2575 - val_acc: 0.9666 - val_f1: 0.9671\n",
      "Epoch 4541/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2541 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4542/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2897 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4543/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.3624 - val_acc: 0.9597 - val_f1: 0.9599\n",
      "Epoch 4544/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8692 - f1: 0.8866 - val_loss: 0.2527 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4545/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2398 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4546/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3325 - acc: 0.8701 - f1: 0.8879 - val_loss: 0.2297 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4547/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8684 - f1: 0.8864 - val_loss: 0.2504 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4548/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2468 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4549/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8762 - f1: 0.8924 - val_loss: 0.2559 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4550/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8664 - f1: 0.8847 - val_loss: 0.2234 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4551/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8678 - f1: 0.8855 - val_loss: 0.2442 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4552/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2434 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4553/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2382 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4554/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3373 - acc: 0.8663 - f1: 0.8845 - val_loss: 0.2547 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4555/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2498 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 4556/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2491 - val_acc: 0.9663 - val_f1: 0.9671\n",
      "Epoch 4557/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8696 - f1: 0.8873 - val_loss: 0.2458 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4558/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2706 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4559/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2576 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4560/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8733 - f1: 0.8898 - val_loss: 0.2392 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4561/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8747 - f1: 0.8916 - val_loss: 0.3016 - val_acc: 0.9634 - val_f1: 0.9640\n",
      "Epoch 4562/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8690 - f1: 0.8869 - val_loss: 0.2359 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4563/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2495 - val_acc: 0.9678 - val_f1: 0.9691\n",
      "Epoch 4564/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3359 - acc: 0.8655 - f1: 0.8842 - val_loss: 0.2648 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 4565/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8764 - f1: 0.8927 - val_loss: 0.2420 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4566/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8730 - f1: 0.8901 - val_loss: 0.2442 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 4567/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2421 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4568/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8729 - f1: 0.8896 - val_loss: 0.2428 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4569/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2293 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4570/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2521 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4571/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8718 - f1: 0.8894 - val_loss: 0.2268 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4572/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2455 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4573/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8702 - f1: 0.8881 - val_loss: 0.2492 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4574/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8722 - f1: 0.8891 - val_loss: 0.2462 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4575/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8759 - f1: 0.8925 - val_loss: 0.2571 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4576/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8721 - f1: 0.8890 - val_loss: 0.2767 - val_acc: 0.9675 - val_f1: 0.9679\n",
      "Epoch 4577/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2455 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4578/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8897 - val_loss: 0.2392 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4579/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8707 - f1: 0.8885 - val_loss: 0.2412 - val_acc: 0.9609 - val_f1: 0.9630\n",
      "Epoch 4580/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8693 - f1: 0.8870 - val_loss: 0.2362 - val_acc: 0.9644 - val_f1: 0.9659\n",
      "Epoch 4581/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8718 - f1: 0.8890 - val_loss: 0.2386 - val_acc: 0.9631 - val_f1: 0.9647\n",
      "Epoch 4582/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2539 - val_acc: 0.9628 - val_f1: 0.9638\n",
      "Epoch 4583/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8874 - val_loss: 0.3021 - val_acc: 0.9613 - val_f1: 0.9617\n",
      "Epoch 4584/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8887 - val_loss: 0.2325 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4585/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3164 - acc: 0.8770 - f1: 0.8934 - val_loss: 0.2933 - val_acc: 0.9638 - val_f1: 0.9642\n",
      "Epoch 4586/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2561 - val_acc: 0.9650 - val_f1: 0.9661\n",
      "Epoch 4587/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2473 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4588/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2578 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4589/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8713 - f1: 0.8886 - val_loss: 0.2761 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4590/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8718 - f1: 0.8895 - val_loss: 0.2854 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4591/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8665 - f1: 0.8849 - val_loss: 0.2574 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4592/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8670 - f1: 0.8853 - val_loss: 0.2701 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 4593/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8703 - f1: 0.8879 - val_loss: 0.2822 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 4594/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8733 - f1: 0.8903 - val_loss: 0.2466 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4595/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2490 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4596/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8678 - f1: 0.8860 - val_loss: 0.2447 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4597/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8715 - f1: 0.8883 - val_loss: 0.2654 - val_acc: 0.9669 - val_f1: 0.9674\n",
      "Epoch 4598/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3305 - acc: 0.8684 - f1: 0.8860 - val_loss: 0.2745 - val_acc: 0.9559 - val_f1: 0.9578\n",
      "Epoch 4599/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3315 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2702 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4600/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8759 - f1: 0.8923 - val_loss: 0.2761 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4601/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8689 - f1: 0.8867 - val_loss: 0.2673 - val_acc: 0.9619 - val_f1: 0.9631\n",
      "Epoch 4602/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8701 - f1: 0.8880 - val_loss: 0.2562 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4603/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2542 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4604/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8721 - f1: 0.8893 - val_loss: 0.2539 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4605/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3208 - acc: 0.8741 - f1: 0.8909 - val_loss: 0.2543 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4606/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8743 - f1: 0.8907 - val_loss: 0.2710 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4607/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2589 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4608/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3174 - acc: 0.8770 - f1: 0.8931 - val_loss: 0.2539 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4609/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3197 - acc: 0.8748 - f1: 0.8916 - val_loss: 0.2606 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4610/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3141 - acc: 0.8780 - f1: 0.8942 - val_loss: 0.2601 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4611/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2959 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 4612/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3326 - acc: 0.8675 - f1: 0.8850 - val_loss: 0.2523 - val_acc: 0.9606 - val_f1: 0.9621\n",
      "Epoch 4613/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3156 - acc: 0.8776 - f1: 0.8935 - val_loss: 0.2713 - val_acc: 0.9678 - val_f1: 0.9694\n",
      "Epoch 4614/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3335 - acc: 0.8671 - f1: 0.8853 - val_loss: 0.2453 - val_acc: 0.9650 - val_f1: 0.9667\n",
      "Epoch 4615/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3206 - acc: 0.8738 - f1: 0.8902 - val_loss: 0.2632 - val_acc: 0.9666 - val_f1: 0.9672\n",
      "Epoch 4616/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8698 - f1: 0.8877 - val_loss: 0.2626 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4617/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8738 - f1: 0.8907 - val_loss: 0.2671 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4618/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2565 - val_acc: 0.9638 - val_f1: 0.9656\n",
      "Epoch 4619/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2400 - val_acc: 0.9669 - val_f1: 0.9681\n",
      "Epoch 4620/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8727 - f1: 0.8893 - val_loss: 0.2423 - val_acc: 0.9647 - val_f1: 0.9664\n",
      "Epoch 4621/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3300 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2652 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 4622/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3183 - acc: 0.8749 - f1: 0.8915 - val_loss: 0.2599 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4623/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8674 - f1: 0.8857 - val_loss: 0.2822 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4624/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2413 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4625/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2652 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 4626/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8718 - f1: 0.8896 - val_loss: 0.2459 - val_acc: 0.9656 - val_f1: 0.9664\n",
      "Epoch 4627/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3179 - acc: 0.8752 - f1: 0.8915 - val_loss: 0.2685 - val_acc: 0.9669 - val_f1: 0.9679\n",
      "Epoch 4628/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8699 - f1: 0.8874 - val_loss: 0.2602 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4629/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2573 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4630/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8710 - f1: 0.8884 - val_loss: 0.2688 - val_acc: 0.9641 - val_f1: 0.9644\n",
      "Epoch 4631/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8713 - f1: 0.8890 - val_loss: 0.2314 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4632/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2497 - val_acc: 0.9625 - val_f1: 0.9641\n",
      "Epoch 4633/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8676 - f1: 0.8854 - val_loss: 0.2669 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4634/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8686 - f1: 0.8865 - val_loss: 0.2740 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4635/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8723 - f1: 0.8890 - val_loss: 0.2109 - val_acc: 0.9644 - val_f1: 0.9652\n",
      "Epoch 4636/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3313 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2609 - val_acc: 0.9663 - val_f1: 0.9678\n",
      "Epoch 4637/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8704 - f1: 0.8878 - val_loss: 0.2694 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4638/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8760 - f1: 0.8923 - val_loss: 0.2640 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 4639/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2625 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4640/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2664 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4641/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3155 - acc: 0.8772 - f1: 0.8935 - val_loss: 0.2637 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4642/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8866 - val_loss: 0.3037 - val_acc: 0.9638 - val_f1: 0.9640\n",
      "Epoch 4643/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2721 - val_acc: 0.9641 - val_f1: 0.9650\n",
      "Epoch 4644/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2904 - val_acc: 0.9669 - val_f1: 0.9670\n",
      "Epoch 4645/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3294 - acc: 0.8688 - f1: 0.8865 - val_loss: 0.2740 - val_acc: 0.9647 - val_f1: 0.9654\n",
      "Epoch 4646/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8725 - f1: 0.8892 - val_loss: 0.2704 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4647/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8742 - f1: 0.8910 - val_loss: 0.2760 - val_acc: 0.9675 - val_f1: 0.9682\n",
      "Epoch 4648/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8718 - f1: 0.8891 - val_loss: 0.2670 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4649/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8667 - f1: 0.8846 - val_loss: 0.2391 - val_acc: 0.9597 - val_f1: 0.9615\n",
      "Epoch 4650/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8725 - f1: 0.8895 - val_loss: 0.2423 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4651/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3295 - acc: 0.8687 - f1: 0.8869 - val_loss: 0.2645 - val_acc: 0.9656 - val_f1: 0.9662\n",
      "Epoch 4652/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3248 - acc: 0.8712 - f1: 0.8886 - val_loss: 0.2581 - val_acc: 0.9656 - val_f1: 0.9665\n",
      "Epoch 4653/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3269 - acc: 0.8698 - f1: 0.8871 - val_loss: 0.2678 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4654/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3160 - acc: 0.8768 - f1: 0.8929 - val_loss: 0.2461 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4655/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3170 - acc: 0.8758 - f1: 0.8919 - val_loss: 0.2644 - val_acc: 0.9663 - val_f1: 0.9667\n",
      "Epoch 4656/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8693 - f1: 0.8872 - val_loss: 0.2323 - val_acc: 0.9603 - val_f1: 0.9620\n",
      "Epoch 4657/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2297 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 4658/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3441 - acc: 0.8620 - f1: 0.8815 - val_loss: 0.2635 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4659/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8680 - f1: 0.8862 - val_loss: 0.2780 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4660/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2491 - val_acc: 0.9625 - val_f1: 0.9642\n",
      "Epoch 4661/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8730 - f1: 0.8896 - val_loss: 0.2335 - val_acc: 0.9663 - val_f1: 0.9673\n",
      "Epoch 4662/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8736 - f1: 0.8905 - val_loss: 0.2571 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 4663/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8704 - f1: 0.8874 - val_loss: 0.2327 - val_acc: 0.9625 - val_f1: 0.9635\n",
      "Epoch 4664/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2702 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4665/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8709 - f1: 0.8880 - val_loss: 0.2417 - val_acc: 0.9684 - val_f1: 0.9687\n",
      "Epoch 4666/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8691 - f1: 0.8871 - val_loss: 0.2475 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4667/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3223 - acc: 0.8731 - f1: 0.8906 - val_loss: 0.2390 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4668/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3162 - acc: 0.8766 - f1: 0.8929 - val_loss: 0.2650 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4669/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8725 - f1: 0.8893 - val_loss: 0.2728 - val_acc: 0.9647 - val_f1: 0.9651\n",
      "Epoch 4670/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8699 - f1: 0.8875 - val_loss: 0.2550 - val_acc: 0.9641 - val_f1: 0.9645\n",
      "Epoch 4671/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2359 - val_acc: 0.9600 - val_f1: 0.9617\n",
      "Epoch 4672/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8702 - f1: 0.8875 - val_loss: 0.2542 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4673/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8753 - f1: 0.8918 - val_loss: 0.2485 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4674/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8698 - f1: 0.8874 - val_loss: 0.2516 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4675/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8678 - f1: 0.8863 - val_loss: 0.2483 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4676/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8732 - f1: 0.8900 - val_loss: 0.2864 - val_acc: 0.9681 - val_f1: 0.9690\n",
      "Epoch 4677/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3182 - acc: 0.8759 - f1: 0.8919 - val_loss: 0.2641 - val_acc: 0.9625 - val_f1: 0.9638\n",
      "Epoch 4678/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3337 - acc: 0.8678 - f1: 0.8856 - val_loss: 0.2421 - val_acc: 0.9659 - val_f1: 0.9670\n",
      "Epoch 4679/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8729 - f1: 0.8897 - val_loss: 0.2573 - val_acc: 0.9653 - val_f1: 0.9660\n",
      "Epoch 4680/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8729 - f1: 0.8898 - val_loss: 0.2836 - val_acc: 0.9606 - val_f1: 0.9619\n",
      "Epoch 4681/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8702 - f1: 0.8873 - val_loss: 0.2384 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4682/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3283 - acc: 0.8691 - f1: 0.8869 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4683/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8705 - f1: 0.8876 - val_loss: 0.2432 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4684/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2260 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4685/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8690 - f1: 0.8867 - val_loss: 0.2529 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4686/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8722 - f1: 0.8890 - val_loss: 0.2966 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4687/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8737 - f1: 0.8902 - val_loss: 0.2678 - val_acc: 0.9647 - val_f1: 0.9663\n",
      "Epoch 4688/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2519 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4689/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3099 - acc: 0.8804 - f1: 0.8959 - val_loss: 0.2465 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4690/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2811 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4691/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8700 - f1: 0.8872 - val_loss: 0.2709 - val_acc: 0.9663 - val_f1: 0.9668\n",
      "Epoch 4692/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8740 - f1: 0.8908 - val_loss: 0.2424 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4693/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3333 - acc: 0.8668 - f1: 0.8853 - val_loss: 0.2378 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4694/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2698 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4695/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2683 - val_acc: 0.9650 - val_f1: 0.9664\n",
      "Epoch 4696/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8733 - f1: 0.8902 - val_loss: 0.2461 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4697/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8703 - f1: 0.8872 - val_loss: 0.2912 - val_acc: 0.9622 - val_f1: 0.9632\n",
      "Epoch 4698/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3348 - acc: 0.8666 - f1: 0.8852 - val_loss: 0.2293 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4699/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8699 - f1: 0.8878 - val_loss: 0.2494 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4700/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8691 - f1: 0.8865 - val_loss: 0.2253 - val_acc: 0.9597 - val_f1: 0.9613\n",
      "Epoch 4701/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3260 - acc: 0.8708 - f1: 0.8881 - val_loss: 0.2522 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4702/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8711 - f1: 0.8886 - val_loss: 0.2430 - val_acc: 0.9663 - val_f1: 0.9670\n",
      "Epoch 4703/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8717 - f1: 0.8892 - val_loss: 0.2489 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4704/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2389 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4705/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2548 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4706/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3278 - acc: 0.8702 - f1: 0.8877 - val_loss: 0.2300 - val_acc: 0.9669 - val_f1: 0.9685\n",
      "Epoch 4707/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2366 - val_acc: 0.9594 - val_f1: 0.9613\n",
      "Epoch 4708/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3322 - acc: 0.8690 - f1: 0.8868 - val_loss: 0.2607 - val_acc: 0.9663 - val_f1: 0.9677\n",
      "Epoch 4709/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3201 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2574 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4710/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2550 - val_acc: 0.9638 - val_f1: 0.9649\n",
      "Epoch 4711/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8733 - f1: 0.8901 - val_loss: 0.2554 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4712/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8724 - f1: 0.8896 - val_loss: 0.2865 - val_acc: 0.9644 - val_f1: 0.9655\n",
      "Epoch 4713/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8711 - f1: 0.8888 - val_loss: 0.2449 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4714/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8866 - val_loss: 0.2368 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4715/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8712 - f1: 0.8880 - val_loss: 0.2412 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4716/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8662 - f1: 0.8846 - val_loss: 0.2382 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4717/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8687 - f1: 0.8862 - val_loss: 0.2439 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4718/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8731 - f1: 0.8902 - val_loss: 0.2640 - val_acc: 0.9684 - val_f1: 0.9693\n",
      "Epoch 4719/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3232 - acc: 0.8727 - f1: 0.8888 - val_loss: 0.2404 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4720/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3203 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2544 - val_acc: 0.9634 - val_f1: 0.9651\n",
      "Epoch 4721/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3262 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2575 - val_acc: 0.9650 - val_f1: 0.9658\n",
      "Epoch 4722/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8720 - f1: 0.8890 - val_loss: 0.2716 - val_acc: 0.9663 - val_f1: 0.9669\n",
      "Epoch 4723/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8754 - f1: 0.8915 - val_loss: 0.2494 - val_acc: 0.9616 - val_f1: 0.9632\n",
      "Epoch 4724/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3350 - acc: 0.8663 - f1: 0.8850 - val_loss: 0.2428 - val_acc: 0.9672 - val_f1: 0.9684\n",
      "Epoch 4725/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2507 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4726/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3327 - acc: 0.8677 - f1: 0.8859 - val_loss: 0.2465 - val_acc: 0.9622 - val_f1: 0.9638\n",
      "Epoch 4727/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8724 - f1: 0.8894 - val_loss: 0.2306 - val_acc: 0.9497 - val_f1: 0.9530\n",
      "Epoch 4728/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3250 - acc: 0.8715 - f1: 0.8888 - val_loss: 0.2535 - val_acc: 0.9653 - val_f1: 0.9661\n",
      "Epoch 4729/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8909 - val_loss: 0.2344 - val_acc: 0.9659 - val_f1: 0.9675\n",
      "Epoch 4730/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8873 - val_loss: 0.2333 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 4731/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3202 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2683 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4732/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8697 - f1: 0.8877 - val_loss: 0.2828 - val_acc: 0.9628 - val_f1: 0.9634\n",
      "Epoch 4733/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3212 - acc: 0.8743 - f1: 0.8912 - val_loss: 0.2525 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4734/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3167 - acc: 0.8761 - f1: 0.8919 - val_loss: 0.2774 - val_acc: 0.9688 - val_f1: 0.9696\n",
      "Epoch 4735/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8717 - f1: 0.8891 - val_loss: 0.2811 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4736/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8748 - f1: 0.8912 - val_loss: 0.2463 - val_acc: 0.9644 - val_f1: 0.9657\n",
      "Epoch 4737/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8714 - f1: 0.8888 - val_loss: 0.2557 - val_acc: 0.9622 - val_f1: 0.9628\n",
      "Epoch 4738/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2573 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4739/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8721 - f1: 0.8895 - val_loss: 0.2926 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4740/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3396 - acc: 0.8663 - f1: 0.8844 - val_loss: 0.2155 - val_acc: 0.9513 - val_f1: 0.9541\n",
      "Epoch 4741/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3462 - acc: 0.8609 - f1: 0.8802 - val_loss: 0.2298 - val_acc: 0.9603 - val_f1: 0.9622\n",
      "Epoch 4742/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2559 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4743/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2561 - val_acc: 0.9678 - val_f1: 0.9688\n",
      "Epoch 4744/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3222 - acc: 0.8723 - f1: 0.8891 - val_loss: 0.2454 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4745/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3200 - acc: 0.8748 - f1: 0.8914 - val_loss: 0.2400 - val_acc: 0.9572 - val_f1: 0.9591\n",
      "Epoch 4746/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3312 - acc: 0.8677 - f1: 0.8858 - val_loss: 0.2454 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4747/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3285 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2619 - val_acc: 0.9675 - val_f1: 0.9685\n",
      "Epoch 4748/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3346 - acc: 0.8655 - f1: 0.8839 - val_loss: 0.2871 - val_acc: 0.9634 - val_f1: 0.9643\n",
      "Epoch 4749/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3336 - acc: 0.8673 - f1: 0.8857 - val_loss: 0.2726 - val_acc: 0.9656 - val_f1: 0.9667\n",
      "Epoch 4750/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3318 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2893 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 4751/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3338 - acc: 0.8681 - f1: 0.8857 - val_loss: 0.2442 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4752/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8735 - f1: 0.8906 - val_loss: 0.2711 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4753/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8693 - f1: 0.8871 - val_loss: 0.2519 - val_acc: 0.9681 - val_f1: 0.9693\n",
      "Epoch 4754/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2383 - val_acc: 0.9653 - val_f1: 0.9663\n",
      "Epoch 4755/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8728 - f1: 0.8896 - val_loss: 0.2613 - val_acc: 0.9672 - val_f1: 0.9681\n",
      "Epoch 4756/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3307 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2672 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4757/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8676 - f1: 0.8853 - val_loss: 0.2657 - val_acc: 0.9678 - val_f1: 0.9685\n",
      "Epoch 4758/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8717 - f1: 0.8885 - val_loss: 0.2397 - val_acc: 0.9631 - val_f1: 0.9646\n",
      "Epoch 4759/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2590 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4760/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3167 - acc: 0.8761 - f1: 0.8923 - val_loss: 0.2659 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4761/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8747 - f1: 0.8912 - val_loss: 0.2552 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4762/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8878 - val_loss: 0.2650 - val_acc: 0.9666 - val_f1: 0.9683\n",
      "Epoch 4763/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2655 - val_acc: 0.9647 - val_f1: 0.9653\n",
      "Epoch 4764/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3171 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2855 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4765/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3243 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2862 - val_acc: 0.9644 - val_f1: 0.9653\n",
      "Epoch 4766/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8700 - f1: 0.8875 - val_loss: 0.2579 - val_acc: 0.9619 - val_f1: 0.9632\n",
      "Epoch 4767/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8701 - f1: 0.8872 - val_loss: 0.2412 - val_acc: 0.9628 - val_f1: 0.9640\n",
      "Epoch 4768/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2426 - val_acc: 0.9666 - val_f1: 0.9676\n",
      "Epoch 4769/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3342 - acc: 0.8682 - f1: 0.8860 - val_loss: 0.2800 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 4770/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3317 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2340 - val_acc: 0.9581 - val_f1: 0.9600\n",
      "Epoch 4771/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3301 - acc: 0.8687 - f1: 0.8866 - val_loss: 0.2661 - val_acc: 0.9625 - val_f1: 0.9634\n",
      "Epoch 4772/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3211 - acc: 0.8736 - f1: 0.8902 - val_loss: 0.2237 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4773/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8722 - f1: 0.8894 - val_loss: 0.2378 - val_acc: 0.9694 - val_f1: 0.9705\n",
      "Epoch 4774/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8690 - f1: 0.8864 - val_loss: 0.2793 - val_acc: 0.9675 - val_f1: 0.9683\n",
      "Epoch 4775/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3323 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2480 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4776/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8742 - f1: 0.8905 - val_loss: 0.2420 - val_acc: 0.9678 - val_f1: 0.9689\n",
      "Epoch 4777/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2605 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4778/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3331 - acc: 0.8681 - f1: 0.8858 - val_loss: 0.2453 - val_acc: 0.9472 - val_f1: 0.9507\n",
      "Epoch 4779/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2592 - val_acc: 0.9678 - val_f1: 0.9684\n",
      "Epoch 4780/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3332 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2463 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4781/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3299 - acc: 0.8695 - f1: 0.8870 - val_loss: 0.2313 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4782/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3303 - acc: 0.8682 - f1: 0.8859 - val_loss: 0.2653 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4783/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8901 - val_loss: 0.2684 - val_acc: 0.9634 - val_f1: 0.9642\n",
      "Epoch 4784/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8744 - f1: 0.8913 - val_loss: 0.2703 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4785/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8709 - f1: 0.8883 - val_loss: 0.2680 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4786/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8754 - f1: 0.8918 - val_loss: 0.2550 - val_acc: 0.9672 - val_f1: 0.9677\n",
      "Epoch 4787/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3235 - acc: 0.8715 - f1: 0.8885 - val_loss: 0.2563 - val_acc: 0.9622 - val_f1: 0.9633\n",
      "Epoch 4788/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8726 - f1: 0.8896 - val_loss: 0.2799 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4789/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2483 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4790/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3221 - acc: 0.8741 - f1: 0.8906 - val_loss: 0.2717 - val_acc: 0.9609 - val_f1: 0.9615\n",
      "Epoch 4791/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3234 - acc: 0.8724 - f1: 0.8892 - val_loss: 0.2498 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4792/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3149 - acc: 0.8780 - f1: 0.8935 - val_loss: 0.2714 - val_acc: 0.9656 - val_f1: 0.9659\n",
      "Epoch 4793/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3398 - acc: 0.8641 - f1: 0.8830 - val_loss: 0.2226 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4794/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2629 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4795/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3267 - acc: 0.8705 - f1: 0.8877 - val_loss: 0.2333 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4796/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2572 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4797/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3193 - acc: 0.8746 - f1: 0.8912 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9660\n",
      "Epoch 4798/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2408 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4799/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8720 - f1: 0.8887 - val_loss: 0.2534 - val_acc: 0.9656 - val_f1: 0.9672\n",
      "Epoch 4800/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3191 - acc: 0.8748 - f1: 0.8915 - val_loss: 0.2624 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4801/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3210 - acc: 0.8745 - f1: 0.8912 - val_loss: 0.2554 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 4802/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3142 - acc: 0.8781 - f1: 0.8940 - val_loss: 0.2670 - val_acc: 0.9613 - val_f1: 0.9626\n",
      "Epoch 4803/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8710 - f1: 0.8885 - val_loss: 0.2461 - val_acc: 0.9591 - val_f1: 0.9607\n",
      "Epoch 4804/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8731 - f1: 0.8892 - val_loss: 0.2419 - val_acc: 0.9647 - val_f1: 0.9656\n",
      "Epoch 4805/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2545 - val_acc: 0.9634 - val_f1: 0.9646\n",
      "Epoch 4806/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3266 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2521 - val_acc: 0.9622 - val_f1: 0.9631\n",
      "Epoch 4807/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3199 - acc: 0.8748 - f1: 0.8911 - val_loss: 0.2612 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4808/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2397 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4809/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8739 - f1: 0.8908 - val_loss: 0.2884 - val_acc: 0.9622 - val_f1: 0.9634\n",
      "Epoch 4810/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2845 - val_acc: 0.9516 - val_f1: 0.9535\n",
      "Epoch 4811/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8726 - f1: 0.8894 - val_loss: 0.2547 - val_acc: 0.9641 - val_f1: 0.9660\n",
      "Epoch 4812/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3163 - acc: 0.8767 - f1: 0.8924 - val_loss: 0.2623 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4813/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8729 - f1: 0.8894 - val_loss: 0.2610 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4814/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3198 - acc: 0.8754 - f1: 0.8922 - val_loss: 0.2531 - val_acc: 0.9644 - val_f1: 0.9647\n",
      "Epoch 4815/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2382 - val_acc: 0.9653 - val_f1: 0.9666\n",
      "Epoch 4816/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3353 - acc: 0.8648 - f1: 0.8836 - val_loss: 0.2304 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4817/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3230 - acc: 0.8728 - f1: 0.8890 - val_loss: 0.2325 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4818/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3239 - acc: 0.8715 - f1: 0.8884 - val_loss: 0.2825 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4819/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8695 - f1: 0.8869 - val_loss: 0.2342 - val_acc: 0.9572 - val_f1: 0.9596\n",
      "Epoch 4820/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3460 - acc: 0.8613 - f1: 0.8805 - val_loss: 0.2618 - val_acc: 0.9641 - val_f1: 0.9653\n",
      "Epoch 4821/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3354 - acc: 0.8662 - f1: 0.8847 - val_loss: 0.2497 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4822/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8734 - f1: 0.8903 - val_loss: 0.2853 - val_acc: 0.9641 - val_f1: 0.9652\n",
      "Epoch 4823/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3297 - acc: 0.8682 - f1: 0.8864 - val_loss: 0.2608 - val_acc: 0.9663 - val_f1: 0.9676\n",
      "Epoch 4824/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8735 - f1: 0.8908 - val_loss: 0.2710 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4825/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3240 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2466 - val_acc: 0.9656 - val_f1: 0.9671\n",
      "Epoch 4826/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8755 - f1: 0.8914 - val_loss: 0.2634 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4827/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8736 - f1: 0.8907 - val_loss: 0.2673 - val_acc: 0.9644 - val_f1: 0.9658\n",
      "Epoch 4828/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8695 - f1: 0.8868 - val_loss: 0.2241 - val_acc: 0.9591 - val_f1: 0.9610\n",
      "Epoch 4829/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3319 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2568 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4830/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8684 - f1: 0.8862 - val_loss: 0.2905 - val_acc: 0.9625 - val_f1: 0.9632\n",
      "Epoch 4831/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3340 - acc: 0.8679 - f1: 0.8859 - val_loss: 0.2562 - val_acc: 0.9669 - val_f1: 0.9676\n",
      "Epoch 4832/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3195 - acc: 0.8750 - f1: 0.8916 - val_loss: 0.2441 - val_acc: 0.9638 - val_f1: 0.9643\n",
      "Epoch 4833/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8706 - f1: 0.8877 - val_loss: 0.2581 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4834/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2615 - val_acc: 0.9656 - val_f1: 0.9668\n",
      "Epoch 4835/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3237 - acc: 0.8713 - f1: 0.8882 - val_loss: 0.2824 - val_acc: 0.9644 - val_f1: 0.9648\n",
      "Epoch 4836/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8713 - f1: 0.8885 - val_loss: 0.2319 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4837/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3186 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2489 - val_acc: 0.9647 - val_f1: 0.9660\n",
      "Epoch 4838/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3196 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2575 - val_acc: 0.9606 - val_f1: 0.9620\n",
      "Epoch 4839/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8693 - f1: 0.8869 - val_loss: 0.2907 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4840/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3217 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2590 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4841/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3180 - acc: 0.8757 - f1: 0.8921 - val_loss: 0.2908 - val_acc: 0.9663 - val_f1: 0.9666\n",
      "Epoch 4842/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3228 - acc: 0.8723 - f1: 0.8894 - val_loss: 0.2726 - val_acc: 0.9631 - val_f1: 0.9640\n",
      "Epoch 4843/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2437 - val_acc: 0.9644 - val_f1: 0.9661\n",
      "Epoch 4844/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8713 - f1: 0.8887 - val_loss: 0.2540 - val_acc: 0.9619 - val_f1: 0.9630\n",
      "Epoch 4845/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3405 - acc: 0.8631 - f1: 0.8824 - val_loss: 0.2265 - val_acc: 0.9650 - val_f1: 0.9668\n",
      "Epoch 4846/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8738 - f1: 0.8904 - val_loss: 0.2382 - val_acc: 0.9566 - val_f1: 0.9589\n",
      "Epoch 4847/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3357 - acc: 0.8674 - f1: 0.8859 - val_loss: 0.2186 - val_acc: 0.9619 - val_f1: 0.9636\n",
      "Epoch 4848/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8690 - f1: 0.8866 - val_loss: 0.2451 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4849/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3177 - acc: 0.8759 - f1: 0.8920 - val_loss: 0.2600 - val_acc: 0.9628 - val_f1: 0.9633\n",
      "Epoch 4850/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8709 - f1: 0.8885 - val_loss: 0.2563 - val_acc: 0.9638 - val_f1: 0.9653\n",
      "Epoch 4851/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3221 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2253 - val_acc: 0.9619 - val_f1: 0.9638\n",
      "Epoch 4852/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3282 - acc: 0.8703 - f1: 0.8882 - val_loss: 0.2700 - val_acc: 0.9641 - val_f1: 0.9651\n",
      "Epoch 4853/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3233 - acc: 0.8731 - f1: 0.8899 - val_loss: 0.2564 - val_acc: 0.9681 - val_f1: 0.9683\n",
      "Epoch 4854/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3214 - acc: 0.8737 - f1: 0.8905 - val_loss: 0.2416 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4855/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8738 - f1: 0.8903 - val_loss: 0.2458 - val_acc: 0.9634 - val_f1: 0.9653\n",
      "Epoch 4856/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8702 - f1: 0.8878 - val_loss: 0.2485 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4857/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3147 - acc: 0.8780 - f1: 0.8938 - val_loss: 0.2523 - val_acc: 0.9541 - val_f1: 0.9559\n",
      "Epoch 4858/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3238 - acc: 0.8741 - f1: 0.8905 - val_loss: 0.2509 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4859/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3238 - acc: 0.8716 - f1: 0.8894 - val_loss: 0.2616 - val_acc: 0.9650 - val_f1: 0.9657\n",
      "Epoch 4860/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3275 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2691 - val_acc: 0.9631 - val_f1: 0.9644\n",
      "Epoch 4861/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3315 - acc: 0.8694 - f1: 0.8869 - val_loss: 0.2309 - val_acc: 0.9591 - val_f1: 0.9614\n",
      "Epoch 4862/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8771 - f1: 0.8926 - val_loss: 0.2593 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4863/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3190 - acc: 0.8741 - f1: 0.8907 - val_loss: 0.2661 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4864/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3161 - acc: 0.8764 - f1: 0.8930 - val_loss: 0.2591 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 4865/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3187 - acc: 0.8751 - f1: 0.8917 - val_loss: 0.2764 - val_acc: 0.9650 - val_f1: 0.9654\n",
      "Epoch 4866/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8712 - f1: 0.8882 - val_loss: 0.2339 - val_acc: 0.9622 - val_f1: 0.9637\n",
      "Epoch 4867/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3289 - acc: 0.8701 - f1: 0.8873 - val_loss: 0.2550 - val_acc: 0.9634 - val_f1: 0.9645\n",
      "Epoch 4868/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3222 - acc: 0.8735 - f1: 0.8905 - val_loss: 0.2695 - val_acc: 0.9672 - val_f1: 0.9682\n",
      "Epoch 4869/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8718 - f1: 0.8886 - val_loss: 0.2561 - val_acc: 0.9659 - val_f1: 0.9668\n",
      "Epoch 4870/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8725 - f1: 0.8896 - val_loss: 0.2523 - val_acc: 0.9622 - val_f1: 0.9635\n",
      "Epoch 4871/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8739 - f1: 0.8904 - val_loss: 0.2502 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4872/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8761 - f1: 0.8919 - val_loss: 0.2278 - val_acc: 0.9609 - val_f1: 0.9623\n",
      "Epoch 4873/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3236 - acc: 0.8730 - f1: 0.8902 - val_loss: 0.2621 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4874/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3204 - acc: 0.8745 - f1: 0.8908 - val_loss: 0.2356 - val_acc: 0.9619 - val_f1: 0.9635\n",
      "Epoch 4875/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3372 - acc: 0.8664 - f1: 0.88 - 0s 16us/sample - loss: 0.3359 - acc: 0.8667 - f1: 0.8850 - val_loss: 0.2478 - val_acc: 0.9575 - val_f1: 0.9597\n",
      "Epoch 4876/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8720 - f1: 0.8885 - val_loss: 0.2499 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4877/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3291 - acc: 0.8702 - f1: 0.8879 - val_loss: 0.2733 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4878/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3330 - acc: 0.8673 - f1: 0.8852 - val_loss: 0.2446 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4879/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3249 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2533 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4880/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3240 - acc: 0.8717 - f1: 0.8893 - val_loss: 0.2570 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 4881/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8709 - f1: 0.8877 - val_loss: 0.2647 - val_acc: 0.9653 - val_f1: 0.9664\n",
      "Epoch 4882/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3256 - acc: 0.8707 - f1: 0.8880 - val_loss: 0.2690 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4883/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3151 - acc: 0.8778 - f1: 0.8936 - val_loss: 0.2709 - val_acc: 0.9659 - val_f1: 0.9666\n",
      "Epoch 4884/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3242 - acc: 0.8712 - f1: 0.8884 - val_loss: 0.2649 - val_acc: 0.9641 - val_f1: 0.9657\n",
      "Epoch 4885/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3253 - acc: 0.8720 - f1: 0.8892 - val_loss: 0.2752 - val_acc: 0.9625 - val_f1: 0.9629\n",
      "Epoch 4886/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2633 - val_acc: 0.9638 - val_f1: 0.9644\n",
      "Epoch 4887/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3209 - acc: 0.8745 - f1: 0.8914 - val_loss: 0.2476 - val_acc: 0.9672 - val_f1: 0.9676\n",
      "Epoch 4888/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2555 - val_acc: 0.9641 - val_f1: 0.9656\n",
      "Epoch 4889/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3281 - acc: 0.8701 - f1: 0.8876 - val_loss: 0.2430 - val_acc: 0.9638 - val_f1: 0.9646\n",
      "Epoch 4890/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8907 - val_loss: 0.2583 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4891/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8730 - f1: 0.8898 - val_loss: 0.2806 - val_acc: 0.9656 - val_f1: 0.9663\n",
      "Epoch 4892/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8708 - f1: 0.8885 - val_loss: 0.2691 - val_acc: 0.9650 - val_f1: 0.9656\n",
      "Epoch 4893/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8732 - f1: 0.8904 - val_loss: 0.2722 - val_acc: 0.9644 - val_f1: 0.9656\n",
      "Epoch 4894/5000\n",
      "12800/12800 [==============================] - ETA: 0s - loss: 0.3280 - acc: 0.8705 - f1: 0.88 - 0s 16us/sample - loss: 0.3293 - acc: 0.8697 - f1: 0.8874 - val_loss: 0.2370 - val_acc: 0.9669 - val_f1: 0.9680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4895/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3343 - acc: 0.8666 - f1: 0.8848 - val_loss: 0.2499 - val_acc: 0.9609 - val_f1: 0.9628\n",
      "Epoch 4896/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3273 - acc: 0.8709 - f1: 0.8879 - val_loss: 0.2468 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4897/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2740 - val_acc: 0.9663 - val_f1: 0.9674\n",
      "Epoch 4898/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3251 - acc: 0.8710 - f1: 0.8883 - val_loss: 0.2715 - val_acc: 0.9647 - val_f1: 0.9652\n",
      "Epoch 4899/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8715 - f1: 0.8889 - val_loss: 0.2143 - val_acc: 0.9597 - val_f1: 0.9614\n",
      "Epoch 4900/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3308 - acc: 0.8681 - f1: 0.8859 - val_loss: 0.2613 - val_acc: 0.9641 - val_f1: 0.9655\n",
      "Epoch 4901/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8723 - f1: 0.8892 - val_loss: 0.2241 - val_acc: 0.9600 - val_f1: 0.9615\n",
      "Epoch 4902/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3207 - acc: 0.8737 - f1: 0.8906 - val_loss: 0.2516 - val_acc: 0.9613 - val_f1: 0.9631\n",
      "Epoch 4903/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2663 - val_acc: 0.9631 - val_f1: 0.9642\n",
      "Epoch 4904/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3253 - acc: 0.8717 - f1: 0.8884 - val_loss: 0.2777 - val_acc: 0.9647 - val_f1: 0.9657\n",
      "Epoch 4905/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3192 - acc: 0.8746 - f1: 0.8913 - val_loss: 0.2606 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4906/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8687 - f1: 0.8867 - val_loss: 0.2526 - val_acc: 0.9653 - val_f1: 0.9668\n",
      "Epoch 4907/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3176 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2546 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4908/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3254 - acc: 0.8704 - f1: 0.8880 - val_loss: 0.2620 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4909/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3391 - acc: 0.8644 - f1: 0.8833 - val_loss: 0.2305 - val_acc: 0.9603 - val_f1: 0.9623\n",
      "Epoch 4910/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3219 - acc: 0.8737 - f1: 0.8900 - val_loss: 0.2442 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4911/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8753 - f1: 0.8921 - val_loss: 0.2696 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4912/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3231 - acc: 0.8716 - f1: 0.8889 - val_loss: 0.2567 - val_acc: 0.9669 - val_f1: 0.9675\n",
      "Epoch 4913/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3384 - acc: 0.8636 - f1: 0.8826 - val_loss: 0.2484 - val_acc: 0.9659 - val_f1: 0.9676\n",
      "Epoch 4914/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3329 - acc: 0.8663 - f1: 0.8846 - val_loss: 0.2714 - val_acc: 0.9641 - val_f1: 0.9658\n",
      "Epoch 4915/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8722 - f1: 0.8893 - val_loss: 0.2863 - val_acc: 0.9634 - val_f1: 0.9649\n",
      "Epoch 4916/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3258 - acc: 0.8717 - f1: 0.8890 - val_loss: 0.2423 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4917/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8761 - f1: 0.8922 - val_loss: 0.2410 - val_acc: 0.9672 - val_f1: 0.9685\n",
      "Epoch 4918/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3247 - acc: 0.8723 - f1: 0.8893 - val_loss: 0.2490 - val_acc: 0.9675 - val_f1: 0.9684\n",
      "Epoch 4919/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3272 - acc: 0.8706 - f1: 0.8878 - val_loss: 0.2435 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 4920/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2762 - val_acc: 0.9669 - val_f1: 0.9678\n",
      "Epoch 4921/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3205 - acc: 0.8745 - f1: 0.8911 - val_loss: 0.2609 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4922/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3215 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2772 - val_acc: 0.9672 - val_f1: 0.9680\n",
      "Epoch 4923/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3302 - acc: 0.8685 - f1: 0.8866 - val_loss: 0.2302 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4924/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3284 - acc: 0.8695 - f1: 0.8873 - val_loss: 0.2597 - val_acc: 0.9634 - val_f1: 0.9648\n",
      "Epoch 4925/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3268 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2732 - val_acc: 0.9669 - val_f1: 0.9677\n",
      "Epoch 4926/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8684 - f1: 0.8867 - val_loss: 0.2625 - val_acc: 0.9606 - val_f1: 0.9618\n",
      "Epoch 4927/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2407 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4928/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3287 - acc: 0.8691 - f1: 0.8863 - val_loss: 0.2563 - val_acc: 0.9622 - val_f1: 0.9636\n",
      "Epoch 4929/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3139 - acc: 0.8784 - f1: 0.8941 - val_loss: 0.2682 - val_acc: 0.9641 - val_f1: 0.9649\n",
      "Epoch 4930/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8753 - f1: 0.8915 - val_loss: 0.2535 - val_acc: 0.9647 - val_f1: 0.9661\n",
      "Epoch 4931/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8705 - f1: 0.8881 - val_loss: 0.2632 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4932/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3252 - acc: 0.8716 - f1: 0.8890 - val_loss: 0.2819 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4933/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3224 - acc: 0.8727 - f1: 0.8898 - val_loss: 0.2786 - val_acc: 0.9650 - val_f1: 0.9660\n",
      "Epoch 4934/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8719 - f1: 0.8890 - val_loss: 0.2685 - val_acc: 0.9650 - val_f1: 0.9659\n",
      "Epoch 4935/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8761 - f1: 0.8926 - val_loss: 0.2644 - val_acc: 0.9659 - val_f1: 0.9674\n",
      "Epoch 4936/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3181 - acc: 0.8754 - f1: 0.8914 - val_loss: 0.2760 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4937/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3292 - acc: 0.8694 - f1: 0.8870 - val_loss: 0.2243 - val_acc: 0.9603 - val_f1: 0.9621\n",
      "Epoch 4938/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3345 - acc: 0.8680 - f1: 0.8860 - val_loss: 0.2457 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4939/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3189 - acc: 0.8755 - f1: 0.8917 - val_loss: 0.2702 - val_acc: 0.9647 - val_f1: 0.9659\n",
      "Epoch 4940/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3261 - acc: 0.8721 - f1: 0.8891 - val_loss: 0.2598 - val_acc: 0.9634 - val_f1: 0.9647\n",
      "Epoch 4941/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3296 - acc: 0.8686 - f1: 0.8863 - val_loss: 0.2494 - val_acc: 0.9656 - val_f1: 0.9670\n",
      "Epoch 4942/5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3310 - acc: 0.8675 - f1: 0.8853 - val_loss: 0.2501 - val_acc: 0.9644 - val_f1: 0.9649\n",
      "Epoch 4943/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8707 - f1: 0.8879 - val_loss: 0.2619 - val_acc: 0.9641 - val_f1: 0.9659\n",
      "Epoch 4944/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3256 - acc: 0.8708 - f1: 0.8884 - val_loss: 0.2673 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4945/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8742 - f1: 0.8909 - val_loss: 0.2646 - val_acc: 0.9684 - val_f1: 0.9683\n",
      "Epoch 4946/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8737 - f1: 0.8903 - val_loss: 0.2343 - val_acc: 0.9644 - val_f1: 0.9651\n",
      "Epoch 4947/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3321 - acc: 0.8681 - f1: 0.8865 - val_loss: 0.2584 - val_acc: 0.9569 - val_f1: 0.9584\n",
      "Epoch 4948/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3274 - acc: 0.8698 - f1: 0.8872 - val_loss: 0.2384 - val_acc: 0.9666 - val_f1: 0.9681\n",
      "Epoch 4949/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3225 - acc: 0.8731 - f1: 0.8898 - val_loss: 0.2568 - val_acc: 0.9659 - val_f1: 0.9677\n",
      "Epoch 4950/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3304 - acc: 0.8687 - f1: 0.8868 - val_loss: 0.2880 - val_acc: 0.9638 - val_f1: 0.9648\n",
      "Epoch 4951/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3288 - acc: 0.8705 - f1: 0.8874 - val_loss: 0.2492 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4952/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3400 - acc: 0.8645 - f1: 0.8831 - val_loss: 0.2240 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4953/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3280 - acc: 0.8714 - f1: 0.8883 - val_loss: 0.2352 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4954/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3293 - acc: 0.8691 - f1: 0.8867 - val_loss: 0.2272 - val_acc: 0.9631 - val_f1: 0.9645\n",
      "Epoch 4955/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3218 - acc: 0.8734 - f1: 0.8905 - val_loss: 0.2481 - val_acc: 0.9653 - val_f1: 0.9667\n",
      "Epoch 4956/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3213 - acc: 0.8737 - f1: 0.8904 - val_loss: 0.2474 - val_acc: 0.9634 - val_f1: 0.9650\n",
      "Epoch 4957/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3298 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2676 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4958/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3264 - acc: 0.8709 - f1: 0.8884 - val_loss: 0.2319 - val_acc: 0.9666 - val_f1: 0.9675\n",
      "Epoch 4959/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8698 - f1: 0.8878 - val_loss: 0.2255 - val_acc: 0.9638 - val_f1: 0.9650\n",
      "Epoch 4960/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3244 - acc: 0.8724 - f1: 0.8891 - val_loss: 0.2507 - val_acc: 0.9644 - val_f1: 0.9654\n",
      "Epoch 4961/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8729 - f1: 0.8899 - val_loss: 0.2711 - val_acc: 0.9653 - val_f1: 0.9669\n",
      "Epoch 4962/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3311 - acc: 0.8680 - f1: 0.8859 - val_loss: 0.2818 - val_acc: 0.9666 - val_f1: 0.9674\n",
      "Epoch 4963/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3178 - acc: 0.8766 - f1: 0.8928 - val_loss: 0.2527 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4964/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3290 - acc: 0.8694 - f1: 0.8874 - val_loss: 0.2536 - val_acc: 0.9659 - val_f1: 0.9671\n",
      "Epoch 4965/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3173 - acc: 0.8755 - f1: 0.8918 - val_loss: 0.2530 - val_acc: 0.9659 - val_f1: 0.9669\n",
      "Epoch 4966/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3168 - acc: 0.8756 - f1: 0.8918 - val_loss: 0.2714 - val_acc: 0.9653 - val_f1: 0.9659\n",
      "Epoch 4967/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3356 - acc: 0.8645 - f1: 0.8830 - val_loss: 0.2610 - val_acc: 0.9659 - val_f1: 0.9660\n",
      "Epoch 4968/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3246 - acc: 0.8720 - f1: 0.8891 - val_loss: 0.2883 - val_acc: 0.9663 - val_f1: 0.9675\n",
      "Epoch 4969/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3194 - acc: 0.8764 - f1: 0.8917 - val_loss: 0.2192 - val_acc: 0.9628 - val_f1: 0.9645\n",
      "Epoch 4970/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3216 - acc: 0.8741 - f1: 0.8910 - val_loss: 0.3012 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4971/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3277 - acc: 0.8696 - f1: 0.8872 - val_loss: 0.2204 - val_acc: 0.9666 - val_f1: 0.9679\n",
      "Epoch 4972/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8708 - f1: 0.8878 - val_loss: 0.2507 - val_acc: 0.9650 - val_f1: 0.9663\n",
      "Epoch 4973/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3252 - acc: 0.8712 - f1: 0.8881 - val_loss: 0.2563 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4974/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3270 - acc: 0.8705 - f1: 0.8879 - val_loss: 0.2491 - val_acc: 0.9650 - val_f1: 0.9665\n",
      "Epoch 4975/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3227 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2573 - val_acc: 0.9669 - val_f1: 0.9682\n",
      "Epoch 4976/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3276 - acc: 0.8711 - f1: 0.8882 - val_loss: 0.2876 - val_acc: 0.9628 - val_f1: 0.9636\n",
      "Epoch 4977/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3226 - acc: 0.8723 - f1: 0.8895 - val_loss: 0.2626 - val_acc: 0.9672 - val_f1: 0.9687\n",
      "Epoch 4978/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8714 - f1: 0.8886 - val_loss: 0.2763 - val_acc: 0.9631 - val_f1: 0.9638\n",
      "Epoch 4979/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3229 - acc: 0.8723 - f1: 0.8898 - val_loss: 0.2833 - val_acc: 0.9650 - val_f1: 0.9655\n",
      "Epoch 4980/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8719 - f1: 0.8884 - val_loss: 0.2454 - val_acc: 0.9650 - val_f1: 0.9662\n",
      "Epoch 4981/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3197 - acc: 0.8762 - f1: 0.8925 - val_loss: 0.2569 - val_acc: 0.9625 - val_f1: 0.9639\n",
      "Epoch 4982/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3345 - acc: 0.8673 - f1: 0.8850 - val_loss: 0.2659 - val_acc: 0.9663 - val_f1: 0.9672\n",
      "Epoch 4983/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3271 - acc: 0.8699 - f1: 0.8871 - val_loss: 0.2597 - val_acc: 0.9656 - val_f1: 0.9669\n",
      "Epoch 4984/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3156 - acc: 0.8766 - f1: 0.8927 - val_loss: 0.2558 - val_acc: 0.9628 - val_f1: 0.9641\n",
      "Epoch 4985/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3377 - acc: 0.8637 - f1: 0.8827 - val_loss: 0.2836 - val_acc: 0.9631 - val_f1: 0.9641\n",
      "Epoch 4986/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3276 - acc: 0.8701 - f1: 0.8875 - val_loss: 0.2684 - val_acc: 0.9669 - val_f1: 0.9680\n",
      "Epoch 4987/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3348 - acc: 0.8670 - f1: 0.8850 - val_loss: 0.2270 - val_acc: 0.9625 - val_f1: 0.9640\n",
      "Epoch 4988/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3257 - acc: 0.8716 - f1: 0.8884 - val_loss: 0.2570 - val_acc: 0.9666 - val_f1: 0.9677\n",
      "Epoch 4989/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3255 - acc: 0.8711 - f1: 0.8883 - val_loss: 0.2618 - val_acc: 0.9644 - val_f1: 0.9650\n",
      "Epoch 4990/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3259 - acc: 0.8709 - f1: 0.8882 - val_loss: 0.2490 - val_acc: 0.9628 - val_f1: 0.9643\n",
      "Epoch 4991/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3265 - acc: 0.8705 - f1: 0.8880 - val_loss: 0.2635 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 4992/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3175 - acc: 0.8759 - f1: 0.8924 - val_loss: 0.2647 - val_acc: 0.9653 - val_f1: 0.9662\n",
      "Epoch 4993/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3220 - acc: 0.8734 - f1: 0.8902 - val_loss: 0.2687 - val_acc: 0.9666 - val_f1: 0.9678\n",
      "Epoch 4994/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3286 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2361 - val_acc: 0.9647 - val_f1: 0.9658\n",
      "Epoch 4995/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3275 - acc: 0.8699 - f1: 0.8873 - val_loss: 0.2621 - val_acc: 0.9681 - val_f1: 0.9689\n",
      "Epoch 4996/5000\n",
      "12800/12800 [==============================] - 0s 16us/sample - loss: 0.3250 - acc: 0.8710 - f1: 0.8886 - val_loss: 0.2546 - val_acc: 0.9659 - val_f1: 0.9672\n",
      "Epoch 4997/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3245 - acc: 0.8715 - f1: 0.8887 - val_loss: 0.2553 - val_acc: 0.9675 - val_f1: 0.9680\n",
      "Epoch 4998/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3306 - acc: 0.8680 - f1: 0.8856 - val_loss: 0.2400 - val_acc: 0.9638 - val_f1: 0.9651\n",
      "Epoch 4999/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3241 - acc: 0.8716 - f1: 0.8886 - val_loss: 0.2654 - val_acc: 0.9659 - val_f1: 0.9667\n",
      "Epoch 5000/5000\n",
      "12800/12800 [==============================] - 0s 15us/sample - loss: 0.3324 - acc: 0.8668 - f1: 0.8850 - val_loss: 0.2491 - val_acc: 0.9647 - val_f1: 0.9659\n"
     ]
    }
   ],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "\n",
    "epochs_range = [30,60, 5000]                                                                                                                                            \n",
    "max_ep = max(epochs_range)                                                                                                                                                         \n",
    "\n",
    "for ep in epochs_range:                                                                                                                                                            \n",
    "    model = RN_model(layer_sizes, dropout, learning_rate)                                                                                                                          \n",
    "    #### Apprentissage                                                                                                                                                             \n",
    "    start = time.time()                                                                                                                                                            \n",
    "    #model.fit(X_train, Y_train, batch_size = 100, epochs = 60)                                                                                                                    \n",
    "    hist_obj = model.fit(X_train, Y_train, batch_size = batch_size, epochs = ep, validation_data=(X_test, Y_test))                                                                 \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    training_delay_RN.append(end - start)                                                                                                                                          \n",
    "\n",
    "    ho_tmp = list(hist_obj.history.values())                                                                                                                                       \n",
    "    ho_tmp = [i + [np.nan for _ in range(max_ep-ep)] for i in ho_tmp ]                                                                                                             \n",
    "    history_obj.append(ho_tmp)\n",
    "    #### Prédiction                                                                                                                                                                \n",
    "    start = time.time()                                                                                                                                                            \n",
    "\n",
    "    Y_pred = np.where(model.predict(X_test) > 0.5, 1, 0)                                                                                                                           \n",
    "\n",
    "    end = time.time()                                                                                                                                                              \n",
    "    predicting_delay_RN.append(end - start) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)\n",
    "\n",
    "leg = [str(i) for i in epochs_range]                                                                                                                                                \n",
    "                                                                                                                                       \n",
    "titre = \"RN : HyperParam = number of epochs\"                                                                                                                                          \n",
    "\n",
    "plot_perf(ho, leg, titre ,sub_title)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "EXPLICATION A REVOIR CAR JE NE VOIS PAS DE SURAPPRENTISSAGE : \n",
    "Nous remarquons que les performances (accuracy et f1_score) tendent vers les mêmes taux qu'il y ait 30, 60 ou 120 itérations. \n",
    "\n",
    "(graphe time - itérations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "plot_delay(training_delay_RN,predicting_delay_RN,titre)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "metadata": false
    }
   },
   "source": [
    "Notons ici que le temps d'apprentissage et de prédiction croissent avec le nombre d'itération."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 5\n",
    "(1 - La démarche de comparaison des hyperparamètres est sérieuse. Les résultats sont présentés de façon correcte et concise dans un tableau et un graphique.\n",
    "2 - Les explications montrant les différences sont claires, concises et plausibles.\n",
    "3 - La configuration matérielle sur laquelle les expérimentations est présenteainsi que le temps d’exécution requis pour compléter les expérimentations)\n",
    "\n",
    "1&2 : (alterner graphe et explication (cf q3) ou mettre tous les graphes (en q3) puis explication ici en q5.\n",
    "\n",
    "3 : regarder les specs du PC."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca commence\n",
      "best param\n",
      "{'C': 10, 'gamma': 1, 'kernel': 'rbf'}\n",
      "best score\n",
      "0.9948977743496463\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_grid,Y_grid = get_data_GridSearch()\n",
    "Grid=GridSearch_bestparam(X_grid,Y_grid)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse Linear\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:13: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  del sys.path[0]\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:14: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  \n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:15: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  from ipykernel import kernelapp as app\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:16: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  app.launch_new_instance()\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:17: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:18: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/ipykernel_launcher.py:19: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Analyse RBF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:241: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_accuracy.append(df.get_value(i, 35, 'mean_train_Accuracy'))\n",
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:242: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_time.append(df.get_value(i, 0, 'mean_fit_time'))\n",
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:243: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_Param_C.append(df.get_value(i, 4, 'param_C'))\n",
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:244: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_gamma.append(df.get_value(i, 6, 'param_gamma'))\n",
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:245: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_kernel.append(df.get_value(i, 5, 'param_kernel'))\n",
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:246: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_test_acc.append(df.get_value(i, 28, 'mean_test_Accuracy'))\n",
      "/home/ens/AN03460/Desktop/tp3/GTI770-AlexandreBleau_TP3-branch/GTI770_Laboratoire3_-_BLEA14058906_LETD05129708_LIOT20069605/functions.py:247: FutureWarning: get_value is deprecated and will be removed in a future release. Please use .at[] or .iat[] accessors instead\n",
      "  list_std_train_acc.append(df.get_value(i, 36, 'std_train_Accuracy'))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Table de valeur\n",
      "____________________________________________________________________________________________________\n",
      "Kernel           Param C   Param Gamma                     Precision Temps de traitement\n",
      "____________________________________________________________________________________________________\n",
      "linear             0.001                 nan            0.8214202015467542  56.413630199432376\n",
      "linear               0.1                 nan            0.9289118037653308  20.981645107269287\n",
      "linear                 1                 nan            0.9426607296304976  12.610642528533935\n",
      "linear                10                 nan             0.949535192563081   10.10038890838623\n",
      "rbf                0.001               0.001            0.5191781892039684   61.78293933868408\n",
      "rbf                0.001                 0.1            0.5191781892039684   60.65386543273926\n",
      "rbf                0.001                   1            0.7639246933833295  60.547062969207765\n",
      "rbf                0.001                  10            0.5191781892039684   59.71654653549194\n",
      "rbf                  0.1               0.001            0.5191781892039684  60.213500022888184\n",
      "rbf                  0.1                 0.1            0.9110225763612217  31.187091445922853\n",
      "rbf                  0.1                   1            0.9511756893992657   17.10279474258423\n",
      "rbf                  0.1                  10            0.9222716975236309   28.09838738441467\n",
      "rbf                    1               0.001            0.8261854542613858   58.05534648895264\n",
      "rbf                    1                 0.1            0.9469572689633622  17.652470064163207\n",
      "rbf                    1                   1            0.9675806577611125   9.351421785354614\n",
      "rbf                    1                  10            0.9912506835403484  20.290639209747315\n",
      "rbf                   10               0.001            0.8983673150535114  31.532392501831055\n",
      "rbf                   10                 0.1            0.9590656979923443   9.637727880477906\n",
      "rbf                   10                   1            0.9811733458323568   6.396997499465942\n",
      "linear avec meilleur param\n",
      "[[1442   97]\n",
      " [  85 1576]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.94      0.94      1539\n",
      "           1       0.94      0.95      0.95      1661\n",
      "\n",
      "    accuracy                           0.94      3200\n",
      "   macro avg       0.94      0.94      0.94      3200\n",
      "weighted avg       0.94      0.94      0.94      3200\n",
      "\n",
      "rbf avec meilleur param\n",
      "[[1486   53]\n",
      " [  40 1621]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      0.97      0.97      1539\n",
      "           1       0.97      0.98      0.97      1661\n",
      "\n",
      "    accuracy                           0.97      3200\n",
      "   macro avg       0.97      0.97      0.97      3200\n",
      "weighted avg       0.97      0.97      0.97      3200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print ('Analyse Linear')\n",
    "\n",
    "plot_Linear_acc(Grid)\n",
    "\n",
    "print('Analyse RBF')\n",
    "plot_RBF_acc(Grid)\n",
    "\n",
    "print('Table de valeur')\n",
    "plot_analyse(Grid)\n",
    "dash= '_'* 100\n",
    "\n",
    "\n",
    "SVCLine(X_train, Y_train, X_test, Y_test,1)\n",
    "\n",
    "print('rbf avec meilleur param')\n",
    "SVC_rbf(X_train, Y_train, X_test, Y_test,10,1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 6\n",
    "(1 - La méthode est décrite et un lien avec l’implémentation est fait afin d’expliquer comment l’équipe a trouvé le meilleur modèle SVM. \n",
    "2- Les résultats sont présentés de façon correcte et concise dans un TABLEAU ET un GRAPHIQUE. \n",
    "3 - La configuration matérielle sur laquelle les expérimentations est présente ainsi que le temps d’exécution requis pour compléter les expérimentations.)\n",
    "\n",
    "1 - explication implémentation SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {},
    "scrolled": true
   },
   "source": [
    "## Question 7\n",
    "(L’impact de la taille de l’ensemble d’apprentissage sur les performances est présent et décrit convenablement.)\n",
    "\n",
    "Dans le cas du MLP, on remarque que pour 1600 images, le temps d'apprentissage se situe autour de 5 secondes. Pour 16000, le temps d'apprentissage est d'environ 32 secondes. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 8\n",
    "(Un classificateur est recommandé en se basant sur l’expérimentation précédemment effectuée.)\n",
    "\n",
    "SVM ou MLP en fonction des résultats (perf + time)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Question 9\n",
    "(Des pistes d’amélioration sont proposées.)\n",
    "\n",
    "Bonne question : investiguer davantages les études d'hyperparamètres pour trouver une solution optimale ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {}
   },
   "source": [
    "## Conlusion\n",
    "\n",
    "(1 - Un court résumé du problème est présent.\n",
    "2 - Un rappel des résultats est présent.\n",
    "3 - Des pistes pour de possibles améliorations sont présentes.)\n",
    "\n",
    "Ce troisième laboratoire nous a permis de comprendre davantage le fonctionnment de deux nouvelles méthodes de classification : SVM et MLP. Dans les deux cas, les temps d'apprentissage sont bien plus long que les premiers laboratoires. \n",
    "Avantages et incovénients entre les deux méthodes:\n",
    "MLP : nb de sorties non limitée != svm => MLP plus évolutif si plus de deux catégories. \n",
    "\n",
    "Les résultats sont meilleurs dans le cas de ..... (MLP,SVM ?).\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
