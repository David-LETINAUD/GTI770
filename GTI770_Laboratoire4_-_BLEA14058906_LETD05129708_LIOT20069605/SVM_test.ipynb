{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {}
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "salut\n"
     ]
    }
   ],
   "source": [
    "print('salut')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from functions import *\n",
    "from SVC_model import PCA_Find_ncomp,PCA_transform,SVM_Gridsearch,SVC_Linear,SVC_rbf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC ssd\n",
      "28\n",
      "best param\n",
      "{'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}\n",
      "best score\n",
      "0.196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/sklearn/model_selection/_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.032049</td>\n",
       "      <td>0.158971</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.115492</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>0.011665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>0.115365</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>0.085984</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.008061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.063088</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.033002</td>\n",
       "      <td>0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.078126</td>\n",
       "      <td>0.021830</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.006309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.138871</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.035252</td>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.136252</td>\n",
       "      <td>0.013262</td>\n",
       "      <td>0.121260</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>0.016788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>0.152828</td>\n",
       "      <td>0.022614</td>\n",
       "      <td>0.147022</td>\n",
       "      <td>0.033294</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.001165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.093401</td>\n",
       "      <td>0.017001</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.011037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.023951</td>\n",
       "      <td>0.083201</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.156612</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.004913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.058851</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.151654</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.007873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.104328</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.104254</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.020364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.098520</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.006185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.111241</td>\n",
       "      <td>0.036913</td>\n",
       "      <td>0.039061</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.090990</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.045566</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.101602</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.033498</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.112797</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.044978</td>\n",
       "      <td>0.015403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.101287</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.034547</td>\n",
       "      <td>0.006468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.177027</td>\n",
       "      <td>0.041403</td>\n",
       "      <td>0.042906</td>\n",
       "      <td>0.014360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.126650</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.047056</td>\n",
       "      <td>0.013823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_kernel param_C param_gamma  rank_test_Accuracy  mean_test_Accuracy  \\\n",
       "3        linear      10         NaN                   3               0.189   \n",
       "2        linear       1         NaN                   4               0.182   \n",
       "1        linear     0.1         NaN                   8               0.110   \n",
       "0        linear   0.001         NaN                  12               0.072   \n",
       "17          rbf      10         0.1                   1               0.196   \n",
       "14          rbf       1           1                   2               0.191   \n",
       "18          rbf      10           1                   5               0.177   \n",
       "13          rbf       1         0.1                   6               0.133   \n",
       "19          rbf      10          10                   7               0.119   \n",
       "15          rbf       1          10                   8               0.110   \n",
       "10          rbf     0.1           1                  10               0.083   \n",
       "16          rbf      10       0.001                  11               0.075   \n",
       "4           rbf   0.001       0.001                  12               0.072   \n",
       "5           rbf   0.001         0.1                  12               0.072   \n",
       "6           rbf   0.001           1                  12               0.072   \n",
       "7           rbf   0.001          10                  12               0.072   \n",
       "8           rbf     0.1       0.001                  12               0.072   \n",
       "9           rbf     0.1         0.1                  12               0.072   \n",
       "11          rbf     0.1          10                  12               0.072   \n",
       "12          rbf       1       0.001                  12               0.072   \n",
       "\n",
       "    std_test_Accuracy  mean_test_F1  std_test_F1  mean_fit_time  std_fit_time  \\\n",
       "3            0.032049      0.158971     0.029847       0.115492      0.021713   \n",
       "2            0.019597      0.115365     0.016097       0.085984      0.027128   \n",
       "1            0.007006      0.035022     0.001842       0.063088      0.006446   \n",
       "0            0.001571      0.005373     0.000109       0.078126      0.021830   \n",
       "17           0.011179      0.138871     0.010335       0.117540      0.027340   \n",
       "14           0.019076      0.136252     0.013262       0.121260      0.021151   \n",
       "18           0.024885      0.152828     0.022614       0.147022      0.033294   \n",
       "13           0.010517      0.049987     0.007795       0.093401      0.017001   \n",
       "19           0.023951      0.083201     0.014046       0.156612      0.026966   \n",
       "15           0.005819      0.058851     0.012346       0.151654      0.044906   \n",
       "10           0.010641      0.021178     0.004356       0.104328      0.013185   \n",
       "16           0.003718      0.009647     0.002243       0.104254      0.019675   \n",
       "4            0.001571      0.005373     0.000109       0.098520      0.023966   \n",
       "5            0.001571      0.005373     0.000109       0.111241      0.036913   \n",
       "6            0.001571      0.005373     0.000109       0.090990      0.006875   \n",
       "7            0.001571      0.005373     0.000109       0.101602      0.017586   \n",
       "8            0.001571      0.005373     0.000109       0.112797      0.034542   \n",
       "9            0.001571      0.005373     0.000109       0.101287      0.013304   \n",
       "11           0.001571      0.005373     0.000109       0.177027      0.041403   \n",
       "12           0.001571      0.005373     0.000109       0.126650      0.034911   \n",
       "\n",
       "    mean_score_time  std_score_time  \n",
       "3          0.032272        0.011665  \n",
       "2          0.030430        0.008061  \n",
       "1          0.033002        0.007925  \n",
       "0          0.028752        0.006309  \n",
       "17         0.035252        0.005718  \n",
       "14         0.044523        0.016788  \n",
       "18         0.030921        0.001165  \n",
       "13         0.040984        0.011037  \n",
       "19         0.030073        0.004913  \n",
       "15         0.038389        0.007873  \n",
       "10         0.037039        0.005660  \n",
       "16         0.042880        0.020364  \n",
       "4          0.036519        0.006185  \n",
       "5          0.039061        0.015089  \n",
       "6          0.045566        0.018642  \n",
       "7          0.033498        0.001976  \n",
       "8          0.044978        0.015403  \n",
       "9          0.034547        0.006468  \n",
       "11         0.042906        0.014360  \n",
       "12         0.047056        0.013823  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_pat=(\"/home/ens/AN03460/Desktop/TP4/music/music/tagged_feature_sets/msd-ssd_dev/msd-ssd_dev.csv\")\n",
    "print('Test ACC ssd')\n",
    "X, Y, le= get_data(dataset_pat)\n",
    "X = preprocessing.normalize(X, norm='max',axis = 0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=60, stratify=Y)\n",
    "N_comp=PCA_Find_ncomp(X_train,0.95)\n",
    "print(N_comp)\n",
    "PCA_X_Train,PCA_X_Test=PCA_transform(X_train,X_test,N_comp)\n",
    "\n",
    "Grid = SVM_Gridsearch(PCA_X_Train, Y_train)\n",
    "\n",
    "print('best param')\n",
    "print(Grid.best_params_)\n",
    "\n",
    "\n",
    "print('best score')\n",
    "print(Grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "Res = plot_analyse_grille(Grid)\n",
    "Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n"
     ]
    }
   ],
   "source": [
    "PCA_X_Train,PCA_X_Test=PCA_transform(X_train,X_test,N_comp)\n",
    "#print('Linear')\n",
    "#SVC_Linear(PCA_X_Train, Y_train, PCA_X_Test, Y_test,1)\n",
    "print('rbf')\n",
    "\n",
    "Svc_ssd,y_pred,train_time,pred_time=SVC_rbf(PCA_X_Train, Y_train, PCA_X_Test, Y_test, 10, 1)\n",
    "print(Svc_ssd)\n",
    "pickle.dump(Svc_ssd,open('svm_ssd.sav','wb'))\n",
    "loaded_model =pickle.load(open('svm_ssd.sav','rb'))\n",
    "\n",
    "svm_result_ssd=loaded_model.score(PCA_X_Test,Y_test)\n",
    "\n",
    "print(loaded_model.predict(PCA_X_Test))\n",
    "print('pickle result')\n",
    "print (svm_result_ssd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC mfccs\n",
      "3\n",
      "best param\n",
      "{'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "best score\n",
      "0.1404\n"
     ]
    }
   ],
   "source": [
    "dataset_path=(\"/home/ens/AN03460/Desktop/TP4/music/music/tagged_feature_sets/msd-jmirmfccs_dev/msd-jmirmfccs_dev.csv\")\n",
    "print('Test ACC mfccs')\n",
    "X, Y,le = get_data(dataset_path)\n",
    "X = preprocessing.normalize(X, norm='max',axis = 0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=60, stratify=Y)\n",
    "# N_comp=PCA_Find_ncomp(X_train,0.95)\n",
    "# print(N_comp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#PCA_X_Train,PCA_X_Test=PCA_transform(X_train,X_test,N_comp)\n",
    "\n",
    "Grid = SVM_Gridsearch(X_Train[:30000], Y_train[:30000])\n",
    "\n",
    "print('best param')\n",
    "print(Grid.best_params_)\n",
    "\n",
    "\n",
    "print('best score')\n",
    "print(Grid.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mean_fit_time': array([26.72469625, 25.57011623, 25.54970007, 32.64484248, 53.91286888,\n",
      "       54.86628165, 55.18106117, 55.93486056, 54.750419  , 53.67972298,\n",
      "       49.68433213, 48.48181171, 54.43011436, 50.1214973 , 48.94948068,\n",
      "       52.89856391, 52.70722251, 51.59332728, 59.4559731 , 74.81414485]), 'std_fit_time': array([1.04170657, 1.03355321, 0.59853451, 1.05009155, 1.11950953,\n",
      "       1.58059995, 2.77150886, 1.39250743, 1.9863211 , 1.37145123,\n",
      "       0.82312713, 1.31739687, 1.2243021 , 0.89164307, 0.90092513,\n",
      "       0.99151546, 0.41501351, 0.93456974, 1.81506376, 1.68161018]), 'mean_score_time': array([23.48875957, 23.14463782, 20.33279142, 23.59023485, 24.68051019,\n",
      "       26.43022356, 25.4460351 , 25.66032491, 25.45206685, 26.01465445,\n",
      "       25.80742579, 26.60310726, 25.70872784, 26.05961776, 25.40318375,\n",
      "       26.7483664 , 25.50741992, 26.49528227, 23.91405568, 26.7616785 ]), 'std_score_time': array([0.36563545, 0.37880231, 0.79353644, 0.77004633, 1.30019695,\n",
      "       1.27428134, 0.22355442, 1.23714043, 0.64517877, 0.69226994,\n",
      "       0.75357474, 0.32942387, 1.12229845, 0.6260352 , 1.05197096,\n",
      "       0.66914603, 1.53816845, 0.39319565, 1.01820892, 0.68474372]), 'param_C': masked_array(data=[0.001, 0.1, 1, 10, 0.001, 0.001, 0.001, 0.001, 0.1,\n",
      "                   0.1, 0.1, 0.1, 1, 1, 1, 1, 10, 10, 10, 10],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_kernel': masked_array(data=['linear', 'linear', 'linear', 'linear', 'rbf', 'rbf',\n",
      "                   'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf',\n",
      "                   'rbf', 'rbf', 'rbf', 'rbf', 'rbf', 'rbf'],\n",
      "             mask=[False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_gamma': masked_array(data=[--, --, --, --, 0.001, 0.1, 1, 10, 0.001, 0.1, 1, 10,\n",
      "                   0.001, 0.1, 1, 10, 0.001, 0.1, 1, 10],\n",
      "             mask=[ True,  True,  True,  True, False, False, False, False,\n",
      "                   False, False, False, False, False, False, False, False,\n",
      "                   False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'C': 0.001, 'kernel': 'linear'}, {'C': 0.1, 'kernel': 'linear'}, {'C': 1, 'kernel': 'linear'}, {'C': 10, 'kernel': 'linear'}, {'C': 0.001, 'gamma': 0.001, 'kernel': 'rbf'}, {'C': 0.001, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 0.001, 'gamma': 1, 'kernel': 'rbf'}, {'C': 0.001, 'gamma': 10, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 0.001, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 1, 'kernel': 'rbf'}, {'C': 0.1, 'gamma': 10, 'kernel': 'rbf'}, {'C': 1, 'gamma': 0.001, 'kernel': 'rbf'}, {'C': 1, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 1, 'gamma': 1, 'kernel': 'rbf'}, {'C': 1, 'gamma': 10, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.001, 'kernel': 'rbf'}, {'C': 10, 'gamma': 0.1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 1, 'kernel': 'rbf'}, {'C': 10, 'gamma': 10, 'kernel': 'rbf'}], 'split0_test_F1': array([0.00496956, 0.0359543 , 0.05390457, 0.05917043, 0.00496724,\n",
      "       0.00496724, 0.00496724, 0.00496724, 0.00496724, 0.02904036,\n",
      "       0.05730237, 0.08027711, 0.00497112, 0.05074875, 0.07780399,\n",
      "       0.09314061, 0.02636236, 0.07108148, 0.08509473, 0.09674296]), 'split1_test_F1': array([0.00496483, 0.0351808 , 0.05578442, 0.06121576, 0.00496095,\n",
      "       0.00496095, 0.00496095, 0.00496095, 0.00496095, 0.02919008,\n",
      "       0.05297971, 0.08145338, 0.00496483, 0.04516493, 0.07774909,\n",
      "       0.08906597, 0.02711981, 0.07196184, 0.08348196, 0.09778468]), 'split2_test_F1': array([0.0049726 , 0.03552859, 0.05661514, 0.05834804, 0.00496793,\n",
      "       0.00496793, 0.00496793, 0.00496793, 0.00496793, 0.02763881,\n",
      "       0.05186551, 0.08166785, 0.00497416, 0.04795664, 0.07861997,\n",
      "       0.09101283, 0.02593434, 0.06953173, 0.08387595, 0.0923425 ]), 'split3_test_F1': array([0.00495143, 0.03603832, 0.05438956, 0.06016214, 0.00496871,\n",
      "       0.00496871, 0.00496871, 0.00496871, 0.00496871, 0.02676951,\n",
      "       0.05649854, 0.0837998 , 0.00495453, 0.04736141, 0.08374107,\n",
      "       0.09042513, 0.02624938, 0.07188539, 0.08412937, 0.09306643]), 'split4_test_F1': array([0.00533686, 0.03581966, 0.05517207, 0.05799836, 0.00497104,\n",
      "       0.00497104, 0.00497104, 0.00497104, 0.00497104, 0.0273249 ,\n",
      "       0.05007307, 0.07842513, 0.00533602, 0.04938723, 0.07375832,\n",
      "       0.08575778, 0.02540261, 0.06571864, 0.07849807, 0.08831808]), 'mean_test_F1': array([0.00503896, 0.03570428, 0.05517268, 0.05937954, 0.00496717,\n",
      "       0.00496717, 0.00496717, 0.00496717, 0.00496717, 0.02799378,\n",
      "       0.05374591, 0.08112457, 0.00504003, 0.04812416, 0.07833446,\n",
      "       0.08988249, 0.02621416, 0.07003747, 0.08301783, 0.09365455]), 'std_test_F1': array([1.49000825e-04, 3.13853370e-04, 9.67255831e-04, 1.18310319e-03,\n",
      "       3.36665760e-06, 3.36665760e-06, 3.36665760e-06, 3.36665760e-06,\n",
      "       3.36665760e-06, 9.59182246e-04, 2.75089939e-03, 1.76357225e-03,\n",
      "       1.48022016e-04, 1.89045843e-03, 3.18830923e-03, 2.44399047e-03,\n",
      "       5.62161399e-04, 2.32780499e-03, 2.31987686e-03, 3.38039720e-03]), 'rank_test_F1': array([15, 11,  8,  7, 16, 16, 16, 16, 16, 12,  9,  4, 14, 10,  5,  2, 13,\n",
      "        6,  3,  1], dtype=int32), 'split0_train_F1': array([0.00505633, 0.03553417, 0.05537725, 0.05827954, 0.00496716,\n",
      "       0.00496716, 0.00496716, 0.00496716, 0.00496716, 0.02855809,\n",
      "       0.05322772, 0.0854015 , 0.00505698, 0.04853469, 0.08205391,\n",
      "       0.10226318, 0.02716947, 0.07271858, 0.08820946, 0.11429297]), 'split1_train_F1': array([0.00505772, 0.03589826, 0.05519169, 0.05843106, 0.00496873,\n",
      "       0.00496873, 0.00496873, 0.00496873, 0.00496873, 0.0272156 ,\n",
      "       0.05579322, 0.08232545, 0.00505856, 0.04794713, 0.08272402,\n",
      "       0.09728825, 0.02584191, 0.07313535, 0.08766584, 0.11476908]), 'split2_train_F1': array([0.00505577, 0.03609469, 0.05703769, 0.05989547, 0.00496698,\n",
      "       0.00496698, 0.00496698, 0.00496698, 0.00496698, 0.0293257 ,\n",
      "       0.05152524, 0.08197381, 0.00505643, 0.04864271, 0.08093086,\n",
      "       0.10165572, 0.0270986 , 0.06986314, 0.08872118, 0.11397983]), 'split3_train_F1': array([0.00506156, 0.03616836, 0.05393716, 0.05776063, 0.00496679,\n",
      "       0.00496679, 0.00496679, 0.00496679, 0.00496679, 0.02604161,\n",
      "       0.05538599, 0.08131739, 0.00506212, 0.05066417, 0.07976878,\n",
      "       0.09712891, 0.02593021, 0.07107914, 0.08555734, 0.11522248]), 'split4_train_F1': array([0.004965  , 0.03683901, 0.05879609, 0.06301182, 0.00496621,\n",
      "       0.00496621, 0.00496621, 0.00496621, 0.00496621, 0.02844513,\n",
      "       0.05577143, 0.0832793 , 0.00496694, 0.0526743 , 0.08011241,\n",
      "       0.10022483, 0.02710409, 0.07260145, 0.08673186, 0.11351527]), 'mean_train_F1': array([0.00503928, 0.0361069 , 0.05606798, 0.0594757 , 0.00496717,\n",
      "       0.00496717, 0.00496717, 0.00496717, 0.00496717, 0.02791723,\n",
      "       0.05434072, 0.08285949, 0.00504021, 0.0496926 , 0.081118  ,\n",
      "       0.09971218, 0.02662885, 0.07187953, 0.08737713, 0.11435593]), 'std_train_F1': array([3.71928181e-05, 4.26958386e-04, 1.68334792e-03, 1.90493453e-03,\n",
      "       8.41731663e-07, 8.41731663e-07, 8.41731663e-07, 8.41731663e-07,\n",
      "       8.41731663e-07, 1.15614820e-03, 1.69793813e-03, 1.42026353e-03,\n",
      "       3.66858139e-05, 1.75066855e-03, 1.12444409e-03, 2.14925562e-03,\n",
      "       6.07643441e-04, 1.22545475e-03, 1.12344227e-03, 5.95604899e-04]), 'split0_test_Accuracy': array([0.06620093, 0.11676647, 0.12591484, 0.13057219, 0.06620093,\n",
      "       0.06620093, 0.06620093, 0.06620093, 0.06620093, 0.09846973,\n",
      "       0.12757818, 0.13722555, 0.06620093, 0.12292083, 0.13589488,\n",
      "       0.14055223, 0.09431138, 0.1340652 , 0.13922156, 0.13988689]), 'split1_test_Accuracy': array([0.06611157, 0.1122398 , 0.12722731, 0.13005828, 0.06611157,\n",
      "       0.06611157, 0.06611157, 0.06611157, 0.06611157, 0.09525396,\n",
      "       0.11923397, 0.13522065, 0.06611157, 0.11740216, 0.13039134,\n",
      "       0.13888426, 0.09392173, 0.13205662, 0.13355537, 0.14338052]), 'split2_test_Accuracy': array([0.06621081, 0.11257505, 0.12658439, 0.12691795, 0.06621081,\n",
      "       0.06621081, 0.06621081, 0.06621081, 0.06621081, 0.09356237,\n",
      "       0.12324883, 0.13975984, 0.06621081, 0.12058039, 0.13592395,\n",
      "       0.14059373, 0.09222815, 0.13342228, 0.13942628, 0.13959306]), 'split3_test_Accuracy': array([0.06588824, 0.11192661, 0.12493745, 0.12877398, 0.06622185,\n",
      "       0.06622185, 0.06622185, 0.06622185, 0.06622185, 0.09157631,\n",
      "       0.1264387 , 0.14228524, 0.06588824, 0.11893244, 0.14345288,\n",
      "       0.14195163, 0.09074229, 0.13561301, 0.14078399, 0.14478732]), 'split4_test_Accuracy': array([0.0664219 , 0.11381842, 0.12149533, 0.12283044, 0.06625501,\n",
      "       0.06625501, 0.06625501, 0.06625501, 0.06625501, 0.0956275 ,\n",
      "       0.11698932, 0.13467957, 0.0664219 , 0.11799065, 0.13167557,\n",
      "       0.13384513, 0.09312417, 0.126502  , 0.13067423, 0.13434579]), 'mean_test_Accuracy': array([0.06616667, 0.11346667, 0.12523333, 0.12783333, 0.0662    ,\n",
      "       0.0662    , 0.0662    , 0.0662    , 0.0662    , 0.0949    ,\n",
      "       0.1227    , 0.13783333, 0.06616667, 0.11956667, 0.13546667,\n",
      "       0.13916667, 0.09286667, 0.13233333, 0.13673333, 0.1404    ]), 'std_test_Accuracy': array([1.72437270e-04, 1.77227236e-03, 2.01545560e-03, 2.79956722e-03,\n",
      "       4.78374494e-05, 4.78374494e-05, 4.78374494e-05, 4.78374494e-05,\n",
      "       4.78374494e-05, 2.29120562e-03, 4.06701854e-03, 2.85120255e-03,\n",
      "       1.72437270e-04, 1.99354970e-03, 4.56624095e-03, 2.83087107e-03,\n",
      "       1.27971366e-03, 3.12964605e-03, 3.91449937e-03, 3.62332706e-03]), 'rank_test_Accuracy': array([19, 11,  8,  7, 14, 14, 14, 14, 14, 12,  9,  3, 19, 10,  5,  2, 13,\n",
      "        6,  4,  1], dtype=int32), 'split0_train_Accuracy': array([0.06615808, 0.1121394 , 0.12531266, 0.12660497, 0.06619977,\n",
      "       0.06619977, 0.06619977, 0.06619977, 0.06619977, 0.09454727,\n",
      "       0.12256128, 0.14140404, 0.06615808, 0.11926797, 0.13844422,\n",
      "       0.14974154, 0.09338002, 0.13381691, 0.14107054, 0.15812073]), 'split1_train_Accuracy': array([0.06618045, 0.11439883, 0.12681809, 0.12840175, 0.06622213,\n",
      "       0.06622213, 0.06622213, 0.06622213, 0.06622213, 0.09472807,\n",
      "       0.12444259, 0.13857054, 0.06618045, 0.12010836, 0.13965409,\n",
      "       0.14765576, 0.09389456, 0.13369452, 0.14098771, 0.1577412 ]), 'split2_train_Accuracy': array([0.06615564, 0.11360607, 0.12664556, 0.12864523, 0.0661973 ,\n",
      "       0.0661973 , 0.0661973 , 0.0661973 , 0.0661973 , 0.09623396,\n",
      "       0.12168805, 0.13893518, 0.06615564, 0.12022996, 0.13910182,\n",
      "       0.14797534, 0.09390102, 0.13551908, 0.14280953, 0.15718214]), 'split3_train_Accuracy': array([0.0662362 , 0.11385128, 0.12572381, 0.12709852, 0.06619454,\n",
      "       0.06619454, 0.06619454, 0.06619454, 0.06619454, 0.09306395,\n",
      "       0.12339096, 0.13859613, 0.0662362 , 0.12214122, 0.13697146,\n",
      "       0.14767757, 0.09206415, 0.13288898, 0.1400125 , 0.1582587 ]), 'split4_train_Accuracy': array([0.06610297, 0.11500333, 0.12833222, 0.13045651, 0.06618627,\n",
      "       0.06618627, 0.06618627, 0.06618627, 0.06618627, 0.09605132,\n",
      "       0.12616628, 0.14116128, 0.06610297, 0.12308397, 0.1384955 ,\n",
      "       0.14845052, 0.09446851, 0.13537154, 0.14145285, 0.15894702]), 'mean_train_Accuracy': array([0.06616667, 0.11379978, 0.12656647, 0.1282414 , 0.0662    ,\n",
      "       0.0662    , 0.0662    , 0.0662    , 0.0662    , 0.09492491,\n",
      "       0.12364983, 0.13973343, 0.06616667, 0.1209663 , 0.13853342,\n",
      "       0.14830014, 0.09354165, 0.13425821, 0.14126662, 0.15804995]), 'std_train_Accuracy': array([4.30772026e-05, 9.59628243e-04, 1.04590413e-03, 1.34756059e-03,\n",
      "       1.19609487e-05, 1.19609487e-05, 1.19609487e-05, 1.19609487e-05,\n",
      "       1.19609487e-05, 1.15125602e-03, 1.55315860e-03, 1.27378712e-03,\n",
      "       4.30772026e-05, 1.41616166e-03, 8.97561780e-04, 7.75700558e-04,\n",
      "       8.15092726e-04, 1.02142881e-03, 9.06015870e-04, 5.83394257e-04])}\n"
     ]
    }
   ],
   "source": [
    "Res = plot_analyse_grille(Grid)\n",
    "Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rbf\n",
      "[[  8   2  73   6   2  48   8   0   0  26 121   2   0   0   4  58   0   0\n",
      "    0   0   0   0  47   4   0]\n",
      " [ 11   4 125  26   4  43  13   0   0 124 140  32   1   1   7 214   0   5\n",
      "    0   0   0  33 101  18   0]\n",
      " [ 12   3 209  19   2  64   4   0   0 274 177  45   0   2  27 287   0   1\n",
      "    0   0   0  46 280  11   0]\n",
      " [  2   1  76 366   5  39   4   0   0 559 175 141   8   4  79 209   0   0\n",
      "    1   0   0  22 244  41   1]\n",
      " [  3   3  95 150  13  60   7   0   0 279 252  73  14   5  24 193   0   5\n",
      "    0   0   0  31 181  39   3]\n",
      " [  6   2 122  95   9 131   8   0   1 228 248  91  31  20  11 320   0  20\n",
      "    0   0   0  44 122  77   0]\n",
      " [  4   2 127  52   5  62   7   0   0 252 231  35   1   1  28 236   0   3\n",
      "    0   0   0  14 203  30   0]\n",
      " [  1   1  66  27   3  20   1   0   0 230  87  81   1   1  26 172   0   3\n",
      "    0   0   0  29 139  28   0]\n",
      " [  1   0  20  19   1  11   0   0   1  68  27 283  41  27  24 109   0  28\n",
      "    0   0   0  63  35  61   0]\n",
      " [  2   0  56 230   6  40   1   0   0 882 110  77   3   5 113 236   0   4\n",
      "    0   0   1  19 275  56   0]\n",
      " [  9   3  80  86   8  76   5   0   0 165 516   3   0   1   6  92   0   0\n",
      "    0   0   0   2 252  10   0]\n",
      " [  5   0  26  48   1  24   1   0   0 135  40 691 198 100  55 175   0  72\n",
      "    0   0   1  72  79 116   0]\n",
      " [  1   1  14  23   4  33   0   0   0  19  21 291 547 108   6  73   1  50\n",
      "    0   0   0  16   9  80   0]\n",
      " [  1   0  22  52   7  19   1   0   0  68  28 422 332 106  12 107   0  49\n",
      "    0   0   0  38  14 128   0]\n",
      " [  3   1  82 126   3  20   1   0   0 577 156 136  10   8 114 205   0   5\n",
      "    0   0   0  49 265  31   0]\n",
      " [  2   4 160  99   7  84   6   0   0 352 203 199  35  20  32 572   0  49\n",
      "    1   0   1 143 283 119   1]\n",
      " [  1   0  58  41   1  15   1   0   0 368  62  50   0   1  49 160   1   1\n",
      "    0   0   1  17 164  19   0]\n",
      " [  0   0  23  35   2  25   2   0   0  56  21 353 160  80   4 169   0 113\n",
      "    0   0   1  91  27  99   0]\n",
      " [  0   0  39  83   2  28   0   0   0 224  39  25   5   4  10  88   0   3\n",
      "    0   0   0   9 111  17   0]\n",
      " [  1   1  75  32   0  46   6   0   0 231  99   7   0   1  19 133   0   2\n",
      "    0   0   0   4 154  10   0]\n",
      " [  2   2  89  66   2  33   7   0   0 271 104 294  50  30  48 316   0  44\n",
      "    0   0   0  92 152  65   0]\n",
      " [  2   2 111  76   5  56   4   0   0 295 148 307  58  49  34 447   0  66\n",
      "    0   0   0 175 225 111   0]\n",
      " [  2   0 150  90   8  33   1   0   0 542 271 136   5   1 111 282   0   2\n",
      "    0   0   0  54 446  32   0]\n",
      " [  2   0  75 114   2  55   3   0   0 206  56 352 103  57  23 296   0  45\n",
      "    2   0   0  81  81 191   0]\n",
      " [  0   1  48  50   3  40   1   0   0 142  43 386 121  63  10 219   0  65\n",
      "    0   0   0  90  70 100   1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.10      0.02      0.03       409\n",
      "           1       0.12      0.00      0.01       902\n",
      "           2       0.10      0.14      0.12      1463\n",
      "           3       0.18      0.19      0.18      1977\n",
      "           4       0.12      0.01      0.02      1430\n",
      "           5       0.12      0.08      0.10      1586\n",
      "           6       0.08      0.01      0.01      1293\n",
      "           7       0.00      0.00      0.00       916\n",
      "           8       0.50      0.00      0.00       819\n",
      "           9       0.13      0.42      0.20      2116\n",
      "          10       0.15      0.39      0.22      1314\n",
      "          11       0.15      0.38      0.22      1839\n",
      "          12       0.32      0.42      0.36      1297\n",
      "          13       0.15      0.08      0.10      1406\n",
      "          14       0.13      0.06      0.09      1792\n",
      "          15       0.11      0.24      0.15      2372\n",
      "          16       0.50      0.00      0.00      1010\n",
      "          17       0.18      0.09      0.12      1261\n",
      "          18       0.00      0.00      0.00       687\n",
      "          19       0.00      0.00      0.00       821\n",
      "          20       0.00      0.00      0.00      1667\n",
      "          21       0.14      0.08      0.10      2171\n",
      "          22       0.11      0.21      0.15      2166\n",
      "          23       0.13      0.11      0.12      1744\n",
      "          24       0.17      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.14     35911\n",
      "   macro avg       0.15      0.12      0.09     35911\n",
      "weighted avg       0.14      0.14      0.11     35911\n",
      "\n",
      "Temps de training: 1755.3272359371185 Temps de pr√©diction:  240.72392201423645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[  8,   2,  73,   6,   2,  48,   8,   0,   0,  26, 121,   2,   0,\n",
       "           0,   4,  58,   0,   0,   0,   0,   0,   0,  47,   4,   0],\n",
       "        [ 11,   4, 125,  26,   4,  43,  13,   0,   0, 124, 140,  32,   1,\n",
       "           1,   7, 214,   0,   5,   0,   0,   0,  33, 101,  18,   0],\n",
       "        [ 12,   3, 209,  19,   2,  64,   4,   0,   0, 274, 177,  45,   0,\n",
       "           2,  27, 287,   0,   1,   0,   0,   0,  46, 280,  11,   0],\n",
       "        [  2,   1,  76, 366,   5,  39,   4,   0,   0, 559, 175, 141,   8,\n",
       "           4,  79, 209,   0,   0,   1,   0,   0,  22, 244,  41,   1],\n",
       "        [  3,   3,  95, 150,  13,  60,   7,   0,   0, 279, 252,  73,  14,\n",
       "           5,  24, 193,   0,   5,   0,   0,   0,  31, 181,  39,   3],\n",
       "        [  6,   2, 122,  95,   9, 131,   8,   0,   1, 228, 248,  91,  31,\n",
       "          20,  11, 320,   0,  20,   0,   0,   0,  44, 122,  77,   0],\n",
       "        [  4,   2, 127,  52,   5,  62,   7,   0,   0, 252, 231,  35,   1,\n",
       "           1,  28, 236,   0,   3,   0,   0,   0,  14, 203,  30,   0],\n",
       "        [  1,   1,  66,  27,   3,  20,   1,   0,   0, 230,  87,  81,   1,\n",
       "           1,  26, 172,   0,   3,   0,   0,   0,  29, 139,  28,   0],\n",
       "        [  1,   0,  20,  19,   1,  11,   0,   0,   1,  68,  27, 283,  41,\n",
       "          27,  24, 109,   0,  28,   0,   0,   0,  63,  35,  61,   0],\n",
       "        [  2,   0,  56, 230,   6,  40,   1,   0,   0, 882, 110,  77,   3,\n",
       "           5, 113, 236,   0,   4,   0,   0,   1,  19, 275,  56,   0],\n",
       "        [  9,   3,  80,  86,   8,  76,   5,   0,   0, 165, 516,   3,   0,\n",
       "           1,   6,  92,   0,   0,   0,   0,   0,   2, 252,  10,   0],\n",
       "        [  5,   0,  26,  48,   1,  24,   1,   0,   0, 135,  40, 691, 198,\n",
       "         100,  55, 175,   0,  72,   0,   0,   1,  72,  79, 116,   0],\n",
       "        [  1,   1,  14,  23,   4,  33,   0,   0,   0,  19,  21, 291, 547,\n",
       "         108,   6,  73,   1,  50,   0,   0,   0,  16,   9,  80,   0],\n",
       "        [  1,   0,  22,  52,   7,  19,   1,   0,   0,  68,  28, 422, 332,\n",
       "         106,  12, 107,   0,  49,   0,   0,   0,  38,  14, 128,   0],\n",
       "        [  3,   1,  82, 126,   3,  20,   1,   0,   0, 577, 156, 136,  10,\n",
       "           8, 114, 205,   0,   5,   0,   0,   0,  49, 265,  31,   0],\n",
       "        [  2,   4, 160,  99,   7,  84,   6,   0,   0, 352, 203, 199,  35,\n",
       "          20,  32, 572,   0,  49,   1,   0,   1, 143, 283, 119,   1],\n",
       "        [  1,   0,  58,  41,   1,  15,   1,   0,   0, 368,  62,  50,   0,\n",
       "           1,  49, 160,   1,   1,   0,   0,   1,  17, 164,  19,   0],\n",
       "        [  0,   0,  23,  35,   2,  25,   2,   0,   0,  56,  21, 353, 160,\n",
       "          80,   4, 169,   0, 113,   0,   0,   1,  91,  27,  99,   0],\n",
       "        [  0,   0,  39,  83,   2,  28,   0,   0,   0, 224,  39,  25,   5,\n",
       "           4,  10,  88,   0,   3,   0,   0,   0,   9, 111,  17,   0],\n",
       "        [  1,   1,  75,  32,   0,  46,   6,   0,   0, 231,  99,   7,   0,\n",
       "           1,  19, 133,   0,   2,   0,   0,   0,   4, 154,  10,   0],\n",
       "        [  2,   2,  89,  66,   2,  33,   7,   0,   0, 271, 104, 294,  50,\n",
       "          30,  48, 316,   0,  44,   0,   0,   0,  92, 152,  65,   0],\n",
       "        [  2,   2, 111,  76,   5,  56,   4,   0,   0, 295, 148, 307,  58,\n",
       "          49,  34, 447,   0,  66,   0,   0,   0, 175, 225, 111,   0],\n",
       "        [  2,   0, 150,  90,   8,  33,   1,   0,   0, 542, 271, 136,   5,\n",
       "           1, 111, 282,   0,   2,   0,   0,   0,  54, 446,  32,   0],\n",
       "        [  2,   0,  75, 114,   2,  55,   3,   0,   0, 206,  56, 352, 103,\n",
       "          57,  23, 296,   0,  45,   2,   0,   0,  81,  81, 191,   0],\n",
       "        [  0,   1,  48,  50,   3,  40,   1,   0,   0, 142,  43, 386, 121,\n",
       "          63,  10, 219,   0,  65,   0,   0,   0,  90,  70, 100,   1]]),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.10      0.02      0.03       409\\n           1       0.12      0.00      0.01       902\\n           2       0.10      0.14      0.12      1463\\n           3       0.18      0.19      0.18      1977\\n           4       0.12      0.01      0.02      1430\\n           5       0.12      0.08      0.10      1586\\n           6       0.08      0.01      0.01      1293\\n           7       0.00      0.00      0.00       916\\n           8       0.50      0.00      0.00       819\\n           9       0.13      0.42      0.20      2116\\n          10       0.15      0.39      0.22      1314\\n          11       0.15      0.38      0.22      1839\\n          12       0.32      0.42      0.36      1297\\n          13       0.15      0.08      0.10      1406\\n          14       0.13      0.06      0.09      1792\\n          15       0.11      0.24      0.15      2372\\n          16       0.50      0.00      0.00      1010\\n          17       0.18      0.09      0.12      1261\\n          18       0.00      0.00      0.00       687\\n          19       0.00      0.00      0.00       821\\n          20       0.00      0.00      0.00      1667\\n          21       0.14      0.08      0.10      2171\\n          22       0.11      0.21      0.15      2166\\n          23       0.13      0.11      0.12      1744\\n          24       0.17      0.00      0.00      1453\\n\\n    accuracy                           0.14     35911\\n   macro avg       0.15      0.12      0.09     35911\\nweighted avg       0.14      0.14      0.11     35911\\n',\n",
       " 1755.3272359371185,\n",
       " 240.72392201423645)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#print('Linear')\n",
    "#SVC_Linear(PCA_X_Train, Y_train, PCA_X_Test, Y_test,1)\n",
    "print('rbf')\n",
    "SVC_rbf(PCA_X_Train, Y_train, PCA_X_Test, Y_test,10,10)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC marsvas\n",
      "1\n",
      "best param\n",
      "{'C': 10, 'gamma': 10, 'kernel': 'rbf'}\n",
      "best score\n",
      "0.1404\n"
     ]
    }
   ],
   "source": [
    "dataset_path=(\"/home/ens/AN03460/Desktop/TP4/music/music/tagged_feature_sets/msd-marsyas_dev_new/msd-marsyas_dev_new.csv\")\n",
    "print('Test ACC marsvas')\n",
    "X, Y,le = get_data(dataset_path)\n",
    "X = preprocessing.normalize(X, norm='max',axis = 0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=60, stratify=Y)\n",
    "N_comp=PCA_Find_ncomp(X_train,0.999)\n",
    "print(N_comp)\n",
    "Grid = SVM_Gridsearch(PCA_X_Train[:30000], Y_train[:30000])\n",
    "\n",
    "print('best param')\n",
    "print(Grid.best_params_)\n",
    "\n",
    "\n",
    "print('best score')\n",
    "print(Grid.best_score_)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_kernel</th>\n",
       "      <th>param_C</th>\n",
       "      <th>param_gamma</th>\n",
       "      <th>rank_test_Accuracy</th>\n",
       "      <th>mean_test_Accuracy</th>\n",
       "      <th>std_test_Accuracy</th>\n",
       "      <th>mean_test_F1</th>\n",
       "      <th>std_test_F1</th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>linear</td>\n",
       "      <td>10</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>0.189</td>\n",
       "      <td>0.032049</td>\n",
       "      <td>0.158971</td>\n",
       "      <td>0.029847</td>\n",
       "      <td>0.115492</td>\n",
       "      <td>0.021713</td>\n",
       "      <td>0.032272</td>\n",
       "      <td>0.011665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>linear</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>0.182</td>\n",
       "      <td>0.019597</td>\n",
       "      <td>0.115365</td>\n",
       "      <td>0.016097</td>\n",
       "      <td>0.085984</td>\n",
       "      <td>0.027128</td>\n",
       "      <td>0.030430</td>\n",
       "      <td>0.008061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.007006</td>\n",
       "      <td>0.035022</td>\n",
       "      <td>0.001842</td>\n",
       "      <td>0.063088</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.033002</td>\n",
       "      <td>0.007925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>linear</td>\n",
       "      <td>0.001</td>\n",
       "      <td>NaN</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.078126</td>\n",
       "      <td>0.021830</td>\n",
       "      <td>0.028752</td>\n",
       "      <td>0.006309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196</td>\n",
       "      <td>0.011179</td>\n",
       "      <td>0.138871</td>\n",
       "      <td>0.010335</td>\n",
       "      <td>0.117540</td>\n",
       "      <td>0.027340</td>\n",
       "      <td>0.035252</td>\n",
       "      <td>0.005718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.191</td>\n",
       "      <td>0.019076</td>\n",
       "      <td>0.136252</td>\n",
       "      <td>0.013262</td>\n",
       "      <td>0.121260</td>\n",
       "      <td>0.021151</td>\n",
       "      <td>0.044523</td>\n",
       "      <td>0.016788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.177</td>\n",
       "      <td>0.024885</td>\n",
       "      <td>0.152828</td>\n",
       "      <td>0.022614</td>\n",
       "      <td>0.147022</td>\n",
       "      <td>0.033294</td>\n",
       "      <td>0.030921</td>\n",
       "      <td>0.001165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6</td>\n",
       "      <td>0.133</td>\n",
       "      <td>0.010517</td>\n",
       "      <td>0.049987</td>\n",
       "      <td>0.007795</td>\n",
       "      <td>0.093401</td>\n",
       "      <td>0.017001</td>\n",
       "      <td>0.040984</td>\n",
       "      <td>0.011037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>0.119</td>\n",
       "      <td>0.023951</td>\n",
       "      <td>0.083201</td>\n",
       "      <td>0.014046</td>\n",
       "      <td>0.156612</td>\n",
       "      <td>0.026966</td>\n",
       "      <td>0.030073</td>\n",
       "      <td>0.004913</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.005819</td>\n",
       "      <td>0.058851</td>\n",
       "      <td>0.012346</td>\n",
       "      <td>0.151654</td>\n",
       "      <td>0.044906</td>\n",
       "      <td>0.038389</td>\n",
       "      <td>0.007873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>0.083</td>\n",
       "      <td>0.010641</td>\n",
       "      <td>0.021178</td>\n",
       "      <td>0.004356</td>\n",
       "      <td>0.104328</td>\n",
       "      <td>0.013185</td>\n",
       "      <td>0.037039</td>\n",
       "      <td>0.005660</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>rbf</td>\n",
       "      <td>10</td>\n",
       "      <td>0.001</td>\n",
       "      <td>11</td>\n",
       "      <td>0.075</td>\n",
       "      <td>0.003718</td>\n",
       "      <td>0.009647</td>\n",
       "      <td>0.002243</td>\n",
       "      <td>0.104254</td>\n",
       "      <td>0.019675</td>\n",
       "      <td>0.042880</td>\n",
       "      <td>0.020364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.098520</td>\n",
       "      <td>0.023966</td>\n",
       "      <td>0.036519</td>\n",
       "      <td>0.006185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.111241</td>\n",
       "      <td>0.036913</td>\n",
       "      <td>0.039061</td>\n",
       "      <td>0.015089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.090990</td>\n",
       "      <td>0.006875</td>\n",
       "      <td>0.045566</td>\n",
       "      <td>0.018642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.001</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.101602</td>\n",
       "      <td>0.017586</td>\n",
       "      <td>0.033498</td>\n",
       "      <td>0.001976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.112797</td>\n",
       "      <td>0.034542</td>\n",
       "      <td>0.044978</td>\n",
       "      <td>0.015403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.101287</td>\n",
       "      <td>0.013304</td>\n",
       "      <td>0.034547</td>\n",
       "      <td>0.006468</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>rbf</td>\n",
       "      <td>0.1</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.177027</td>\n",
       "      <td>0.041403</td>\n",
       "      <td>0.042906</td>\n",
       "      <td>0.014360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rbf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001</td>\n",
       "      <td>12</td>\n",
       "      <td>0.072</td>\n",
       "      <td>0.001571</td>\n",
       "      <td>0.005373</td>\n",
       "      <td>0.000109</td>\n",
       "      <td>0.126650</td>\n",
       "      <td>0.034911</td>\n",
       "      <td>0.047056</td>\n",
       "      <td>0.013823</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   param_kernel param_C param_gamma  rank_test_Accuracy  mean_test_Accuracy  \\\n",
       "3        linear      10         NaN                   3               0.189   \n",
       "2        linear       1         NaN                   4               0.182   \n",
       "1        linear     0.1         NaN                   8               0.110   \n",
       "0        linear   0.001         NaN                  12               0.072   \n",
       "17          rbf      10         0.1                   1               0.196   \n",
       "14          rbf       1           1                   2               0.191   \n",
       "18          rbf      10           1                   5               0.177   \n",
       "13          rbf       1         0.1                   6               0.133   \n",
       "19          rbf      10          10                   7               0.119   \n",
       "15          rbf       1          10                   8               0.110   \n",
       "10          rbf     0.1           1                  10               0.083   \n",
       "16          rbf      10       0.001                  11               0.075   \n",
       "4           rbf   0.001       0.001                  12               0.072   \n",
       "5           rbf   0.001         0.1                  12               0.072   \n",
       "6           rbf   0.001           1                  12               0.072   \n",
       "7           rbf   0.001          10                  12               0.072   \n",
       "8           rbf     0.1       0.001                  12               0.072   \n",
       "9           rbf     0.1         0.1                  12               0.072   \n",
       "11          rbf     0.1          10                  12               0.072   \n",
       "12          rbf       1       0.001                  12               0.072   \n",
       "\n",
       "    std_test_Accuracy  mean_test_F1  std_test_F1  mean_fit_time  std_fit_time  \\\n",
       "3            0.032049      0.158971     0.029847       0.115492      0.021713   \n",
       "2            0.019597      0.115365     0.016097       0.085984      0.027128   \n",
       "1            0.007006      0.035022     0.001842       0.063088      0.006446   \n",
       "0            0.001571      0.005373     0.000109       0.078126      0.021830   \n",
       "17           0.011179      0.138871     0.010335       0.117540      0.027340   \n",
       "14           0.019076      0.136252     0.013262       0.121260      0.021151   \n",
       "18           0.024885      0.152828     0.022614       0.147022      0.033294   \n",
       "13           0.010517      0.049987     0.007795       0.093401      0.017001   \n",
       "19           0.023951      0.083201     0.014046       0.156612      0.026966   \n",
       "15           0.005819      0.058851     0.012346       0.151654      0.044906   \n",
       "10           0.010641      0.021178     0.004356       0.104328      0.013185   \n",
       "16           0.003718      0.009647     0.002243       0.104254      0.019675   \n",
       "4            0.001571      0.005373     0.000109       0.098520      0.023966   \n",
       "5            0.001571      0.005373     0.000109       0.111241      0.036913   \n",
       "6            0.001571      0.005373     0.000109       0.090990      0.006875   \n",
       "7            0.001571      0.005373     0.000109       0.101602      0.017586   \n",
       "8            0.001571      0.005373     0.000109       0.112797      0.034542   \n",
       "9            0.001571      0.005373     0.000109       0.101287      0.013304   \n",
       "11           0.001571      0.005373     0.000109       0.177027      0.041403   \n",
       "12           0.001571      0.005373     0.000109       0.126650      0.034911   \n",
       "\n",
       "    mean_score_time  std_score_time  \n",
       "3          0.032272        0.011665  \n",
       "2          0.030430        0.008061  \n",
       "1          0.033002        0.007925  \n",
       "0          0.028752        0.006309  \n",
       "17         0.035252        0.005718  \n",
       "14         0.044523        0.016788  \n",
       "18         0.030921        0.001165  \n",
       "13         0.040984        0.011037  \n",
       "19         0.030073        0.004913  \n",
       "15         0.038389        0.007873  \n",
       "10         0.037039        0.005660  \n",
       "16         0.042880        0.020364  \n",
       "4          0.036519        0.006185  \n",
       "5          0.039061        0.015089  \n",
       "6          0.045566        0.018642  \n",
       "7          0.033498        0.001976  \n",
       "8          0.044978        0.015403  \n",
       "9          0.034547        0.006468  \n",
       "11         0.042906        0.014360  \n",
       "12         0.047056        0.013823  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Res = plot_analyse_grille(Grid)\n",
    "Res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "metadata": false,
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test ACC marsvas\n",
      "rbf\n",
      "[[   0    0    0   61    1    0    0    0    0  111  180    6    0    0\n",
      "     0   19    0    1    0    0    0    2   28    0    0]\n",
      " [   0    0    0   92    0    2    0    0    0  337  214   70    3    0\n",
      "     0  112    0    1    0    0    0   19   52    0    0]\n",
      " [   0    0    0  160    2    2    2    0    0  565  268  114    2    0\n",
      "     0  214    0    0    0    0    0   36   97    1    0]\n",
      " [   0    0    0  219    2    3    0    0    0  749  365  155    7    0\n",
      "     1  303    0    1    0    0    0   46  124    0    2]\n",
      " [   0    0    0  143    7    5    1    1    0  484  397  103    5    0\n",
      "     0  179    0    4    0    0    0   23   78    0    0]\n",
      " [   0    0    0  147    5    9    1    0    0  519  409  148   16    0\n",
      "     0  225    1    3    0    0    1   24   78    0    0]\n",
      " [   0    1    0  137    4    2    3    0    0  518  333   56    3    0\n",
      "     0  133    0    1    0    0    0   22   80    0    0]\n",
      " [   0    0    0   76    2    2    0    0    0  383  123  121   11    0\n",
      "     0  139    0    1    0    0    0   17   41    0    0]\n",
      " [   0    0    0   15    0    0    0    0    0  156   45  378   46    0\n",
      "     0  145    0    1    0    0    0   19   14    0    0]\n",
      " [   0    0    0  182    0    8    0    0    0 1076  237  104    3    0\n",
      "     0  339    0    2    0    0    0   36  129    0    0]\n",
      " [   0    0    0  176    3   11    3    0    0  278  700    8    0    0\n",
      "     0   50    0    1    0    0    0    0   84    0    0]\n",
      " [   0    0    0   37    1    1    0    0    0  315   80  918  100    0\n",
      "     0  298    0    5    1    0    0   54   29    0    0]\n",
      " [   0    0    0   19    0    1    0    0    0  177   48  698  111    0\n",
      "     0  199    0    6    0    0    0   23   15    0    0]\n",
      " [   0    0    0   23    1    2    2    0    0  218   57  744   62    1\n",
      "     0  241    0    3    0    0    0   34   18    0    0]\n",
      " [   0    0    0  175    1    1    0    0    0  720  233  219    5    0\n",
      "     0  304    0    1    1    0    0   46   86    0    0]\n",
      " [   0    0    0  173    3    2    1    0    0  822  335  392   37    0\n",
      "     0  424    0    5    0    1    1   42  133    1    0]\n",
      " [   0    0    0   76    0    0    0    0    0  490  107   74    2    1\n",
      "     0  178    0    0    0    0    0   29   53    0    0]\n",
      " [   0    0    0   33    3    4    0    0    0  229   45  581  110    0\n",
      "     0  204    0   13    0    0    1   25   13    0    0]\n",
      " [   0    0    0   88    0    1    0    0    0  315  113   41    2    0\n",
      "     0   74    0    2    0    0    0    9   42    0    0]\n",
      " [   0    0    0  127    0    0    0    0    0  362  171   11    0    0\n",
      "     0   74    0    1    0    0    0    6   69    0    0]\n",
      " [   0    0    0   94    2    1    0    0    0  525  171  443   39    0\n",
      "     0  293    0    7    0    0    0   40   52    0    0]\n",
      " [   0    0    0  143    2    1    2    0    0  688  242  554   51    0\n",
      "     0  377    0    4    0    0    0   35   72    0    0]\n",
      " [   0    0    0  203    1    1    1    0    0  811  392  229   12    0\n",
      "     0  357    0    2    0    0    0   34  122    0    1]\n",
      " [   0    0    0   84    1    3    0    0    0  585  124  500   38    0\n",
      "     0  318    0    4    0    0    0   43   44    0    0]\n",
      " [   0    0    0   54    1    2    0    0    0  356   84  570   74    1\n",
      "     0  236    0    8    0    0    0   33   34    0    0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       409\n",
      "           1       0.00      0.00      0.00       902\n",
      "           2       0.00      0.00      0.00      1463\n",
      "           3       0.08      0.11      0.09      1977\n",
      "           4       0.17      0.00      0.01      1430\n",
      "           5       0.14      0.01      0.01      1586\n",
      "           6       0.19      0.00      0.00      1293\n",
      "           7       0.00      0.00      0.00       916\n",
      "           8       0.00      0.00      0.00       819\n",
      "           9       0.09      0.51      0.15      2116\n",
      "          10       0.13      0.53      0.21      1314\n",
      "          11       0.13      0.50      0.20      1839\n",
      "          12       0.15      0.09      0.11      1297\n",
      "          13       0.33      0.00      0.00      1406\n",
      "          14       0.00      0.00      0.00      1792\n",
      "          15       0.08      0.18      0.11      2372\n",
      "          16       0.00      0.00      0.00      1010\n",
      "          17       0.17      0.01      0.02      1261\n",
      "          18       0.00      0.00      0.00       687\n",
      "          19       0.00      0.00      0.00       821\n",
      "          20       0.00      0.00      0.00      1667\n",
      "          21       0.05      0.02      0.02      2171\n",
      "          22       0.08      0.06      0.07      2166\n",
      "          23       0.00      0.00      0.00      1744\n",
      "          24       0.00      0.00      0.00      1453\n",
      "\n",
      "    accuracy                           0.10     35911\n",
      "   macro avg       0.07      0.08      0.04     35911\n",
      "weighted avg       0.08      0.10      0.05     35911\n",
      "\n",
      "Temps de training: 3156.695788383484 Temps de pr√©diction:  274.0216269493103\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ens/AN03460/venv/lib/python3.6/site-packages/sklearn/metrics/classification.py:1437: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[   0,    0,    0,   61,    1,    0,    0,    0,    0,  111,  180,\n",
       "            6,    0,    0,    0,   19,    0,    1,    0,    0,    0,    2,\n",
       "           28,    0,    0],\n",
       "        [   0,    0,    0,   92,    0,    2,    0,    0,    0,  337,  214,\n",
       "           70,    3,    0,    0,  112,    0,    1,    0,    0,    0,   19,\n",
       "           52,    0,    0],\n",
       "        [   0,    0,    0,  160,    2,    2,    2,    0,    0,  565,  268,\n",
       "          114,    2,    0,    0,  214,    0,    0,    0,    0,    0,   36,\n",
       "           97,    1,    0],\n",
       "        [   0,    0,    0,  219,    2,    3,    0,    0,    0,  749,  365,\n",
       "          155,    7,    0,    1,  303,    0,    1,    0,    0,    0,   46,\n",
       "          124,    0,    2],\n",
       "        [   0,    0,    0,  143,    7,    5,    1,    1,    0,  484,  397,\n",
       "          103,    5,    0,    0,  179,    0,    4,    0,    0,    0,   23,\n",
       "           78,    0,    0],\n",
       "        [   0,    0,    0,  147,    5,    9,    1,    0,    0,  519,  409,\n",
       "          148,   16,    0,    0,  225,    1,    3,    0,    0,    1,   24,\n",
       "           78,    0,    0],\n",
       "        [   0,    1,    0,  137,    4,    2,    3,    0,    0,  518,  333,\n",
       "           56,    3,    0,    0,  133,    0,    1,    0,    0,    0,   22,\n",
       "           80,    0,    0],\n",
       "        [   0,    0,    0,   76,    2,    2,    0,    0,    0,  383,  123,\n",
       "          121,   11,    0,    0,  139,    0,    1,    0,    0,    0,   17,\n",
       "           41,    0,    0],\n",
       "        [   0,    0,    0,   15,    0,    0,    0,    0,    0,  156,   45,\n",
       "          378,   46,    0,    0,  145,    0,    1,    0,    0,    0,   19,\n",
       "           14,    0,    0],\n",
       "        [   0,    0,    0,  182,    0,    8,    0,    0,    0, 1076,  237,\n",
       "          104,    3,    0,    0,  339,    0,    2,    0,    0,    0,   36,\n",
       "          129,    0,    0],\n",
       "        [   0,    0,    0,  176,    3,   11,    3,    0,    0,  278,  700,\n",
       "            8,    0,    0,    0,   50,    0,    1,    0,    0,    0,    0,\n",
       "           84,    0,    0],\n",
       "        [   0,    0,    0,   37,    1,    1,    0,    0,    0,  315,   80,\n",
       "          918,  100,    0,    0,  298,    0,    5,    1,    0,    0,   54,\n",
       "           29,    0,    0],\n",
       "        [   0,    0,    0,   19,    0,    1,    0,    0,    0,  177,   48,\n",
       "          698,  111,    0,    0,  199,    0,    6,    0,    0,    0,   23,\n",
       "           15,    0,    0],\n",
       "        [   0,    0,    0,   23,    1,    2,    2,    0,    0,  218,   57,\n",
       "          744,   62,    1,    0,  241,    0,    3,    0,    0,    0,   34,\n",
       "           18,    0,    0],\n",
       "        [   0,    0,    0,  175,    1,    1,    0,    0,    0,  720,  233,\n",
       "          219,    5,    0,    0,  304,    0,    1,    1,    0,    0,   46,\n",
       "           86,    0,    0],\n",
       "        [   0,    0,    0,  173,    3,    2,    1,    0,    0,  822,  335,\n",
       "          392,   37,    0,    0,  424,    0,    5,    0,    1,    1,   42,\n",
       "          133,    1,    0],\n",
       "        [   0,    0,    0,   76,    0,    0,    0,    0,    0,  490,  107,\n",
       "           74,    2,    1,    0,  178,    0,    0,    0,    0,    0,   29,\n",
       "           53,    0,    0],\n",
       "        [   0,    0,    0,   33,    3,    4,    0,    0,    0,  229,   45,\n",
       "          581,  110,    0,    0,  204,    0,   13,    0,    0,    1,   25,\n",
       "           13,    0,    0],\n",
       "        [   0,    0,    0,   88,    0,    1,    0,    0,    0,  315,  113,\n",
       "           41,    2,    0,    0,   74,    0,    2,    0,    0,    0,    9,\n",
       "           42,    0,    0],\n",
       "        [   0,    0,    0,  127,    0,    0,    0,    0,    0,  362,  171,\n",
       "           11,    0,    0,    0,   74,    0,    1,    0,    0,    0,    6,\n",
       "           69,    0,    0],\n",
       "        [   0,    0,    0,   94,    2,    1,    0,    0,    0,  525,  171,\n",
       "          443,   39,    0,    0,  293,    0,    7,    0,    0,    0,   40,\n",
       "           52,    0,    0],\n",
       "        [   0,    0,    0,  143,    2,    1,    2,    0,    0,  688,  242,\n",
       "          554,   51,    0,    0,  377,    0,    4,    0,    0,    0,   35,\n",
       "           72,    0,    0],\n",
       "        [   0,    0,    0,  203,    1,    1,    1,    0,    0,  811,  392,\n",
       "          229,   12,    0,    0,  357,    0,    2,    0,    0,    0,   34,\n",
       "          122,    0,    1],\n",
       "        [   0,    0,    0,   84,    1,    3,    0,    0,    0,  585,  124,\n",
       "          500,   38,    0,    0,  318,    0,    4,    0,    0,    0,   43,\n",
       "           44,    0,    0],\n",
       "        [   0,    0,    0,   54,    1,    2,    0,    0,    0,  356,   84,\n",
       "          570,   74,    1,    0,  236,    0,    8,    0,    0,    0,   33,\n",
       "           34,    0,    0]]),\n",
       " '              precision    recall  f1-score   support\\n\\n           0       0.00      0.00      0.00       409\\n           1       0.00      0.00      0.00       902\\n           2       0.00      0.00      0.00      1463\\n           3       0.08      0.11      0.09      1977\\n           4       0.17      0.00      0.01      1430\\n           5       0.14      0.01      0.01      1586\\n           6       0.19      0.00      0.00      1293\\n           7       0.00      0.00      0.00       916\\n           8       0.00      0.00      0.00       819\\n           9       0.09      0.51      0.15      2116\\n          10       0.13      0.53      0.21      1314\\n          11       0.13      0.50      0.20      1839\\n          12       0.15      0.09      0.11      1297\\n          13       0.33      0.00      0.00      1406\\n          14       0.00      0.00      0.00      1792\\n          15       0.08      0.18      0.11      2372\\n          16       0.00      0.00      0.00      1010\\n          17       0.17      0.01      0.02      1261\\n          18       0.00      0.00      0.00       687\\n          19       0.00      0.00      0.00       821\\n          20       0.00      0.00      0.00      1667\\n          21       0.05      0.02      0.02      2171\\n          22       0.08      0.06      0.07      2166\\n          23       0.00      0.00      0.00      1744\\n          24       0.00      0.00      0.00      1453\\n\\n    accuracy                           0.10     35911\\n   macro avg       0.07      0.08      0.04     35911\\nweighted avg       0.08      0.10      0.05     35911\\n',\n",
       " 3156.695788383484,\n",
       " 274.0216269493103)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_path=(\"/home/ens/AN03460/Desktop/TP4/music/music/tagged_feature_sets/msd-marsyas_dev_new/msd-marsyas_dev_new.csv\")\n",
    "print('Test ACC marsvas')\n",
    "X, Y,le = get_data(dataset_path)\n",
    "X = preprocessing.normalize(X, norm='max',axis = 0)\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8, random_state=60, stratify=Y)\n",
    "PCA_X_Train,PCA_X_Test=PCA_transform(X_train,X_test,1)\n",
    "#print('Linear')\n",
    "#SVC_Linear(PCA_X_Train, Y_train, PCA_X_Test, Y_test,1)\n",
    "print('rbf')\n",
    "\n",
    "\n",
    "\n",
    "Svc_marsya,y_pred_marsya,train_time_marsya,pred_time_marsya=SVC_rbf(PCA_X_Train, Y_train, PCA_X_Test, Y_test,10,1)\n",
    "pickle.dump(Svc_marsyas,open('svm_marsyas.sav','wb'))\n",
    "loaded_model =pickle.load(open('svm_marsyas.sav','rb'))\n",
    "\n",
    "svm_result_marsyas=loaded_model.score(PCA_X_Test,Y_test)\n",
    "\n",
    "print(loaded_model.predict(PCA_X_Test))\n",
    "print (svm_result_marsyas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
