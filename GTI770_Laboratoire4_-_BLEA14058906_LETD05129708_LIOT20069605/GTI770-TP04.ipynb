{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 4 : Développement d'un système intelligent\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | Alexandre Bleau — BLEA14058906 / David Létinaud  — LETD05129708 / Thomas Lioret   — LIOT20069605|\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | Automne 2019                                            |\n",
    "| Groupe                | 1                                                       |\n",
    "| Numéro du laboratoire | 4                                                       |\n",
    "| Professeur            | Prof. LOMBAERT                                          |\n",
    "| Chargé de laboratoire | Pierre-Luc Delisle                                      |\n",
    "| Date                  | 18/12/2019                                              |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction et revue de la littérature\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour choisir correctement les modèles à associés aux ensembles de features, il est important d'étudier ce qui a déjà été fait.\n",
    "Ainsi, on s'est notamment appuyé sur l'étude \"FACILITATING COMPREHENSIVE BENCHMARKING EXPERIMENTS\n",
    "ON THE MILLION SONG DATASET\" réalisée par l'ISMIR (International Society for Music Information Retrieval) en 2012.\n",
    "\n",
    "La combinaison la plus performante a permis d'obtenir une précision de 27,41 % en appliquant un modèle SVM sur l'ensemble de features \"Statistical Spectrum Descriptor\"(SSD). Sur ces caractéristiques, l'algorithme KNN a produit une précision comparable de 27,07 %. Les autres modèles testés, baïes naïf, l'arbre de décision et \"random forest\" ont tous donné un taux d'exactitude entre 14 et 20 % environ. Outre le SSD, d'autres ensembles ont également fait l'objet d'essais, mais tous ont donné des résultats d'une précision inférieur, à une près. \n",
    "Les ensembles \"MFCC\" et \"Spectral Derivates\" offrent tout de même des performances comparables bien qu'inférieures à celle que peut offrir SSD.\n",
    "\n",
    "Toutefois, cette étude n'analyse pas les performances que peut offrir un réseau de neurones. En effet, ce modèle de classification n'était pas encore très développé. On a tout de même trouvé une étude plus récente sur la classification de genre de musique. Celle-ci utilise une autre base de donnée appelée : \"Free Music Archive\" (FMA) constitué de 161 genres. Cette étude, \"FMA: A DATASET FOR MUSIC ANALYS\" est disponible ici : harxiv.org/pdf/1612.01840.pdf. Bien que le dataset soit différent, il est intéressant de noter que le modèle MLP (\"MultiLayer Perceptron\") performe très bien avec l'ensemble de features MFCC. Il atteint même une précision de 53%, ce qui en fait pottentiellement un très bon candidat pour notre dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme expliqué précedemment, le modèle MLP est un bon candidat. Toutefois, nous n'avons de données sur sa performance avec les ensembles de features du dataset MSD. Nous allons donc créé un modèle MLP est le tester sur tout les ensembles de features disponible pour comparer ses performances. Nous irons plus en détails dans l'ajustement des hyperparamètres par la suite.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from RN_model import RN_model\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from sklearn import preprocessing, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "import time\n",
    "import numpy as np\n",
    "from functions import get_data, plot_perf_epochs,plot_perf_delay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "direct_path_tab = []\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-ssd_dev/msd-ssd_dev.csv\") # best =>31%\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-jmirmfccs_dev/msd-jmirmfccs_dev.csv\")\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-jmirspectral_dev/msd-jmirspectral_dev.csv\")\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-jmirderivatives_dev/msd-jmirderivatives_dev.csv\") # 3rd => 25%\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-jmirlpc_dev/msd-jmirlpc_dev.csv\")\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-jmirmoments_dev/msd-jmirmoments_dev.csv\")\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-marsyas_dev_new/msd-marsyas_dev_new.csv\") # 2nd => 27%\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-mvd_dev/msd-mvd_dev.csv\")\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-rh_dev_new/msd-rh_dev_new.csv\")\n",
    "direct_path_tab.append(\"./tagged_feature_sets/msd-trh_dev/msd-trh_dev.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP hyperparamaters\n",
    "layer_sizes = [500]\n",
    "epochs = 50\n",
    "learning_rate = 0.0005\n",
    "batch_size = 500\n",
    "\n",
    "dropout = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_delay_RN = []\n",
    "predicting_delay_RN = []\n",
    "history_obj = []\n",
    "cpt = 0\n",
    "best_accuracy_RN = 0\n",
    "f1_RN = []\n",
    "acc_RN = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:      \n",
    "    shutil.rmtree('./logs')\n",
    "except:\n",
    "    print(\"nothing to delete\")\n",
    "# Callbacks pour affichage des performances dans tensorboard : callback pour chaque hyperparamètre\n",
    "tensorboard_callback = []\n",
    "for i in range(len(direct_path_tab)):\n",
    "    tensorboard_callback.append(TensorBoard(log_dir=\"logs\\{}\".format(i)))\n",
    "# Par invité de commande : \n",
    "# tensorboard --logdir=\"./logs\" --port 6006"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 143644 samples, validate on 35911 samples\n",
      "Epoch 1/50\n",
      "143644/143644 [==============================] - 7s 48us/sample - loss: 2.7883 - acc: 0.1633 - val_loss: 2.5980 - val_acc: 0.2090\n",
      "Epoch 2/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.5832 - acc: 0.2113 - val_loss: 2.5262 - val_acc: 0.2287\n",
      "Epoch 3/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.5257 - acc: 0.2293 - val_loss: 2.4779 - val_acc: 0.2426\n",
      "Epoch 4/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.4905 - acc: 0.2412 - val_loss: 2.4471 - val_acc: 0.2539\n",
      "Epoch 5/50\n",
      "143644/143644 [==============================] - 6s 40us/sample - loss: 2.4659 - acc: 0.2471 - val_loss: 2.4293 - val_acc: 0.2612\n",
      "Epoch 6/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.4441 - acc: 0.2544 - val_loss: 2.4148 - val_acc: 0.2643\n",
      "Epoch 7/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.4286 - acc: 0.2593 - val_loss: 2.3958 - val_acc: 0.2699\n",
      "Epoch 8/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.4136 - acc: 0.2624 - val_loss: 2.3866 - val_acc: 0.2705\n",
      "Epoch 9/50\n",
      "143644/143644 [==============================] - 7s 45us/sample - loss: 2.4031 - acc: 0.2653 - val_loss: 2.3825 - val_acc: 0.2725\n",
      "Epoch 10/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.3968 - acc: 0.2677 - val_loss: 2.3655 - val_acc: 0.2778\n",
      "Epoch 11/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.3844 - acc: 0.2710 - val_loss: 2.3588 - val_acc: 0.2789\n",
      "Epoch 12/50\n",
      "143644/143644 [==============================] - 9s 64us/sample - loss: 2.3780 - acc: 0.2719 - val_loss: 2.3594 - val_acc: 0.2775\n",
      "Epoch 13/50\n",
      "143644/143644 [==============================] - 7s 45us/sample - loss: 2.3711 - acc: 0.2742 - val_loss: 2.3486 - val_acc: 0.2820\n",
      "Epoch 14/50\n",
      "143644/143644 [==============================] - 6s 39us/sample - loss: 2.3632 - acc: 0.2779 - val_loss: 2.3494 - val_acc: 0.2811\n",
      "Epoch 15/50\n",
      "143644/143644 [==============================] - 6s 39us/sample - loss: 2.3594 - acc: 0.2782 - val_loss: 2.3428 - val_acc: 0.2831\n",
      "Epoch 16/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.3551 - acc: 0.2784 - val_loss: 2.3339 - val_acc: 0.2831\n",
      "Epoch 17/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.3477 - acc: 0.2801 - val_loss: 2.3299 - val_acc: 0.2853\n",
      "Epoch 18/50\n",
      "143644/143644 [==============================] - 7s 50us/sample - loss: 2.3436 - acc: 0.2817 - val_loss: 2.3252 - val_acc: 0.2883\n",
      "Epoch 19/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.3410 - acc: 0.2821 - val_loss: 2.3318 - val_acc: 0.2867\n",
      "Epoch 20/50\n",
      "143644/143644 [==============================] - 6s 40us/sample - loss: 2.3354 - acc: 0.2842 - val_loss: 2.3190 - val_acc: 0.2889\n",
      "Epoch 21/50\n",
      "143644/143644 [==============================] - 6s 39us/sample - loss: 2.3289 - acc: 0.2846 - val_loss: 2.3183 - val_acc: 0.2888\n",
      "Epoch 22/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.3260 - acc: 0.2852 - val_loss: 2.3140 - val_acc: 0.2891\n",
      "Epoch 23/50\n",
      "143644/143644 [==============================] - 5s 36us/sample - loss: 2.3231 - acc: 0.2865 - val_loss: 2.3092 - val_acc: 0.2910\n",
      "Epoch 24/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.3189 - acc: 0.2874 - val_loss: 2.3043 - val_acc: 0.2928\n",
      "Epoch 25/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.3142 - acc: 0.2888 - val_loss: 2.3064 - val_acc: 0.2919\n",
      "Epoch 26/50\n",
      "143644/143644 [==============================] - 5s 36us/sample - loss: 2.3106 - acc: 0.2907 - val_loss: 2.3072 - val_acc: 0.2949\n",
      "Epoch 27/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.3084 - acc: 0.2919 - val_loss: 2.2991 - val_acc: 0.2933\n",
      "Epoch 28/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.3033 - acc: 0.2917 - val_loss: 2.2981 - val_acc: 0.2934\n",
      "Epoch 29/50\n",
      "143644/143644 [==============================] - 5s 36us/sample - loss: 2.3026 - acc: 0.2930 - val_loss: 2.2938 - val_acc: 0.2946\n",
      "Epoch 30/50\n",
      "143644/143644 [==============================] - 5s 38us/sample - loss: 2.2980 - acc: 0.2941 - val_loss: 2.2971 - val_acc: 0.2937\n",
      "Epoch 31/50\n",
      "143644/143644 [==============================] - 5s 38us/sample - loss: 2.2938 - acc: 0.2944 - val_loss: 2.2905 - val_acc: 0.2973\n",
      "Epoch 32/50\n",
      "143644/143644 [==============================] - 5s 38us/sample - loss: 2.2946 - acc: 0.2950 - val_loss: 2.2874 - val_acc: 0.2971\n",
      "Epoch 33/50\n",
      "143644/143644 [==============================] - 7s 49us/sample - loss: 2.2893 - acc: 0.2961 - val_loss: 2.2889 - val_acc: 0.2980\n",
      "Epoch 34/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.2866 - acc: 0.2965 - val_loss: 2.2845 - val_acc: 0.2966\n",
      "Epoch 35/50\n",
      "143644/143644 [==============================] - 12s 87us/sample - loss: 2.2827 - acc: 0.2982 - val_loss: 2.2819 - val_acc: 0.3004\n",
      "Epoch 36/50\n",
      "143644/143644 [==============================] - 9s 63us/sample - loss: 2.2818 - acc: 0.2980 - val_loss: 2.2822 - val_acc: 0.2990\n",
      "Epoch 37/50\n",
      "143644/143644 [==============================] - 14s 96us/sample - loss: 2.2803 - acc: 0.2963 - val_loss: 2.2787 - val_acc: 0.2995\n",
      "Epoch 38/50\n",
      "143644/143644 [==============================] - 9s 63us/sample - loss: 2.2767 - acc: 0.2991 - val_loss: 2.2785 - val_acc: 0.2987\n",
      "Epoch 39/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.2714 - acc: 0.3010 - val_loss: 2.2736 - val_acc: 0.3021\n",
      "Epoch 40/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.2709 - acc: 0.3007 - val_loss: 2.2760 - val_acc: 0.2995\n",
      "Epoch 41/50\n",
      "143644/143644 [==============================] - 6s 44us/sample - loss: 2.2668 - acc: 0.3021 - val_loss: 2.2750 - val_acc: 0.3010\n",
      "Epoch 42/50\n",
      "143644/143644 [==============================] - 6s 43us/sample - loss: 2.2651 - acc: 0.3027 - val_loss: 2.2731 - val_acc: 0.3014\n",
      "Epoch 43/50\n",
      "143644/143644 [==============================] - 9s 65us/sample - loss: 2.2639 - acc: 0.3034 - val_loss: 2.2745 - val_acc: 0.3004\n",
      "Epoch 44/50\n",
      "143644/143644 [==============================] - 7s 48us/sample - loss: 2.2606 - acc: 0.3029 - val_loss: 2.2648 - val_acc: 0.3026\n",
      "Epoch 45/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.2583 - acc: 0.3046 - val_loss: 2.2673 - val_acc: 0.3034\n",
      "Epoch 46/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.2567 - acc: 0.3047 - val_loss: 2.2700 - val_acc: 0.3016\n",
      "Epoch 47/50\n",
      "143644/143644 [==============================] - 7s 45us/sample - loss: 2.2540 - acc: 0.3055 - val_loss: 2.2640 - val_acc: 0.30271\n",
      "Epoch 48/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.2521 - acc: 0.3060 - val_loss: 2.2663 - val_acc: 0.3035\n",
      "Epoch 49/50\n",
      "143644/143644 [==============================] - 6s 43us/sample - loss: 2.2494 - acc: 0.3063 - val_loss: 2.2587 - val_acc: 0.3058\n",
      "Epoch 50/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.2473 - acc: 0.3077 - val_loss: 2.2732 - val_acc: 0.3025\n",
      "acc : 0.30249784188688705 f1 : 0.2847317969761063\n",
      "Train on 143644 samples, validate on 35911 samples\n",
      "Epoch 1/50\n",
      "143644/143644 [==============================] - 5s 36us/sample - loss: 3.0564 - acc: 0.1016 - val_loss: 2.9020 - val_acc: 0.1398\n",
      "Epoch 2/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.8698 - acc: 0.1399 - val_loss: 2.8174 - val_acc: 0.1515\n",
      "Epoch 3/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.8138 - acc: 0.1526 - val_loss: 2.7747 - val_acc: 0.1627.8140 - acc: 0.1\n",
      "Epoch 4/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.7753 - acc: 0.1621 - val_loss: 2.7377 - val_acc: 0.1730\n",
      "Epoch 5/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.7445 - acc: 0.1711 - val_loss: 2.7131 - val_acc: 0.1785\n",
      "Epoch 6/50\n",
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.7238 - acc: 0.1760 - val_loss: 2.6947 - val_acc: 0.1835\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.7055 - acc: 0.1813 - val_loss: 2.6797 - val_acc: 0.18880s - loss: 2.7062 - ac\n",
      "Epoch 8/50\n",
      "143644/143644 [==============================] - 4s 31us/sample - loss: 2.6921 - acc: 0.1852 - val_loss: 2.6645 - val_acc: 0.1943\n",
      "Epoch 9/50\n",
      "143644/143644 [==============================] - 5s 32us/sample - loss: 2.6799 - acc: 0.1883 - val_loss: 2.6539 - val_acc: 0.1966\n",
      "Epoch 10/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.6699 - acc: 0.1923 - val_loss: 2.6455 - val_acc: 0.1998\n",
      "Epoch 11/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.6606 - acc: 0.1954 - val_loss: 2.6362 - val_acc: 0.2012\n",
      "Epoch 12/50\n",
      "143644/143644 [==============================] - 5s 32us/sample - loss: 2.6529 - acc: 0.1971 - val_loss: 2.6278 - val_acc: 0.2036\n",
      "Epoch 13/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.6455 - acc: 0.1995 - val_loss: 2.6237 - val_acc: 0.2050\n",
      "Epoch 14/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.6397 - acc: 0.2021 - val_loss: 2.6180 - val_acc: 0.2078\n",
      "Epoch 15/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.6357 - acc: 0.2043 - val_loss: 2.6111 - val_acc: 0.2087\n",
      "Epoch 16/50\n",
      "143644/143644 [==============================] - 5s 32us/sample - loss: 2.6289 - acc: 0.2052 - val_loss: 2.6062 - val_acc: 0.2097\n",
      "Epoch 17/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.6247 - acc: 0.2069 - val_loss: 2.6034 - val_acc: 0.2108\n",
      "Epoch 18/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.6197 - acc: 0.2088 - val_loss: 2.5981 - val_acc: 0.2120\n",
      "Epoch 19/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.6169 - acc: 0.2083 - val_loss: 2.5937 - val_acc: 0.2130\n",
      "Epoch 20/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.6126 - acc: 0.2096 - val_loss: 2.5917 - val_acc: 0.2138\n",
      "Epoch 21/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.6092 - acc: 0.2116 - val_loss: 2.5873 - val_acc: 0.2147\n",
      "Epoch 22/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.6059 - acc: 0.2123 - val_loss: 2.5864 - val_acc: 0.2165\n",
      "Epoch 23/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.6037 - acc: 0.2129 - val_loss: 2.5831 - val_acc: 0.2179\n",
      "Epoch 24/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.5993 - acc: 0.2141 - val_loss: 2.5830 - val_acc: 0.2156\n",
      "Epoch 25/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5980 - acc: 0.2150 - val_loss: 2.5760 - val_acc: 0.2195\n",
      "Epoch 26/50\n",
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.5950 - acc: 0.2153 - val_loss: 2.5747 - val_acc: 0.2205\n",
      "Epoch 27/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5918 - acc: 0.2173 - val_loss: 2.5706 - val_acc: 0.2215\n",
      "Epoch 28/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.5895 - acc: 0.2179 - val_loss: 2.5698 - val_acc: 0.2209\n",
      "Epoch 29/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5876 - acc: 0.2185 - val_loss: 2.5681 - val_acc: 0.2200\n",
      "Epoch 30/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5866 - acc: 0.2177 - val_loss: 2.5658 - val_acc: 0.2210\n",
      "Epoch 31/50\n",
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.5841 - acc: 0.2186 - val_loss: 2.5631 - val_acc: 0.2223\n",
      "Epoch 32/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.5824 - acc: 0.2181 - val_loss: 2.5638 - val_acc: 0.2224\n",
      "Epoch 33/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.5811 - acc: 0.2195 - val_loss: 2.5594 - val_acc: 0.2243\n",
      "Epoch 34/50\n",
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.5789 - acc: 0.2199 - val_loss: 2.5581 - val_acc: 0.2244\n",
      "Epoch 35/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5773 - acc: 0.2204 - val_loss: 2.5578 - val_acc: 0.2231\n",
      "Epoch 36/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.5752 - acc: 0.2208 - val_loss: 2.5563 - val_acc: 0.2254\n",
      "Epoch 37/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.5737 - acc: 0.2211 - val_loss: 2.5543 - val_acc: 0.2251\n",
      "Epoch 38/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5719 - acc: 0.2228 - val_loss: 2.5530 - val_acc: 0.2242\n",
      "Epoch 39/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5718 - acc: 0.2225 - val_loss: 2.5527 - val_acc: 0.2262\n",
      "Epoch 40/50\n",
      "143644/143644 [==============================] - 5s 32us/sample - loss: 2.5705 - acc: 0.2227 - val_loss: 2.5499 - val_acc: 0.2268\n",
      "Epoch 41/50\n",
      "143644/143644 [==============================] - 5s 32us/sample - loss: 2.5686 - acc: 0.2238 - val_loss: 2.5493 - val_acc: 0.2258\n",
      "Epoch 42/50\n",
      "143644/143644 [==============================] - 4s 31us/sample - loss: 2.5665 - acc: 0.2231 - val_loss: 2.5491 - val_acc: 0.2259\n",
      "Epoch 43/50\n",
      "143644/143644 [==============================] - 5s 31us/sample - loss: 2.5658 - acc: 0.2238 - val_loss: 2.5465 - val_acc: 0.2286\n",
      "Epoch 44/50\n",
      "143644/143644 [==============================] - 5s 36us/sample - loss: 2.5642 - acc: 0.2248 - val_loss: 2.5457 - val_acc: 0.2277\n",
      "Epoch 45/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5627 - acc: 0.2242 - val_loss: 2.5441 - val_acc: 0.2281\n",
      "Epoch 46/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.5616 - acc: 0.2251 - val_loss: 2.5447 - val_acc: 0.2276s - loss: 2.5625 - acc - ETA: 2s - - ETA: 0s - loss: 2.5606 -\n",
      "Epoch 47/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.5610 - acc: 0.2256 - val_loss: 2.5428 - val_acc: 0.2279\n",
      "Epoch 48/50\n",
      "143644/143644 [==============================] - 4s 31us/sample - loss: 2.5582 - acc: 0.2261 - val_loss: 2.5414 - val_acc: 0.2300\n",
      "Epoch 49/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.5581 - acc: 0.2265 - val_loss: 2.5411 - val_acc: 0.2283\n",
      "Epoch 50/50\n",
      "143644/143644 [==============================] - 4s 30us/sample - loss: 2.5563 - acc: 0.2269 - val_loss: 2.5386 - val_acc: 0.2299\n",
      "acc : 0.22987385480771907 f1 : 0.19602825387633718\n",
      "Train on 143644 samples, validate on 35911 samples\n",
      "Epoch 1/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 3.0721 - acc: 0.0975 - val_loss: 2.9439 - val_acc: 0.1341\n",
      "Epoch 2/50\n",
      "143644/143644 [==============================] - 5s 34us/sample - loss: 2.8824 - acc: 0.1403 - val_loss: 2.8391 - val_acc: 0.1496\n",
      "Epoch 3/50\n",
      "143644/143644 [==============================] - 5s 35us/sample - loss: 2.8352 - acc: 0.1494 - val_loss: 2.8138 - val_acc: 0.1535\n",
      "Epoch 4/50\n",
      "143644/143644 [==============================] - 4s 30us/sample - loss: 2.8146 - acc: 0.1523 - val_loss: 2.7960 - val_acc: 0.1583\n",
      "Epoch 5/50\n",
      "143644/143644 [==============================] - 4s 30us/sample - loss: 2.7962 - acc: 0.1585 - val_loss: 2.7786 - val_acc: 0.1587\n",
      "Epoch 6/50\n",
      "143644/143644 [==============================] - 4s 31us/sample - loss: 2.7828 - acc: 0.1601 - val_loss: 2.7667 - val_acc: 0.1638\n",
      "Epoch 7/50\n",
      "143644/143644 [==============================] - 4s 30us/sample - loss: 2.7709 - acc: 0.1635 - val_loss: 2.7571 - val_acc: 0.1645\n",
      "Epoch 8/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.7610 - acc: 0.1644 - val_loss: 2.7471 - val_acc: 0.1681\n",
      "Epoch 9/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.7536 - acc: 0.1673 - val_loss: 2.7408 - val_acc: 0.1704\n",
      "Epoch 10/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.7471 - acc: 0.1686 - val_loss: 2.7343 - val_acc: 0.1719\n",
      "Epoch 11/50\n",
      "143644/143644 [==============================] - 4s 29us/sample - loss: 2.7414 - acc: 0.1688 - val_loss: 2.7288 - val_acc: 0.1748\n",
      "Epoch 12/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.7355 - acc: 0.1719 - val_loss: 2.7238 - val_acc: 0.1751\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.7303 - acc: 0.1721 - val_loss: 2.7178 - val_acc: 0.1775\n",
      "Epoch 14/50\n",
      "143644/143644 [==============================] - 5s 34us/sample - loss: 2.7258 - acc: 0.1733 - val_loss: 2.7139 - val_acc: 0.1788\n",
      "Epoch 15/50\n",
      "143644/143644 [==============================] - 4s 31us/sample - loss: 2.7219 - acc: 0.1754 - val_loss: 2.7089 - val_acc: 0.1793\n",
      "Epoch 16/50\n",
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.7169 - acc: 0.1753 - val_loss: 2.7043 - val_acc: 0.1803loss:\n",
      "Epoch 17/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.7127 - acc: 0.1767 - val_loss: 2.7007 - val_acc: 0.1819\n",
      "Epoch 18/50\n",
      "143644/143644 [==============================] - 4s 30us/sample - loss: 2.7094 - acc: 0.1780 - val_loss: 2.6965 - val_acc: 0.1828\n",
      "Epoch 19/50\n",
      "143644/143644 [==============================] - 4s 26us/sample - loss: 2.7045 - acc: 0.1791 - val_loss: 2.6922 - val_acc: 0.1837\n",
      "Epoch 20/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.7009 - acc: 0.1804 - val_loss: 2.6882 - val_acc: 0.1849\n",
      "Epoch 21/50\n",
      "143644/143644 [==============================] - 4s 28us/sample - loss: 2.6978 - acc: 0.1815 - val_loss: 2.6852 - val_acc: 0.1853\n",
      "Epoch 22/50\n",
      "143644/143644 [==============================] - 5s 32us/sample - loss: 2.6940 - acc: 0.1819 - val_loss: 2.6831 - val_acc: 0.1870\n",
      "Epoch 23/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.6913 - acc: 0.1818 - val_loss: 2.6795 - val_acc: 0.1879\n",
      "Epoch 24/50\n",
      "143644/143644 [==============================] - 4s 27us/sample - loss: 2.6873 - acc: 0.1832 - val_loss: 2.6745 - val_acc: 0.1887\n",
      "Epoch 25/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.6841 - acc: 0.1846 - val_loss: 2.6711 - val_acc: 0.1904\n",
      "Epoch 26/50\n",
      "143644/143644 [==============================] - 5s 36us/sample - loss: 2.6817 - acc: 0.1851 - val_loss: 2.6673 - val_acc: 0.1901\n",
      "Epoch 27/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.6793 - acc: 0.1850 - val_loss: 2.6667 - val_acc: 0.1909\n",
      "Epoch 28/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.6770 - acc: 0.1858 - val_loss: 2.6632 - val_acc: 0.1904\n",
      "Epoch 29/50\n",
      "143644/143644 [==============================] - 5s 38us/sample - loss: 2.6736 - acc: 0.1873 - val_loss: 2.6597 - val_acc: 0.1921\n",
      "Epoch 30/50\n",
      "143644/143644 [==============================] - 5s 37us/sample - loss: 2.6723 - acc: 0.1876 - val_loss: 2.6566 - val_acc: 0.1937\n",
      "Epoch 31/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.6693 - acc: 0.1883 - val_loss: 2.6545 - val_acc: 0.1930\n",
      "Epoch 32/50\n",
      "143644/143644 [==============================] - 6s 40us/sample - loss: 2.6670 - acc: 0.1887 - val_loss: 2.6544 - val_acc: 0.1935\n",
      "Epoch 33/50\n",
      "143644/143644 [==============================] - 6s 44us/sample - loss: 2.6654 - acc: 0.1891 - val_loss: 2.6507 - val_acc: 0.19372.66\n",
      "Epoch 34/50\n",
      "143644/143644 [==============================] - 8s 59us/sample - loss: 2.6631 - acc: 0.1901 - val_loss: 2.6486 - val_acc: 0.1948\n",
      "Epoch 35/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.6620 - acc: 0.1906 - val_loss: 2.6472 - val_acc: 0.1955\n",
      "Epoch 36/50\n",
      "143644/143644 [==============================] - 6s 45us/sample - loss: 2.6602 - acc: 0.1908 - val_loss: 2.6462 - val_acc: 0.1963\n",
      "Epoch 37/50\n",
      "143644/143644 [==============================] - 6s 40us/sample - loss: 2.6593 - acc: 0.1912 - val_loss: 2.6440 - val_acc: 0.1959\n",
      "Epoch 38/50\n",
      "143644/143644 [==============================] - 6s 40us/sample - loss: 2.6570 - acc: 0.1924 - val_loss: 2.6425 - val_acc: 0.1951\n",
      "Epoch 39/50\n",
      "143644/143644 [==============================] - 6s 41us/sample - loss: 2.6556 - acc: 0.1921 - val_loss: 2.6426 - val_acc: 0.1972oss: 2.656\n",
      "Epoch 40/50\n",
      "143644/143644 [==============================] - 6s 43us/sample - loss: 2.6541 - acc: 0.1934 - val_loss: 2.6400 - val_acc: 0.1962\n",
      "Epoch 41/50\n",
      "143644/143644 [==============================] - 6s 42us/sample - loss: 2.6527 - acc: 0.1931 - val_loss: 2.6384 - val_acc: 0.1981\n",
      "Epoch 42/50\n",
      "143644/143644 [==============================] - 6s 39us/sample - loss: 2.6520 - acc: 0.1937 - val_loss: 2.6366 - val_acc: 0.1976\n",
      "Epoch 43/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.6502 - acc: 0.1943 - val_loss: 2.6362 - val_acc: 0.1996\n",
      "Epoch 44/50\n",
      "143644/143644 [==============================] - 7s 48us/sample - loss: 2.6484 - acc: 0.1940 - val_loss: 2.6380 - val_acc: 0.1966\n",
      "Epoch 45/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.6472 - acc: 0.1951 - val_loss: 2.6327 - val_acc: 0.1979\n",
      "Epoch 46/50\n",
      "143644/143644 [==============================] - 7s 48us/sample - loss: 2.6470 - acc: 0.1952 - val_loss: 2.6312 - val_acc: 0.1984: - ETA: 1s - loss: 2.6\n",
      "Epoch 47/50\n",
      "143644/143644 [==============================] - 6s 44us/sample - loss: 2.6457 - acc: 0.1963 - val_loss: 2.6303 - val_acc: 0.2006\n",
      "Epoch 48/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.6446 - acc: 0.1961 - val_loss: 2.6303 - val_acc: 0.2001\n",
      "Epoch 49/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.6445 - acc: 0.1962 - val_loss: 2.6278 - val_acc: 0.2001\n",
      "Epoch 50/50\n",
      "143644/143644 [==============================] - 6s 43us/sample - loss: 2.6426 - acc: 0.1965 - val_loss: 2.6290 - val_acc: 0.2007\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\David\\Anaconda3\\envs\\GTI 770-BIS\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc : 0.20074628943777673 f1 : 0.16373846305366144\n",
      "Train on 143644 samples, validate on 35911 samples\n",
      "Epoch 1/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.9268 - acc: 0.1300 - val_loss: 2.7739 - val_acc: 0.1650\n",
      "Epoch 2/50\n",
      "143644/143644 [==============================] - 8s 58us/sample - loss: 2.7488 - acc: 0.1665 - val_loss: 2.6938 - val_acc: 0.1810s: 2.7514 \n",
      "Epoch 3/50\n",
      "143644/143644 [==============================] - 8s 55us/sample - loss: 2.6865 - acc: 0.1810 - val_loss: 2.6424 - val_acc: 0.1955\n",
      "Epoch 4/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.6455 - acc: 0.1917 - val_loss: 2.6126 - val_acc: 0.2026\n",
      "Epoch 5/50\n",
      "143644/143644 [==============================] - 9s 62us/sample - loss: 2.6211 - acc: 0.1978 - val_loss: 2.6009 - val_acc: 0.2021\n",
      "Epoch 6/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.6048 - acc: 0.2021 - val_loss: 2.5771 - val_acc: 0.2104\n",
      "Epoch 7/50\n",
      "143644/143644 [==============================] - 8s 58us/sample - loss: 2.5916 - acc: 0.2044 - val_loss: 2.5646 - val_acc: 0.2134\n",
      "Epoch 8/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.5796 - acc: 0.2093 - val_loss: 2.5595 - val_acc: 0.2138\n",
      "Epoch 9/50\n",
      "143644/143644 [==============================] - 8s 54us/sample - loss: 2.5694 - acc: 0.2124 - val_loss: 2.5449 - val_acc: 0.2188\n",
      "Epoch 10/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.5601 - acc: 0.2142 - val_loss: 2.5488 - val_acc: 0.2188\n",
      "Epoch 11/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.5534 - acc: 0.2163 - val_loss: 2.5259 - val_acc: 0.2241\n",
      "Epoch 12/50\n",
      "143644/143644 [==============================] - 9s 59us/sample - loss: 2.5456 - acc: 0.2183 - val_loss: 2.5190 - val_acc: 0.2250\n",
      "Epoch 13/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.5396 - acc: 0.2206 - val_loss: 2.5122 - val_acc: 0.2282\n",
      "Epoch 14/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.5320 - acc: 0.2229 - val_loss: 2.5179 - val_acc: 0.2281\n",
      "Epoch 15/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.5276 - acc: 0.2235 - val_loss: 2.5048 - val_acc: 0.2298\n",
      "Epoch 16/50\n",
      "143644/143644 [==============================] - 8s 59us/sample - loss: 2.5210 - acc: 0.2256 - val_loss: 2.4965 - val_acc: 0.2305\n",
      "Epoch 17/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.5170 - acc: 0.2262 - val_loss: 2.4897 - val_acc: 0.2350\n",
      "Epoch 18/50\n",
      "143644/143644 [==============================] - 8s 59us/sample - loss: 2.5131 - acc: 0.2278 - val_loss: 2.4878 - val_acc: 0.2350\n",
      "Epoch 19/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.5076 - acc: 0.2297 - val_loss: 2.4844 - val_acc: 0.2355\n",
      "Epoch 20/50\n",
      "143644/143644 [==============================] - 9s 62us/sample - loss: 2.5046 - acc: 0.2301 - val_loss: 2.4786 - val_acc: 0.2371\n",
      "Epoch 21/50\n",
      "143644/143644 [==============================] - 8s 55us/sample - loss: 2.5001 - acc: 0.2337 - val_loss: 2.4832 - val_acc: 0.2365\n",
      "Epoch 22/50\n",
      "143644/143644 [==============================] - 9s 61us/sample - loss: 2.4968 - acc: 0.2332 - val_loss: 2.4744 - val_acc: 0.2374\n",
      "Epoch 23/50\n",
      "143644/143644 [==============================] - 9s 59us/sample - loss: 2.4943 - acc: 0.2327 - val_loss: 2.4782 - val_acc: 0.2358\n",
      "Epoch 24/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4912 - acc: 0.2347 - val_loss: 2.4668 - val_acc: 0.2394\n",
      "Epoch 25/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4878 - acc: 0.2363 - val_loss: 2.4673 - val_acc: 0.2395\n",
      "Epoch 26/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4840 - acc: 0.2367 - val_loss: 2.4620 - val_acc: 0.2415\n",
      "Epoch 27/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4805 - acc: 0.2384 - val_loss: 2.4712 - val_acc: 0.2419\n",
      "Epoch 28/50\n",
      "143644/143644 [==============================] - 8s 58us/sample - loss: 2.4779 - acc: 0.2380 - val_loss: 2.4583 - val_acc: 0.2431\n",
      "Epoch 29/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4748 - acc: 0.2400 - val_loss: 2.4557 - val_acc: 0.2442\n",
      "Epoch 30/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4730 - acc: 0.2401 - val_loss: 2.4502 - val_acc: 0.2473\n",
      "Epoch 31/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.4700 - acc: 0.2413 - val_loss: 2.4499 - val_acc: 0.2463\n",
      "Epoch 32/50\n",
      "143644/143644 [==============================] - 8s 58us/sample - loss: 2.4664 - acc: 0.2421 - val_loss: 2.4525 - val_acc: 0.2443\n",
      "Epoch 33/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4654 - acc: 0.2427 - val_loss: 2.4435 - val_acc: 0.2476\n",
      "Epoch 34/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4629 - acc: 0.2452 - val_loss: 2.4495 - val_acc: 0.2469\n",
      "Epoch 35/50\n",
      "143644/143644 [==============================] - 9s 61us/sample - loss: 2.4607 - acc: 0.2437 - val_loss: 2.4467 - val_acc: 0.2477\n",
      "Epoch 36/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4587 - acc: 0.2451 - val_loss: 2.4389 - val_acc: 0.2500\n",
      "Epoch 37/50\n",
      "143644/143644 [==============================] - 9s 61us/sample - loss: 2.4562 - acc: 0.2447 - val_loss: 2.4371 - val_acc: 0.2516\n",
      "Epoch 38/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4532 - acc: 0.2462 - val_loss: 2.4336 - val_acc: 0.2503\n",
      "Epoch 39/50\n",
      "143644/143644 [==============================] - 9s 61us/sample - loss: 2.4532 - acc: 0.2467 - val_loss: 2.4394 - val_acc: 0.2498\n",
      "Epoch 40/50\n",
      "143644/143644 [==============================] - 8s 54us/sample - loss: 2.4497 - acc: 0.2466 - val_loss: 2.4361 - val_acc: 0.2525\n",
      "Epoch 41/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.4486 - acc: 0.2471 - val_loss: 2.4298 - val_acc: 0.2526\n",
      "Epoch 42/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4462 - acc: 0.2482 - val_loss: 2.4405 - val_acc: 0.2494\n",
      "Epoch 43/50\n",
      "143644/143644 [==============================] - 9s 60us/sample - loss: 2.4446 - acc: 0.2487 - val_loss: 2.4297 - val_acc: 0.2533\n",
      "Epoch 44/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4438 - acc: 0.2493 - val_loss: 2.4337 - val_acc: 0.2517\n",
      "Epoch 45/50\n",
      "143644/143644 [==============================] - 8s 59us/sample - loss: 2.4422 - acc: 0.2499 - val_loss: 2.4307 - val_acc: 0.2529\n",
      "Epoch 46/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.4389 - acc: 0.2507 - val_loss: 2.4200 - val_acc: 0.2567\n",
      "Epoch 47/50\n",
      "143644/143644 [==============================] - 9s 63us/sample - loss: 2.4370 - acc: 0.2509 - val_loss: 2.4260 - val_acc: 0.2549\n",
      "Epoch 48/50\n",
      "143644/143644 [==============================] - 9s 64us/sample - loss: 2.4373 - acc: 0.2509 - val_loss: 2.4185 - val_acc: 0.2572\n",
      "Epoch 49/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4332 - acc: 0.2527 - val_loss: 2.4177 - val_acc: 0.2560\n",
      "Epoch 50/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.4318 - acc: 0.2527 - val_loss: 2.4178 - val_acc: 0.2577\n",
      "acc : 0.25774832224109606 f1 : 0.23090549621277184\n",
      "Train on 143644 samples, validate on 35911 samples\n",
      "Epoch 1/50\n",
      "143644/143644 [==============================] - 13s 92us/sample - loss: 2.9987 - acc: 0.1106 - val_loss: 2.8866 - val_acc: 0.1377\n",
      "Epoch 2/50\n",
      "143644/143644 [==============================] - 7s 51us/sample - loss: 2.8611 - acc: 0.1444 - val_loss: 2.8179 - val_acc: 0.1558\n",
      "Epoch 3/50\n",
      "143644/143644 [==============================] - 8s 53us/sample - loss: 2.8170 - acc: 0.1576 - val_loss: 2.7895 - val_acc: 0.1625 acc: - ETA: 1s\n",
      "Epoch 4/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.7938 - acc: 0.1628 - val_loss: 2.7726 - val_acc: 0.1656\n",
      "Epoch 5/50\n",
      "143644/143644 [==============================] - 8s 56us/sample - loss: 2.7789 - acc: 0.1665 - val_loss: 2.7597 - val_acc: 0.1701\n",
      "Epoch 6/50\n",
      "143644/143644 [==============================] - 7s 46us/sample - loss: 2.7697 - acc: 0.1694 - val_loss: 2.7518 - val_acc: 0.1719\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "143644/143644 [==============================] - 11s 75us/sample - loss: 2.7615 - acc: 0.1718 - val_loss: 2.7458 - val_acc: 0.1753\n",
      "Epoch 8/50\n",
      "143644/143644 [==============================] - 11s 80us/sample - loss: 2.7541 - acc: 0.1741 - val_loss: 2.7374 - val_acc: 0.1757\n",
      "Epoch 9/50\n",
      "143644/143644 [==============================] - 9s 64us/sample - loss: 2.7492 - acc: 0.1745 - val_loss: 2.7328 - val_acc: 0.1766\n",
      "Epoch 10/50\n",
      "143644/143644 [==============================] - 8s 57us/sample - loss: 2.7432 - acc: 0.1766 - val_loss: 2.7274 - val_acc: 0.1796s - ETA: 0s - loss: 2.7427 - acc:\n",
      "Epoch 11/50\n",
      "143644/143644 [==============================] - 8s 53us/sample - loss: 2.7392 - acc: 0.1770 - val_loss: 2.7223 - val_acc: 0.1801\n",
      "Epoch 12/50\n",
      "143644/143644 [==============================] - 9s 63us/sample - loss: 2.7340 - acc: 0.1787 - val_loss: 2.7187 - val_acc: 0.1808\n",
      "Epoch 13/50\n",
      "143644/143644 [==============================] - 9s 63us/sample - loss: 2.7295 - acc: 0.1796 - val_loss: 2.7130 - val_acc: 0.1822\n",
      "Epoch 14/50\n",
      "143644/143644 [==============================] - 10s 69us/sample - loss: 2.7251 - acc: 0.1819 - val_loss: 2.7112 - val_acc: 0.1830\n",
      "Epoch 15/50\n",
      " 18000/143644 [==>...........................] - ETA: 10s - loss: 2.7176 - acc: 0.18"
     ]
    }
   ],
   "source": [
    "cpt = 0\n",
    "for path_ in direct_path_tab:\n",
    "    # Get data / normalize it / split into train&test\n",
    "    X, Y = get_data(path_)\n",
    "    X = preprocessing.normalize(X, norm='max',axis = 0)\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.8,random_state=60, stratify=Y)  # 70% training and 30% test\n",
    "\n",
    "    # Calcul du nombres de features/classes et taille du dataset\n",
    "    nb_features = len(X[0])\n",
    "    nb_classes = max(Y)+1\n",
    "    train_size = len(X)\n",
    "\n",
    "    model = RN_model(layer_sizes, dropout, learning_rate, nb_features, nb_classes)\n",
    "    \n",
    "    #### Apprentissage                                                                                                                                                               \n",
    "    start = time.time()                                                                                                                   \n",
    "    hist_obj = model.fit(X_train[0:train_size], Y_train[0:train_size], batch_size = batch_size, epochs = epochs, validation_data=(X_test, Y_test), callbacks = [tensorboard_callback[cpt]]) \n",
    "    end = time.time()\n",
    "    training_delay_RN.append(end - start)\n",
    "    \n",
    "    history_obj.append( list(hist_obj.history.values()))\n",
    "\n",
    "    #### Prédiction                                                                                                                                                                  \n",
    "    start = time.time()\n",
    "    Y_pred_temp = model.predict(X_test)\n",
    "    end = time.time()\n",
    "    predicting_delay_RN.append(end - start)\n",
    "\n",
    "    # Remise en forme de Y_pred\n",
    "    Y_pred = []\n",
    "    for i in Y_pred_temp:\n",
    "        Y_pred.append(np.argmax(i)) \n",
    "    \n",
    "    f1 = metrics.f1_score(Y_test, Y_pred,average='weighted')\n",
    "    acc = metrics.accuracy_score(Y_test, Y_pred)\n",
    "    print(\"acc :\", acc,\"f1 :\", f1)\n",
    "    \n",
    "    f1_RN.append(f1)\n",
    "    acc_RN.append(acc)\n",
    "    cpt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mise en forme des données pour l'affichage\n",
    "ho = np.array(history_obj)\n",
    "ho = ho.transpose(1,2,0)  \n",
    "\n",
    "# Pour affichage\n",
    "sub_title = ['loss','acc','val_loss','val_acc']\n",
    "x_lab = \"epochs\"\n",
    "leg = [str(i) for i in range(len(direct_path_tab))]  \n",
    "titre = \"RN : Dataset test\"                                                                                                                                         \n",
    "\n",
    "plot_perf_epochs(ho, leg, titre ,sub_title)\n",
    "plot_perf_delay(f1_RN,acc_RN,training_delay_RN,predicting_delay_RN,titre)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration de l'environnement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Partitionnement des données"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prétraitement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3\n",
    "### Description des modèles et justifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4\n",
    "### Matrice des expérimentations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice des résultats de l'étude des hyperparamètres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Graphiques"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5\n",
    "### Présentation de la conception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 6\n",
    "### Hyperparamètres des modèles choisis dans la conception"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrice des résultats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 7 \n",
    "### Formulation des recommandations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
