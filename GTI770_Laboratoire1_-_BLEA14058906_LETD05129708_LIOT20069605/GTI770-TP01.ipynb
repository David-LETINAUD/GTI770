{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Laboratoire 1 : Extraction de primitives\n",
    "#### Département du génie logiciel et des technologies de l’information\n",
    "\n",
    "| Étudiants             | NOMS - CODE PERMANENT                                   |\n",
    "|-----------------------|---------------------------------------------------------|\n",
    "| Cours                 | GTI770 - Systèmes intelligents et apprentissage machine |\n",
    "| Session               | SAISON ANNÉE                                            |\n",
    "| Groupe                | X                                                       |\n",
    "| Numéro du laboratoire | X                                                       |\n",
    "| Professeur            | Prof. NOM                                               |\n",
    "| Chargé de laboratoire | NOM                                                     |\n",
    "| Date                  | DATE                                                    |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7333333333333333\n"
     ]
    }
   ],
   "source": [
    "#! /usr/bin/env python3 \n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "from skimage import io\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifie\n",
    "import sklearn.metrics as metrics\n",
    "\n",
    "import csv\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from color import center_color,crop_center\n",
    "from fourier_transform import fourier_transform\n",
    "from binaryPattern import binaryPatterns\n",
    "\n",
    "########################################   Initialisations   ########################################\n",
    "\n",
    "image_path = \"C:/Users/David/Desktop/GTI770/data/data/images/\"\n",
    "dataset_path = \"C:/Users/David/Desktop/GTI770/data/data/csv/galaxy/galaxy_label_data_set.csv\"\n",
    "\n",
    "# Nombre d'images total du dataset (training + testing)\n",
    "nb_img = 50\n",
    "# Pourcentage de données utilisées pour l'entrainement\n",
    "ratio_train = 0.7\n",
    "# Taille de rognage de l'image\n",
    "crop_size = 180\n",
    "\n",
    "X = [] # Contient les features de l'image\n",
    "Y = [] # Contient les classes associées aux images \n",
    "\n",
    "feature_cols = ['color', 'fft','binary pattern']\n",
    "# Paramètres de chaque features\n",
    "fft_threshold = 140\n",
    "color_center_size = 18\n",
    "bp_calibration = [100,50]\n",
    "\n",
    "def FeaturesProcess(img,cs_color,th_fft,nr_binaryPattern):\n",
    "    \"\"\"\n",
    "    Fonction qui permet le calcul de chaque features d'img\n",
    "    \n",
    "    input :\n",
    "        img (ndarray) : image quelconque\n",
    "        cs_color (int) : taille du centre de l'image à prendre en compte pour calculer la moyenne du niveau de gris\n",
    "        th_fft (int) : seuil à partir duquel on prend en compte les fréquences (strictement positif)\n",
    "        nr_binaryPattern ([int,int]) : \n",
    "                    nr_binaryPattern[0] : nombre de points à prendre en compte sur le périmètre du cercle\n",
    "                    nr_binaryPattern[1] : taille du rayon du cercle\n",
    "    output : \n",
    "        (list) retourne la liste des features calculées\n",
    "    \n",
    "    \"\"\"\n",
    "    Features = []\n",
    "    \n",
    "    # plt.imshow(img)\n",
    "    # plt.show()\n",
    "\n",
    "    # Calculs des Features\n",
    "    f_c = center_color(img,cs_color)\n",
    "    f_fft = fourier_transform(img,th_fft)\n",
    "    f_bp = binaryPatterns(img,nr_binaryPattern[0],nr_binaryPattern[1])  \n",
    "\n",
    "    Features.append(f_c)   \n",
    "    Features.append(f_fft)\n",
    "    Features.append(f_bp)\n",
    "\n",
    "    # Retourne les features calculés\n",
    "    return Features    \n",
    "\n",
    "\n",
    "########################################   Lecture   ########################################\n",
    "# Lecture du fichier CSV\n",
    "with open(dataset_path) as f:\n",
    "    f_csv = csv.reader(f)\n",
    "    next(f_csv) # On passe la 1ere ligne d'entête\n",
    "    \n",
    "    # Lecture ligne par ligne\n",
    "    for ligne,i in zip(f_csv,range(nb_img)):\n",
    "        \n",
    "        # Lecture et rognage de l'image\n",
    "        image = crop_center(io.imread( image_path + ligne[0] + \".jpg\" ),crop_size,crop_size)\n",
    "        # Calcul des features et stockage dans X\n",
    "        X.append( FeaturesProcess(image, color_center_size, fft_threshold, bp_calibration) )\n",
    "        # Sauvegarde de la classe correspondante dans Y\n",
    "        Y.append(1 * (ligne[1]==\"smooth\"))  # smooth :1 et spiral : 0\n",
    "       \n",
    "\n",
    "########################################    Entrainement   ########################################\n",
    "# Diviser l'ensemble de données en un ensemble d'apprentissage et un ensemble de test\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=ratio_train, random_state=1) # 70% training and 30% test\n",
    "\n",
    "# Création d'un arbre de décision \n",
    "clf = tree.DecisionTreeClassifier()\n",
    "\n",
    "# Construit les décision de l'arbre de classification\n",
    "clf = clf.fit(X_train,Y_train)\n",
    "tree.plot_tree(clf) \n",
    "\n",
    "# Prévoir la réponse pour l'ensemble de données de test\n",
    "Y_pred = clf.predict(X_test)\n",
    "\n",
    "# Précision du modèle, à quelle fréquence le classificateur est-il correct ?\n",
    "print(\"Accuracy:\",metrics.accuracy_score(Y_test, Y_pred)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1 - Introduction et revue de la littérature\n",
    "\n",
    "Dans le cadre de notre laboratoire, notre équipe avait pour objectif de créer une analyse et classification d’une série d’image de galaxie dans le but de séparer les résultats en deux types : smooth et spiral. Ce problème as déjà été résolu et ce, de différentes manières. Nous avons donc, dans un premier temps, étudié les différentes méthodes de résolution. Ensuite, nous nous sommes intéressés aux features permettant de différencier les galaxies. Après avoir codé trois features, nous avons ensuite construit des graphiques et un arbre de décision afin de tester l’efficacité de notre algorithme.\n",
    "\n",
    "Il existe différentes techniques de classification des galaxies. Nous avons parcouru l’ensemble des articles mis à notre disposition, deux d’entre eux ont retenu notre attention. Ces deux articles proposent différentes solutions et feature pour résoudre le Galaxy zoo project [1,2]. Les difficultés proposées par ce challenge sont multiples et s’articulent notamment autour du traitement de l’image. En effet, les images présentent généralement du bruit et d’autres étoiles autour de la galaxie à étudier. Qui plus est, l’angle de vue de la photo prise par les satellites peut varier en fonction des galaxies. Par ailleurs, la qualité de l’image peut aussi avoir une influence sur la distinction des bras d’une galaxie qui fait une transition vers le type spiral. Afin de contourner ces problèmes, l'ensemble des articles étudiés proposent de redimensionner les images dans un premier temps afin de concentrer les traitements sur le centre des images. En effet, c’est au centre que se trouvent les informations essentielles à la discrimination des galaxies. Par ailleurs, les auteurs de l’article [3] proposent également de faire un traitement des images afin de limiter le bruit présent sur les images par une détection de contours. En suivant la même démarche, les auteurs de l’article [2] proposent d’utiliser un algorithme qui supprime le background de l’image afin d’avoir une classification de meilleure qualité. Nous pouvons également appliquer une rotation des images de galaxie afin qu’elles aient toutes leur axe principal vertical [2]. Le challenge de classification des galaxies soulève un grand nombre de problématiques auxquelles il faut faire face notamment autour du traitement préliminaire des données.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 2\n",
    "Nous devions ensuite choisir les trois features à utiliser pour différencier les galaxies. Nous nous sommes intéressés au features qui nécessite seulement du traitement simple sur les images. En effet, nous n’avons pas encore toutes les clés pour utiliser les réseaux de neurones ou encore les détections de contours. Pour cela, nous nous sommes donc appuyés sur l’étude de l’article [1]. Les auteurs présentent les différents résultats et taux d’erreurs obtenus lors de leurs expériences. Nous avons donc par la suite choisi les algorithmes présentant le meilleur taux de validation : Center Color, Galaxy Binary patern et Fourier transform.\n",
    "\n",
    "L’algorithme “center color” a pour objectif de récupérer le niveau de gris du centre de l’image. En effet, cette caractéristique permet de bien discriminer chacune des deux classes puisque le centre des galaxies de la classe “smooth” a tendance à être plus foncé que celui des galaxies de la classe “spiral”. L’algorithme que nous avons développé qui s’appuie sur la transformée de Fourier de l’image permet de calculer le nombre de fréquences spatiales dans l’image. En effet, une galaxie spiral présentera plus de fréquences spatiales qu’une galaxie smooth au vu des bras d’une spirale. Pour déterminer les meilleurs seuils possible, nous avons utilisé une méthode qui permet de choisir la valeur maximisant le taux d’accuracy.\n",
    "\n",
    "L'algorithme qui s'appuie sur le Local binary paterne fonctionne comme suit. Après avoir transformé l’image en nuance de gris, on désigne un point central ainsi que son rayon, ce qui créer une zone de recherche circulaire. Nous comparons ce point aux autres pixels qui se situent dans la zone sélectionnée. Si la valeur du pixel comparé est supérieure à celle du pixel central, il prend la valeur de 1 sinon de 0. On fait par la suite le total des pixels de la zone pour redéfinir l’image en noir et blanc.Ceci nous donne une image codée selon sa texture. Comme le type de donnée n’est pas utilisable dans leur forme primaire, nous faisons l'entropie de la matrice fournie dans le but de nous fournir l’état de chaque image. Une image qui dispose de moins de zones noires comme une smooth retournera une valeur d'entropie plus basse qu’une galaxie de type ‘’spiral’’. Contrairement aux deux autres algorithmes, l’efficacité de celui-ci est directement liée à plusieurs paramètres. Le nombre de points à comparer, le rayon choisi et la taille de l’image. Une image qui a une résolution trop petite ne fournirait pas assez de données pour permettre de trouver une différence notoire à son entropie, il en va de même avec une image trop grande ou beaucoup de zones noires ne fourniraient pas un bon résultat. Si nous prenons un rayon trop grand, coupler avec un nombre de points à calculer élevé, on augmente le temps de calcule, mais si on prend une zone et un nombre de points trop petit on obtient des valeurs similaires et donc non discriminatoires. Par manque de temps et de connaissance, nous n’avons pas pris le risque de chercher les valeurs optimales par algorithme comme pour nos deux autres features. Cela dit elle reste efficace avec nos paramètres actuels.\n",
    "\n",
    "Notre dernier feature, ‘’Center color’’, est probablement la plus efficace. Celle-ci calcule la valeur moyenne des couleurs RGB du centre d’une image de taille X et Y. Relativement simple a comprendre elle permet de différencier les centres de chaque galaxie selon leur couleur. Les valeurs retournées nous donnent une bonne discrimination . Par ailleurs dans le but d'améliorer nos résultats, nous avons implémenté un algorithme capable de tester les valeurs entre 1 et 50 ( taille de l’image) pour définir le résultat le plus discriminant, celui-ci étant une image de 18x18.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 5\n",
    "La feature qui aurait pu être utilisée afin d’améliorer nos résultats utilise l’algorithme principal component analysis (PCA). En effet, ceci permettrait de faire la détection de contours et ainsi améliorer la catégorisation des galaxies. En effet, comme son nom l’indique, les galaxies de type smooth ont des contours plus arrondis et homogènes contrairement aux galaxies spirales qui ont des bras et donc des contours plus abrupts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "Ainsi, en nous basant sur les features Center color, Local binary paterne et Fourier transform, nous obtenons un taux d’accuracy de 65%. Les résultats sont globalement satisfaisants pour une première approche du problème de classification de galaxie. Afin d’améliorer les performances de catégorisation, nous pourrions ajouter de nouvelles features afin d’augmenter le nombre de dimensions. Néanmoins, il faut faire attention à ne pas tomber dans un problème où les dimensions sont trop importantes, où les informations se recoupent.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bibliographie\n",
    "Biblio [0] : Nom, P. ; Nom2, P2. : titre, ouvrage, date, page.\n",
    "[1] : Chou, F.C. : Galaxy Zoo Challenge: Classify Galaxy Morphologies from Images, March 19, 2014.\n",
    "[2] : Gauthier, A.; Jain, A.; Noordeh, E. : Galaxy Morphology Classification, December 16, 2016).\n",
    "[3] : Abd Elfattah, M.; EI-Bendary, N.; Abu Elsoud, M.A.; Hassanien, A.E.; Tolba, M.P. : An Intelligent Approach for Galaxies Images Classification, 13th International Conference on Hybrid Intelligent Systems (HIS), 2013.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
